
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>mkvdup: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_batch.go (70.6%)</option>
				
				<option value="file1">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_create.go (1.5%)</option>
				
				<option value="file2">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_debug.go (0.0%)</option>
				
				<option value="file3">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_diag.go (29.2%)</option>
				
				<option value="file4">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_helpers.go (75.0%)</option>
				
				<option value="file5">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_info.go (62.9%)</option>
				
				<option value="file6">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_mount.go (14.6%)</option>
				
				<option value="file7">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_probe.go (20.3%)</option>
				
				<option value="file8">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_stats.go (85.9%)</option>
				
				<option value="file9">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_validate.go (84.8%)</option>
				
				<option value="file10">github.com/stuckj/mkvdup/cmd/mkvdup/cmd_verify.go (30.2%)</option>
				
				<option value="file11">github.com/stuckj/mkvdup/cmd/mkvdup/help.go (82.9%)</option>
				
				<option value="file12">github.com/stuckj/mkvdup/cmd/mkvdup/main.go (6.0%)</option>
				
				<option value="file13">github.com/stuckj/mkvdup/cmd/mkvdup/profile.go (33.3%)</option>
				
				<option value="file14">github.com/stuckj/mkvdup/cmd/mkvdup/progress.go (78.9%)</option>
				
				<option value="file15">github.com/stuckj/mkvdup/internal/daemon/daemon.go (37.3%)</option>
				
				<option value="file16">github.com/stuckj/mkvdup/internal/dedup/config.go (91.5%)</option>
				
				<option value="file17">github.com/stuckj/mkvdup/internal/dedup/format.go (85.7%)</option>
				
				<option value="file18">github.com/stuckj/mkvdup/internal/dedup/rangemap.go (87.2%)</option>
				
				<option value="file19">github.com/stuckj/mkvdup/internal/dedup/reader.go (75.6%)</option>
				
				<option value="file20">github.com/stuckj/mkvdup/internal/dedup/stridedcopy.go (100.0%)</option>
				
				<option value="file21">github.com/stuckj/mkvdup/internal/dedup/writer.go (74.7%)</option>
				
				<option value="file22">github.com/stuckj/mkvdup/internal/fuse/adapters.go (50.0%)</option>
				
				<option value="file23">github.com/stuckj/mkvdup/internal/fuse/fs.go (100.0%)</option>
				
				<option value="file24">github.com/stuckj/mkvdup/internal/fuse/fs_dir.go (84.7%)</option>
				
				<option value="file25">github.com/stuckj/mkvdup/internal/fuse/fs_init.go (74.5%)</option>
				
				<option value="file26">github.com/stuckj/mkvdup/internal/fuse/fs_node.go (83.1%)</option>
				
				<option value="file27">github.com/stuckj/mkvdup/internal/fuse/fs_root.go (73.0%)</option>
				
				<option value="file28">github.com/stuckj/mkvdup/internal/fuse/notifier.go (92.1%)</option>
				
				<option value="file29">github.com/stuckj/mkvdup/internal/fuse/permissions.go (79.2%)</option>
				
				<option value="file30">github.com/stuckj/mkvdup/internal/fuse/tree.go (96.9%)</option>
				
				<option value="file31">github.com/stuckj/mkvdup/internal/fuse/watcher.go (57.1%)</option>
				
				<option value="file32">github.com/stuckj/mkvdup/internal/fuse/watcher_linux.go (85.7%)</option>
				
				<option value="file33">github.com/stuckj/mkvdup/internal/matcher/matcher.go (74.2%)</option>
				
				<option value="file34">github.com/stuckj/mkvdup/internal/matcher/matcher_expand.go (45.1%)</option>
				
				<option value="file35">github.com/stuckj/mkvdup/internal/matcher/matcher_parallel.go (82.8%)</option>
				
				<option value="file36">github.com/stuckj/mkvdup/internal/mkv/ebml.go (89.4%)</option>
				
				<option value="file37">github.com/stuckj/mkvdup/internal/mkv/parser.go (59.2%)</option>
				
				<option value="file38">github.com/stuckj/mkvdup/internal/mmap/mmap.go (93.0%)</option>
				
				<option value="file39">github.com/stuckj/mkvdup/internal/mmap/pread.go (77.5%)</option>
				
				<option value="file40">github.com/stuckj/mkvdup/internal/source/audio.go (82.8%)</option>
				
				<option value="file41">github.com/stuckj/mkvdup/internal/source/codec.go (68.4%)</option>
				
				<option value="file42">github.com/stuckj/mkvdup/internal/source/esranges.go (83.5%)</option>
				
				<option value="file43">github.com/stuckj/mkvdup/internal/source/indexer.go (56.4%)</option>
				
				<option value="file44">github.com/stuckj/mkvdup/internal/source/iso.go (77.1%)</option>
				
				<option value="file45">github.com/stuckj/mkvdup/internal/source/iso_adapter.go (42.5%)</option>
				
				<option value="file46">github.com/stuckj/mkvdup/internal/source/mpegps.go (81.9%)</option>
				
				<option value="file47">github.com/stuckj/mkvdup/internal/source/mpegps_codecs.go (83.1%)</option>
				
				<option value="file48">github.com/stuckj/mkvdup/internal/source/mpegts.go (74.7%)</option>
				
				<option value="file49">github.com/stuckj/mkvdup/internal/source/mpegts_codecs.go (71.1%)</option>
				
				<option value="file50">github.com/stuckj/mkvdup/internal/source/multi_region.go (77.2%)</option>
				
				<option value="file51">github.com/stuckj/mkvdup/internal/source/source.go (79.2%)</option>
				
				<option value="file52">github.com/stuckj/mkvdup/internal/source/subtitle.go (100.0%)</option>
				
				<option value="file53">github.com/stuckj/mkvdup/internal/source/udf.go (62.1%)</option>
				
				<option value="file54">github.com/stuckj/mkvdup/internal/source/video.go (94.9%)</option>
				
				<option value="file55">github.com/stuckj/mkvdup/testdata/testdata.go (45.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">no coverage</span>
				<span class="cov1">low coverage</span>
				<span class="cov2">*</span>
				<span class="cov3">*</span>
				<span class="cov4">*</span>
				<span class="cov5">*</span>
				<span class="cov6">*</span>
				<span class="cov7">*</span>
				<span class="cov8">*</span>
				<span class="cov9">*</span>
				<span class="cov10">high coverage</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package main

import (
        "fmt"
        "os"
        "path/filepath"
        "strings"
        "time"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

// sourceGroup represents a set of files sharing the same source directory.
type sourceGroup struct {
        sourceDir string
        indices   []int // indices into the manifest Files slice
}

// groupBySource groups batch manifest files by their SourceDir.
// Groups are returned in first-seen order, and file indices within each group
// preserve their original manifest order.
func groupBySource(files []dedup.BatchManifestFile) []sourceGroup <span class="cov7" title="10">{
        var groups []sourceGroup
        seen := map[string]int{} // sourceDir -&gt; index in groups
        for i, f := range files </span><span class="cov9" title="23">{
                if gi, ok := seen[f.SourceDir]; ok </span><span class="cov6" title="7">{
                        groups[gi].indices = append(groups[gi].indices, i)
                }</span> else<span class="cov8" title="16"> {
                        seen[f.SourceDir] = len(groups)
                        groups = append(groups, sourceGroup{sourceDir: f.SourceDir, indices: []int{i}})
                }</span>
        }
        <span class="cov7" title="10">return groups</span>
}

// codecMismatchAction controls how reportCodecMismatches handles a mismatch.
type codecMismatchAction int

const (
        codecMismatchPrompt   codecMismatchAction = iota // interactive: prompt user
        codecMismatchContinue                            // non-interactive: warn and continue
        codecMismatchSkip                                // skip: warn and signal skip
)

// reportCodecMismatches prints codec mismatch warnings and handles the response
// based on the action: prompt the user, continue without prompting (still logging to stderr),
// or signal a skip. Returns an error if the user declines to continue (prompt mode only).
func reportCodecMismatches(mismatches []source.CodecMismatch, action codecMismatchAction) error <span class="cov3" title="3">{
        if len(mismatches) == 0 </span><span class="cov1" title="1">{
                return nil
        }</span>

        // Print warning to stderr (always visible, even in quiet mode)
        <span class="cov2" title="2">fmt.Fprintln(os.Stderr)
        fmt.Fprintln(os.Stderr, "  WARNING: Codec mismatch detected")
        for _, m := range mismatches </span><span class="cov2" title="2">{
                mkvName := source.CodecTypeName(m.MKVCodecType)
                var sourceNames []string
                for _, sc := range m.SourceCodecs </span><span class="cov2" title="2">{
                        sourceNames = append(sourceNames, source.CodecTypeName(sc))
                }</span>
                <span class="cov2" title="2">fmt.Fprintf(os.Stderr, "    MKV %s:    %s (%s)\n", m.TrackType, mkvName, m.MKVCodecID)
                fmt.Fprintf(os.Stderr, "    Source %s: %s\n", m.TrackType, strings.Join(sourceNames, ", "))</span>
        }
        <span class="cov2" title="2">fmt.Fprintln(os.Stderr)
        fmt.Fprintln(os.Stderr, "  Deduplication may produce poor results if the MKV was transcoded.")

        switch action </span>{
        case codecMismatchSkip:<span class="cov1" title="1">
                fmt.Fprintln(os.Stderr, "  Skipping (--skip-codec-mismatch)...")
                fmt.Fprintln(os.Stderr)
                return nil</span>
        case codecMismatchContinue:<span class="cov1" title="1">
                fmt.Fprintln(os.Stderr, "  Continuing (non-interactive mode)...")
                fmt.Fprintln(os.Stderr)
                return nil</span>
        default:<span class="cov0" title="0">
                // Interactive prompt — auto-continue if stdin is not a terminal
                if !isTerminal() </span><span class="cov0" title="0">{
                        fmt.Fprintln(os.Stderr, "  Continuing (non-interactive mode)...")
                        fmt.Fprintln(os.Stderr)
                        return nil
                }</span>
                <span class="cov0" title="0">fmt.Print("\n  Continue anyway? [y/N]: ")
                var response string
                fmt.Scanln(&amp;response)
                response = strings.TrimSpace(strings.ToLower(response))
                if response != "y" &amp;&amp; response != "yes" </span><span class="cov0" title="0">{
                        return fmt.Errorf("aborted due to codec mismatch")
                }</span>
                <span class="cov0" title="0">fmt.Println()
                return nil</span>
        }
}

// createBatch processes multiple MKVs from a batch manifest.
// Files are grouped by source directory so each source is indexed once.
// If skipCodecMismatch is true, MKVs with codec mismatches are skipped instead of processed.
func createBatch(manifestPath string, warnThreshold float64, skipCodecMismatch bool) error <span class="cov6" title="9">{
        totalStart := time.Now()

        manifest, err := dedup.ReadBatchManifest(manifestPath)
        if err != nil </span><span class="cov3" title="3">{
                return err
        }</span>

        <span class="cov5" title="6">groups := groupBySource(manifest.Files)
        multiSource := len(groups) &gt; 1

        if multiSource </span><span class="cov3" title="3">{
                printInfo("Batch create: %d %s from %d %s\n\n",
                        len(manifest.Files), plural(len(manifest.Files), "file", "files"),
                        len(groups), plural(len(groups), "source", "sources"))
        }</span> else<span class="cov3" title="3"> {
                printInfo("Batch create: %d %s from %s\n\n",
                        len(manifest.Files), plural(len(manifest.Files), "file", "files"), groups[0].sourceDir)
        }</span>

        <span class="cov5" title="6">results := make([]*createResult, len(manifest.Files))
        skipReasons := make([]string, len(manifest.Files))
        var totalIndexDuration time.Duration
        processed := 0

        for gi, g := range groups </span><span class="cov6" title="9">{
                if multiSource </span><span class="cov5" title="6">{
                        if gi &gt; 0 </span><span class="cov3" title="3">{
                                printInfoln()
                        }</span>
                        <span class="cov5" title="6">fileWord := "files"
                        if len(g.indices) == 1 </span><span class="cov5" title="6">{
                                fileWord = "file"
                        }</span>
                        <span class="cov5" title="6">printInfo("--- Source %d/%d: %s (%d %s) ---\n", gi+1, len(groups), g.sourceDir, len(g.indices), fileWord)</span>
                }

                // Pre-check: skip files whose output already exists (resuming interrupted batch)
                <span class="cov6" title="9">for _, fi := range g.indices </span><span class="cov7" title="12">{
                        f := manifest.Files[fi]
                        if _, err := os.Stat(f.Output); err == nil </span><span class="cov3" title="3">{
                                skipReasons[fi] = "output exists"
                        }</span>
                }

                // Pre-check: detect source codecs and warn about incompatible MKVs
                // before the expensive indexing step.
                <span class="cov6" title="9">sourceCodecs, codecErr := source.DetectSourceCodecsFromDir(g.sourceDir)
                if codecErr != nil </span><span class="cov6" title="9">{
                        if verbose </span><span class="cov0" title="0">{
                                printInfo("Note: could not detect source codecs for %s: %v\n", g.sourceDir, codecErr)
                        }</span>
                        <span class="cov6" title="9">printInfoln()</span>
                } else<span class="cov0" title="0"> {
                        for _, fi := range g.indices </span><span class="cov0" title="0">{
                                if skipReasons[fi] != "" </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov0" title="0">f := manifest.Files[fi]
                                codecParser, err := mkv.NewParser(f.MKV)
                                if err != nil </span><span class="cov0" title="0">{
                                        if verbose </span><span class="cov0" title="0">{
                                                printInfo("Note: skipping codec pre-check for %s: %v\n", filepath.Base(f.MKV), err)
                                        }</span>
                                        <span class="cov0" title="0">continue</span>
                                }
                                <span class="cov0" title="0">if err := codecParser.ParseTracksOnly(); err != nil </span><span class="cov0" title="0">{
                                        codecParser.Close()
                                        if verbose </span><span class="cov0" title="0">{
                                                printInfo("Note: skipping codec pre-check for %s: %v\n", filepath.Base(f.MKV), err)
                                        }</span>
                                        <span class="cov0" title="0">continue</span>
                                }
                                <span class="cov0" title="0">mismatches := source.CheckCodecCompatibility(codecParser.Tracks(), sourceCodecs)
                                codecParser.Close()
                                if skipCodecMismatch &amp;&amp; len(mismatches) &gt; 0 </span><span class="cov0" title="0">{
                                        reportCodecMismatches(mismatches, codecMismatchSkip)
                                        skipReasons[fi] = "codec mismatch"
                                        continue</span>
                                }
                                <span class="cov0" title="0">if err := reportCodecMismatches(mismatches, codecMismatchContinue); err != nil </span><span class="cov0" title="0">{
                                        return err
                                }</span>
                        }
                        <span class="cov0" title="0">printInfoln()</span>
                }

                // Check if all files in this group are already skipped — skip indexing entirely
                <span class="cov6" title="9">allSkipped := true
                for _, fi := range g.indices </span><span class="cov7" title="11">{
                        if skipReasons[fi] == "" </span><span class="cov6" title="8">{
                                allSkipped = false
                                break</span>
                        }
                }
                <span class="cov6" title="9">if allSkipped </span><span class="cov1" title="1">{
                        for _, fi := range g.indices </span><span class="cov2" title="2">{
                                processed++
                                f := manifest.Files[fi]
                                printInfo("\n[%d/%d] %s\n", processed, len(manifest.Files), filepath.Base(f.MKV))
                                results[fi] = newSkipResult(f.MKV, f.Output, skipReasons[fi])
                                printSkipStatus(results[fi])
                        }</span>
                        <span class="cov1" title="1">continue</span>
                }

                // Index this source directory
                <span class="cov6" title="8">indexLabel := "Indexing source directory..."
                if multiSource </span><span class="cov5" title="6">{
                        indexLabel = fmt.Sprintf("Indexing source %d/%d...", gi+1, len(groups))
                }</span>
                <span class="cov6" title="8">indexStart := time.Now()
                indexer, index, err := buildSourceIndex(g.sourceDir, indexLabel)
                totalIndexDuration += time.Since(indexStart)
                if err != nil </span><span class="cov6" title="8">{
                        fmt.Fprintf(os.Stderr, "  ERROR indexing %s: %v\n", g.sourceDir, err)
                        // Mark non-skipped files in this group as failed
                        for _, fi := range g.indices </span><span class="cov7" title="10">{
                                processed++
                                f := manifest.Files[fi]
                                printInfo("\n[%d/%d] %s\n", processed, len(manifest.Files), filepath.Base(f.MKV))
                                if skipReasons[fi] != "" </span><span class="cov1" title="1">{
                                        results[fi] = newSkipResult(f.MKV, f.Output, skipReasons[fi])
                                        printSkipStatus(results[fi])
                                }</span> else<span class="cov6" title="9"> {
                                        results[fi] = &amp;createResult{MkvPath: f.MKV, Err: fmt.Errorf("index %s: %w", g.sourceDir, err)}
                                }</span>
                        }
                        <span class="cov6" title="8">if gi &lt; len(groups)-1 </span><span class="cov3" title="3">{
                                fmt.Fprintln(os.Stderr, "  Continuing with remaining sources...")
                        }</span>
                        <span class="cov6" title="8">continue</span>
                }

                // Process files in this group
                <span class="cov0" title="0">for _, fi := range g.indices </span><span class="cov0" title="0">{
                        processed++
                        f := manifest.Files[fi]
                        printInfo("\n[%d/%d] %s\n", processed, len(manifest.Files), filepath.Base(f.MKV))
                        if skipReasons[fi] != "" </span><span class="cov0" title="0">{
                                results[fi] = newSkipResult(f.MKV, f.Output, skipReasons[fi])
                                printSkipStatus(results[fi])
                                continue</span>
                        }
                        <span class="cov0" title="0">results[fi] = createDedupWithIndex(f.MKV, f.SourceDir, f.Output, f.Name, indexer, index, 1, 4, true, skipCodecMismatch)
                        r := results[fi]
                        if r.Skipped </span><span class="cov0" title="0">{
                                printSkipStatus(r)
                        }</span> else<span class="cov0" title="0"> if r.Err != nil </span><span class="cov0" title="0">{
                                fmt.Fprintf(os.Stderr, "  ERROR: %v\n", r.Err)
                                if processed &lt; len(manifest.Files) </span><span class="cov0" title="0">{
                                        fmt.Fprintln(os.Stderr, "  Continuing with remaining files...")
                                }</span>
                        } else<span class="cov0" title="0"> {
                                printInfo("  MKV: %s bytes | Dedup: %s bytes | Savings: %.1f%% | Time: %v\n",
                                        formatInt(r.MkvSize), formatInt(r.DedupSize), r.Savings, r.Duration.Round(time.Second))
                        }</span>
                }
                <span class="cov0" title="0">index.Close()</span>
        }

        // Print summary
        <span class="cov5" title="6">printBatchSummary(results, totalIndexDuration, totalStart, warnThreshold)

        // Return error if any file failed
        for _, r := range results </span><span class="cov6" title="8">{
                if r.Err != nil </span><span class="cov5" title="5">{
                        return fmt.Errorf("batch create completed with errors")
                }</span>
        }
        <span class="cov1" title="1">return nil</span>
}

// newSkipResult creates a createResult for a skipped file. When the skip reason
// is "output exists", it populates stats from the existing MKV and dedup files.
func newSkipResult(mkvPath, outputPath, reason string) *createResult <span class="cov3" title="3">{
        r := &amp;createResult{MkvPath: mkvPath, Skipped: true, SkipReason: reason}
        if reason == "output exists" </span><span class="cov3" title="3">{
                r.OutputPath = outputPath
                if mkvStat, err := os.Stat(mkvPath); err == nil </span><span class="cov0" title="0">{
                        r.MkvSize = mkvStat.Size()
                }</span>
                <span class="cov3" title="3">if dedupStat, err := os.Stat(outputPath); err == nil </span><span class="cov3" title="3">{
                        r.DedupSize = dedupStat.Size()
                        if r.MkvSize &gt; 0 </span><span class="cov0" title="0">{
                                r.Savings = float64(r.MkvSize-r.DedupSize) / float64(r.MkvSize) * 100
                        }</span>
                }
        }
        <span class="cov3" title="3">return r</span>
}

// printSkipStatus prints the per-file skip message during batch processing.
// For "output exists" skips with populated stats, it shows file sizes and savings.
func printSkipStatus(r *createResult) <span class="cov3" title="3">{
        if r.SkipReason == "output exists" &amp;&amp; r.MkvSize &gt; 0 </span><span class="cov0" title="0">{
                printInfo("  Skipping (%s): %s bytes | Dedup: %s bytes | Savings: %.1f%%\n",
                        r.SkipReason, formatInt(r.MkvSize), formatInt(r.DedupSize), r.Savings)
        }</span> else<span class="cov3" title="3"> {
                printInfo("  Skipping (%s)\n", r.SkipReason)
        }</span>
}

// printBatchSummary prints the aggregate results of a batch create operation.
func printBatchSummary(results []*createResult, indexDuration time.Duration, totalStart time.Time, warnThreshold float64) <span class="cov8" title="14">{
        printInfoln()
        printInfoln("=== Batch Results ===")
        printInfo("Total time: %v (indexing: %v)\n\n", time.Since(totalStart), indexDuration)

        succeeded := 0
        cached := 0
        skipped := 0
        var lowSavings []string
        for _, r := range results </span><span class="cov10" title="28">{
                base := filepath.Base(r.MkvPath)
                if r.Skipped &amp;&amp; r.SkipReason == "output exists" </span><span class="cov4" title="4">{
                        // Already-processed files: show as OK with stats
                        cached++
                        if r.OutputPath != "" </span><span class="cov3" title="3">{
                                printInfo("  OK    %s -&gt; %s (%.1f%% savings) [cached]\n", base, filepath.Base(r.OutputPath), r.Savings)
                        }</span> else<span class="cov1" title="1"> {
                                printInfo("  OK    %s [cached]\n", base)
                        }</span>
                        <span class="cov4" title="4">if r.Savings &lt; warnThreshold &amp;&amp; r.MkvSize &gt; 0 </span><span class="cov0" title="0">{
                                lowSavings = append(lowSavings, fmt.Sprintf("  %s: %.1f%% savings", base, r.Savings))
                        }</span>
                } else<span class="cov9" title="24"> if r.Skipped </span><span class="cov2" title="2">{
                        printInfo("  SKIP  %s: %s\n", base, r.SkipReason)
                        skipped++
                }</span> else<span class="cov9" title="22"> if r.Err != nil </span><span class="cov7" title="11">{
                        fmt.Fprintf(os.Stderr, "  FAIL  %s: %v\n", base, r.Err)
                }</span> else<span class="cov7" title="11"> {
                        printInfo("  OK    %s -&gt; %s (%.1f%% savings)\n", base, filepath.Base(r.OutputPath), r.Savings)
                        if r.Savings &lt; warnThreshold </span><span class="cov3" title="3">{
                                lowSavings = append(lowSavings, fmt.Sprintf("  %s: %.1f%% savings", base, r.Savings))
                        }</span>
                }
                <span class="cov10" title="28">if !r.Skipped &amp;&amp; r.Err == nil || (r.Skipped &amp;&amp; r.SkipReason == "output exists") </span><span class="cov8" title="15">{
                        succeeded++
                }</span>
        }
        <span class="cov8" title="14">switch </span>{
        case cached &gt; 0 &amp;&amp; skipped &gt; 0:<span class="cov1" title="1">
                printInfo("\nSucceeded: %d/%d (%d cached, %d skipped)\n", succeeded, len(results), cached, skipped)</span>
        case cached &gt; 0:<span class="cov2" title="2">
                printInfo("\nSucceeded: %d/%d (%d cached)\n", succeeded, len(results), cached)</span>
        case skipped &gt; 0:<span class="cov1" title="1">
                printInfo("\nSucceeded: %d/%d (%d skipped)\n", succeeded, len(results), skipped)</span>
        default:<span class="cov7" title="10">
                printInfo("\nSucceeded: %d/%d\n", succeeded, len(results))</span>
        }

        <span class="cov8" title="14">if !quiet &amp;&amp; len(lowSavings) &gt; 0 </span><span class="cov2" title="2">{
                printInfo("\nWARNING: %d %s with space savings below %.0f%%:\n", len(lowSavings), plural(len(lowSavings), "file", "files"), warnThreshold)
                for _, s := range lowSavings </span><span class="cov2" title="2">{
                        printInfoln(s)
                }</span>
                <span class="cov2" title="2">printInfoln("  This may indicate wrong source or transcoded MKV.")</span>
        }
}
</pre>
		
		<pre class="file" id="file1" style="display: none">package main

import (
        "fmt"
        "log"
        "os"
        "path/filepath"
        "strings"
        "time"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

// parseMKVWithProgress parses an MKV file with progress reporting.
// The phasePrefix is shown during parsing (e.g., "Phase 3/6: Parsing MKV file...").
// Returns the parser (caller must Close it) and an error if any.
func parseMKVWithProgress(mkvPath, phasePrefix string) (*mkv.Parser, time.Duration, error) <span class="cov0" title="0">{
        parser, err := mkv.NewParser(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, 0, fmt.Errorf("create parser: %w", err)
        }</span>

        <span class="cov0" title="0">bar := newProgressBar(phasePrefix, parser.Size(), "bytes")
        parseStart := time.Now()
        if err := parser.Parse(func(processed, total int64) </span><span class="cov0" title="0">{
                bar.Update(processed)
        }</span>); err != nil <span class="cov0" title="0">{
                bar.Cancel()
                parser.Close()
                return nil, 0, fmt.Errorf("parse MKV: %w", err)
        }</span>
        <span class="cov0" title="0">bar.Finish()
        elapsed := time.Since(parseStart)
        return parser, elapsed, nil</span>
}

// createResult holds per-file statistics from a create operation.
type createResult struct {
        MkvPath        string
        OutputPath     string
        VirtualName    string
        MkvSize        int64
        DedupSize      int64
        MatchedBytes   int64
        UnmatchedBytes int64
        MatchedPackets int
        TotalPackets   int
        IndexEntries   int
        Savings        float64
        Duration       time.Duration
        Err            error
        Skipped        bool   // true when file was skipped (e.g., codec mismatch, output exists)
        SkipReason     string // reason for skipping (shown in summary)
}

// buildSourceIndex indexes a source directory and returns the indexer and index.
// This is the expensive step that should only happen once in batch mode.
// The phasePrefix is shown on the progress bar (e.g., "Phase 2/6: Building source index...").
func buildSourceIndex(sourceDir, phasePrefix string) (*source.Indexer, *source.Index, error) <span class="cov10" title="8">{
        indexer, err := source.NewIndexer(sourceDir, source.DefaultWindowSize)
        if err != nil </span><span class="cov10" title="8">{
                return nil, nil, fmt.Errorf("create indexer: %w", err)
        }</span>
        <span class="cov0" title="0">indexer.SetVerbose(verbose)

        // We don't know total size until Build starts calling back with it,
        // so create bar with 0 and let first Update set the total.
        bar := newProgressBar(phasePrefix, 0, "bytes")
        err = indexer.Build(func(processed, total int64) </span><span class="cov0" title="0">{
                if bar.total == 0 &amp;&amp; total &gt; 0 </span><span class="cov0" title="0">{
                        bar.total = total
                }</span>
                <span class="cov0" title="0">bar.Update(processed)</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                bar.Cancel()
                return nil, nil, fmt.Errorf("build index: %w", err)
        }</span>
        <span class="cov0" title="0">bar.Finish()
        index := indexer.Index()
        printInfo("  Indexed %d hashes\n", len(index.HashToLocations))
        if index.UsesESOffsets </span><span class="cov0" title="0">{
                printInfo("  (Using ES-aware indexing for %v)\n", indexer.SourceType())
        }</span>

        <span class="cov0" title="0">return indexer, index, nil</span>
}

// checkCodecCompatibilityFromDir performs a lightweight codec check using only
// the source directory (no index needed). This runs before the expensive indexing step.
func checkCodecCompatibilityFromDir(tracks []mkv.Track, sourceDir string, nonInteractive bool) error <span class="cov0" title="0">{
        sourceCodecs, err := source.DetectSourceCodecsFromDir(sourceDir)
        if err != nil </span><span class="cov0" title="0">{
                if verbose </span><span class="cov0" title="0">{
                        fmt.Printf("  Note: could not detect source codecs: %v\n", err)
                }</span>
                <span class="cov0" title="0">return nil</span>
        }

        <span class="cov0" title="0">mismatches := source.CheckCodecCompatibility(tracks, sourceCodecs)
        action := codecMismatchPrompt
        if nonInteractive </span><span class="cov0" title="0">{
                action = codecMismatchContinue
        }</span>
        <span class="cov0" title="0">return reportCodecMismatches(mismatches, action)</span>
}

// createDedupWithIndex processes a single MKV using a pre-built source index.
// It handles parsing, matching, writing, and verification.
// phaseStart and phaseTotal control phase numbering (e.g., 3,6 for single create; 1,4 for batch).
// If nonInteractive is true, codec mismatch warnings do not prompt the user.
// If skipCodecMismatch is true, the result is marked as Skipped on codec mismatch instead of continuing.
func createDedupWithIndex(mkvPath, sourceDir, outputPath, virtualName string,
        indexer *source.Indexer, index *source.Index, phaseStart, phaseTotal int, nonInteractive, skipCodecMismatch bool) *createResult <span class="cov0" title="0">{
        start := time.Now()
        result := &amp;createResult{
                MkvPath:     mkvPath,
                OutputPath:  outputPath,
                VirtualName: virtualName,
        }

        phaseLabel := func(offset int, label string) string </span><span class="cov0" title="0">{
                return fmt.Sprintf("Phase %d/%d: %s", phaseStart+offset, phaseTotal, label)
        }</span>

        // Parse MKV
        <span class="cov0" title="0">parser, _, err := parseMKVWithProgress(mkvPath, phaseLabel(0, "Parsing MKV file..."))
        if err != nil </span><span class="cov0" title="0">{
                result.Err = err
                return result
        }</span>
        <span class="cov0" title="0">defer parser.Close()

        // Fallback codec check using the index (in case the pre-indexing directory-based
        // check was skipped, e.g. detection failure or batch mode with undetectable codecs)
        sourceCodecs, codecErr := source.DetectSourceCodecs(index)
        if codecErr == nil </span><span class="cov0" title="0">{
                mismatches := source.CheckCodecCompatibility(parser.Tracks(), sourceCodecs)
                if skipCodecMismatch &amp;&amp; len(mismatches) &gt; 0 </span><span class="cov0" title="0">{
                        reportCodecMismatches(mismatches, codecMismatchSkip)
                        result.Skipped = true
                        result.SkipReason = "codec mismatch"
                        return result
                }</span>
                <span class="cov0" title="0">action := codecMismatchPrompt
                if nonInteractive </span><span class="cov0" title="0">{
                        action = codecMismatchContinue
                }</span>
                <span class="cov0" title="0">if err := reportCodecMismatches(mismatches, action); err != nil </span><span class="cov0" title="0">{
                        result.Err = err
                        return result
                }</span>
        }

        // Calculate MKV checksum
        <span class="cov0" title="0">printInfo("  Calculating MKV checksum...")
        mkvChecksum, err := calculateFileChecksum(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                result.Err = fmt.Errorf("calculate MKV checksum: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">printInfo(" done\n")

        // Match packets
        m, err := matcher.NewMatcher(index)
        if err != nil </span><span class="cov0" title="0">{
                result.Err = fmt.Errorf("create matcher: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">defer m.Close()
        m.SetVerbose(verbose)

        matchBar := newProgressBar(phaseLabel(1, "Matching packets..."), int64(len(parser.Packets())), "packets")
        matchResult, err := m.Match(mkvPath, parser.Packets(), parser.Tracks(), func(processed, total int) </span><span class="cov0" title="0">{
                matchBar.Update(int64(processed))
        }</span>)
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                matchBar.Cancel()
                result.Err = fmt.Errorf("match: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">defer matchResult.Close()
        matchBar.Finish()

        // Write dedup file
        writer, err := dedup.NewWriter(outputPath)
        if err != nil </span><span class="cov0" title="0">{
                result.Err = fmt.Errorf("create dedup writer: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">defer writer.Close()

        writer.SetHeader(parser.Size(), mkvChecksum, indexer.SourceType())
        writer.SetCreatorVersion("mkvdup " + version)
        writer.SetSourceFiles(index.Files)

        // For sources with ES offsets, decide between V3 (convert to raw) and V4 (range maps).
        // V4 stores ES offsets with embedded range maps for ES-to-raw translation at read time.
        // V3 converts ES offsets to raw file offsets at write time (simpler, smaller files).
        // V4 is only used for Blu-ray (M2TS) where the TS packet structure makes V3 conversion
        // impractical. DVDs use V3 since MPEG-PS raw offsets are straightforward.
        var esConverters []source.ESRangeConverter
        if index.UsesESOffsets &amp;&amp; len(index.ESReaders) &gt; 0 </span><span class="cov0" title="0">{
                if indexer.SourceType() == source.TypeBluray </span><span class="cov0" title="0">{
                        // V4: use range maps for Blu-ray (preserves ES offsets in entries)
                        var rangeMaps []dedup.RangeMapData
                        for i, reader := range index.ESReaders </span><span class="cov0" title="0">{
                                if provider, ok := reader.(source.PESRangeProvider); ok </span><span class="cov0" title="0">{
                                        rm := dedup.RangeMapData{
                                                FileIndex:   uint16(i),
                                                VideoRanges: provider.FilteredVideoRanges(),
                                        }
                                        // If this reader provides offset conversion (e.g., ISO adapter),
                                        // set the converter for range map encoding.
                                        if adj, ok := reader.(source.FileOffsetAdjuster); ok </span><span class="cov0" title="0">{
                                                rm.OffsetFunc = adj.FileOffsetConverter()
                                        }</span>
                                        <span class="cov0" title="0">for _, subID := range provider.AudioSubStreams() </span><span class="cov0" title="0">{
                                                rm.AudioStreams = append(rm.AudioStreams, dedup.AudioRangeData{
                                                        SubStreamID: subID,
                                                        Ranges:      provider.FilteredAudioRanges(subID),
                                                })
                                        }</span>
                                        <span class="cov0" title="0">rangeMaps = append(rangeMaps, rm)</span>
                                }
                        }
                        <span class="cov0" title="0">if len(rangeMaps) &gt; 0 </span><span class="cov0" title="0">{
                                writer.SetRangeMaps(rangeMaps)
                        }</span>
                } else<span class="cov0" title="0"> {
                        // V3: convert ES offsets to raw offsets for DVDs
                        esConverters = make([]source.ESRangeConverter, len(index.ESReaders))
                        for i, r := range index.ESReaders </span><span class="cov0" title="0">{
                                if converter, ok := r.(source.ESRangeConverter); ok </span><span class="cov0" title="0">{
                                        esConverters[i] = converter
                                }</span>
                        }
                }
        }

        <span class="cov0" title="0">if err := writer.SetMatchResult(matchResult, esConverters); err != nil </span><span class="cov0" title="0">{
                os.Remove(outputPath)
                result.Err = fmt.Errorf("set match result: %w", err)
                return result
        }</span>

        // Pre-encode range maps (CPU-intensive) before the progress-tracked write.
        <span class="cov0" title="0">rangeMapSize, err := writer.EncodeRangeMaps()
        if err != nil </span><span class="cov0" title="0">{
                os.Remove(outputPath)
                result.Err = fmt.Errorf("encode range maps: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">if rangeMapSize &gt; 0 </span><span class="cov0" title="0">{
                printInfo("  Range maps encoded: %s bytes\n", formatInt(rangeMapSize))
        }</span>

        <span class="cov0" title="0">writeBar := newProgressBar(phaseLabel(2, "Writing dedup file..."), 0, "bytes")
        if err := writer.WriteWithProgress(func(written, total int64) </span><span class="cov0" title="0">{
                if writeBar.total == 0 &amp;&amp; total &gt; 0 </span><span class="cov0" title="0">{
                        writeBar.total = total
                }</span>
                <span class="cov0" title="0">writeBar.Update(written)</span>
        }); err != nil <span class="cov0" title="0">{
                writeBar.Cancel()
                os.Remove(outputPath)
                result.Err = fmt.Errorf("write dedup file: %w", err)
                return result
        }</span>
        <span class="cov0" title="0">writeBar.Finish()

        // Write config file
        configPath := outputPath + ".yaml"
        if err := dedup.WriteConfig(configPath, virtualName, outputPath, sourceDir); err != nil </span><span class="cov0" title="0">{
                printInfo("  Warning: failed to write config file: %v\n", err)
        }</span> else<span class="cov0" title="0"> {
                printInfo("  Config: %s\n", configPath)
        }</span>

        // Verify reconstruction
        <span class="cov0" title="0">verifyPrefix := phaseLabel(3, "Verifying reconstruction...")
        if err := verifyReconstruction(outputPath, sourceDir, mkvPath, index, verbose, verifyPrefix); err != nil </span><span class="cov0" title="0">{
                printInfo("  WARNING: Verification failed: %v\n", err)
                printInfoln("  Keeping files for debugging")
        }</span>

        // Populate result
        <span class="cov0" title="0">result.MkvSize = parser.Size()
        result.MatchedBytes = matchResult.MatchedBytes
        result.UnmatchedBytes = matchResult.UnmatchedBytes
        result.MatchedPackets = matchResult.MatchedPackets
        result.TotalPackets = matchResult.TotalPackets
        result.IndexEntries = len(matchResult.Entries)

        dedupInfo, _ := os.Stat(outputPath)
        if dedupInfo != nil </span><span class="cov0" title="0">{
                result.DedupSize = dedupInfo.Size()
                result.Savings = float64(result.MkvSize-result.DedupSize) / float64(result.MkvSize) * 100
        }</span>
        <span class="cov0" title="0">result.Duration = time.Since(start)

        return result</span>
}

// createDedup creates a .mkvdup file from an MKV and source directory.
func createDedup(mkvPath, sourceDir, outputPath, virtualName string, warnThreshold float64, nonInteractive bool) error <span class="cov0" title="0">{
        totalStart := time.Now()

        // Default virtual name
        if virtualName == "" </span><span class="cov0" title="0">{
                virtualName = filepath.Base(mkvPath)
        }</span>
        // Ensure virtual name has .mkv extension
        <span class="cov0" title="0">if !strings.HasSuffix(strings.ToLower(virtualName), ".mkv") </span><span class="cov0" title="0">{
                virtualName += ".mkv"
        }</span>

        <span class="cov0" title="0">printInfoln("Creating dedup file...")
        printInfo("  MKV:     %s\n", mkvPath)
        printInfo("  Source:  %s\n", sourceDir)
        printInfo("  Output:  %s\n", outputPath)
        printInfoln()

        // Phase 1: Quick codec compatibility check (only reads MKV track headers, not full file)
        printInfo("Phase 1/6: Checking codec compatibility...")
        codecParser, err := mkv.NewParser(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open MKV: %w", err)
        }</span>
        <span class="cov0" title="0">if err := codecParser.ParseTracksOnly(); err != nil </span><span class="cov0" title="0">{
                // Fail open: this fast-path parser can't handle all MKV layouts.
                // Log and continue without the pre-index codec compatibility check.
                log.Printf("Warning: fast MKV track parsing failed for %q: %v; continuing without pre-index codec check", mkvPath, err)
                codecParser.Close()
        }</span> else<span class="cov0" title="0"> {
                if err := checkCodecCompatibilityFromDir(codecParser.Tracks(), sourceDir, nonInteractive); err != nil </span><span class="cov0" title="0">{
                        codecParser.Close()
                        return err
                }</span>
                <span class="cov0" title="0">codecParser.Close()</span>
        }
        <span class="cov0" title="0">printInfoln(" done")

        // Phase 2: Index source (expensive)
        indexer, index, err := buildSourceIndex(sourceDir, "Phase 2/6: Building source index...")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer index.Close()

        // Phase 3-6: Process MKV (re-parses MKV, but parsing is fast relative to indexing)
        result := createDedupWithIndex(mkvPath, sourceDir, outputPath, virtualName, indexer, index, 3, 6, nonInteractive, false)
        if result.Err != nil </span><span class="cov0" title="0">{
                return result.Err
        }</span>

        // Summary
        <span class="cov0" title="0">printInfoln()
        printInfoln("=== Results ===")
        printInfo("Total time: %v\n", time.Since(totalStart))
        printInfoln()

        printInfo("MKV file size:      %s bytes (%.2f MB)\n", formatInt(result.MkvSize), float64(result.MkvSize)/(1024*1024))
        printInfo("Matched bytes:      %s bytes (%.2f MB, %.1f%%)\n",
                formatInt(result.MatchedBytes), float64(result.MatchedBytes)/(1024*1024),
                float64(result.MatchedBytes)/float64(result.MkvSize)*100)
        printInfo("Delta (unmatched):  %s bytes (%.2f MB, %.1f%%)\n",
                formatInt(result.UnmatchedBytes), float64(result.UnmatchedBytes)/(1024*1024),
                float64(result.UnmatchedBytes)/float64(result.MkvSize)*100)
        printInfoln()

        printInfo("Dedup file size:    %s bytes (%.2f MB)\n", formatInt(result.DedupSize), float64(result.DedupSize)/(1024*1024))
        printInfo("Space savings:      %.1f%%\n", result.Savings)
        printInfoln()

        printInfo("Packets matched:    %s / %s (%.1f%%)\n",
                formatInt(int64(result.MatchedPackets)), formatInt(int64(result.TotalPackets)),
                float64(result.MatchedPackets)/float64(result.TotalPackets)*100)
        printInfo("Index entries:      %s\n", formatInt(int64(result.IndexEntries)))

        // Warning for low savings
        if !quiet &amp;&amp; result.Savings &lt; warnThreshold </span><span class="cov0" title="0">{
                printInfoln()
                printInfo("WARNING: Space savings (%.1f%%) below %.0f%%\n", result.Savings, warnThreshold)
                printInfoln("  This may indicate wrong source or transcoded MKV.")
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package main

import (
        "fmt"
        "time"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

func parseMKV(path string) error <span class="cov0" title="0">{
        fmt.Printf("Parsing MKV file: %s\n", path)

        parser, err := mkv.NewParser(path)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create parser: %w", err)
        }</span>
        <span class="cov0" title="0">defer parser.Close()

        fmt.Printf("File size: %s bytes (%.2f GB)\n", formatInt(parser.Size()), float64(parser.Size())/(1024*1024*1024))

        start := time.Now()
        lastProgress := time.Now()

        err = parser.Parse(func(processed, total int64) </span><span class="cov0" title="0">{
                if time.Since(lastProgress) &gt; 500*time.Millisecond </span><span class="cov0" title="0">{
                        pct := float64(processed) / float64(total) * 100
                        fmt.Printf("\rProgress: %.1f%% (%s / %s bytes)", pct, formatInt(processed), formatInt(total))
                        lastProgress = time.Now()
                }</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse: %w", err)
        }</span>

        <span class="cov0" title="0">elapsed := time.Since(start)
        fmt.Printf("\rProgress: 100.0%% - Complete                    \n")
        fmt.Printf("Parse time: %v\n", elapsed)
        fmt.Println()

        fmt.Printf("Tracks: %d\n", len(parser.Tracks()))
        for _, t := range parser.Tracks() </span><span class="cov0" title="0">{
                typeStr := "unknown"
                switch t.Type </span>{
                case mkv.TrackTypeVideo:<span class="cov0" title="0">
                        typeStr = "video"</span>
                case mkv.TrackTypeAudio:<span class="cov0" title="0">
                        typeStr = "audio"</span>
                case mkv.TrackTypeSubtitle:<span class="cov0" title="0">
                        typeStr = "subtitle"</span>
                }
                <span class="cov0" title="0">extra := ""
                if t.Type == mkv.TrackTypeVideo </span><span class="cov0" title="0">{
                        nalSize := matcher.NALLengthSizeForTrack(t.CodecID, t.CodecPrivate)
                        if nalSize &gt; 0 </span><span class="cov0" title="0">{
                                extra = fmt.Sprintf(", NAL length: %d bytes (AVCC/HVCC)", nalSize)
                        }</span> else<span class="cov0" title="0"> {
                                extra = ", Annex B"
                        }</span>
                }
                <span class="cov0" title="0">fmt.Printf("  Track %d: %s (codec: %s%s)\n", t.Number, typeStr, t.CodecID, extra)</span>
        }
        <span class="cov0" title="0">fmt.Println()

        fmt.Printf("Total packets: %d\n", parser.PacketCount())
        fmt.Printf("  Video packets: %d\n", parser.VideoPacketCount())
        fmt.Printf("  Audio packets: %d\n", parser.AudioPacketCount())

        // Show some sample packets
        packets := parser.Packets()
        if len(packets) &gt; 0 </span><span class="cov0" title="0">{
                fmt.Println()
                fmt.Println("Sample packets (first 5):")
                for i := 0; i &lt; 5 &amp;&amp; i &lt; len(packets); i++ </span><span class="cov0" title="0">{
                        p := packets[i]
                        fmt.Printf("  Packet %d: offset=%d, size=%d, track=%d, keyframe=%v\n",
                                i, p.Offset, p.Size, p.TrackNum, p.Keyframe)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

func indexSource(dir string) error <span class="cov0" title="0">{
        fmt.Printf("Indexing source directory: %s\n", dir)

        indexer, err := source.NewIndexer(dir, source.DefaultWindowSize)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create indexer: %w", err)
        }</span>

        <span class="cov0" title="0">fmt.Printf("Source type: %s\n", indexer.SourceType())

        start := time.Now()
        lastProgress := time.Now()

        err = indexer.Build(func(processed, total int64) </span><span class="cov0" title="0">{
                if time.Since(lastProgress) &gt; 500*time.Millisecond </span><span class="cov0" title="0">{
                        pct := float64(processed) / float64(total) * 100
                        fmt.Printf("\rProgress: %.1f%% (%s / %s bytes)", pct, formatInt(processed), formatInt(total))
                        lastProgress = time.Now()
                }</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("build index: %w", err)
        }</span>

        <span class="cov0" title="0">elapsed := time.Since(start)
        fmt.Printf("\rProgress: 100.0%% - Complete                    \n")
        fmt.Printf("Index time: %v\n", elapsed)
        fmt.Println()

        index := indexer.Index()
        defer index.Close()
        fmt.Printf("Source files: %d\n", len(index.Files))
        for _, f := range index.Files </span><span class="cov0" title="0">{
                fmt.Printf("  %s: %s bytes\n", f.RelativePath, formatInt(f.Size))
        }</span>
        <span class="cov0" title="0">fmt.Println()

        fmt.Printf("Unique hashes: %d\n", len(index.HashToLocations))
        if index.UsesESOffsets </span><span class="cov0" title="0">{
                containerType := "MPEG-PS"
                if indexer.SourceType() == source.TypeBluray </span><span class="cov0" title="0">{
                        containerType = "MPEG-TS"
                }</span>
                <span class="cov0" title="0">fmt.Printf("Index type: ES-aware (%s)\n", containerType)</span>
        }

        // Count total locations
        <span class="cov0" title="0">totalLocations := 0
        for _, locs := range index.HashToLocations </span><span class="cov0" title="0">{
                totalLocations += len(locs)
        }</span>
        <span class="cov0" title="0">fmt.Printf("Total indexed locations: %d\n", totalLocations)

        return nil</span>
}

func matchMKV(mkvPath, sourceDir string) error <span class="cov0" title="0">{
        totalStart := time.Now()

        // Phase 1: Parse MKV
        parser, _, err := parseMKVWithProgress(mkvPath, "Phase 1/3: Parsing MKV file...")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer parser.Close()

        // Phase 2: Index source
        _, index, err := buildSourceIndex(sourceDir, "Phase 2/3: Indexing source...")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer index.Close()

        // Phase 3: Match packets
        fmt.Println("Phase 3/3: Matching packets...")
        m, err := matcher.NewMatcher(index)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create matcher: %w", err)
        }</span>
        <span class="cov0" title="0">defer m.Close()

        start := time.Now()
        lastProgress := time.Now()
        result, err := m.Match(mkvPath, parser.Packets(), parser.Tracks(), func(processed, total int) </span><span class="cov0" title="0">{
                if time.Since(lastProgress) &gt; 500*time.Millisecond </span><span class="cov0" title="0">{
                        pct := float64(processed) / float64(total) * 100
                        fmt.Printf("\r  Progress: %.1f%% (%d/%d packets)", pct, processed, total)
                        lastProgress = time.Now()
                }</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("match: %w", err)
        }</span>
        <span class="cov0" title="0">fmt.Printf("\r  Matched in %v                              \n", time.Since(start))

        // Summary
        fmt.Println()
        fmt.Println("=== Results ===")
        fmt.Printf("Total time: %v\n", time.Since(totalStart))
        fmt.Println()

        mkvSize := parser.Size()
        fmt.Printf("MKV file size:      %s bytes (%.2f MB)\n", formatInt(mkvSize), float64(mkvSize)/(1024*1024))
        fmt.Printf("Matched bytes:      %s bytes (%.2f MB, %.1f%%)\n",
                formatInt(result.MatchedBytes), float64(result.MatchedBytes)/(1024*1024),
                float64(result.MatchedBytes)/float64(mkvSize)*100)
        fmt.Printf("Delta (unmatched):  %s bytes (%.2f MB, %.1f%%)\n",
                formatInt(result.UnmatchedBytes), float64(result.UnmatchedBytes)/(1024*1024),
                float64(result.UnmatchedBytes)/float64(mkvSize)*100)
        fmt.Println()

        fmt.Printf("Packets matched:    %d / %d (%.1f%%)\n",
                result.MatchedPackets, result.TotalPackets,
                float64(result.MatchedPackets)/float64(result.TotalPackets)*100)
        fmt.Printf("Index entries:      %d\n", len(result.Entries))
        fmt.Println()

        // Storage savings (using actual format constants)
        indexSize := int64(len(result.Entries) * dedup.EntrySize)
        headerSize := int64(dedup.HeaderSize)
        footerSize := int64(dedup.FooterSize)
        totalDedupSize := headerSize + indexSize + int64(len(result.DeltaData)) + footerSize

        // For Blu-ray sources, V4 format includes range map section (estimate)
        rangeMapNote := ""
        if index.UsesESOffsets </span><span class="cov0" title="0">{
                // Range map is compressed; rough estimate is ~5-10% of index size
                rangeMapEstimate := indexSize / 10
                totalDedupSize += rangeMapEstimate
                footerSize = int64(dedup.FooterV4Size)
                rangeMapNote = fmt.Sprintf(" + ~%s range map", formatInt(rangeMapEstimate))
        }</span>

        <span class="cov0" title="0">savings := float64(mkvSize-totalDedupSize) / float64(mkvSize) * 100

        fmt.Printf("Estimated dedup file size:\n")
        fmt.Printf("  Header:     %s bytes\n", formatInt(headerSize))
        fmt.Printf("  Index:      %s bytes (%s entries × %d)\n", formatInt(indexSize), formatInt(int64(len(result.Entries))), dedup.EntrySize)
        fmt.Printf("  Delta:      %s bytes\n", formatInt(int64(len(result.DeltaData))))
        fmt.Printf("  Footer:     %s bytes\n", formatInt(footerSize))
        fmt.Printf("  Total:      ~%s bytes (%.2f MB)%s\n", formatInt(totalDedupSize), float64(totalDedupSize)/(1024*1024), rangeMapNote)
        fmt.Printf("  Savings:    ~%.1f%% reduction\n", savings)

        return nil</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">package main

import (
        "encoding/binary"
        "fmt"
        "os"
        "sort"
        "strings"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/mmap"
)

// deltaClass accumulates byte count and entry count for delta classification.
type deltaClass struct {
        bytes int64
        count int
}

// deltadiag analyzes delta (unmatched) entries in a .mkvdup file by
// cross-referencing with the original MKV to classify what stream type
// each delta region belongs to (video/audio/container).
func deltadiag(dedupPath, mkvPath string) error <span class="cov0" title="0">{
        // Open dedup file
        reader, err := dedup.NewReader(dedupPath, "")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open dedup file: %w", err)
        }</span>
        <span class="cov0" title="0">defer reader.Close()

        entryCount := reader.EntryCount()
        origSize := reader.OriginalSize()
        fmt.Fprintf(os.Stderr, "Dedup file: %d %s, original size %s bytes (%.2f MB)\n",
                entryCount, plural(entryCount, "entry", "entries"), formatInt(origSize), float64(origSize)/(1024*1024))

        // Parse MKV to get packet boundaries
        fmt.Fprintf(os.Stderr, "Parsing MKV file...\n")
        mkvParser, err := mkv.NewParser(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create MKV parser: %w", err)
        }</span>
        <span class="cov0" title="0">defer mkvParser.Close()

        if err := mkvParser.Parse(nil); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse MKV: %w", err)
        }</span>

        <span class="cov0" title="0">packets := mkvParser.Packets()
        tracks := mkvParser.Tracks()
        fmt.Fprintf(os.Stderr, "  %d packets, %d tracks\n", len(packets), len(tracks))

        // Build track type map and detect AVCC NAL length size
        trackTypes := make(map[int]int)
        nalLenSizes := make(map[int]int)
        isAVCTrack := make(map[int]bool)
        for _, t := range tracks </span><span class="cov0" title="0">{
                trackTypes[int(t.Number)] = t.Type
                nalLenSizes[int(t.Number)] = matcher.NALLengthSizeForTrack(t.CodecID, t.CodecPrivate)
                if strings.HasPrefix(t.CodecID, "V_MPEG4/ISO/AVC") </span><span class="cov0" title="0">{
                        isAVCTrack[int(t.Number)] = true
                }</span>
        }

        // Memory-map MKV for reading delta bytes
        <span class="cov0" title="0">mkvMmap, err := mmap.Open(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("mmap MKV: %w", err)
        }</span>
        <span class="cov0" title="0">defer mkvMmap.Close()
        mkvData := mkvMmap.Data()

        // Sort packets by offset for binary search
        sort.Slice(packets, func(i, j int) bool </span><span class="cov0" title="0">{
                return packets[i].Offset &lt; packets[j].Offset
        }</span>)

        // Classify each delta entry
        <span class="cov0" title="0">fmt.Fprintf(os.Stderr, "Classifying delta entries...\n")

        var deltaVideo, deltaAudio, deltaContainer deltaClass
        var deltaVideoByNAL [32]deltaClass
        var deltaVideoSliceSmall, deltaVideoSliceLarge deltaClass

        for i := 0; i &lt; entryCount; i++ </span><span class="cov0" title="0">{
                ent, ok := reader.GetEntry(i)
                if !ok </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">if ent.Source != 0 </span><span class="cov0" title="0">{
                        continue</span> // Skip matched entries
                }

                // Find which MKV packet contains this delta region.
                // NOTE: Classification is approximate — a delta entry can span multiple
                // packets or tracks, but we classify based on the single packet containing
                // the start offset. This is usually accurate since matches expand to
                // cover full NALs/frames, leaving delta gaps within a single packet.
                <span class="cov0" title="0">pktIdx := deltadiagFindPacket(packets, ent.MkvOffset)
                if pktIdx &lt; 0 </span><span class="cov0" title="0">{
                        deltaContainer.bytes += ent.Length
                        deltaContainer.count++
                        continue</span>
                }

                <span class="cov0" title="0">pkt := packets[pktIdx]
                ttype := trackTypes[int(pkt.TrackNum)]

                if ttype == mkv.TrackTypeVideo </span><span class="cov0" title="0">{
                        deltaVideo.bytes += ent.Length
                        deltaVideo.count++

                        // Parse AVCC NALs in the delta region (H.264 only — HEVC uses different NAL type encoding)
                        nalLenSize := nalLenSizes[int(pkt.TrackNum)]
                        if nalLenSize &gt; 0 &amp;&amp; isAVCTrack[int(pkt.TrackNum)] &amp;&amp; ent.Length &gt;= int64(nalLenSize+1) </span><span class="cov0" title="0">{
                                deltaStart := ent.MkvOffset
                                deltaEnd := ent.MkvOffset + ent.Length
                                if deltaEnd &lt;= int64(len(mkvData)) </span><span class="cov0" title="0">{
                                        deltadiagClassifyAVCC(mkvData, pkt, nalLenSize, deltaStart, deltaEnd,
                                                &amp;deltaVideoByNAL, &amp;deltaVideoSliceSmall, &amp;deltaVideoSliceLarge)
                                }</span>
                        }
                } else<span class="cov0" title="0"> if ttype == mkv.TrackTypeAudio </span><span class="cov0" title="0">{
                        deltaAudio.bytes += ent.Length
                        deltaAudio.count++
                }</span> else<span class="cov0" title="0"> {
                        deltaContainer.bytes += ent.Length
                        deltaContainer.count++
                }</span>
        }

        // Print results
        <span class="cov0" title="0">totalDelta := deltaVideo.bytes + deltaAudio.bytes + deltaContainer.bytes
        if totalDelta == 0 </span><span class="cov0" title="0">{
                fmt.Printf("\nNo delta entries found (100%% matched).\n")
                return nil
        }</span>

        <span class="cov0" title="0">fmt.Printf("\n=== Delta Classification ===\n")
        fmt.Printf("Total delta: %s bytes (%.2f MB)\n\n", formatInt(totalDelta), float64(totalDelta)/(1024*1024))

        fmt.Printf("Video delta:     %12s bytes (%8.2f MB) [%6d entries] (%.1f%% of delta)\n",
                formatInt(deltaVideo.bytes), float64(deltaVideo.bytes)/(1024*1024), deltaVideo.count,
                float64(deltaVideo.bytes)/float64(totalDelta)*100)
        fmt.Printf("Audio delta:     %12s bytes (%8.2f MB) [%6d entries] (%.1f%% of delta)\n",
                formatInt(deltaAudio.bytes), float64(deltaAudio.bytes)/(1024*1024), deltaAudio.count,
                float64(deltaAudio.bytes)/float64(totalDelta)*100)
        fmt.Printf("Container delta: %12s bytes (%8.2f MB) [%6d entries] (%.1f%% of delta)\n",
                formatInt(deltaContainer.bytes), float64(deltaContainer.bytes)/(1024*1024), deltaContainer.count,
                float64(deltaContainer.bytes)/float64(totalDelta)*100)

        // Video NAL type breakdown
        nalTypeNames := map[int]string{
                1: "non-IDR slice", 2: "slice A", 3: "slice B", 4: "slice C",
                5: "IDR slice", 6: "SEI", 7: "SPS", 8: "PPS", 9: "AUD", 12: "filler",
        }

        hasNALBreakdown := false
        for i := 0; i &lt; 32; i++ </span><span class="cov0" title="0">{
                if deltaVideoByNAL[i].count &gt; 0 </span><span class="cov0" title="0">{
                        hasNALBreakdown = true
                        break</span>
                }
        }
        <span class="cov0" title="0">if hasNALBreakdown </span><span class="cov0" title="0">{
                fmt.Printf("\n=== Video Delta by H.264 NAL Type ===\n")
                for i := 0; i &lt; 32; i++ </span><span class="cov0" title="0">{
                        if deltaVideoByNAL[i].count == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">name := nalTypeNames[i]
                        if name == "" </span><span class="cov0" title="0">{
                                name = fmt.Sprintf("type %d", i)
                        }</span>
                        <span class="cov0" title="0">fmt.Printf("  %-14s: %10s bytes (%8.2f MB) [%6d NALs]\n",
                                name, formatInt(deltaVideoByNAL[i].bytes),
                                float64(deltaVideoByNAL[i].bytes)/(1024*1024),
                                deltaVideoByNAL[i].count)</span>
                }

                <span class="cov0" title="0">fmt.Printf("\n=== Video Slice Delta Size Breakdown ===\n")
                fmt.Printf("  Slice NALs &lt; 4KB:  %10s bytes (%8.2f MB) [%6d NALs]\n",
                        formatInt(deltaVideoSliceSmall.bytes), float64(deltaVideoSliceSmall.bytes)/(1024*1024),
                        deltaVideoSliceSmall.count)
                fmt.Printf("  Slice NALs &gt;= 4KB: %10s bytes (%8.2f MB) [%6d NALs]\n",
                        formatInt(deltaVideoSliceLarge.bytes), float64(deltaVideoSliceLarge.bytes)/(1024*1024),
                        deltaVideoSliceLarge.count)</span>
        }

        // Summary
        <span class="cov0" title="0">fmt.Printf("\n=== Summary ===\n")
        fmt.Printf("Original file:    %.2f MB\n", float64(origSize)/(1024*1024))
        fmt.Printf("Total delta:      %.2f MB (%.1f%% of original)\n",
                float64(totalDelta)/(1024*1024), float64(totalDelta)/float64(origSize)*100)
        fmt.Printf("  Video delta:    %.2f MB (%.1f%% of delta)\n",
                float64(deltaVideo.bytes)/(1024*1024), float64(deltaVideo.bytes)/float64(totalDelta)*100)
        fmt.Printf("  Audio delta:    %.2f MB (%.1f%% of delta)\n",
                float64(deltaAudio.bytes)/(1024*1024), float64(deltaAudio.bytes)/float64(totalDelta)*100)
        fmt.Printf("  Container:      %.2f MB (%.1f%% of delta)\n",
                float64(deltaContainer.bytes)/(1024*1024), float64(deltaContainer.bytes)/float64(totalDelta)*100)

        return nil</span>
}

// deltadiagFindPacket finds the packet containing the given offset using binary search.
func deltadiagFindPacket(packets []mkv.Packet, offset int64) int <span class="cov8" title="14">{
        low, high := 0, len(packets)-1
        for low &lt;= high </span><span class="cov10" title="25">{
                mid := (low + high) / 2
                pkt := packets[mid]
                if offset &lt; pkt.Offset </span><span class="cov5" title="5">{
                        high = mid - 1
                }</span> else<span class="cov9" title="20"> if offset &gt;= pkt.Offset+pkt.Size </span><span class="cov7" title="11">{
                        low = mid + 1
                }</span> else<span class="cov7" title="9"> {
                        return mid
                }</span>
        }
        <span class="cov5" title="5">return -1</span>
}

// deltadiagClassifyAVCC parses AVCC NAL units within a packet to classify which
// NAL types fall within the delta region [deltaStart, deltaEnd).
func deltadiagClassifyAVCC(mkvData []byte, pkt mkv.Packet, nalLenSize int,
        deltaStart, deltaEnd int64,
        byNAL *[32]deltaClass, sliceSmall, sliceLarge *deltaClass) <span class="cov2" title="2">{

        pktEnd := pkt.Offset + pkt.Size
        if pktEnd &gt; int64(len(mkvData)) </span><span class="cov0" title="0">{
                pktEnd = int64(len(mkvData))
        }</span>
        <span class="cov2" title="2">pktData := mkvData[pkt.Offset:pktEnd]

        pos := 0
        for pos+nalLenSize &lt; len(pktData) </span><span class="cov4" title="4">{
                var nalLen uint32
                switch nalLenSize </span>{
                case 4:<span class="cov4" title="4">
                        nalLen = binary.BigEndian.Uint32(pktData[pos:])</span>
                case 2:<span class="cov0" title="0">
                        nalLen = uint32(binary.BigEndian.Uint16(pktData[pos:]))</span>
                case 1:<span class="cov0" title="0">
                        nalLen = uint32(pktData[pos])</span>
                }

                <span class="cov4" title="4">nalDataStart := pkt.Offset + int64(pos+nalLenSize)
                nalDataEnd := nalDataStart + int64(nalLen)
                if nalLen == 0 || nalDataEnd &gt; pktEnd </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov4" title="4">nalFullStart := pkt.Offset + int64(pos)

                // Check overlap with delta region
                overlapStart := nalFullStart
                if overlapStart &lt; deltaStart </span><span class="cov1" title="1">{
                        overlapStart = deltaStart
                }</span>
                <span class="cov4" title="4">overlapEnd := nalDataEnd
                if overlapEnd &gt; deltaEnd </span><span class="cov1" title="1">{
                        overlapEnd = deltaEnd
                }</span>
                <span class="cov4" title="4">if overlapStart &lt; overlapEnd </span><span class="cov4" title="4">{
                        overlapBytes := overlapEnd - overlapStart

                        if nalDataStart &lt; int64(len(mkvData)) </span><span class="cov4" title="4">{
                                nalType := mkvData[nalDataStart] &amp; 0x1F
                                byNAL[nalType].bytes += overlapBytes
                                byNAL[nalType].count++

                                if nalType == 1 || nalType == 5 </span><span class="cov2" title="2">{
                                        if nalLen &gt;= 4096 </span><span class="cov1" title="1">{
                                                sliceLarge.bytes += overlapBytes
                                                sliceLarge.count++
                                        }</span> else<span class="cov1" title="1"> {
                                                sliceSmall.bytes += overlapBytes
                                                sliceSmall.count++
                                        }</span>
                                }
                        }
                }

                <span class="cov4" title="4">pos = int(nalDataEnd - pkt.Offset)
                if pos &lt;= 0 </span><span class="cov0" title="0">{
                        break</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file4" style="display: none">package main

import (
        "os"
        "strconv"
)

// formatInt formats an integer with thousands separators (e.g., 1234567 → "1,234,567").
func formatInt(n int64) string <span class="cov8" title="43">{
        s := strconv.FormatInt(n, 10)
        if len(s) &lt;= 3 </span><span class="cov8" title="36">{
                return s
        }</span>
        // Insert commas from the right
        <span class="cov5" title="7">var result []byte
        for i, c := range s </span><span class="cov9" title="46">{
                if i &gt; 0 &amp;&amp; (len(s)-i)%3 == 0 </span><span class="cov6" title="12">{
                        result = append(result, ',')
                }</span>
                <span class="cov9" title="46">result = append(result, byte(c))</span>
        }
        <span class="cov5" title="7">return string(result)</span>
}

// plural returns singular when n == 1, plural otherwise.
// Example: plural(n, "file", "files")
func plural(n int, singular, pl string) string <span class="cov10" title="70">{
        if n == 1 </span><span class="cov8" title="32">{
                return singular
        }</span>
        <span class="cov8" title="38">return pl</span>
}

// isTerminal returns true if stdin is a terminal (not piped).
func isTerminal() bool <span class="cov0" title="0">{
        fi, err := os.Stdin.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">return fi.Mode()&amp;os.ModeCharDevice != 0</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">package main

import (
        "fmt"
        "io"
        "os"
        "path/filepath"
        "strings"
        "time"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/dedup"
)

// showInfo displays information about a dedup file.
func showInfo(dedupPath string, hideUnused bool) error <span class="cov0" title="0">{
        reader, err := dedup.NewReader(dedupPath, "")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open dedup file: %w", err)
        }</span>
        <span class="cov0" title="0">defer reader.Close()

        info := reader.Info()

        fmt.Printf("Dedup file: %s\n", dedupPath)
        fmt.Println()

        creatorVersion := info["creator_version"].(string)
        if creatorVersion != "" </span><span class="cov0" title="0">{
                fmt.Printf("Created by:         %s\n", creatorVersion)
        }</span> else<span class="cov0" title="0"> {
                fmt.Printf("Created by:         unknown (pre-0.9.0)\n")
        }</span>
        <span class="cov0" title="0">fmt.Printf("Format version:     %d\n", info["version"].(uint32))
        fmt.Printf("Original MKV size:  %s bytes (%.2f MB)\n",
                formatInt(info["original_size"].(int64)),
                float64(info["original_size"].(int64))/(1024*1024))
        fmt.Printf("Original checksum:  %016x\n", info["original_checksum"].(uint64))
        fmt.Println()

        sourceType := "Unknown"
        switch info["source_type"].(uint8) </span>{
        case 0:<span class="cov0" title="0">
                sourceType = "DVD"</span>
        case 1:<span class="cov0" title="0">
                sourceType = "Blu-ray"</span>
        }
        <span class="cov0" title="0">fmt.Printf("Source type:        %s\n", sourceType)
        fmt.Printf("Uses ES offsets:    %v\n", info["uses_es_offsets"].(bool))
        if info["has_range_maps"].(bool) </span><span class="cov0" title="0">{
                fmt.Printf("Has range maps:     true\n")
        }</span>
        <span class="cov0" title="0">fmt.Printf("Source file count:  %d\n", info["source_file_count"].(int))
        fmt.Printf("Index entry count:  %d\n", info["entry_count"].(int))
        fmt.Printf("Delta size:         %s bytes (%.2f MB)\n",
                formatInt(info["delta_size"].(int64)),
                float64(info["delta_size"].(int64))/(1024*1024))
        fmt.Println()

        // Source files
        fmt.Println("Source files:")
        hasUsedFlags := reader.HasSourceUsedFlags()
        for _, sf := range reader.SourceFiles() </span><span class="cov0" title="0">{
                if hideUnused &amp;&amp; hasUsedFlags &amp;&amp; !sf.Used </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">suffix := ""
                if hasUsedFlags &amp;&amp; !sf.Used </span><span class="cov0" title="0">{
                        suffix = " (unused)"
                }</span>
                <span class="cov0" title="0">fmt.Printf("  %s (%s bytes)%s\n", sf.RelativePath, formatInt(sf.Size), suffix)</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// calculateFileChecksum calculates xxhash checksum of a file.
func calculateFileChecksum(path string) (uint64, error) <span class="cov8" title="6">{
        return calculateFileChecksumWithProgress(path, 0, "")
}</span>

// calculateFileChecksumWithProgress calculates xxhash checksum of a file,
// showing inline progress when expectedSize &gt; 0.
func calculateFileChecksumWithProgress(path string, expectedSize int64, displayName string) (uint64, error) <span class="cov10" title="8">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov1" title="1">{
                return 0, err
        }</span>
        <span class="cov9" title="7">defer f.Close()

        hasher := xxhash.New()
        showProgress := expectedSize &gt; 0

        if !showProgress </span><span class="cov7" title="5">{
                if _, err := io.Copy(hasher, f); err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>
                <span class="cov7" title="5">return hasher.Sum64(), nil</span>
        }

        <span class="cov4" title="2">buf := make([]byte, 4*1024*1024) // 4MB buffer
        var processed int64
        lastProgress := time.Time{}

        for </span><span class="cov7" title="4">{
                n, err := f.Read(buf)
                if n &gt; 0 </span><span class="cov4" title="2">{
                        if _, werr := hasher.Write(buf[:n]); werr != nil </span><span class="cov0" title="0">{
                                return 0, werr
                        }</span>
                        <span class="cov4" title="2">processed += int64(n)

                        if time.Since(lastProgress) &gt; 500*time.Millisecond </span><span class="cov4" title="2">{
                                pct := float64(processed) / float64(expectedSize) * 100
                                fmt.Printf("\r  Verifying %s... %.1f%%", displayName, pct)
                                lastProgress = time.Now()
                        }</span>
                }
                <span class="cov7" title="4">if err == io.EOF </span><span class="cov4" title="2">{
                        break</span>
                }
                <span class="cov4" title="2">if err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>
        }

        // Clear progress line
        <span class="cov4" title="2">progressText := fmt.Sprintf("  Verifying %s... 100.0%%", displayName)
        fmt.Printf("\r%s\r", strings.Repeat(" ", len(progressText)))

        return hasher.Sum64(), nil</span>
}

// checkDedup checks the integrity of a dedup file and its source files.
func checkDedup(dedupPath, sourceDir string, sourceChecksums bool) error <span class="cov10" title="8">{
        fmt.Printf("Checking dedup file: %s\n", dedupPath)
        fmt.Printf("Source directory:    %s\n", sourceDir)
        fmt.Println()

        // Phase 1: Open and verify dedup file integrity
        reader, err := dedup.NewReader(dedupPath, sourceDir)
        if err != nil </span><span class="cov1" title="1">{
                return fmt.Errorf("open dedup file: %w", err)
        }</span>
        <span class="cov9" title="7">defer reader.Close()

        fmt.Print("Checking dedup file integrity...")
        if err := reader.VerifyIntegrity(); err != nil </span><span class="cov1" title="1">{
                fmt.Println(" FAILED")
                return fmt.Errorf("integrity check: %w", err)
        }</span>
        <span class="cov8" title="6">fmt.Println(" OK")

        // Phase 2: Check source files exist with correct sizes
        sourceFiles := reader.SourceFiles()
        fmt.Printf("\nChecking source files (%d %s)...\n", len(sourceFiles), plural(len(sourceFiles), "file", "files"))

        errCount := 0
        for _, sf := range sourceFiles </span><span class="cov8" title="6">{
                sfPath := filepath.Join(sourceDir, sf.RelativePath)
                stat, err := os.Stat(sfPath)
                if err != nil </span><span class="cov1" title="1">{
                        fmt.Printf("  FAILED  %s: %v\n", sf.RelativePath, err)
                        errCount++
                        continue</span>
                }
                <span class="cov7" title="5">if stat.Size() != sf.Size </span><span class="cov4" title="2">{
                        fmt.Printf("  FAILED  %s: size mismatch (expected %s, got %s)\n",
                                sf.RelativePath, formatInt(sf.Size), formatInt(stat.Size()))
                        errCount++
                        continue</span>
                }
                <span class="cov5" title="3">fmt.Printf("  OK      %s (%s bytes)\n", sf.RelativePath, formatInt(sf.Size))</span>
        }

        // Phase 3: Optionally verify source file checksums
        <span class="cov8" title="6">if sourceChecksums </span><span class="cov5" title="3">{
                if errCount &gt; 0 </span><span class="cov1" title="1">{
                        fmt.Println("\nSkipping source checksum verification due to earlier errors")
                }</span> else<span class="cov4" title="2"> {
                        fmt.Printf("\nVerifying source file checksums...\n")
                        for _, sf := range sourceFiles </span><span class="cov4" title="2">{
                                sfPath := filepath.Join(sourceDir, sf.RelativePath)

                                checksum, err := calculateFileChecksumWithProgress(sfPath, sf.Size, sf.RelativePath)
                                if err != nil </span><span class="cov0" title="0">{
                                        fmt.Printf("  FAILED  %s: %v\n", sf.RelativePath, err)
                                        errCount++
                                        continue</span>
                                }
                                <span class="cov4" title="2">if checksum != sf.Checksum </span><span class="cov1" title="1">{
                                        fmt.Printf("  FAILED  %s: checksum mismatch (expected %016x, got %016x)\n",
                                                sf.RelativePath, sf.Checksum, checksum)
                                        errCount++
                                        continue</span>
                                }
                                <span class="cov1" title="1">fmt.Printf("  OK      %s\n", sf.RelativePath)</span>
                        }
                }
        }

        // Final summary
        <span class="cov8" title="6">fmt.Println()
        if errCount &gt; 0 </span><span class="cov7" title="4">{
                return fmt.Errorf("check FAILED: %d %s found", errCount, plural(errCount, "error", "errors"))
        }</span>
        <span class="cov4" title="2">fmt.Println("Check PASSED")
        return nil</span>
}
</pre>
		
		<pre class="file" id="file6" style="display: none">package main

import (
        "fmt"
        "log"
        "log/syslog"
        "os"
        "os/signal"
        "path/filepath"
        "syscall"

        "github.com/hanwen/go-fuse/v2/fs"
        "github.com/hanwen/go-fuse/v2/fuse"
        "github.com/stuckj/mkvdup/internal/daemon"
        "github.com/stuckj/mkvdup/internal/dedup"
        mkvfuse "github.com/stuckj/mkvdup/internal/fuse"
)

// defaultConfigPath is the default config file location.
const defaultConfigPath = "/etc/mkvdup.conf"

// expandConfigDir expands a directory path to a list of .yaml/.yml files it contains.
func expandConfigDir(dir string) ([]string, error) <span class="cov5" title="5">{
        entries, err := os.ReadDir(dir)
        if err != nil </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("read config directory %s: %w", dir, err)
        }</span>
        <span class="cov5" title="4">var paths []string
        for _, entry := range entries </span><span class="cov6" title="6">{
                if !entry.IsDir() &amp;&amp; (filepath.Ext(entry.Name()) == ".yaml" || filepath.Ext(entry.Name()) == ".yml") </span><span class="cov5" title="5">{
                        paths = append(paths, filepath.Join(dir, entry.Name()))
                }</span>
        }
        <span class="cov5" title="4">if len(paths) == 0 </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("no YAML files (.yaml, .yml) found in %s", dir)
        }</span>
        <span class="cov4" title="3">return paths, nil</span>
}

// mountFuse mounts a FUSE filesystem exposing dedup files as MKV files.
func mountFuse(mountpoint string, configPaths []string, opts MountOptions) error <span class="cov0" title="0">{
        // Daemonize unless --foreground is set or we're already a daemon child
        if !opts.Foreground &amp;&amp; !daemon.IsChild() </span><span class="cov0" title="0">{
                return daemon.Daemonize(opts.PidFile, opts.DaemonTimeout)
        }</span>

        // Write PID file in foreground mode (daemon mode writes it in Daemonize)
        <span class="cov0" title="0">if opts.Foreground &amp;&amp; opts.PidFile != "" </span><span class="cov0" title="0">{
                if err := daemon.WritePidFile(opts.PidFile, os.Getpid()); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("write pid file: %w", err)
                }</span>
        }

        // Clean up PID file on exit (for both foreground and daemon child modes)
        <span class="cov0" title="0">if opts.PidFile != "" &amp;&amp; (opts.Foreground || daemon.IsChild()) </span><span class="cov0" title="0">{
                defer func() </span><span class="cov0" title="0">{
                        _ = daemon.RemovePidFile(opts.PidFile)
                }</span>()
        }

        // If no config paths provided, use default
        <span class="cov0" title="0">if len(configPaths) == 0 </span><span class="cov0" title="0">{
                if _, err := os.Stat(defaultConfigPath); err == nil </span><span class="cov0" title="0">{
                        configPaths = []string{defaultConfigPath}
                }</span> else<span class="cov0" title="0"> {
                        if daemon.IsChild() </span><span class="cov0" title="0">{
                                daemon.NotifyError(fmt.Errorf("no config files specified and %s not found", defaultConfigPath))
                        }</span>
                        <span class="cov0" title="0">return fmt.Errorf("no config files specified and %s not found", defaultConfigPath)</span>
                }
        }

        // Store the config-dir path for SIGHUP re-expansion
        <span class="cov0" title="0">var configDirPath string
        if opts.ConfigDir </span><span class="cov0" title="0">{
                configDirPath = configPaths[0]
        }</span>

        // If configDir is set, expand directory to list of .yaml files
        <span class="cov0" title="0">if opts.ConfigDir </span><span class="cov0" title="0">{
                if len(configPaths) != 1 </span><span class="cov0" title="0">{
                        err := fmt.Errorf("--config-dir requires exactly one directory path, got %d", len(configPaths))
                        if daemon.IsChild() </span><span class="cov0" title="0">{
                                daemon.NotifyError(err)
                        }</span>
                        <span class="cov0" title="0">return err</span>
                }
                <span class="cov0" title="0">expanded, err := expandConfigDir(configPaths[0])
                if err != nil </span><span class="cov0" title="0">{
                        if daemon.IsChild() </span><span class="cov0" title="0">{
                                daemon.NotifyError(err)
                        }</span>
                        <span class="cov0" title="0">return err</span>
                }
                <span class="cov0" title="0">configPaths = expanded</span>
        }

        // Set up permission store
        <span class="cov0" title="0">defaults := mkvfuse.Defaults{
                FileUID:  opts.DefaultUID,
                FileGID:  opts.DefaultGID,
                FileMode: opts.DefaultFileMode,
                DirUID:   opts.DefaultUID,
                DirGID:   opts.DefaultGID,
                DirMode:  opts.DefaultDirMode,
        }
        permPath := mkvfuse.ResolvePermissionsPath(opts.PermissionsFile)
        permStore := mkvfuse.NewPermissionStore(permPath, defaults, verbose)
        if err := permStore.Load(); err != nil </span><span class="cov0" title="0">{
                if daemon.IsChild() </span><span class="cov0" title="0">{
                        daemon.NotifyError(fmt.Errorf("load permissions: %w", err))
                }</span>
                <span class="cov0" title="0">return fmt.Errorf("load permissions: %w", err)</span>
        }

        // Resolve configs (expands includes, globs, virtual_files) and extract
        // on_error_command (first-wins across all config files).
        <span class="cov0" title="0">configs, errorCmdConfig, err := dedup.ResolveConfigs(configPaths)
        if err != nil </span><span class="cov0" title="0">{
                err = fmt.Errorf("resolve configs: %w", err)
                if daemon.IsChild() </span><span class="cov0" title="0">{
                        daemon.NotifyError(err)
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov0" title="0">opts.OnErrorCommand = errorCmdConfig

        // Create the root filesystem
        root, err := mkvfuse.NewMKVFSFromConfigs(configs, verbose, &amp;mkvfuse.DefaultReaderFactory{ReadTimeout: opts.SourceReadTimeout}, permStore)
        if err != nil </span><span class="cov0" title="0">{
                err = fmt.Errorf("create filesystem: %w", err)
                if daemon.IsChild() </span><span class="cov0" title="0">{
                        daemon.NotifyError(err)
                }</span>
                <span class="cov0" title="0">return err</span>
        }

        // Mount the filesystem
        <span class="cov0" title="0">fuseOpts := &amp;fs.Options{
                MountOptions: fuse.MountOptions{
                        AllowOther: opts.AllowOther,
                        Name:       "mkvdup",
                        FsName:     "mkvdup",
                        MaxWrite:   1 &lt;&lt; 20, // 1MB max read/write; go-fuse sets max_read = MaxWrite
                        // Enable kernel permission checks for standard Unix semantics.
                        // This properly handles supplementary groups and matches behavior
                        // of real filesystems (ext4, XFS, btrfs, etc.).
                        Options: []string{"default_permissions"},
                },
        }

        server, err := fs.Mount(mountpoint, root, fuseOpts)
        if err != nil </span><span class="cov0" title="0">{
                err = fmt.Errorf("mount: %w", err)
                if daemon.IsChild() </span><span class="cov0" title="0">{
                        daemon.NotifyError(err)
                }</span>
                <span class="cov0" title="0">return err</span>
        }

        // Wait for mount to be ready
        <span class="cov0" title="0">server.WaitMount()

        // Enable FUSE kernel notifications (NotifyDelete, NotifyEntry, etc.)
        // now that the go-fuse bridge is initialized.
        root.SetMounted()

        // Set up source file watcher (monitors source files for changes)
        var sourceWatcher *mkvfuse.SourceWatcher
        if !opts.NoSourceWatch </span><span class="cov0" title="0">{
                // Closure over log.Printf: syslog setup below redirects the default
                // logger's output, so the watcher automatically picks it up.
                watchLogFn := func(format string, args ...interface{}) </span><span class="cov0" title="0">{
                        log.Printf(format, args...)
                }</span>
                <span class="cov0" title="0">var err error
                sourceWatcher, err = mkvfuse.NewSourceWatcher(opts.OnSourceChange, opts.SourceWatchPollInterval, opts.OnErrorCommand, watchLogFn)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("source-watch: warning: failed to create watcher: %v", err)
                }</span> else<span class="cov0" title="0"> {
                        sourceWatcher.Update(root.Files(), &amp;mkvfuse.DefaultReaderFactory{ReadTimeout: opts.SourceReadTimeout})
                        sourceWatcher.Start()
                }</span>
        }

        // If we're a daemon child, signal success and detach from terminal
        <span class="cov0" title="0">if daemon.IsChild() </span><span class="cov0" title="0">{
                if err := daemon.NotifyReady(); err != nil </span><span class="cov0" title="0">{
                        // Parent may have timed out; log and continue since mount succeeded
                        fmt.Fprintf(os.Stderr, "warning: failed to notify parent: %v\n", err)
                }</span>
                <span class="cov0" title="0">daemon.Detach()</span>
        } else<span class="cov0" title="0"> {
                // Running in foreground mode - print info
                fmt.Printf("Mounted at %s\n", mountpoint)
                fmt.Printf("Files:\n")
                for _, configPath := range configPaths </span><span class="cov0" title="0">{
                        config, _ := dedup.ReadConfig(configPath)
                        if config != nil </span><span class="cov0" title="0">{
                                fmt.Printf("  %s\n", config.Name)
                        }</span>
                }
                <span class="cov0" title="0">fmt.Println()
                fmt.Println("Press Ctrl+C to unmount")</span>
        }

        // Set up logging function. In daemon mode, use syslog since
        // stderr is redirected to /dev/null after Detach().
        <span class="cov0" title="0">logFn := func(format string, args ...interface{}) </span><span class="cov0" title="0">{
                log.Printf(format, args...)
        }</span>
        <span class="cov0" title="0">var syslogWriter *syslog.Writer
        if daemon.IsChild() </span><span class="cov0" title="0">{
                if w, err := syslog.New(syslog.LOG_INFO|syslog.LOG_DAEMON, "mkvdup"); err == nil </span><span class="cov0" title="0">{
                        syslogWriter = w
                        logFn = func(format string, args ...interface{}) </span><span class="cov0" title="0">{
                                syslogWriter.Info(fmt.Sprintf(format, args...))
                        }</span>
                }
        }
        <span class="cov0" title="0">if syslogWriter != nil </span><span class="cov0" title="0">{
                // Redirect global log output to syslog so that log.Printf calls
                // from BuildDirectoryTree (during reload) go to syslog too.
                log.SetOutput(syslogWriter)
                log.SetFlags(0) // syslog adds its own timestamp
                defer syslogWriter.Close()
        }</span>

        // Handle signals for graceful shutdown and config reload
        <span class="cov0" title="0">sigChan := make(chan os.Signal, 1)
        signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM, syscall.SIGHUP)

        go func() </span><span class="cov0" title="0">{
                for sig := range sigChan </span><span class="cov0" title="0">{
                        switch sig </span>{
                        case syscall.SIGHUP:<span class="cov0" title="0">
                                logFn("received SIGHUP, reloading config...")

                                // Re-expand config-dir if applicable
                                var reloadPaths []string
                                if configDirPath != "" </span><span class="cov0" title="0">{
                                        expanded, err := expandConfigDir(configDirPath)
                                        if err != nil </span><span class="cov0" title="0">{
                                                logFn("reload failed: expand config dir: %v", err)
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">reloadPaths = expanded</span>
                                } else<span class="cov0" title="0"> {
                                        reloadPaths = configPaths
                                }</span>

                                // Resolve configs (expands includes, globs, virtual_files)
                                <span class="cov0" title="0">configs, _, err := dedup.ResolveConfigs(reloadPaths)
                                if err != nil </span><span class="cov0" title="0">{
                                        logFn("reload failed: resolve configs: %v", err)
                                        continue</span>
                                }

                                // Reload the filesystem
                                <span class="cov0" title="0">if err := root.Reload(configs, logFn); err != nil </span><span class="cov0" title="0">{
                                        logFn("reload failed: %v", err)
                                        continue</span>
                                }

                                // Update source watcher with new file set
                                <span class="cov0" title="0">if sourceWatcher != nil </span><span class="cov0" title="0">{
                                        sourceWatcher.Update(root.Files(), &amp;mkvfuse.DefaultReaderFactory{ReadTimeout: opts.SourceReadTimeout})
                                }</span>

                                <span class="cov0" title="0">logFn("config reloaded successfully")</span>

                        case syscall.SIGINT, syscall.SIGTERM:<span class="cov0" title="0">
                                if !daemon.IsChild() </span><span class="cov0" title="0">{
                                        fmt.Println("\nUnmounting...")
                                }</span>
                                <span class="cov0" title="0">server.Unmount()
                                return</span>
                        }
                }
        }()

        // Serve until unmounted
        <span class="cov0" title="0">server.Wait()

        // Stop source watcher
        if sourceWatcher != nil </span><span class="cov0" title="0">{
                sourceWatcher.Stop()
        }</span>

        <span class="cov0" title="0">if !daemon.IsChild() </span><span class="cov0" title="0">{
                fmt.Println("Unmounted")
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// reloadDaemon validates config files and sends SIGHUP to the running daemon.
func reloadDaemon(pid int, configPaths []string, configDir bool) error <span class="cov3" title="2">{
        // Verify the process exists (on Unix, FindProcess always succeeds;
        // send signal 0 to check if process is actually running)
        process, err := os.FindProcess(pid)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("find process %d: %w", pid, err)
        }</span>
        <span class="cov3" title="2">if err := process.Signal(syscall.Signal(0)); err != nil </span><span class="cov1" title="1">{
                return fmt.Errorf("daemon process %d is not running: %w", pid, err)
        }</span>

        // Validate config if paths provided
        <span class="cov1" title="1">if len(configPaths) &gt; 0 </span><span class="cov0" title="0">{
                resolved, err := resolveConfigPaths(configPaths, configDir)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("resolve config paths: %w", err)
                }</span>

                <span class="cov0" title="0">fmt.Println("Validating configuration...")
                allEntries, _, hasErrors := validateConfigEntries(resolved)
                nameErrors, _ := checkNameConflicts(allEntries)
                if hasErrors || nameErrors </span><span class="cov0" title="0">{
                        return fmt.Errorf("config validation failed, not sending reload signal")
                }</span>
                <span class="cov0" title="0">fmt.Println("Configuration valid.")
                fmt.Println()</span>
        }

        // Send SIGHUP to the daemon
        <span class="cov1" title="1">fmt.Printf("Sending SIGHUP to daemon (pid %d)...\n", pid)
        if err := process.Signal(syscall.SIGHUP); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("send SIGHUP to process %d: %w", pid, err)
        }</span>

        <span class="cov1" title="1">fmt.Println("Reload signal sent successfully.")
        return nil</span>
}

// resolveConfigPaths expands --config-dir and applies defaults to get the final
// list of config file paths to validate.
func resolveConfigPaths(configPaths []string, configDir bool) ([]string, error) <span class="cov10" title="21">{
        if configDir </span><span class="cov3" title="2">{
                if len(configPaths) != 1 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("--config-dir requires exactly one directory path, got %d", len(configPaths))
                }</span>
                <span class="cov3" title="2">return expandConfigDir(configPaths[0])</span>
        }

        <span class="cov9" title="19">if len(configPaths) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no config files specified\nRun 'mkvdup validate --help' for usage")
        }</span>

        <span class="cov9" title="19">return configPaths, nil</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">package main

import (
        "fmt"
        "os"
        "path/filepath"
        "sort"

        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

// ProbeResult represents the result of probing a source against an MKV.
type ProbeResult struct {
        MKVPath      string
        SourcePath   string
        MatchCount   int
        TotalSamples int
        MatchPercent float64
}

// mkvProbeData holds the pre-computed probe hashes for a single MKV file.
type mkvProbeData struct {
        Path        string
        HashCount   int
        ProbeHashes []matcher.ProbeHash
        Error       string // non-empty if MKV could not be parsed
}

// probe tests if one or more MKV files match one or more source directories.
// When multiple MKVs are provided, each source is indexed only once and all
// MKV hash sets are checked against it, making multi-MKV probing much faster.
func probe(mkvPaths []string, sourceDirs []string) error <span class="cov0" title="0">{
        fmt.Printf("Probing %d MKV(s) against %d source(s)...\n", len(mkvPaths), len(sourceDirs))
        fmt.Println()

        windowSize := source.DefaultWindowSize

        // Phase 1: Parse all MKVs and compute probe hashes
        mkvData := make([]mkvProbeData, 0, len(mkvPaths))
        for i, mkvPath := range mkvPaths </span><span class="cov0" title="0">{
                if len(mkvPaths) &gt; 1 </span><span class="cov0" title="0">{
                        fmt.Printf("[%d/%d] Parsing %s...\n", i+1, len(mkvPaths), filepath.Base(mkvPath))
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf("Parsing %s...\n", filepath.Base(mkvPath))
                }</span>

                <span class="cov0" title="0">hashes, err := computeProbeHashes(mkvPath, windowSize)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("  Error: %v\n", err)
                        mkvData = append(mkvData, mkvProbeData{
                                Path:  mkvPath,
                                Error: err.Error(),
                        })
                        continue</span>
                }

                <span class="cov0" title="0">fmt.Printf("  Computed %d probe hashes\n", len(hashes))
                mkvData = append(mkvData, mkvProbeData{
                        Path:        mkvPath,
                        HashCount:   len(hashes),
                        ProbeHashes: hashes,
                })</span>
        }
        <span class="cov0" title="0">fmt.Println()

        // Phase 2: For each source, index once and check all MKV hash sets
        // results[mkvIdx] = []ProbeResult for that MKV
        results := make([][]ProbeResult, len(mkvData))
        for i := range results </span><span class="cov0" title="0">{
                results[i] = make([]ProbeResult, 0, len(sourceDirs))
        }</span>

        <span class="cov0" title="0">for _, sourceDir := range sourceDirs </span><span class="cov0" title="0">{
                fmt.Printf("Indexing source: %s...\n", sourceDir)

                indexer, err := source.NewIndexer(sourceDir, windowSize)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("  Error: %v\n", err)
                        for i, md := range mkvData </span><span class="cov0" title="0">{
                                if md.Error != "" </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov0" title="0">results[i] = append(results[i], ProbeResult{
                                        MKVPath:      md.Path,
                                        SourcePath:   sourceDir,
                                        TotalSamples: md.HashCount,
                                })</span>
                        }
                        <span class="cov0" title="0">continue</span>
                }
                <span class="cov0" title="0">indexer.SetVerbose(verbose)

                if err := indexer.Build(nil); err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("  Error building index: %v\n", err)
                        for i, md := range mkvData </span><span class="cov0" title="0">{
                                if md.Error != "" </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov0" title="0">results[i] = append(results[i], ProbeResult{
                                        MKVPath:      md.Path,
                                        SourcePath:   sourceDir,
                                        TotalSamples: md.HashCount,
                                })</span>
                        }
                        <span class="cov0" title="0">continue</span>
                }

                <span class="cov0" title="0">index := indexer.Index()

                // Check each MKV's hashes against this source
                for i, md := range mkvData </span><span class="cov0" title="0">{
                        if md.Error != "" </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov0" title="0">matchCount := 0
                        for _, ph := range md.ProbeHashes </span><span class="cov0" title="0">{
                                if locs, ok := index.HashToLocations[ph.Hash]; ok </span><span class="cov0" title="0">{
                                        if index.UsesESOffsets </span><span class="cov0" title="0">{
                                                for _, loc := range locs </span><span class="cov0" title="0">{
                                                        if loc.IsVideo == ph.IsVideo </span><span class="cov0" title="0">{
                                                                matchCount++
                                                                break</span>
                                                        }
                                                }
                                        } else<span class="cov0" title="0"> if len(locs) &gt; 0 </span><span class="cov0" title="0">{
                                                matchCount++
                                        }</span>
                                }
                        }

                        <span class="cov0" title="0">matchPercent := float64(matchCount) / float64(md.HashCount) * 100
                        results[i] = append(results[i], ProbeResult{
                                MKVPath:      md.Path,
                                SourcePath:   sourceDir,
                                MatchCount:   matchCount,
                                TotalSamples: md.HashCount,
                                MatchPercent: matchPercent,
                        })

                        if len(mkvPaths) &gt; 1 </span><span class="cov0" title="0">{
                                fmt.Printf("  %s: %d/%d (%.0f%%)\n",
                                        filepath.Base(md.Path), matchCount, md.HashCount, matchPercent)
                        }</span> else<span class="cov0" title="0"> {
                                fmt.Printf("  Matched %d/%d hashes (%.0f%%)\n",
                                        matchCount, md.HashCount, matchPercent)
                        }</span>
                }

                <span class="cov0" title="0">index.Close()</span>
        }

        // Phase 3: Print results
        <span class="cov0" title="0">fmt.Println()
        fmt.Println("=== Results ===")

        for i, md := range mkvData </span><span class="cov0" title="0">{
                if md.Error != "" </span><span class="cov0" title="0">{
                        fmt.Printf("\n  %s: ERROR: %s\n", filepath.Base(md.Path), md.Error)
                        continue</span>
                }

                <span class="cov0" title="0">if len(mkvPaths) &gt; 1 </span><span class="cov0" title="0">{
                        fmt.Printf("\n  %s:\n", filepath.Base(md.Path))
                }</span> else<span class="cov0" title="0"> {
                        fmt.Println()
                }</span>

                // Sort this MKV's results by match percentage
                <span class="cov0" title="0">sort.Slice(results[i], func(a, b int) bool </span><span class="cov0" title="0">{
                        return results[i][a].MatchPercent &gt; results[i][b].MatchPercent
                }</span>)

                <span class="cov0" title="0">for _, r := range results[i] </span><span class="cov0" title="0">{
                        indicator := ""
                        if r.MatchPercent &gt;= 80 </span><span class="cov0" title="0">{
                                indicator = " ← likely match"
                        }</span> else<span class="cov0" title="0"> if r.MatchPercent &gt;= 40 </span><span class="cov0" title="0">{
                                indicator = " ← possible match"
                        }</span>
                        <span class="cov0" title="0">if len(mkvPaths) &gt; 1 </span><span class="cov0" title="0">{
                                fmt.Printf("    %s  %d/%d matches (%.0f%%)%s\n",
                                        r.SourcePath, r.MatchCount, r.TotalSamples, r.MatchPercent, indicator)
                        }</span> else<span class="cov0" title="0"> {
                                fmt.Printf("  %s  %d/%d matches (%.0f%%)%s\n",
                                        r.SourcePath, r.MatchCount, r.TotalSamples, r.MatchPercent, indicator)
                        }</span>
                }
        }

        <span class="cov0" title="0">fmt.Println()
        fmt.Println("Interpretation:")
        fmt.Println("  80-100%: Very likely the correct source")
        fmt.Println("  40-80%:  Possible match (may be partial content)")
        fmt.Println("  &lt;40%:    Unlikely to be the source")

        return nil</span>
}

// computeProbeHashes parses an MKV and returns its probe hashes.
func computeProbeHashes(mkvPath string, windowSize int) ([]matcher.ProbeHash, error) <span class="cov0" title="0">{
        parser, _, err := parseMKVWithProgress(mkvPath, "")
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer parser.Close()

        packets := parser.Packets()
        if len(packets) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no packets found in MKV")
        }</span>

        <span class="cov0" title="0">trackTypes := make(map[int]int)
        trackNALLengthSize := make(map[int]int)
        for _, t := range parser.Tracks() </span><span class="cov0" title="0">{
                trackTypes[int(t.Number)] = t.Type
                trackNALLengthSize[int(t.Number)] = matcher.NALLengthSizeForTrack(t.CodecID, t.CodecPrivate)
        }</span>

        <span class="cov0" title="0">samples := samplePackets(packets, 20)

        mkvFile, err := os.Open(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("open MKV: %w", err)
        }</span>
        <span class="cov0" title="0">defer mkvFile.Close()

        var probeHashes []matcher.ProbeHash
        for _, pkt := range samples </span><span class="cov0" title="0">{
                readSize := pkt.Size
                if readSize &gt; 4096 </span><span class="cov0" title="0">{
                        readSize = 4096
                }</span>
                <span class="cov0" title="0">if readSize &lt; int64(windowSize) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">data := make([]byte, readSize)
                n, err := mkvFile.ReadAt(data, pkt.Offset)
                if err != nil || n &lt; windowSize </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">trackType := trackTypes[int(pkt.TrackNum)]
                isVideo := trackType == mkv.TrackTypeVideo
                nalLenSize := trackNALLengthSize[int(pkt.TrackNum)]

                hashes := matcher.ExtractProbeHashes(data[:n], isVideo, windowSize, nalLenSize)
                if len(hashes) &gt; 0 </span><span class="cov0" title="0">{
                        probeHashes = append(probeHashes, hashes[0])
                }</span>
        }

        <span class="cov0" title="0">if len(probeHashes) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no valid hashes computed from sampled packets")
        }</span>

        <span class="cov0" title="0">return probeHashes, nil</span>
}

// samplePackets selects N packets distributed across the file:
// - 25% from first 10% of packets (early content)
// - 50% from middle 80% of packets (main content)
// - 25% from last 10% of packets (late content)
func samplePackets(packets []mkv.Packet, n int) []mkv.Packet <span class="cov6" title="17">{
        if len(packets) &lt;= n </span><span class="cov4" title="7">{
                return packets
        }</span>

        // Calculate distribution
        <span class="cov5" title="10">earlyCount := n / 4                    // 25% from first 10%
        lateCount := n / 4                     // 25% from last 10%
        midCount := n - earlyCount - lateCount // 50% from middle 80%

        // Calculate packet ranges
        earlyEnd := len(packets) / 10
        lateStart := len(packets) - len(packets)/10
        if earlyEnd &lt; 1 </span><span class="cov1" title="1">{
                earlyEnd = 1
        }</span>
        <span class="cov5" title="10">if lateStart &lt;= earlyEnd </span><span class="cov0" title="0">{
                lateStart = earlyEnd + 1
        }</span>

        <span class="cov5" title="10">samples := make([]mkv.Packet, 0, n)

        // Sample from early portion (first 10%)
        if earlyCount &gt; 0 &amp;&amp; earlyEnd &gt; 0 </span><span class="cov4" title="7">{
                step := earlyEnd / earlyCount
                if step &lt; 1 </span><span class="cov3" title="3">{
                        step = 1
                }</span>
                <span class="cov4" title="7">for i := 0; i &lt; earlyEnd &amp;&amp; len(samples) &lt; earlyCount; i += step </span><span class="cov8" title="56">{
                        samples = append(samples, packets[i])
                }</span>
        }

        // Sample from middle portion (middle 80%)
        <span class="cov5" title="10">midStart := earlyEnd
        midEnd := lateStart
        if midCount &gt; 0 &amp;&amp; midEnd &gt; midStart </span><span class="cov5" title="9">{
                step := (midEnd - midStart) / midCount
                if step &lt; 1 </span><span class="cov0" title="0">{
                        step = 1
                }</span>
                <span class="cov5" title="9">for i := midStart; i &lt; midEnd &amp;&amp; len(samples) &lt; earlyCount+midCount; i += step </span><span class="cov10" title="122">{
                        samples = append(samples, packets[i])
                }</span>
        }

        // Sample from late portion (last 10%)
        <span class="cov5" title="10">if lateCount &gt; 0 &amp;&amp; lateStart &lt; len(packets) </span><span class="cov4" title="6">{
                step := (len(packets) - lateStart) / lateCount
                if step &lt; 1 </span><span class="cov2" title="2">{
                        step = 1
                }</span>
                <span class="cov4" title="6">for i := lateStart; i &lt; len(packets) &amp;&amp; len(samples) &lt; n; i += step </span><span class="cov8" title="55">{
                        samples = append(samples, packets[i])
                }</span>
        }

        <span class="cov5" title="10">return samples</span>
}
</pre>
		
		<pre class="file" id="file8" style="display: none">package main

import (
        "fmt"
        "os"

        "github.com/stuckj/mkvdup/internal/dedup"
)

// fileStats holds statistics for a single dedup file.
type fileStats struct {
        name        string
        dedupFile   string
        sourceDir   string
        origSize    int64
        dedupSize   int64
        sourceType  string
        sourceFiles int
        entryCount  int
        err         error
}

// showStats displays space savings and file statistics for mkvdup-managed files.
func showStats(configPaths []string, configDir bool) error <span class="cov8" title="5">{
        resolved, err := resolveConfigPaths(configPaths, configDir)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Resolve each config independently so a single bad config doesn't
        // abort the entire stats run.
        <span class="cov8" title="5">var configs []dedup.Config
        for _, cfgPath := range resolved </span><span class="cov10" title="7">{
                cfgs, _, cfgErr := dedup.ResolveConfigs([]string{cfgPath})
                if cfgErr != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "Failed to load config %s: %v\n", cfgPath, cfgErr)
                        continue</span>
                }
                <span class="cov10" title="7">configs = append(configs, cfgs...)</span>
        }

        <span class="cov8" title="5">if len(configs) == 0 </span><span class="cov0" title="0">{
                printInfoln("No files found.")
                return nil
        }</span>

        <span class="cov8" title="5">var stats []fileStats
        for _, cfg := range configs </span><span class="cov10" title="7">{
                fs := collectFileStats(cfg)
                stats = append(stats, fs)

                if fs.err != nil </span><span class="cov4" title="2">{
                        fmt.Fprintf(os.Stderr, "%s\n  Error: %v\n\n", fs.name, fs.err)
                        continue</span>
                }

                <span class="cov8" title="5">printFileStats(fs)</span>
        }

        <span class="cov8" title="5">printRollupStats(stats)

        return nil</span>
}

// collectFileStats gathers statistics for a single dedup file from its config.
func collectFileStats(cfg dedup.Config) fileStats <span class="cov10" title="7">{
        fs := fileStats{
                name:      cfg.Name,
                dedupFile: cfg.DedupFile,
                sourceDir: cfg.SourceDir,
        }

        reader, err := dedup.NewReaderLazy(cfg.DedupFile, cfg.SourceDir)
        if err != nil </span><span class="cov4" title="2">{
                fs.err = fmt.Errorf("open dedup file: %w", err)
                return fs
        }</span>
        <span class="cov8" title="5">defer reader.Close()

        info := reader.Info()
        if errMsg, ok := info["error"]; ok </span><span class="cov0" title="0">{
                fs.err = fmt.Errorf("read dedup file: %v", errMsg)
                return fs
        }</span>

        <span class="cov8" title="5">fs.origSize = info["original_size"].(int64)
        fs.sourceFiles = info["source_file_count"].(int)
        fs.entryCount = info["entry_count"].(int)

        switch info["source_type"].(uint8) </span>{
        case 0:<span class="cov8" title="5">
                fs.sourceType = "DVD"</span>
        case 1:<span class="cov0" title="0">
                fs.sourceType = "Blu-ray"</span>
        default:<span class="cov0" title="0">
                fs.sourceType = "Unknown"</span>
        }

        <span class="cov8" title="5">dedupInfo, err := os.Stat(cfg.DedupFile)
        if err != nil </span><span class="cov0" title="0">{
                fs.err = fmt.Errorf("stat dedup file: %w", err)
                return fs
        }</span>
        <span class="cov8" title="5">fs.dedupSize = dedupInfo.Size()

        return fs</span>
}

// printFileStats prints per-file statistics.
func printFileStats(fs fileStats) <span class="cov8" title="5">{
        savings := float64(0)
        if fs.origSize &gt; 0 </span><span class="cov8" title="5">{
                savings = float64(fs.origSize-fs.dedupSize) / float64(fs.origSize) * 100
        }</span>

        <span class="cov8" title="5">printInfo("%s\n", fs.name)
        printInfo("  Original size:     %s bytes (%s)\n", formatInt(fs.origSize), formatSize(fs.origSize))
        printInfo("  Dedup file size:   %s bytes (%s)\n", formatInt(fs.dedupSize), formatSize(fs.dedupSize))
        printInfo("  Space savings:     %s bytes (%.2f%%)\n", formatInt(fs.origSize-fs.dedupSize), savings)
        printInfo("  Source type:       %s\n", fs.sourceType)
        printInfo("  Source directory:  %s\n", fs.sourceDir)
        printInfo("  Source files:      %d\n", fs.sourceFiles)
        printInfo("  Index entries:     %s\n", formatInt(int64(fs.entryCount)))
        printInfoln()</span>
}

// printRollupStats prints aggregate statistics across all successful files.
func printRollupStats(stats []fileStats) <span class="cov8" title="5">{
        var totalOrig, totalDedup int64
        var succeeded int
        uniqueSources := map[string]struct{}{}

        for _, fs := range stats </span><span class="cov10" title="7">{
                if fs.err != nil </span><span class="cov4" title="2">{
                        continue</span>
                }
                <span class="cov8" title="5">succeeded++
                totalOrig += fs.origSize
                totalDedup += fs.dedupSize
                uniqueSources[fs.sourceDir] = struct{}{}</span>
        }

        <span class="cov8" title="5">if succeeded &lt; 2 </span><span class="cov7" title="4">{
                return
        }</span>

        <span class="cov1" title="1">savings := float64(0)
        if totalOrig &gt; 0 </span><span class="cov1" title="1">{
                savings = float64(totalOrig-totalDedup) / float64(totalOrig) * 100
        }</span>

        <span class="cov1" title="1">printInfo("Totals (%d %s):\n", succeeded, plural(succeeded, "file", "files"))
        printInfo("  Original size:     %s bytes (%s)\n", formatInt(totalOrig), formatSize(totalOrig))
        printInfo("  Dedup file size:   %s bytes (%s)\n", formatInt(totalDedup), formatSize(totalDedup))
        printInfo("  Space savings:     %s bytes (%.2f%%)\n", formatInt(totalOrig-totalDedup), savings)
        printInfo("  Unique sources:    %d\n", len(uniqueSources))</span>
}
</pre>
		
		<pre class="file" id="file9" style="display: none">package main

import (
        "fmt"
        "os"
        "path"
        "path/filepath"
        "slices"
        "strings"

        "github.com/stuckj/mkvdup/internal/dedup"
)

// validationEntry tracks the result of validating a single resolved config entry.
type validationEntry struct {
        name       string // virtual file name
        status     string // "OK", "WARN", "ERR"
        message    string // detail message (empty for OK)
        configFile string // which input config file this came from
        dedupFile  string // resolved dedup file path
}

// validateConfigEntries resolves and validates each config file: YAML parsing,
// path existence checks, and dedup file header validation. Returns the
// validation entries, the successfully-parsed configs, and whether any errors
// were found.
func validateConfigEntries(configPaths []string) ([]validationEntry, []dedup.Config, bool) <span class="cov8" title="16">{
        var allEntries []validationEntry
        var allConfigs []dedup.Config
        hasErrors := false

        for _, configPath := range configPaths </span><span class="cov8" title="20">{
                fmt.Printf("Validating %s...\n", filepath.Base(configPath))

                configs, _, err := dedup.ResolveConfigs([]string{configPath})
                if err != nil </span><span class="cov2" title="2">{
                        fmt.Printf("  ERR  %s\n", err)
                        allEntries = append(allEntries, validationEntry{
                                name:       filepath.Base(configPath),
                                status:     "ERR",
                                message:    err.Error(),
                                configFile: configPath,
                        })
                        hasErrors = true
                        continue</span>
                }

                <span class="cov8" title="18">if len(configs) == 0 </span><span class="cov1" title="1">{
                        fmt.Printf("  (no entries)\n")
                        continue</span>
                }

                <span class="cov8" title="17">for _, cfg := range configs </span><span class="cov8" title="18">{
                        entry := validationEntry{
                                name:       cfg.Name,
                                status:     "OK",
                                configFile: configPath,
                                dedupFile:  cfg.DedupFile,
                        }

                        // Check dedup file exists
                        dedupStat, err := os.Stat(cfg.DedupFile)
                        if err != nil </span><span class="cov1" title="1">{
                                entry.status = "ERR"
                                entry.message = fmt.Sprintf("dedup file: %v", err)
                                fmt.Printf("  ERR  %s: %s\n", cfg.Name, entry.message)
                                allEntries = append(allEntries, entry)
                                hasErrors = true
                                continue</span>
                        }
                        <span class="cov8" title="17">if dedupStat.IsDir() </span><span class="cov0" title="0">{
                                entry.status = "ERR"
                                entry.message = fmt.Sprintf("dedup file is a directory: %s", cfg.DedupFile)
                                fmt.Printf("  ERR  %s: %s\n", cfg.Name, entry.message)
                                allEntries = append(allEntries, entry)
                                hasErrors = true
                                continue</span>
                        }

                        // Check source dir exists and is a directory
                        <span class="cov8" title="17">sourceStat, err := os.Stat(cfg.SourceDir)
                        if err != nil </span><span class="cov1" title="1">{
                                entry.status = "ERR"
                                entry.message = fmt.Sprintf("source directory: %v", err)
                                fmt.Printf("  ERR  %s: %s\n", cfg.Name, entry.message)
                                allEntries = append(allEntries, entry)
                                hasErrors = true
                                continue</span>
                        }
                        <span class="cov8" title="16">if !sourceStat.IsDir() </span><span class="cov1" title="1">{
                                entry.status = "ERR"
                                entry.message = fmt.Sprintf("source path is not a directory: %s", cfg.SourceDir)
                                fmt.Printf("  ERR  %s: %s\n", cfg.Name, entry.message)
                                allEntries = append(allEntries, entry)
                                hasErrors = true
                                continue</span>
                        }

                        // Validate dedup file header
                        <span class="cov7" title="15">reader, err := dedup.NewReaderLazy(cfg.DedupFile, cfg.SourceDir)
                        if err != nil </span><span class="cov0" title="0">{
                                entry.status = "ERR"
                                entry.message = fmt.Sprintf("invalid dedup file: %v", err)
                                fmt.Printf("  ERR  %s: %s\n", cfg.Name, entry.message)
                                allEntries = append(allEntries, entry)
                                hasErrors = true
                                continue</span>
                        }
                        <span class="cov7" title="15">reader.Close()

                        allEntries = append(allEntries, entry)
                        allConfigs = append(allConfigs, cfg)</span>
                }
        }

        <span class="cov8" title="16">return allEntries, allConfigs, hasErrors</span>
}

// checkNameConflicts validates virtual file paths and detects duplicate names
// and file/directory conflicts across all entries. Updates entry statuses
// in-place and returns whether any errors or warnings were found.
func checkNameConflicts(entries []validationEntry) (hasErrors, hasWarnings bool) <span class="cov8" title="16">{
        nameToConfig := make(map[string]string)   // clean path -&gt; config file
        dirComponents := make(map[string]string)  // paths used as directories -&gt; config file
        fileComponents := make(map[string]string) // paths used as files -&gt; config file

        for i, entry := range entries </span><span class="cov8" title="20">{
                if entry.status == "ERR" </span><span class="cov5" title="5">{
                        continue</span>
                }

                <span class="cov7" title="15">name := entry.name

                // Check for ".." path components
                if slices.Contains(strings.Split(name, "/"), "..") </span><span class="cov1" title="1">{
                        entries[i].status = "ERR"
                        entries[i].message = "invalid path: contains '..' component"
                        fmt.Printf("  ERR  %s: %s\n", name, entries[i].message)
                        hasErrors = true
                        continue</span>
                }

                // Clean and validate the path (same logic as tree.go insertFile)
                <span class="cov7" title="14">cleanPath := cleanVirtualPath(name)
                if cleanPath == "" </span><span class="cov1" title="1">{
                        entries[i].status = "ERR"
                        entries[i].message = "invalid path: empty after cleaning"
                        fmt.Printf("  ERR  %s: %s\n", name, entries[i].message)
                        hasErrors = true
                        continue</span>
                }

                // Check for duplicate names
                <span class="cov7" title="13">if prevConfig, exists := nameToConfig[cleanPath]; exists </span><span class="cov2" title="2">{
                        entries[i].status = "WARN"
                        entries[i].message = fmt.Sprintf("duplicate name (also in %s)", filepath.Base(prevConfig))
                        fmt.Printf("  WARN %s: %s\n", name, entries[i].message)
                        hasWarnings = true
                        continue</span>
                }
                <span class="cov7" title="11">nameToConfig[cleanPath] = entry.configFile

                // Check for file/directory conflicts
                parts := strings.Split(cleanPath, "/")
                conflictFound := false

                // Check if any prefix of this path is used as a file
                for j := 0; j &lt; len(parts)-1; j++ </span><span class="cov1" title="1">{
                        dirPath := strings.Join(parts[:j+1], "/")
                        if prevConfig, exists := fileComponents[dirPath]; exists </span><span class="cov1" title="1">{
                                entries[i].status = "WARN"
                                entries[i].message = fmt.Sprintf("path component %q conflicts with file in %s", dirPath, filepath.Base(prevConfig))
                                fmt.Printf("  WARN %s: %s\n", name, entries[i].message)
                                hasWarnings = true
                                conflictFound = true
                                break</span>
                        }
                        // Record as directory component
                        <span class="cov0" title="0">if _, exists := dirComponents[dirPath]; !exists </span><span class="cov0" title="0">{
                                dirComponents[dirPath] = entry.configFile
                        }</span>
                }
                <span class="cov7" title="11">if conflictFound </span><span class="cov1" title="1">{
                        continue</span>
                }

                // Check if this file name conflicts with a directory
                <span class="cov6" title="10">if prevConfig, exists := dirComponents[cleanPath]; exists </span><span class="cov0" title="0">{
                        entries[i].status = "WARN"
                        entries[i].message = fmt.Sprintf("conflicts with directory from %s", filepath.Base(prevConfig))
                        fmt.Printf("  WARN %s: %s\n", name, entries[i].message)
                        hasWarnings = true
                        continue</span>
                }

                <span class="cov6" title="10">fileComponents[cleanPath] = entry.configFile

                // Print OK for entries that passed all checks
                if entries[i].status == "OK" </span><span class="cov6" title="10">{
                        fmt.Printf("  OK   %s\n", name)
                }</span>
        }

        <span class="cov8" title="16">return hasErrors, hasWarnings</span>
}

// runDeepValidation performs integrity verification on dedup files that passed
// basic validation. Returns whether any errors were found.
func runDeepValidation(entries []validationEntry, configs []dedup.Config) bool <span class="cov2" title="2">{
        fmt.Println()
        fmt.Println("Running deep validation...")
        hasErrors := false
        for _, cfg := range configs </span><span class="cov2" title="2">{
                // Only deep-validate entries that passed basic validation
                entryOK := false
                for _, e := range entries </span><span class="cov2" title="2">{
                        if e.name == cfg.Name &amp;&amp; e.dedupFile == cfg.DedupFile &amp;&amp; e.status != "ERR" </span><span class="cov2" title="2">{
                                entryOK = true
                                break</span>
                        }
                }
                <span class="cov2" title="2">if !entryOK </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov2" title="2">reader, err := dedup.NewReader(cfg.DedupFile, cfg.SourceDir)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("  ERR  %s: failed to open: %v\n", cfg.Name, err)
                        hasErrors = true
                        continue</span>
                }
                <span class="cov2" title="2">if err := reader.VerifyIntegrity(); err != nil </span><span class="cov1" title="1">{
                        fmt.Printf("  ERR  %s: integrity check failed: %v\n", cfg.Name, err)
                        reader.Close()
                        hasErrors = true
                        continue</span>
                }
                <span class="cov1" title="1">reader.Close()
                fmt.Printf("  OK   %s: checksums valid\n", cfg.Name)</span>
        }
        <span class="cov2" title="2">return hasErrors</span>
}

// validateConfigs validates configuration files and returns an exit code.
// Returns 0 if all configs are valid (warnings OK without strict), 1 otherwise.
func validateConfigs(configPaths []string, configDir, deep, strict bool) int <span class="cov8" title="16">{
        resolved, err := resolveConfigPaths(configPaths, configDir)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "Error: %v\n", err)
                return 1
        }</span>

        <span class="cov8" title="16">allEntries, allConfigs, hasErrors := validateConfigEntries(resolved)

        nameErrors, hasWarnings := checkNameConflicts(allEntries)
        hasErrors = hasErrors || nameErrors

        if deep </span><span class="cov2" title="2">{
                hasErrors = hasErrors || runDeepValidation(allEntries, allConfigs)
        }</span>

        // Print summary
        <span class="cov8" title="16">var okCount, warnCount, errCount int
        for _, e := range allEntries </span><span class="cov8" title="20">{
                switch e.status </span>{
                case "OK":<span class="cov6" title="10">
                        okCount++</span>
                case "WARN":<span class="cov3" title="3">
                        warnCount++</span>
                case "ERR":<span class="cov6" title="7">
                        errCount++</span>
                }
        }

        <span class="cov8" title="16">fmt.Println()
        fmt.Printf("Summary: %d %s, %d valid, %d %s, %d %s\n",
                len(allEntries), plural(len(allEntries), "entry", "entries"),
                okCount,
                warnCount, plural(warnCount, "warning", "warnings"),
                errCount, plural(errCount, "error", "errors"))

        if hasErrors </span><span class="cov6" title="8">{
                return 1
        }</span>
        <span class="cov6" title="8">if strict &amp;&amp; hasWarnings </span><span class="cov1" title="1">{
                return 1
        }</span>
        <span class="cov6" title="7">return 0</span>
}

// cleanVirtualPath normalizes a virtual file path, matching the logic in
// internal/fuse/tree.go insertFile(). Returns empty string if the path is invalid.
func cleanVirtualPath(name string) string <span class="cov9" title="23">{
        // Clean the path using path.Clean (not filepath.Clean) to match
        // internal/fuse/tree.go insertFile() which uses forward-slash paths.
        cleaned := path.Clean(name)
        // Split and filter
        parts := strings.Split(cleaned, "/")
        var valid []string
        for _, p := range parts </span><span class="cov10" title="33">{
                if p != "" &amp;&amp; p != "." </span><span class="cov9" title="26">{
                        valid = append(valid, p)
                }</span>
        }
        <span class="cov9" title="23">if len(valid) == 0 </span><span class="cov4" title="4">{
                return ""
        }</span>
        <span class="cov8" title="19">return strings.Join(valid, "/")</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">package main

import (
        "bytes"
        "fmt"
        "io"
        "os"
        "path/filepath"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/source"
)

// verifyReconstruction verifies that the dedup file can reconstruct the original MKV.
// Set verbose=true to enable debug output for troubleshooting.
// If phasePrefix is non-empty, a progress bar is shown.
func verifyReconstruction(dedupPath, sourceDir, originalPath string, index *source.Index, verbose bool, phasePrefix string) error <span class="cov0" title="0">{
        reader, err := dedup.NewReader(dedupPath, sourceDir)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open dedup file: %w", err)
        }</span>
        <span class="cov0" title="0">defer reader.Close()

        if err := reader.LoadSourceFiles(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("load source files: %w", err)
        }</span>

        // Open original MKV
        <span class="cov0" title="0">original, err := os.Open(originalPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open original: %w", err)
        }</span>
        <span class="cov0" title="0">defer original.Close()

        // Debug: show first few bytes comparison (controlled by verbose flag)
        if verbose </span><span class="cov0" title="0">{
                origFirst := make([]byte, 32)
                reconFirst := make([]byte, 32)
                n, _ := original.ReadAt(origFirst, 0)
                fmt.Printf("  Debug: Original ReadAt(32, 0) returned %d bytes\n", n)
                n, _ = reader.ReadAt(reconFirst, 0)
                fmt.Printf("  Debug: Reader ReadAt(32, 0) returned %d bytes\n", n)
                fmt.Printf("  Debug: Original first 32 bytes:      %x\n", origFirst)
                fmt.Printf("  Debug: Reconstructed first 32 bytes: %x\n", reconFirst)
                original.Seek(0, 0) // Reset file position
        }</span>

        <span class="cov0" title="0">totalSize := reader.OriginalSize()
        var bar *progressBar
        if phasePrefix != "" </span><span class="cov0" title="0">{
                bar = newProgressBar(phasePrefix, totalSize, "bytes")
                defer bar.Cancel() // clean up if we return early on error
        }</span>

        // Compare chunk by chunk
        <span class="cov0" title="0">const chunkSize = 1024 * 1024 // 1MB
        originalBuf := make([]byte, chunkSize)
        reconstructedBuf := make([]byte, chunkSize)

        var offset int64
        for </span><span class="cov0" title="0">{
                n1, err1 := original.Read(originalBuf)
                if n1 == 0 &amp;&amp; err1 == io.EOF </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">n2, err2 := reader.ReadAt(reconstructedBuf[:n1], offset)

                if verbose &amp;&amp; offset == 0 </span><span class="cov0" title="0">{
                        fmt.Printf("  Debug: Loop first read - n1=%d, n2=%d, err1=%v, err2=%v\n", n1, n2, err1, err2)
                        fmt.Printf("  Debug: originalBuf first 32:      %x\n", originalBuf[:32])
                        fmt.Printf("  Debug: reconstructedBuf first 32: %x\n", reconstructedBuf[:32])
                }</span>

                <span class="cov0" title="0">if n1 != n2 </span><span class="cov0" title="0">{
                        return fmt.Errorf("size mismatch at offset %d: original=%d, reconstructed=%d", offset, n1, n2)
                }</span>

                <span class="cov0" title="0">if !bytes.Equal(originalBuf[:n1], reconstructedBuf[:n2]) </span><span class="cov0" title="0">{
                        // Find first mismatch
                        for i := 0; i &lt; n1; i++ </span><span class="cov0" title="0">{
                                if originalBuf[i] != reconstructedBuf[i] </span><span class="cov0" title="0">{
                                        return fmt.Errorf("data mismatch at offset %d (orig: %02x, recon: %02x)",
                                                offset+int64(i), originalBuf[i], reconstructedBuf[i])
                                }</span>
                        }
                }

                <span class="cov0" title="0">offset += int64(n1)
                if bar != nil </span><span class="cov0" title="0">{
                        bar.Update(offset)
                }</span>

                <span class="cov0" title="0">if err1 != nil &amp;&amp; err1 != io.EOF </span><span class="cov0" title="0">{
                        return fmt.Errorf("read original at %d: %w", offset, err1)
                }</span>
                <span class="cov0" title="0">if err2 != nil &amp;&amp; err2 != io.EOF </span><span class="cov0" title="0">{
                        return fmt.Errorf("read reconstructed at %d: %w", offset, err2)
                }</span>
        }

        <span class="cov0" title="0">if bar != nil </span><span class="cov0" title="0">{
                bar.Finish()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// openDedupReader opens a dedup file with its source directory, verifies
// integrity, loads source files, and checks source file sizes. This is the
// shared preamble for verify, extract, and similar commands.
func openDedupReader(dedupPath, sourceDir string) (*dedup.Reader, error) <span class="cov10" title="2">{
        reader, err := dedup.NewReader(dedupPath, sourceDir)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("open dedup file: %w", err)
        }</span>

        <span class="cov10" title="2">printInfo("Verifying dedup file checksums...")
        if err := reader.VerifyIntegrity(); err != nil </span><span class="cov0" title="0">{
                printInfoln(" FAILED")
                reader.Close()
                return nil, fmt.Errorf("integrity check: %w", err)
        }</span>
        <span class="cov10" title="2">printInfoln(" OK")

        if err := reader.LoadSourceFiles(); err != nil </span><span class="cov0" title="0">{
                reader.Close()
                return nil, fmt.Errorf("load source files: %w", err)
        }</span>

        <span class="cov10" title="2">printInfo("Verifying source files...")
        for _, sf := range reader.SourceFiles() </span><span class="cov10" title="2">{
                path := filepath.Join(sourceDir, sf.RelativePath)
                stat, err := os.Stat(path)
                if err != nil </span><span class="cov0" title="0">{
                        printInfoln(" FAILED")
                        reader.Close()
                        return nil, fmt.Errorf("source file %s: %w", sf.RelativePath, err)
                }</span>
                <span class="cov10" title="2">if stat.Size() != sf.Size </span><span class="cov0" title="0">{
                        printInfoln(" FAILED")
                        reader.Close()
                        return nil, fmt.Errorf("source file %s size mismatch: expected %d, got %d",
                                sf.RelativePath, sf.Size, stat.Size())
                }</span>
        }
        <span class="cov10" title="2">printInfoln(" OK")

        return reader, nil</span>
}

// verifyDedup verifies a dedup file against the original MKV.
func verifyDedup(dedupPath, sourceDir, originalPath string) error <span class="cov0" title="0">{
        printInfo("Verifying dedup file: %s\n", dedupPath)
        printInfo("Source directory:     %s\n", sourceDir)
        printInfo("Original MKV:         %s\n", originalPath)
        printInfoln()

        reader, err := openDedupReader(dedupPath, sourceDir)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer reader.Close()

        // Verify reconstruction matches original
        original, err := os.Open(originalPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open original: %w", err)
        }</span>
        <span class="cov0" title="0">defer original.Close()

        totalSize := reader.OriginalSize()
        bar := newProgressBar("Verifying reconstruction...", totalSize, "bytes")
        defer bar.Cancel() // clean up if we return early on error

        const chunkSize = 4 * 1024 * 1024
        originalBuf := make([]byte, chunkSize)
        reconstructedBuf := make([]byte, chunkSize)
        var offset int64

        for offset &lt; totalSize </span><span class="cov0" title="0">{
                remaining := totalSize - offset
                readSize := int64(chunkSize)
                if readSize &gt; remaining </span><span class="cov0" title="0">{
                        readSize = remaining
                }</span>

                <span class="cov0" title="0">n1, err1 := original.Read(originalBuf[:readSize])
                n2, err2 := reader.ReadAt(reconstructedBuf[:readSize], offset)

                if n1 != n2 </span><span class="cov0" title="0">{
                        return fmt.Errorf("size mismatch at offset %d", offset)
                }</span>

                <span class="cov0" title="0">if !bytes.Equal(originalBuf[:n1], reconstructedBuf[:n2]) </span><span class="cov0" title="0">{
                        for i := 0; i &lt; n1; i++ </span><span class="cov0" title="0">{
                                if originalBuf[i] != reconstructedBuf[i] </span><span class="cov0" title="0">{
                                        return fmt.Errorf("data mismatch at offset %d", offset+int64(i))
                                }</span>
                        }
                }

                <span class="cov0" title="0">if err1 != nil &amp;&amp; err1 != io.EOF </span><span class="cov0" title="0">{
                        return fmt.Errorf("read original: %w", err1)
                }</span>
                <span class="cov0" title="0">if err2 != nil &amp;&amp; err2 != io.EOF </span><span class="cov0" title="0">{
                        return fmt.Errorf("read reconstructed: %w", err2)
                }</span>

                <span class="cov0" title="0">offset += int64(n1)
                bar.Update(offset)</span>
        }
        <span class="cov0" title="0">bar.Finish()

        printInfoln()
        printInfoln("Verification PASSED")
        return nil</span>
}

// extractDedup rebuilds the original MKV from a dedup file and source.
func extractDedup(dedupPath, sourceDir, outputPath string) (retErr error) <span class="cov10" title="2">{
        printInfo("Dedup file:        %s\n", dedupPath)
        printInfo("Source directory:  %s\n", sourceDir)
        printInfo("Output MKV:        %s\n", outputPath)
        printInfoln()

        reader, err := openDedupReader(dedupPath, sourceDir)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov10" title="2">defer reader.Close()

        out, err := os.Create(outputPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create output file: %w", err)
        }</span>
        <span class="cov10" title="2">defer func() </span><span class="cov10" title="2">{
                // Only close if not already closed by the success path below.
                // On error, clean up the partial output file.
                if retErr != nil </span><span class="cov1" title="1">{
                        out.Close()
                        os.Remove(outputPath)
                }</span>
        }()

        <span class="cov10" title="2">totalSize := reader.OriginalSize()
        bar := newProgressBar("Extracting...", totalSize, "bytes")
        defer bar.Cancel() // clean up if we return early on error

        const chunkSize = 4 * 1024 * 1024
        buf := make([]byte, chunkSize)
        var offset int64

        for offset &lt; totalSize </span><span class="cov10" title="2">{
                remaining := totalSize - offset
                readSize := int64(chunkSize)
                if readSize &gt; remaining </span><span class="cov10" title="2">{
                        readSize = remaining
                }</span>

                <span class="cov10" title="2">n, err := reader.ReadAt(buf[:readSize], offset)
                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        return fmt.Errorf("read at offset %d: %w", offset, err)
                }</span>

                <span class="cov10" title="2">if n == 0 </span><span class="cov1" title="1">{
                        return fmt.Errorf("unexpected EOF at offset %d (expected %d bytes)", offset, totalSize)
                }</span>

                <span class="cov1" title="1">if _, err := out.Write(buf[:n]); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("write at offset %d: %w", offset, err)
                }</span>

                <span class="cov1" title="1">offset += int64(n)
                bar.Update(offset)</span>
        }
        <span class="cov1" title="1">bar.Finish()

        if err := out.Close(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("close output: %w", err)
        }</span>

        <span class="cov1" title="1">printInfo("\nExtracted %s bytes to %s\n", formatInt(totalSize), outputPath)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file11" style="display: none">package main

import (
        "fmt"
        "os"
)

func printUsage() <span class="cov3" title="2">{
        fmt.Print(`mkvdup - MKV deduplication tool using FUSE

Usage: mkvdup [options] &lt;command&gt; [args...]

Commands:
  create       Create dedup file from MKV + source directory
  batch-create Create multiple dedup files from one source
  probe        Quick test if MKV matches source(s)
  mount        Mount dedup files as FUSE filesystem
  info         Show dedup file information
  verify       Verify dedup file against original MKV
  extract      Rebuild original MKV from dedup + source
  check        Check dedup + source file integrity
  stats        Show space savings and file statistics
  validate     Validate configuration files
  reload       Reload running daemon's configuration

Analysis commands:
  deltadiag    Analyze unmatched regions by stream type

Debug commands:
  parse-mkv    Parse MKV and show packet info
  index-source Index source directory
  match        Match MKV packets to source

Options:
  -v, --verbose      Enable verbose output
  -q, --quiet        Suppress informational progress output
  --no-progress      Disable progress bars (still show status messages)
  --log-file PATH    Duplicate output to a log file (non-TTY style)
  -h, --help         Show help
  --version          Show version
`)
        fmt.Print(debugOptionsHelp())
        fmt.Print(`Run 'mkvdup &lt;command&gt; --help' for more information on a command.
See 'man mkvdup' for detailed documentation.
`)
}</span>

func printCommandUsage(cmd string) <span class="cov10" title="13">{
        switch cmd </span>{
        case "create":<span class="cov1" title="1">
                printCreateUsage()</span>
        case "batch-create":<span class="cov1" title="1">
                printBatchCreateUsage()</span>
        case "probe":<span class="cov1" title="1">
                printProbeUsage()</span>
        case "mount":<span class="cov1" title="1">
                printMountUsage()</span>
        case "info":<span class="cov1" title="1">
                printInfoUsage()</span>
        case "verify":<span class="cov1" title="1">
                printVerifyUsage()</span>
        case "extract":<span class="cov1" title="1">
                printExtractUsage()</span>
        case "check":<span class="cov0" title="0">
                printCheckUsage()</span>
        case "stats":<span class="cov1" title="1">
                printStatsUsage()</span>
        case "validate":<span class="cov0" title="0">
                printValidateUsage()</span>
        case "reload":<span class="cov1" title="1">
                printReloadUsage()</span>
        case "deltadiag":<span class="cov0" title="0">
                printDeltadiagUsage()</span>
        case "parse-mkv":<span class="cov1" title="1">
                printParseMKVUsage()</span>
        case "index-source":<span class="cov1" title="1">
                printIndexSourceUsage()</span>
        case "match":<span class="cov1" title="1">
                printMatchUsage()</span>
        default:<span class="cov1" title="1">
                printUsage()</span>
        }
}

func printCreateUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup create [options] &lt;mkv-file&gt; &lt;source-dir&gt; &lt;output&gt; [name]

Create a dedup file from an MKV and its source media.

Arguments:
    &lt;mkv-file&gt;    Path to the MKV file to deduplicate
    &lt;source-dir&gt;  Directory containing source media (ISO files or BDMV folders)
    &lt;output&gt;      Output .mkvdup file path
    [name]        Display name in FUSE mount (default: basename of mkv-file;
                  .mkv extension auto-added if missing)

Options:
    -v, --verbose       Enable verbose/debug output
    --warn-threshold N  Minimum space savings percentage to avoid warning (default: 75)
    --non-interactive   Don't prompt on codec mismatch (show warning and continue)

Before matching, codecs in the MKV are compared against the source media.
If a mismatch is detected (e.g., MKV has H.264 but source is MPEG-2), you
will be prompted to continue. Use --non-interactive for scripted usage.

Examples:
    mkvdup create movie.mkv /media/dvd-backups movie.mkvdup
    mkvdup create movie.mkv /media/dvd-backups movie.mkvdup "My Movie"
    mkvdup create --warn-threshold 50 movie.mkv /media/dvd-backups movie.mkvdup
    mkvdup create --non-interactive movie.mkv /media/dvd-backups movie.mkvdup
`)
}</span>

func printBatchCreateUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup batch-create [options] &lt;manifest.yaml&gt;

Create multiple dedup files from a YAML manifest. Files sharing the same
source directory are grouped and the source is indexed once per group.

Codec compatibility is checked for each file. If a mismatch is detected,
a warning is printed but processing continues (non-interactive mode).
Use --skip-codec-mismatch to skip mismatched files instead.

Arguments:
    &lt;manifest.yaml&gt;  YAML manifest file specifying source(s) and MKV files

Options:
    -v, --verbose          Enable verbose/debug output
    --warn-threshold N     Minimum space savings percentage to avoid warning (default: 75)
    --skip-codec-mismatch  Skip MKVs with codec mismatch instead of processing them

Manifest format:
    source_dir: /media/dvd-backups/disc1   # default for all files (optional)
    files:
      - mkv: episode1.mkv
        output: episode1.mkvdup
        name: "Show/S01/Episode 1"         # optional (.mkv auto-added)
      - mkv: episode2.mkv
        output: episode2.mkvdup
      - mkv: movie.mkv
        output: movie.mkvdup
        source_dir: /media/dvd-backups/disc2  # per-file override

Fields:
    source_dir          Default source directory (optional if all files specify their own)
    files               List of MKV files to process (required, at least one)
    files[].mkv         Path to MKV file (required)
    files[].output      Output .mkvdup file (required)
    files[].source_dir  Source directory for this file (overrides top-level default)
    files[].name        Display name in FUSE mount (default: basename of mkv;
                        .mkv extension auto-added if missing)

Relative paths are resolved against the manifest file's directory.

Examples:
    mkvdup batch-create episodes.yaml
    mkvdup batch-create --warn-threshold 50 episodes.yaml
    mkvdup batch-create --skip-codec-mismatch episodes.yaml
`)
}</span>

func printProbeUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup probe &lt;mkv-file&gt;... -- &lt;source-dir&gt;...

Quick test to check if MKV file(s) match one or more source directories.
When multiple MKVs are provided, each source is indexed only once.

Arguments:
    &lt;mkv-file&gt;    One or more MKV files to test (before --)
    --            Separator between MKV files and source directories
    &lt;source-dir&gt;  One or more directories to test against (after --)

For backward compatibility, a single MKV without -- is also supported:
    mkvdup probe movie.mkv /media/disc1 /media/disc2

Examples:
    mkvdup probe movie.mkv /media/disc1 /media/disc2
    mkvdup probe ep1.mkv ep2.mkv ep3.mkv -- /media/disc1 /media/disc2
`)
}</span>

func printMountUsage() <span class="cov1" title="1">{
        os.Stdout.WriteString(`Usage: mkvdup mount [options] &lt;mountpoint&gt; [config.yaml...]

Mount dedup files as a FUSE filesystem.

Arguments:
    &lt;mountpoint&gt;   Directory to mount the filesystem
    [config.yaml]  YAML config files (default: /etc/mkvdup.conf)

Options:
    --allow-other          Allow other users to access the mount
    --foreground           Run in foreground (for debugging or systemd)
    --config-dir           Treat config argument as directory of YAML files (.yaml, .yml)
    --pid-file PATH        Write daemon PID to file
    --daemon-timeout DUR   Timeout waiting for daemon startup (default: 30s)

Permission Options:
    --default-uid UID          Default UID for files and directories (default: calling user's UID)
    --default-gid GID          Default GID for files and directories (default: calling user's GID)
    --default-file-mode MODE   Default mode for files (octal, default: 0444)
    --default-dir-mode MODE    Default mode for directories (octal, default: 0555)
    --permissions-file PATH    Path to permissions file (overrides default locations)

Source Watch Options:
    --no-source-watch                    Disable source file monitoring (enabled by default)
    --on-source-change ACTION            Action on source change: warn, disable, checksum (default)
                                         warn     - log a warning
                                         disable  - disable affected virtual files (reads return EIO)
                                         checksum - size change: disable immediately
                                                    timestamp-only: verify checksum in background,
                                                    disable on mismatch, re-enable on pass
    --source-watch-poll-interval DUR     Poll interval for source file changes (default: 60s)
    --source-read-timeout DUR            Read timeout for network FS sources (default: 30s)

Error Notification (configured in YAML config, not CLI):
    on_error_command:
      command: ["/path/to/script", "%source%", "%event%", "%files%"]
      timeout: 30s          # command timeout (default: 30s)
      batch_interval: 5s    # debounce window for batching events (default: 5s)
    Placeholders: %source% (path), %files% (affected files), %event% (error type)
    String form (sh -c) auto-escapes placeholders; do not add your own quotes.
    See docs/FUSE.md for details.

By default, mkvdup daemonizes after the mount is ready and returns.
Use --foreground to keep it attached to the terminal.

Permission files are searched in order:
  1. --permissions-file (if specified)
  2. ~/.config/mkvdup/permissions.yaml (if exists)
  3. /etc/mkvdup/permissions.yaml (if exists)
New permissions are written to ~/.config/mkvdup/permissions.yaml (user) or
/etc/mkvdup/permissions.yaml (root).

Examples:
    mkvdup mount /mnt/videos movie.mkvdup.yaml
    mkvdup mount /mnt/videos *.yaml
    mkvdup mount --allow-other /mnt/videos
    mkvdup mount --config-dir /mnt/videos /etc/mkvdup.d/
    mkvdup mount --foreground /mnt/videos config.yaml
    mkvdup mount --default-uid 1000 --default-gid 1000 /mnt/videos config.yaml
    mkvdup mount --source-watch-poll-interval 10s /mnt/videos config.yaml
    mkvdup mount --source-read-timeout 1m /mnt/videos config.yaml
`)
}</span>

func printInfoUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup info [options] &lt;dedup-file&gt;

Show information about a dedup file.

Arguments:
    &lt;dedup-file&gt;  Path to the .mkvdup file

Options:
    --hide-unused-files  Hide source files not referenced by any index entry

Examples:
    mkvdup info movie.mkvdup
    mkvdup info --hide-unused-files movie.mkvdup
`)
}</span>

func printVerifyUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup verify &lt;dedup-file&gt; &lt;source-dir&gt; &lt;original-mkv&gt;

Verify that a dedup file correctly reconstructs the original MKV.

Arguments:
    &lt;dedup-file&gt;    Path to the .mkvdup file
    &lt;source-dir&gt;    Directory containing the source media
    &lt;original-mkv&gt;  Path to the original MKV for comparison

Examples:
    mkvdup verify movie.mkvdup /media/dvd-backups original.mkv
`)
}</span>

func printExtractUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup extract &lt;dedup-file&gt; &lt;source-dir&gt; &lt;output-mkv&gt;

Rebuild the original MKV from a dedup file and source media.

Arguments:
    &lt;dedup-file&gt;    Path to the .mkvdup file
    &lt;source-dir&gt;    Directory containing the source media
    &lt;output-mkv&gt;    Path for the reconstructed MKV file

Examples:
    mkvdup extract movie.mkvdup /media/dvd-backups restored-movie.mkv
`)
}</span>

func printCheckUsage() <span class="cov0" title="0">{
        fmt.Print(`Usage: mkvdup check &lt;dedup-file&gt; &lt;source-dir&gt; [options]

Check integrity of a dedup file and its source files.

Arguments:
    &lt;dedup-file&gt;  Path to the .mkvdup file
    &lt;source-dir&gt;  Directory containing the source media

Options:
    --source-checksums  Verify source file checksums (slow, reads entire files)

Checks performed:
    - Dedup file header validity (magic, version, structure)
    - Index and delta checksum verification
    - Source file existence and size
    With --source-checksums:
    - Source file checksum verification (reads entire files)

Examples:
    mkvdup check movie.mkvdup /media/dvd-backups
    mkvdup check --source-checksums movie.mkvdup /media/dvd-backups
`)
}</span>

func printStatsUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup stats [options] &lt;config.yaml...&gt;

Show space savings and file statistics for mkvdup-managed files.

Arguments:
    &lt;config.yaml&gt;  YAML config files (same format as mount/validate)

Options:
    --config-dir   Treat config argument as directory of YAML files (.yaml, .yml)

Output includes per-file statistics (original size, dedup file size, space
savings, source type) and a rollup summary when multiple files are present.

Examples:
    mkvdup stats config.yaml
    mkvdup stats --config-dir /etc/mkvdup.d/
    mkvdup stats movie1.yaml movie2.yaml
`)
}</span>

func printValidateUsage() <span class="cov0" title="0">{
        fmt.Print(`Usage: mkvdup validate [options] &lt;config.yaml...&gt;

Validate configuration files for correctness before mounting.

Arguments:
    &lt;config.yaml&gt;  YAML config files to validate

Options:
    --config-dir   Treat config argument as directory of YAML files (.yaml, .yml)
    --deep         Verify dedup file headers and internal checksums
    --strict       Treat warnings as errors (exit 1 on warnings)

Validations performed:
    - YAML syntax and required fields (name, dedup_file, source_dir)
    - Include cycle detection
    - Dedup file existence and header validity
    - Source directory existence
    - Duplicate virtual file names (warning)
    - File/directory path conflicts (warning)
    - Invalid path names (empty, contains "..")
    With --deep:
    - Dedup file internal checksum verification

Exit codes:
    0  All configs valid (warnings may be present)
    1  Errors found (or warnings with --strict)

Examples:
    mkvdup validate config.yaml
    mkvdup validate *.yaml
    mkvdup validate --config-dir /etc/mkvdup.d/
    mkvdup validate --deep --strict /etc/mkvdup.conf
`)
}</span>

func printReloadUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup reload {--pid-file PATH | --pid PID} [options] [config.yaml...]

Reload a running daemon's configuration by validating the config
and sending SIGHUP to the daemon process.

The config is validated BEFORE sending the signal. If validation
fails, the signal is not sent and the error is reported.

If no config files are specified, the signal is sent without
pre-validation (the daemon validates internally on SIGHUP).

Arguments:
    [config.yaml]  Config files to validate (same as mount's config args)

Required (one of):
    --pid-file PATH    PID file of running daemon (must match mount's --pid-file)
    --pid PID          PID of the running daemon (e.g., for foreground mode)

Options:
    --config-dir       Treat config argument as directory of YAML files

Examples:
    mkvdup reload --pid-file /run/mkvdup.pid config.yaml
    mkvdup reload --pid-file /run/mkvdup.pid --config-dir /etc/mkvdup.d/
    mkvdup reload --pid-file /run/mkvdup.pid
    mkvdup reload --pid $(pidof mkvdup)
`)
}</span>

func printDeltadiagUsage() <span class="cov0" title="0">{
        fmt.Print(`Usage: mkvdup deltadiag &lt;dedup-file&gt; &lt;mkv-file&gt;

Analyze unmatched (delta) regions in a dedup file by cross-referencing
with the original MKV to determine what stream type each delta region
belongs to (video, audio, or container overhead).

For video delta, further classifies by H.264 NAL type (IDR/non-IDR slices,
SEI, SPS, PPS, etc.) and shows size breakdown.

Works with dedup file versions 3 through 8 (DVD, Blu-ray, and newer).

Arguments:
    &lt;dedup-file&gt;  Path to the .mkvdup file
    &lt;mkv-file&gt;    Path to the original MKV file

Examples:
    mkvdup deltadiag movie.mkvdup movie.mkv
`)
}</span>

func printParseMKVUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup parse-mkv &lt;mkv-file&gt;

Parse an MKV file and display packet information (debugging).

Arguments:
    &lt;mkv-file&gt;  Path to the MKV file to parse

Examples:
    mkvdup parse-mkv movie.mkv
`)
}</span>

func printIndexSourceUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup index-source &lt;source-dir&gt;

Index a source directory and display statistics (debugging).

Arguments:
    &lt;source-dir&gt;  Directory containing source media (ISO files or BDMV folders)

Examples:
    mkvdup index-source /media/dvd-backups
`)
}</span>

func printMatchUsage() <span class="cov1" title="1">{
        fmt.Print(`Usage: mkvdup match &lt;mkv-file&gt; &lt;source-dir&gt;

Match MKV packets to source and show detailed results (debugging).

Arguments:
    &lt;mkv-file&gt;    Path to the MKV file
    &lt;source-dir&gt;  Directory containing source media

Examples:
    mkvdup match movie.mkv /media/dvd-backups
`)
}</span>
</pre>
		
		<pre class="file" id="file12" style="display: none">// Command mkvdup is the CLI tool for MKV-ISO deduplication.
package main

import (
        "fmt"
        "log"
        "os"
        "strconv"
        "strings"
        "time"

        "github.com/stuckj/mkvdup/internal/daemon"
        "github.com/stuckj/mkvdup/internal/dedup"
)

// MountOptions holds all options for the mount command.
type MountOptions struct {
        AllowOther              bool
        Foreground              bool
        ConfigDir               bool
        PidFile                 string
        DaemonTimeout           time.Duration
        PermissionsFile         string
        DefaultUID              uint32
        DefaultGID              uint32
        DefaultFileMode         uint32
        DefaultDirMode          uint32
        NoSourceWatch           bool                      // Disable source file watching
        OnSourceChange          string                    // Action on source change: "warn", "disable", "checksum"
        SourceWatchPollInterval time.Duration             // Poll interval for network FS source watching (0 = 60s default)
        SourceReadTimeout       time.Duration             // Pread timeout for network FS sources (0 = disabled; CLI default 30s)
        OnErrorCommand          *dedup.ErrorCommandConfig // External command to run on source integrity error (from YAML config)
}

// parseUint32 parses a string as uint32.
func parseUint32(s string) (uint32, error) <span class="cov8" title="8">{
        v, err := strconv.ParseUint(s, 10, 32)
        if err != nil </span><span class="cov6" title="4">{
                return 0, err
        }</span>
        <span class="cov6" title="4">return uint32(v), nil</span>
}

// parseOctalMode parses a string as an octal file mode.
func parseOctalMode(s string) (uint32, error) <span class="cov9" title="10">{
        // Strip leading 0 prefix for octal if present
        v, err := strconv.ParseUint(s, 8, 32)
        if err != nil </span><span class="cov4" title="3">{
                return 0, err
        }</span>
        <span class="cov8" title="7">return uint32(v), nil</span>
}

// parseWarnFlags extracts --warn-threshold from args, returning the
// parsed value and the remaining positional arguments.
func parseWarnFlags(args []string) (warnThreshold float64, remaining []string) <span class="cov6" title="5">{
        warnThreshold = 75.0
        for i := 0; i &lt; len(args); i++ </span><span class="cov10" title="12">{
                switch args[i] </span>{
                case "--warn-threshold":<span class="cov6" title="4">
                        if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov6" title="4">{
                                v, err := strconv.ParseFloat(args[i+1], 64)
                                if err != nil </span><span class="cov0" title="0">{
                                        log.Fatalf("Error: --warn-threshold invalid: %v", err)
                                }</span>
                                <span class="cov6" title="4">if v &lt; 0 || v &gt; 100 </span><span class="cov0" title="0">{
                                        log.Fatalf("Error: --warn-threshold must be between 0 and 100")
                                }</span>
                                <span class="cov6" title="4">warnThreshold = v
                                i++</span>
                        } else<span class="cov0" title="0"> {
                                log.Fatalf("Error: --warn-threshold requires a numeric argument")
                        }</span>
                default:<span class="cov8" title="8">
                        remaining = append(remaining, args[i])</span>
                }
        }
        <span class="cov6" title="5">return</span>
}

// isTerminalStdout returns true if stdout is a terminal (not piped/redirected).
func isTerminalStdout() bool <span class="cov0" title="0">{
        fi, err := os.Stdout.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">return fi.Mode()&amp;os.ModeCharDevice != 0</span>
}

// version is set at build time via -ldflags
var version = "dev"

// verbose is set to true when -v flag is passed
var verbose bool

// showProgress controls whether progress bars are rendered. Set to false by
// --no-progress, --quiet, or when stdout is not a TTY.
var showProgress = true

// quiet suppresses all informational stdout output. Errors still go to stderr.
var quiet bool

func printVersion() <span class="cov1" title="1">{
        fmt.Printf("mkvdup version %s\n", version)
}</span>

func main() <span class="cov0" title="0">{
        // Process global flags before command
        args := os.Args[1:]
        var filteredArgs []string
        showHelp := false
        showVersion := false

        // Extract --cpuprofile flag (only available in debug builds)
        args, cpuprofile := parseCPUProfileFlag(args)
        defer startCPUProfile(cpuprofile)()

        for i := 0; i &lt; len(args); i++ </span><span class="cov0" title="0">{
                arg := args[i]
                switch </span>{
                case arg == "-v" || arg == "--verbose":<span class="cov0" title="0">
                        verbose = true</span>
                case arg == "-h" || arg == "--help":<span class="cov0" title="0">
                        showHelp = true</span>
                case arg == "--version":<span class="cov0" title="0">
                        showVersion = true</span>
                case arg == "--no-progress":<span class="cov0" title="0">
                        showProgress = false</span>
                case arg == "-q" || arg == "--quiet":<span class="cov0" title="0">
                        quiet = true
                        showProgress = false</span>
                case arg == "--log-file":<span class="cov0" title="0">
                        if i+1 &lt; len(args) </span><span class="cov0" title="0">{
                                i++
                                var err error
                                logFile, err = os.Create(args[i])
                                if err != nil </span><span class="cov0" title="0">{
                                        log.Fatalf("Error: cannot create log file %s: %v", args[i], err)
                                }</span>
                        } else<span class="cov0" title="0"> {
                                log.Fatalf("Error: --log-file requires a path argument")
                        }</span>
                default:<span class="cov0" title="0">
                        filteredArgs = append(filteredArgs, arg)</span>
                }
        }
        <span class="cov0" title="0">args = filteredArgs

        // Auto-disable progress bars when stdout is not a TTY
        if !isTerminalStdout() </span><span class="cov0" title="0">{
                showProgress = false
        }</span>

        // Close log file on exit
        <span class="cov0" title="0">if logFile != nil </span><span class="cov0" title="0">{
                defer logFile.Close()
        }</span>

        // Handle --version (always top-level)
        <span class="cov0" title="0">if showVersion </span><span class="cov0" title="0">{
                printVersion()
                os.Exit(0)
        }</span>

        // If no command given, show appropriate help
        <span class="cov0" title="0">if len(args) &lt; 1 </span><span class="cov0" title="0">{
                if showHelp </span><span class="cov0" title="0">{
                        printUsage()
                        os.Exit(0)
                }</span>
                <span class="cov0" title="0">printUsage()
                os.Exit(1)</span>
        }

        <span class="cov0" title="0">cmd := args[0]
        args = args[1:]

        // If help flag was given with a command, show command-specific help
        if showHelp </span><span class="cov0" title="0">{
                printCommandUsage(cmd)
                os.Exit(0)
        }</span>

        <span class="cov0" title="0">switch cmd </span>{
        case "create":<span class="cov0" title="0">
                warnThreshold, remaining := parseWarnFlags(args)
                nonInteractive := false
                var createArgs []string
                for i := 0; i &lt; len(remaining); i++ </span><span class="cov0" title="0">{
                        switch remaining[i] </span>{
                        case "--non-interactive":<span class="cov0" title="0">
                                nonInteractive = true</span>
                        default:<span class="cov0" title="0">
                                createArgs = append(createArgs, remaining[i])</span>
                        }
                }
                <span class="cov0" title="0">if len(createArgs) &lt; 3 </span><span class="cov0" title="0">{
                        printCommandUsage("create")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">output := createArgs[2]
                name := ""
                if len(createArgs) &gt;= 4 </span><span class="cov0" title="0">{
                        name = createArgs[3]
                }</span>
                <span class="cov0" title="0">if err := createDedup(createArgs[0], createArgs[1], output, name, warnThreshold, nonInteractive); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "batch-create":<span class="cov0" title="0">
                warnThreshold, remaining := parseWarnFlags(args)
                skipCodecMismatch := false
                var batchArgs []string
                for _, arg := range remaining </span><span class="cov0" title="0">{
                        if arg == "--skip-codec-mismatch" </span><span class="cov0" title="0">{
                                skipCodecMismatch = true
                        }</span> else<span class="cov0" title="0"> {
                                batchArgs = append(batchArgs, arg)
                        }</span>
                }
                <span class="cov0" title="0">if len(batchArgs) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("batch-create")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := createBatch(batchArgs[0], warnThreshold, skipCodecMismatch); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "probe":<span class="cov0" title="0">
                if len(args) &lt; 2 </span><span class="cov0" title="0">{
                        printCommandUsage("probe")
                        os.Exit(1)
                }</span>
                // Split on "--": MKVs before, sources after
                // For backward compat: if no "--", first arg is MKV, rest are sources
                <span class="cov0" title="0">var mkvPaths, sourceDirs []string
                sepIdx := -1
                for i, a := range args </span><span class="cov0" title="0">{
                        if a == "--" </span><span class="cov0" title="0">{
                                sepIdx = i
                                break</span>
                        }
                }
                <span class="cov0" title="0">if sepIdx &gt;= 0 </span><span class="cov0" title="0">{
                        mkvPaths = args[:sepIdx]
                        sourceDirs = args[sepIdx+1:]
                }</span> else<span class="cov0" title="0"> {
                        mkvPaths = args[:1]
                        sourceDirs = args[1:]
                }</span>
                <span class="cov0" title="0">if len(mkvPaths) == 0 || len(sourceDirs) == 0 </span><span class="cov0" title="0">{
                        printCommandUsage("probe")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := probe(mkvPaths, sourceDirs); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "mount":<span class="cov0" title="0">
                // Parse mount-specific options
                allowOther := false
                foreground := false
                configDir := false
                pidFile := ""
                daemonTimeout := 30 * time.Second
                permissionsFile := ""
                defaultUID := uint32(os.Getuid())
                defaultGID := uint32(os.Getgid())
                defaultFileMode := uint32(0444)
                defaultDirMode := uint32(0555)
                noSourceWatch := false
                onSourceChange := "checksum"
                sourceWatchPollInterval := time.Duration(0)
                sourceReadTimeout := 30 * time.Second
                var mountArgs []string
                for i := 0; i &lt; len(args); i++ </span><span class="cov0" title="0">{
                        switch args[i] </span>{
                        case "--allow-other":<span class="cov0" title="0">
                                allowOther = true</span>
                        case "--foreground", "-f":<span class="cov0" title="0">
                                foreground = true</span>
                        case "--config-dir":<span class="cov0" title="0">
                                configDir = true</span>
                        case "--pid-file":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        pidFile = args[i+1]
                                        i++
                                }</span> else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --pid-file requires a path argument")
                                }</span>
                        case "--daemon-timeout":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        d, err := time.ParseDuration(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --daemon-timeout invalid duration: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">daemonTimeout = d
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --daemon-timeout requires a duration argument (e.g., 30s, 1m)")
                                }</span>
                        case "--permissions-file":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        permissionsFile = args[i+1]
                                        i++
                                }</span> else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --permissions-file requires a path argument")
                                }</span>
                        case "--default-uid":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        uid, err := parseUint32(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --default-uid invalid: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">defaultUID = uid
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --default-uid requires a numeric argument")
                                }</span>
                        case "--default-gid":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        gid, err := parseUint32(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --default-gid invalid: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">defaultGID = gid
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --default-gid requires a numeric argument")
                                }</span>
                        case "--default-file-mode":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        mode, err := parseOctalMode(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --default-file-mode invalid: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">defaultFileMode = mode
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --default-file-mode requires an octal mode argument")
                                }</span>
                        case "--default-dir-mode":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        mode, err := parseOctalMode(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --default-dir-mode invalid: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">defaultDirMode = mode
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --default-dir-mode requires an octal mode argument")
                                }</span>
                        case "--no-source-watch":<span class="cov0" title="0">
                                noSourceWatch = true</span>
                        case "--on-source-change":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        onSourceChange = args[i+1]
                                        switch onSourceChange </span>{
                                        case "warn", "disable", "checksum":<span class="cov0" title="0"></span>
                                                // valid
                                        default:<span class="cov0" title="0">
                                                log.Fatalf("Error: --on-source-change must be warn, disable, or checksum")</span>
                                        }
                                        <span class="cov0" title="0">i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --on-source-change requires an argument (warn, disable, or checksum)")
                                }</span>
                        case "--source-watch-poll-interval":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        d, err := time.ParseDuration(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --source-watch-poll-interval invalid duration: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">if d &lt;= 0 </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --source-watch-poll-interval must be positive")
                                        }</span>
                                        <span class="cov0" title="0">sourceWatchPollInterval = d
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --source-watch-poll-interval requires a duration argument (e.g., 10s, 5m)")
                                }</span>
                        case "--source-read-timeout":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        d, err := time.ParseDuration(args[i+1])
                                        if err != nil </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --source-read-timeout invalid duration: %v", err)
                                        }</span>
                                        <span class="cov0" title="0">if d &lt; 0 </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --source-read-timeout must be non-negative")
                                        }</span>
                                        <span class="cov0" title="0">sourceReadTimeout = d
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --source-read-timeout requires a duration argument (e.g., 30s, 1m)")
                                }</span>
                        default:<span class="cov0" title="0">
                                mountArgs = append(mountArgs, args[i])</span>
                        }
                }
                <span class="cov0" title="0">if len(mountArgs) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("mount")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">mountpoint := mountArgs[0]
                configPaths := mountArgs[1:]
                mountOpts := MountOptions{
                        AllowOther:              allowOther,
                        Foreground:              foreground,
                        ConfigDir:               configDir,
                        PidFile:                 pidFile,
                        DaemonTimeout:           daemonTimeout,
                        PermissionsFile:         permissionsFile,
                        DefaultUID:              defaultUID,
                        DefaultGID:              defaultGID,
                        DefaultFileMode:         defaultFileMode,
                        DefaultDirMode:          defaultDirMode,
                        NoSourceWatch:           noSourceWatch,
                        OnSourceChange:          onSourceChange,
                        SourceWatchPollInterval: sourceWatchPollInterval,
                        SourceReadTimeout:       sourceReadTimeout,
                }
                if err := mountFuse(mountpoint, configPaths, mountOpts); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "info":<span class="cov0" title="0">
                hideUnused := false
                var infoArgs []string
                for _, a := range args </span><span class="cov0" title="0">{
                        if a == "--hide-unused-files" </span><span class="cov0" title="0">{
                                hideUnused = true
                        }</span> else<span class="cov0" title="0"> {
                                infoArgs = append(infoArgs, a)
                        }</span>
                }
                <span class="cov0" title="0">if len(infoArgs) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("info")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := showInfo(infoArgs[0], hideUnused); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "verify":<span class="cov0" title="0">
                if len(args) &lt; 3 </span><span class="cov0" title="0">{
                        printCommandUsage("verify")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := verifyDedup(args[0], args[1], args[2]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "extract":<span class="cov0" title="0">
                if len(args) &lt; 3 </span><span class="cov0" title="0">{
                        printCommandUsage("extract")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := extractDedup(args[0], args[1], args[2]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "check":<span class="cov0" title="0">
                sourceChecksums := false
                var checkArgs []string
                for i := 0; i &lt; len(args); i++ </span><span class="cov0" title="0">{
                        switch args[i] </span>{
                        case "--source-checksums":<span class="cov0" title="0">
                                sourceChecksums = true</span>
                        default:<span class="cov0" title="0">
                                checkArgs = append(checkArgs, args[i])</span>
                        }
                }
                <span class="cov0" title="0">if len(checkArgs) &lt; 2 </span><span class="cov0" title="0">{
                        printCommandUsage("check")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := checkDedup(checkArgs[0], checkArgs[1], sourceChecksums); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "stats":<span class="cov0" title="0">
                configDir := false
                var statsArgs []string
                for _, arg := range args </span><span class="cov0" title="0">{
                        if arg == "--config-dir" </span><span class="cov0" title="0">{
                                configDir = true
                        }</span> else<span class="cov0" title="0"> {
                                statsArgs = append(statsArgs, arg)
                        }</span>
                }
                <span class="cov0" title="0">if len(statsArgs) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("stats")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := showStats(statsArgs, configDir); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "validate":<span class="cov0" title="0">
                configDir := false
                deep := false
                strict := false
                var valArgs []string
                for i := 0; i &lt; len(args); i++ </span><span class="cov0" title="0">{
                        switch args[i] </span>{
                        case "--config-dir":<span class="cov0" title="0">
                                configDir = true</span>
                        case "--deep":<span class="cov0" title="0">
                                deep = true</span>
                        case "--strict":<span class="cov0" title="0">
                                strict = true</span>
                        default:<span class="cov0" title="0">
                                valArgs = append(valArgs, args[i])</span>
                        }
                }
                <span class="cov0" title="0">if len(valArgs) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("validate")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">os.Exit(validateConfigs(valArgs, configDir, deep, strict))</span>

        case "reload":<span class="cov0" title="0">
                if len(args) == 0 </span><span class="cov0" title="0">{
                        printCommandUsage("reload")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">pidFile := ""
                pidDirect := 0
                configDir := false
                var reloadArgs []string
                for i := 0; i &lt; len(args); i++ </span><span class="cov0" title="0">{
                        switch args[i] </span>{
                        case "--pid-file":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        pidFile = args[i+1]
                                        i++
                                }</span> else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --pid-file requires a path argument")
                                }</span>
                        case "--pid":<span class="cov0" title="0">
                                if i+1 &lt; len(args) &amp;&amp; !strings.HasPrefix(args[i+1], "--") </span><span class="cov0" title="0">{
                                        p, err := strconv.Atoi(args[i+1])
                                        if err != nil || p &lt;= 0 </span><span class="cov0" title="0">{
                                                log.Fatalf("Error: --pid requires a positive integer argument")
                                        }</span>
                                        <span class="cov0" title="0">pidDirect = p
                                        i++</span>
                                } else<span class="cov0" title="0"> {
                                        log.Fatalf("Error: --pid requires a PID argument")
                                }</span>
                        case "--config-dir":<span class="cov0" title="0">
                                configDir = true</span>
                        default:<span class="cov0" title="0">
                                reloadArgs = append(reloadArgs, args[i])</span>
                        }
                }
                <span class="cov0" title="0">if pidFile != "" &amp;&amp; pidDirect != 0 </span><span class="cov0" title="0">{
                        log.Fatalf("Error: --pid-file and --pid are mutually exclusive")
                }</span>
                <span class="cov0" title="0">var pid int
                if pidDirect != 0 </span><span class="cov0" title="0">{
                        pid = pidDirect
                }</span> else<span class="cov0" title="0"> if pidFile != "" </span><span class="cov0" title="0">{
                        var err error
                        pid, err = daemon.ReadPidFile(pidFile)
                        if err != nil </span><span class="cov0" title="0">{
                                log.Fatalf("Error: %v", err)
                        }</span>
                } else<span class="cov0" title="0"> {
                        log.Fatalf("Error: --pid-file or --pid is required for reload")
                }</span>
                <span class="cov0" title="0">if err := reloadDaemon(pid, reloadArgs, configDir); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "deltadiag":<span class="cov0" title="0">
                if len(args) &lt; 2 </span><span class="cov0" title="0">{
                        printCommandUsage("deltadiag")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := deltadiag(args[0], args[1]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "parse-mkv":<span class="cov0" title="0">
                if len(args) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("parse-mkv")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := parseMKV(args[0]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "index-source":<span class="cov0" title="0">
                if len(args) &lt; 1 </span><span class="cov0" title="0">{
                        printCommandUsage("index-source")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := indexSource(args[0]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "match":<span class="cov0" title="0">
                if len(args) &lt; 2 </span><span class="cov0" title="0">{
                        printCommandUsage("match")
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">if err := matchMKV(args[0], args[1]); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Error: %v", err)
                }</span>

        case "help":<span class="cov0" title="0">
                if len(args) &gt; 0 </span><span class="cov0" title="0">{
                        printCommandUsage(args[0])
                }</span> else<span class="cov0" title="0"> {
                        printUsage()
                }</span>
                <span class="cov0" title="0">os.Exit(0)</span>

        default:<span class="cov0" title="0">
                fmt.Fprintf(os.Stderr, "Unknown command: %s\n\n", cmd)
                printUsage()
                os.Exit(1)</span>
        }
}
</pre>
		
		<pre class="file" id="file13" style="display: none">//go:build !debug

package main

// parseCPUProfileFlag is a no-op in release builds.
// The --cpuprofile flag is only available in debug builds (go build -tags debug).
func parseCPUProfileFlag(args []string) ([]string, string) <span class="cov0" title="0">{
        return args, ""
}</span>

// debugOptionsHelp returns empty string in release builds.
func debugOptionsHelp() string <span class="cov10" title="2">{
        return ""
}</span>

// startCPUProfile is a no-op in release builds.
func startCPUProfile(_ string) func() <span class="cov0" title="0">{
        return func() </span>{<span class="cov0" title="0">}</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">package main

import (
        "fmt"
        "os"
        "strings"
        "time"
)

// logFile is set by --log-file to duplicate output to a file.
// Console output is unchanged; the log file receives non-TTY-style output
// (milestones instead of progress bars, no ANSI escape sequences).
var logFile *os.File

// progressBar renders an in-place progress bar with ETA.
//
// When showProgress is true (TTY mode), it renders:
//
//        Phase 2/6: Building source index...
//          [████████████████████░░░░░░░░░░░░░░░░░░░░]  52%  2.3 GB / 4.5 GB  ETA: 00:00:14
//
// On Finish(), the bar line is cleared and replaced with:
//
//        Phase 2/6: Building source index... done (00:00:27)
//
// When showProgress is false (non-TTY), milestone percentages are printed at
// 10% intervals so redirected logs still show progress.
// When quiet is true, nothing is printed to stdout (log file still receives output).
type progressBar struct {
        prefix        string
        total         int64
        processed     int64
        startTime     time.Time
        lastDraw      time.Time
        unit          string // "bytes" or "packets"
        done          bool
        lastMilestone int // last 10% milestone printed (0-10)
}

const barWidth = 40

// newProgressBar creates and displays a new progress bar.
// The prefix (e.g., "Phase 2/6: Building source index...") is printed immediately.
// Unit should be "bytes" or "packets".
func newProgressBar(prefix string, total int64, unit string) *progressBar <span class="cov3" title="5">{
        p := &amp;progressBar{
                prefix:    prefix,
                total:     total,
                unit:      unit,
                startTime: time.Now(),
        }
        if !quiet </span><span class="cov3" title="4">{
                fmt.Println(prefix)
        }</span>
        <span class="cov3" title="5">if logFile != nil </span><span class="cov0" title="0">{
                fmt.Fprintln(logFile, prefix)
        }</span>
        <span class="cov3" title="5">return p</span>
}

// Update sets the current progress and redraws the bar (throttled to 500ms).
func (p *progressBar) Update(processed int64) <span class="cov3" title="4">{
        if p.done </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov3" title="4">p.processed = processed

        // Milestone progress for non-TTY stdout and/or log file
        if (!showProgress &amp;&amp; !quiet) || logFile != nil </span><span class="cov1" title="1">{
                p.updateMilestone()
        }</span>

        <span class="cov3" title="4">if quiet || !showProgress </span><span class="cov2" title="2">{
                return
        }</span>

        <span class="cov2" title="2">if time.Since(p.lastDraw) &lt; 500*time.Millisecond </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov2" title="2">p.lastDraw = time.Now()
        p.draw()</span>
}

// updateMilestone prints percentage milestones at 10% intervals.
// Output goes to stdout (when non-TTY) and/or the log file.
func (p *progressBar) updateMilestone() <span class="cov1" title="1">{
        if p.total &lt;= 0 </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov1" title="1">pct := float64(p.processed) / float64(p.total) * 100
        milestone := int(pct / 10)
        if milestone &gt; 10 </span><span class="cov0" title="0">{
                milestone = 10
        }</span>
        <span class="cov1" title="1">if milestone &lt;= p.lastMilestone </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov1" title="1">p.lastMilestone = milestone

        elapsed := time.Since(p.startTime)
        line := fmt.Sprintf("  %d%% (%s)\n", milestone*10, formatDuration(elapsed))

        if !showProgress &amp;&amp; !quiet </span><span class="cov1" title="1">{
                fmt.Print(line)
        }</span>
        <span class="cov1" title="1">if logFile != nil </span><span class="cov0" title="0">{
                fmt.Fprint(logFile, line)
        }</span>
}

// Cancel cleans up a progress bar on error without printing "done".
// It prints a newline to move past any partial bar line. Safe to call
// after Finish() (no-op if already done).
func (p *progressBar) Cancel() <span class="cov2" title="2">{
        if p.done </span><span class="cov1" title="1">{
                return
        }</span>
        <span class="cov1" title="1">p.done = true
        if !quiet &amp;&amp; showProgress </span><span class="cov1" title="1">{
                // Clear partial bar line and move to next line
                fmt.Print("\r\033[2K\n")
        }</span>
}

// Finish completes the progress bar and prints the elapsed time.
func (p *progressBar) Finish() <span class="cov3" title="4">{
        if p.done </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov3" title="4">p.done = true
        elapsed := time.Since(p.startTime)

        if !quiet </span><span class="cov3" title="3">{
                if showProgress </span><span class="cov2" title="2">{
                        // Clear the bar line, move up, and overwrite the prefix line with completion
                        fmt.Printf("\r\033[2K\033[A\r\033[2K%s done (%s)\n", p.prefix, formatDuration(elapsed))
                }</span> else<span class="cov1" title="1"> {
                        fmt.Printf("%s done (%s)\n", p.prefix, formatDuration(elapsed))
                }</span>
        }
        <span class="cov3" title="4">if logFile != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(logFile, "%s done (%s)\n", p.prefix, formatDuration(elapsed))
        }</span>
}

// draw renders the progress bar line.
func (p *progressBar) draw() <span class="cov2" title="2">{
        if p.total &lt;= 0 </span><span class="cov1" title="1">{
                return
        }</span>

        <span class="cov1" title="1">pct := float64(p.processed) / float64(p.total)
        if pct &gt; 1.0 </span><span class="cov0" title="0">{
                pct = 1.0
        }</span>

        // Build the bar: [████████░░░░░░░░░░░░]
        <span class="cov1" title="1">filled := int(pct * float64(barWidth))
        if filled &gt; barWidth </span><span class="cov0" title="0">{
                filled = barWidth
        }</span>
        <span class="cov1" title="1">bar := strings.Repeat("█", filled) + strings.Repeat("░", barWidth-filled)

        // Build the stats portion
        var stats string
        switch p.unit </span>{
        case "bytes":<span class="cov1" title="1">
                stats = fmt.Sprintf("%s / %s", formatSize(p.processed), formatSize(p.total))</span>
        case "packets":<span class="cov0" title="0">
                stats = fmt.Sprintf("%s / %s", formatInt(p.processed), formatInt(p.total))</span>
        }

        // ETA
        <span class="cov1" title="1">eta := p.eta()

        line := fmt.Sprintf("  [%s] %3.0f%%  %s  ETA: %s", bar, pct*100, stats, eta)

        fmt.Printf("\r\033[2K%s", line)</span>
}

// eta calculates the estimated time remaining.
func (p *progressBar) eta() string <span class="cov1" title="1">{
        elapsed := time.Since(p.startTime)

        // Don't show ETA for first 2 seconds or when no progress
        if elapsed &lt; 2*time.Second || p.processed &lt;= 0 || p.total &lt;= 0 </span><span class="cov1" title="1">{
                return "--:--:--"
        }</span>

        <span class="cov0" title="0">rate := float64(p.processed) / elapsed.Seconds()
        remaining := float64(p.total-p.processed) / rate
        if remaining &lt; 0 </span><span class="cov0" title="0">{
                remaining = 0
        }</span>

        <span class="cov0" title="0">return formatDuration(time.Duration(remaining * float64(time.Second)))</span>
}

// formatDuration formats a duration as HH:MM:SS.
func formatDuration(d time.Duration) string <span class="cov5" title="13">{
        d = d.Round(time.Second)
        h := int(d.Hours())
        m := int(d.Minutes()) % 60
        s := int(d.Seconds()) % 60
        return fmt.Sprintf("%02d:%02d:%02d", h, m, s)
}</span>

// formatSize formats a byte count as a human-readable string.
func formatSize(n int64) string <span class="cov6" title="25">{
        const (
                kb = 1024
                mb = 1024 * kb
                gb = 1024 * mb
        )
        switch </span>{
        case n &gt;= gb:<span class="cov3" title="3">
                return fmt.Sprintf("%.1f GB", float64(n)/float64(gb))</span>
        case n &gt;= mb:<span class="cov2" title="2">
                return fmt.Sprintf("%.1f MB", float64(n)/float64(mb))</span>
        case n &gt;= kb:<span class="cov2" title="2">
                return fmt.Sprintf("%.1f KB", float64(n)/float64(kb))</span>
        default:<span class="cov6" title="18">
                return fmt.Sprintf("%d B", n)</span>
        }
}

// printInfo prints informational output, suppressed on stdout when quiet is true.
// Always written to logFile if one is open.
func printInfo(format string, a ...any) <span class="cov10" title="130">{
        if !quiet </span><span class="cov9" title="127">{
                fmt.Printf(format, a...)
        }</span>
        <span class="cov10" title="130">if logFile != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(logFile, format, a...)
        }</span>
}

// printInfoln prints informational output with a newline, suppressed on stdout when quiet is true.
// Always written to logFile if one is open.
func printInfoln(a ...any) <span class="cov8" title="55">{
        if !quiet </span><span class="cov8" title="53">{
                fmt.Println(a...)
        }</span>
        <span class="cov8" title="55">if logFile != nil </span><span class="cov0" title="0">{
                fmt.Fprintln(logFile, a...)
        }</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">// Package daemon provides daemonization support for mkvdup FUSE mount.
//
// It uses a re-exec pattern where the parent process spawns a child with
// an environment variable marker. The child signals readiness to the parent
// via a pipe, allowing the parent to return success/failure appropriately.
package daemon

import (
        "errors"
        "fmt"
        "io"
        "os"
        "os/exec"
        "strconv"
        "strings"
        "syscall"
        "time"

        "golang.org/x/sys/unix"
)

// childEnvVar is the environment variable that marks a child daemon process.
const childEnvVar = "MKVDUP_DAEMON_CHILD"

// readyPipeFdEnvVar is the environment variable containing the pipe fd for signaling.
const readyPipeFdEnvVar = "MKVDUP_READY_PIPE_FD"

// Status codes sent from child to parent via the ready pipe.
const (
        statusReady byte = 0 // Mount successful
        statusError byte = 1 // Mount failed
)

// IsChild returns true if the current process is a daemon child.
func IsChild() bool <span class="cov7" title="4">{
        return os.Getenv(childEnvVar) == "1"
}</span>

// Daemonize spawns the current executable as a background daemon.
// It waits for the child to signal readiness or error via a pipe.
// Returns nil on success (child signaled ready) or error on failure.
// The timeout specifies how long to wait for the child to signal.
func Daemonize(pidFile string, timeout time.Duration) error <span class="cov0" title="0">{
        // Create pipe for child to signal readiness
        readPipe, writePipe, err := os.Pipe()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create pipe: %w", err)
        }</span>
        <span class="cov0" title="0">defer readPipe.Close()

        // Build command with same arguments
        cmd := exec.Command(os.Args[0], os.Args[1:]...)

        // Set up environment
        cmd.Env = append(os.Environ(),
                childEnvVar+"=1",
                readyPipeFdEnvVar+"=3", // fd 3 is after stdin/stdout/stderr
        )

        // Pass write end of pipe to child as fd 3
        cmd.ExtraFiles = []*os.File{writePipe}

        // Detach from terminal
        cmd.Stdin = nil
        cmd.Stdout = nil
        cmd.Stderr = nil
        cmd.SysProcAttr = &amp;syscall.SysProcAttr{
                Setsid: true, // Create new session
        }

        // Start child process
        if err := cmd.Start(); err != nil </span><span class="cov0" title="0">{
                writePipe.Close()
                return fmt.Errorf("start daemon: %w", err)
        }</span>

        // Close write end in parent (child has it)
        <span class="cov0" title="0">writePipe.Close()

        // Wait for child to signal with timeout
        resultChan := make(chan error, 1)
        go func() </span><span class="cov0" title="0">{
                status := make([]byte, 1)
                n, err := readPipe.Read(status)
                if err != nil </span><span class="cov0" title="0">{
                        if errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                                resultChan &lt;- fmt.Errorf("daemon child exited unexpectedly")
                        }</span> else<span class="cov0" title="0"> {
                                resultChan &lt;- fmt.Errorf("read from child: %w", err)
                        }</span>
                        <span class="cov0" title="0">return</span>
                }
                <span class="cov0" title="0">if n != 1 </span><span class="cov0" title="0">{
                        resultChan &lt;- fmt.Errorf("unexpected read size from child: %d", n)
                        return
                }</span>

                <span class="cov0" title="0">if status[0] == statusReady </span><span class="cov0" title="0">{
                        resultChan &lt;- nil
                }</span> else<span class="cov0" title="0"> {
                        // Read full error message until EOF to avoid truncation
                        errMsg, readErr := io.ReadAll(readPipe)
                        if readErr != nil &amp;&amp; !errors.Is(readErr, io.EOF) </span><span class="cov0" title="0">{
                                resultChan &lt;- fmt.Errorf("daemon failed (error reading message): %v", readErr)
                                return
                        }</span>
                        <span class="cov0" title="0">if len(errMsg) &gt; 0 </span><span class="cov0" title="0">{
                                resultChan &lt;- fmt.Errorf("daemon failed: %s", string(errMsg))
                        }</span> else<span class="cov0" title="0"> {
                                resultChan &lt;- fmt.Errorf("daemon failed with unknown error")
                        }</span>
                }
        }()

        <span class="cov0" title="0">select </span>{
        case err := &lt;-resultChan:<span class="cov0" title="0">
                if err != nil </span><span class="cov0" title="0">{
                        // Try to clean up the child
                        if cmd.Process != nil </span><span class="cov0" title="0">{
                                cmd.Process.Kill()
                        }</span>
                        <span class="cov0" title="0">return err</span>
                }
                // Success - child is running and mount is ready
                <span class="cov0" title="0">if pidFile != "" </span><span class="cov0" title="0">{
                        // Write PID file from parent since child may not have permission
                        if err := WritePidFile(pidFile, cmd.Process.Pid); err != nil </span><span class="cov0" title="0">{
                                fmt.Fprintf(os.Stderr, "warning: failed to write pid file: %v\n", err)
                        }</span>
                }
                <span class="cov0" title="0">return nil</span>
        case &lt;-time.After(timeout):<span class="cov0" title="0">
                // Close pipe to unblock the goroutine waiting on Read()
                readPipe.Close()
                if cmd.Process != nil </span><span class="cov0" title="0">{
                        cmd.Process.Kill()
                }</span>
                <span class="cov0" title="0">return fmt.Errorf("daemon startup timed out after %v", timeout)</span>
        }
}

// NotifyReady signals to the parent that the mount is ready.
// This should be called by the child after the FUSE mount is ready.
func NotifyReady() error <span class="cov4" title="2">{
        fd, err := getReadyPipeFd()
        if err != nil </span><span class="cov1" title="1">{
                return err
        }</span>

        <span class="cov1" title="1">pipe := os.NewFile(fd, "ready-pipe")
        if pipe == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid pipe fd")
        }</span>
        <span class="cov1" title="1">defer pipe.Close()

        _, err = pipe.Write([]byte{statusReady})
        return err</span>
}

// NotifyError signals to the parent that the mount failed.
// This should be called by the child if an error occurs during startup.
func NotifyError(mountErr error) error <span class="cov5" title="3">{
        fd, err := getReadyPipeFd()
        if err != nil </span><span class="cov1" title="1">{
                return err
        }</span>

        <span class="cov4" title="2">pipe := os.NewFile(fd, "ready-pipe")
        if pipe == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid pipe fd")
        }</span>
        <span class="cov4" title="2">defer pipe.Close()

        // Write error status followed by error message
        _, err = pipe.Write([]byte{statusError})
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov4" title="2">_, err = pipe.Write([]byte(mountErr.Error()))
        return err</span>
}

// getReadyPipeFd returns the file descriptor for the ready pipe.
func getReadyPipeFd() (uintptr, error) <span class="cov10" title="8">{
        fdStr := os.Getenv(readyPipeFdEnvVar)
        if fdStr == "" </span><span class="cov5" title="3">{
                return 0, fmt.Errorf("not running as daemon child")
        }</span>
        <span class="cov7" title="5">fd, err := strconv.ParseUint(fdStr, 10, strconv.IntSize)
        if err != nil </span><span class="cov1" title="1">{
                return 0, fmt.Errorf("invalid pipe fd: %w", err)
        }</span>
        <span class="cov7" title="4">return uintptr(fd), nil</span>
}

// Detach closes stdin, stdout, and stderr to fully detach from the terminal.
// This should be called by the child after signaling ready.
func Detach() <span class="cov0" title="0">{
        // Redirect standard file descriptors to /dev/null
        devNull, err := os.OpenFile("/dev/null", os.O_RDWR, 0)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "daemon: failed to open /dev/null: %v\n", err)
                return
        }</span>

        // Replace stdin, stdout, stderr with /dev/null
        // Use unix.Dup2 for cross-architecture compatibility (syscall.Dup2 not available on arm64)
        // Errors are logged but not fatal since the daemon can still function
        <span class="cov0" title="0">if err := unix.Dup2(int(devNull.Fd()), int(os.Stdin.Fd())); err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "daemon: failed to redirect stdin: %v\n", err)
        }</span>
        <span class="cov0" title="0">if err := unix.Dup2(int(devNull.Fd()), int(os.Stdout.Fd())); err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "daemon: failed to redirect stdout: %v\n", err)
        }</span>
        <span class="cov0" title="0">if err := unix.Dup2(int(devNull.Fd()), int(os.Stderr.Fd())); err != nil </span><span class="cov0" title="0">{
                // stderr may already be redirected, best effort
                _ = err
        }</span>
        <span class="cov0" title="0">if err := devNull.Close(); err != nil </span><span class="cov0" title="0">{
                // Can't log since stderr may be redirected
                _ = err
        }</span>
}

// WritePidFile writes the given PID to a file.
func WritePidFile(path string, pid int) error <span class="cov5" title="3">{
        return os.WriteFile(path, []byte(strconv.Itoa(pid)+"\n"), 0644)
}</span>

// RemovePidFile removes the PID file at the given path.
func RemovePidFile(path string) error <span class="cov4" title="2">{
        return os.Remove(path)
}</span>

// ReadPidFile reads a PID from the given file path.
func ReadPidFile(path string) (int, error) <span class="cov7" title="5">{
        data, err := os.ReadFile(path)
        if err != nil </span><span class="cov1" title="1">{
                return 0, fmt.Errorf("read pid file: %w", err)
        }</span>
        <span class="cov7" title="4">pidStr := strings.TrimSpace(string(data))
        pid, err := strconv.Atoi(pidStr)
        if err != nil </span><span class="cov1" title="1">{
                return 0, fmt.Errorf("invalid pid in %s: %w", path, err)
        }</span>
        <span class="cov5" title="3">if pid &lt;= 0 </span><span class="cov4" title="2">{
                return 0, fmt.Errorf("invalid pid %d in %s", pid, path)
        }</span>
        <span class="cov1" title="1">return pid, nil</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">package dedup

import (
        "fmt"
        "log"
        "os"
        "path/filepath"
        "sort"
        "strings"
        "time"

        "github.com/bmatcuk/doublestar/v4"
        "gopkg.in/yaml.v3"
)

// Config represents the contents of a .mkvdup.yaml file.
type Config struct {
        Name      string `yaml:"name"`
        DedupFile string `yaml:"dedup_file"`
        SourceDir string `yaml:"source_dir"`
}

// configFile is the internal YAML representation that supports includes
// and virtual_files in addition to the standard Config fields.
type configFile struct {
        Name           string              `yaml:"name"`
        DedupFile      string              `yaml:"dedup_file"`
        SourceDir      string              `yaml:"source_dir"`
        Includes       []string            `yaml:"includes"`
        VirtualFiles   []Config            `yaml:"virtual_files"`
        OnErrorCommand *ErrorCommandConfig `yaml:"on_error_command"`
}

// ErrorCommandConfig configures an external command to run when a source
// integrity issue is detected. Placeholders in command arguments (%source%,
// %files%, %event%) are substituted at runtime.
type ErrorCommandConfig struct {
        Command       CommandValue  `yaml:"command"`
        Timeout       time.Duration `yaml:"timeout"`
        BatchInterval time.Duration `yaml:"batch_interval"`
}

// applyDefaults fills in zero-value fields with sensible defaults.
func (c *ErrorCommandConfig) applyDefaults() <span class="cov4" title="10">{
        if c.Timeout &lt;= 0 </span><span class="cov3" title="4">{
                c.Timeout = 30 * time.Second
        }</span>
        <span class="cov4" title="10">if c.BatchInterval &lt;= 0 </span><span class="cov4" title="8">{
                c.BatchInterval = 5 * time.Second
        }</span>
}

// CommandValue supports both string and []string YAML formats.
// A string value is executed via "sh -c"; a list is executed directly.
type CommandValue struct {
        IsShell bool     // true if the original YAML was a string (run via sh -c)
        Args    []string // for shell: single element with the command string; for list: the arg list
}

// UnmarshalYAML implements custom unmarshaling for CommandValue.
func (c *CommandValue) UnmarshalYAML(value *yaml.Node) error <span class="cov5" title="14">{
        // Try string first
        if value.Kind == yaml.ScalarNode </span><span class="cov2" title="2">{
                var s string
                if err := value.Decode(&amp;s); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov2" title="2">if s == "" </span><span class="cov0" title="0">{
                        return fmt.Errorf("on_error_command: command must not be empty")
                }</span>
                <span class="cov2" title="2">c.IsShell = true
                c.Args = []string{s}
                return nil</span>
        }

        // Try list
        <span class="cov4" title="12">if value.Kind == yaml.SequenceNode </span><span class="cov4" title="12">{
                var list []string
                if err := value.Decode(&amp;list); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov4" title="12">if len(list) == 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("on_error_command: command list must not be empty")
                }</span>
                <span class="cov4" title="12">c.IsShell = false
                c.Args = list
                return nil</span>
        }

        <span class="cov0" title="0">return fmt.Errorf("on_error_command: command must be a string or list of strings")</span>
}

// WriteConfig writes the .mkvdup.yaml config file.
func WriteConfig(configPath, name, dedupFile, sourceDir string) error <span class="cov5" title="24">{
        content := fmt.Sprintf(`# Auto-generated by mkvdup create
name: %q
dedup_file: %q
source_dir: %q
`, name, dedupFile, sourceDir)

        return os.WriteFile(configPath, []byte(content), 0644)
}</span>

// ReadConfig reads a .mkvdup.yaml config file.
func ReadConfig(configPath string) (*Config, error) <span class="cov6" title="27">{
        data, err := os.ReadFile(configPath)
        if err != nil </span><span class="cov3" title="4">{
                return nil, fmt.Errorf("read config file: %w", err)
        }</span>

        <span class="cov5" title="23">var config Config
        if err := yaml.Unmarshal(data, &amp;config); err != nil </span><span class="cov3" title="4">{
                return nil, fmt.Errorf("parse config %s: %w", configPath, err)
        }</span>

        <span class="cov5" title="19">if config.Name == "" || config.DedupFile == "" || config.SourceDir == "" </span><span class="cov4" title="10">{
                return nil, fmt.Errorf("invalid config: missing required fields")
        }</span>

        <span class="cov4" title="9">return &amp;config, nil</span>
}

// ResolveConfigs reads config files and recursively expands includes and
// virtual_files into a flat list of Config entries. Cycle detection prevents
// infinite recursion from circular includes.
//
// If any config file contains an on_error_command block, the first one
// encountered (depth-first, in file order) is returned. Defaults are applied
// for omitted timeout and batch_interval fields.
func ResolveConfigs(configPaths []string) ([]Config, *ErrorCommandConfig, error) <span class="cov8" title="89">{
        seen := make(map[string]bool)
        var all []Config
        var errorCmd *ErrorCommandConfig
        for _, p := range configPaths </span><span class="cov8" title="95">{
                configs, cmd, err := resolveConfig(p, seen)
                if err != nil </span><span class="cov4" title="10">{
                        return nil, nil, err
                }</span>
                <span class="cov7" title="85">all = append(all, configs...)
                if errorCmd == nil &amp;&amp; cmd != nil </span><span class="cov4" title="12">{
                        errorCmd = cmd
                }</span>
        }
        <span class="cov7" title="79">if errorCmd != nil </span><span class="cov4" title="12">{
                if len(errorCmd.Command.Args) == 0 </span><span class="cov2" title="2">{
                        return nil, nil, fmt.Errorf("invalid on_error_command: missing command")
                }</span>
                <span class="cov4" title="10">errorCmd.applyDefaults()</span>
        }
        <span class="cov7" title="77">return all, errorCmd, nil</span>
}

// resolveConfig recursively resolves a single config file.
// Returns the file configs and the first on_error_command encountered (or nil).
func resolveConfig(configPath string, seen map[string]bool) ([]Config, *ErrorCommandConfig, error) <span class="cov8" title="116">{
        absPath, err := filepath.Abs(configPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("resolve path %s: %w", configPath, err)
        }</span>

        // Resolve symlinks for reliable cycle detection.
        <span class="cov8" title="116">realPath, err := filepath.EvalSymlinks(absPath)
        if err != nil </span><span class="cov2" title="2">{
                return nil, nil, fmt.Errorf("resolve symlinks %s: %w", absPath, err)
        }</span>

        <span class="cov8" title="114">if seen[realPath] </span><span class="cov2" title="3">{
                log.Printf("warning: skipping already-seen config %s (cycle detection)", realPath)
                return nil, nil, nil
        }</span>
        <span class="cov8" title="111">seen[realPath] = true

        data, err := os.ReadFile(realPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("read config file %s: %w", realPath, err)
        }</span>

        <span class="cov8" title="111">var cf configFile
        if err := yaml.Unmarshal(data, &amp;cf); err != nil </span><span class="cov2" title="3">{
                return nil, nil, fmt.Errorf("parse config %s: %w", realPath, err)
        }</span>

        <span class="cov8" title="108">configDir := filepath.Dir(realPath)
        var configs []Config
        var errorCmd *ErrorCommandConfig

        // Capture on_error_command from this file (first-wins across resolution).
        if cf.OnErrorCommand != nil </span><span class="cov5" title="16">{
                errorCmd = cf.OnErrorCommand
        }</span>

        // If top-level name/dedup_file/source_dir are set, add as a Config entry.
        <span class="cov8" title="108">hasName := cf.Name != ""
        hasDedup := cf.DedupFile != ""
        hasSource := cf.SourceDir != ""
        if hasName || hasDedup || hasSource </span><span class="cov7" title="72">{
                if !hasName || !hasDedup || !hasSource </span><span class="cov2" title="3">{
                        return nil, nil, fmt.Errorf("config %s: name, dedup_file, and source_dir must all be set if any is set", realPath)
                }</span>
                <span class="cov7" title="69">configs = append(configs, Config{
                        Name:      cf.Name,
                        DedupFile: resolveRelative(configDir, cf.DedupFile),
                        SourceDir: resolveRelative(configDir, cf.SourceDir),
                })</span>
        }

        // Process includes.
        <span class="cov8" title="105">for _, pattern := range cf.Includes </span><span class="cov5" title="21">{
                pattern = resolveRelative(configDir, pattern)
                matches, err := doublestar.FilepathGlob(pattern)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, nil, fmt.Errorf("expand include pattern %q in %s: %w", pattern, realPath, err)
                }</span>
                <span class="cov5" title="21">sort.Strings(matches)
                for _, match := range matches </span><span class="cov5" title="21">{
                        sub, cmd, err := resolveConfig(match, seen)
                        if err != nil </span><span class="cov2" title="2">{
                                return nil, nil, err
                        }</span>
                        <span class="cov5" title="19">configs = append(configs, sub...)
                        if errorCmd == nil &amp;&amp; cmd != nil </span><span class="cov0" title="0">{
                                errorCmd = cmd
                        }</span>
                }
        }

        // Process virtual_files.
        <span class="cov8" title="103">for _, vf := range cf.VirtualFiles </span><span class="cov4" title="12">{
                if vf.Name == "" || vf.DedupFile == "" || vf.SourceDir == "" </span><span class="cov2" title="2">{
                        return nil, nil, fmt.Errorf("config %s: virtual_files entry missing required fields (name, dedup_file, source_dir)", realPath)
                }</span>
                <span class="cov4" title="10">configs = append(configs, Config{
                        Name:      vf.Name,
                        DedupFile: resolveRelative(configDir, vf.DedupFile),
                        SourceDir: resolveRelative(configDir, vf.SourceDir),
                })</span>
        }

        <span class="cov8" title="101">return configs, errorCmd, nil</span>
}

// BatchManifest represents the batch create manifest file format.
type BatchManifest struct {
        SourceDir string              `yaml:"source_dir"`
        Files     []BatchManifestFile `yaml:"files"`
}

// BatchManifestFile represents a single file entry in a batch manifest.
type BatchManifestFile struct {
        MKV       string `yaml:"mkv"`
        Output    string `yaml:"output"`
        Name      string `yaml:"name"`
        SourceDir string `yaml:"source_dir"`
}

// ReadBatchManifest reads and validates a batch manifest file.
// Relative paths are resolved against the manifest file's directory.
// Default values are applied for optional fields.
func ReadBatchManifest(manifestPath string) (*BatchManifest, error) <span class="cov6" title="35">{
        data, err := os.ReadFile(manifestPath)
        if err != nil </span><span class="cov2" title="3">{
                return nil, fmt.Errorf("read batch manifest: %w", err)
        }</span>

        <span class="cov6" title="32">var manifest BatchManifest
        if err := yaml.Unmarshal(data, &amp;manifest); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("parse batch manifest %s: %w", manifestPath, err)
        }</span>

        <span class="cov6" title="32">if len(manifest.Files) == 0 </span><span class="cov2" title="3">{
                return nil, fmt.Errorf("batch manifest %s: files list is empty", manifestPath)
        }</span>

        <span class="cov6" title="29">absPath, err := filepath.Abs(manifestPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resolve manifest path: %w", err)
        }</span>
        <span class="cov6" title="29">manifestDir := filepath.Dir(absPath)

        // Resolve and normalize top-level source_dir relative to manifest (if set)
        if manifest.SourceDir != "" </span><span class="cov5" title="18">{
                manifest.SourceDir = filepath.Clean(resolveRelative(manifestDir, manifest.SourceDir))
        }</span>

        // Validate and resolve each file entry
        <span class="cov6" title="29">for i := range manifest.Files </span><span class="cov7" title="53">{
                f := &amp;manifest.Files[i]
                if f.MKV == "" </span><span class="cov2" title="2">{
                        return nil, fmt.Errorf("batch manifest %s: files[%d] missing required 'mkv' field", manifestPath, i)
                }</span>
                <span class="cov7" title="51">f.MKV = resolveRelative(manifestDir, f.MKV)

                if f.Output == "" </span><span class="cov2" title="3">{
                        return nil, fmt.Errorf("batch manifest %s: files[%d] missing required 'output' field", manifestPath, i)
                }</span>
                <span class="cov7" title="48">f.Output = resolveRelative(manifestDir, f.Output)

                // Default name to MKV basename
                if f.Name == "" </span><span class="cov6" title="40">{
                        f.Name = filepath.Base(f.MKV)
                }</span>
                // Ensure name has .mkv extension
                <span class="cov7" title="48">if !strings.HasSuffix(strings.ToLower(f.Name), ".mkv") </span><span class="cov2" title="2">{
                        f.Name += ".mkv"
                }</span>

                // Resolve and normalize per-file source_dir, fall back to top-level default
                <span class="cov7" title="48">if f.SourceDir != "" </span><span class="cov5" title="18">{
                        f.SourceDir = filepath.Clean(resolveRelative(manifestDir, f.SourceDir))
                }</span> else<span class="cov6" title="30"> if manifest.SourceDir != "" </span><span class="cov6" title="26">{
                        f.SourceDir = manifest.SourceDir
                }</span> else<span class="cov3" title="4"> {
                        return nil, fmt.Errorf("batch manifest %s: files[%d] has no source_dir (set per-file or top-level default)", manifestPath, i)
                }</span>
        }

        <span class="cov5" title="20">return &amp;manifest, nil</span>
}

// resolveRelative resolves a path relative to baseDir. If the path is already
// absolute, it is returned unchanged.
func resolveRelative(baseDir, path string) string <span class="cov10" title="314">{
        if filepath.IsAbs(path) </span><span class="cov9" title="278">{
                return path
        }</span>
        <span class="cov6" title="36">return filepath.Join(baseDir, path)</span>
}
</pre>
		
		<pre class="file" id="file17" style="display: none">// Package dedup provides reading and writing of .mkvdup deduplication files.
package dedup

import (
        "encoding/binary"

        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/source"
)

// File format constants
const (
        Magic   = "MKVDUP01"
        Version = 3 // v3: Source field expanded to uint16 for &gt;256 source files
        // VersionRangeMap is the version for files with embedded range maps.
        // Entries use ES offsets; a range map section maps ES offsets to raw file offsets.
        VersionRangeMap uint32 = 4
        // VersionCreator is V3 with a creator version string after the header.
        VersionCreator uint32 = 5
        // VersionRangeMapCreator is V4 with a creator version string after the header.
        VersionRangeMapCreator uint32 = 6
        // VersionUsed is V7: V5 with a per-source-file Used byte after the checksum.
        VersionUsed uint32 = 7
        // VersionRangeMapUsed is V8: V6 with a per-source-file Used byte after the checksum.
        VersionRangeMapUsed uint32 = 8
        // HeaderSize = Magic(8) + Version(4) + Flags(4) + OriginalSize(8) + OriginalChecksum(8) +
        //              SourceType(1) + UsesESOffsets(1) + SourceFileCount(2) + EntryCount(8) +
        //              DeltaOffset(8) + DeltaSize(8) = 60 bytes
        HeaderSize           = 60
        EntrySize            = 28 // Fixed entry size: 8+8+2+8+1+1 = 28 bytes
        FooterSize           = 24
        FooterV4Size         = 32 // V4 footer adds RangeMapChecksum (8 bytes)
        MagicSize            = 8
        VersionSize          = 4
        MaxCreatorVersionLen = 4096 // Max bytes for creator version string (writer truncates, reader rejects)
)

// Source types
const (
        SourceTypeDVD    uint8 = 0
        SourceTypeBluray uint8 = 1
)

// Header represents the fixed header at the start of a .mkvdup file.
type Header struct {
        Magic            [8]byte // "MKVDUP01"
        Version          uint32  // File format version
        Flags            uint32  // Reserved for future use
        OriginalSize     int64   // Size of original MKV file
        OriginalChecksum uint64  // xxhash of original MKV file
        SourceType       uint8   // 0=DVD, 1=Blu-ray
        UsesESOffsets    uint8   // 1 if source uses ES offsets (MPEG-PS)
        SourceFileCount  uint16  // Number of source files
        EntryCount       uint64  // Number of index entries
        DeltaOffset      int64   // Offset to delta section
        DeltaSize        int64   // Size of delta section
}

// SourceFile represents a source file entry in the dedup file.
type SourceFile struct {
        RelativePath string // Path relative to source directory
        Size         int64  // File size
        Checksum     uint64 // xxhash of file
        Used         bool   // Whether this source file is referenced by any entry (V7/V8 only)
}

// Entry represents an index entry in the dedup file.
// This mirrors matcher.Entry but is specifically for serialization.
type Entry struct {
        MkvOffset        int64  // Start offset in the MKV file
        Length           int64  // Length of this region
        Source           uint16 // 0 = delta, 1+ = source file index + 1 (supports up to 65535 files)
        SourceOffset     int64  // Offset in source file (or ES offset)
        IsVideo          bool   // For ES-based sources
        AudioSubStreamID byte   // For ES-based audio sub-streams
}

// RawEntry matches the 28-byte on-disk entry format exactly.
// Uses byte arrays for int64 fields to handle unaligned access portably.
// This enables direct memory-mapped access without parsing into []Entry.
type RawEntry struct {
        MkvOffset        [8]byte // int64, little-endian
        Length           [8]byte // int64, little-endian
        Source           [2]byte // uint16, little-endian
        SourceOffset     [8]byte // int64, little-endian (unaligned at byte 18)
        ESFlags          uint8   // bit 0 = IsVideo
        AudioSubStreamID uint8
}

// ToEntry converts a RawEntry to an Entry by parsing the byte arrays.
func (r *RawEntry) ToEntry() Entry <span class="cov10" title="1250648">{
        return Entry{
                MkvOffset:        int64(binary.LittleEndian.Uint64(r.MkvOffset[:])),
                Length:           int64(binary.LittleEndian.Uint64(r.Length[:])),
                Source:           binary.LittleEndian.Uint16(r.Source[:]),
                SourceOffset:     int64(binary.LittleEndian.Uint64(r.SourceOffset[:])),
                IsVideo:          r.ESFlags&amp;1 == 1,
                AudioSubStreamID: r.AudioSubStreamID,
        }
}</span>

// Footer represents the footer at the end of a .mkvdup file.
type Footer struct {
        IndexChecksum    uint64  // xxhash of index section
        DeltaChecksum    uint64  // xxhash of delta section
        RangeMapChecksum uint64  // xxhash of range map section (V4 only; 0 for V3)
        Magic            [8]byte // "MKVDUP01" (for reverse scanning)
}

// File represents a complete dedup file structure for reconstruction.
// Note: Entries are accessed directly from mmap via Reader.getEntry(),
// not stored in this struct, to avoid large memory allocation.
type File struct {
        Header         Header
        SourceFiles    []SourceFile
        DeltaOffset    int64 // Offset to delta section in file
        UsesESOffsets  bool
        CreatorVersion string // Version of mkvdup that created this file (V5+ only)
        headerSize     int64  // Effective header size (60 for V3/V4, 60+2+len for V5-V8)
}

// creatorVersionSize returns the on-disk size of the creator version field.
func creatorVersionSize(v string) int64 <span class="cov3" title="88">{
        if v == "" </span><span class="cov3" title="78">{
                return 0
        }</span>
        <span class="cov2" title="10">return 2 + int64(len(v))</span>
}

// ToMatcherEntry converts a dedup Entry to a matcher Entry.
func (e *Entry) ToMatcherEntry() matcher.Entry <span class="cov0" title="0">{
        return matcher.Entry{
                MkvOffset:        e.MkvOffset,
                Length:           e.Length,
                Source:           e.Source,
                SourceOffset:     e.SourceOffset,
                IsVideo:          e.IsVideo,
                AudioSubStreamID: e.AudioSubStreamID,
        }
}</span>

// FromMatcherEntry creates a dedup Entry from a matcher Entry.
func FromMatcherEntry(e matcher.Entry) Entry <span class="cov8" title="152047">{
        return Entry{
                MkvOffset:        e.MkvOffset,
                Length:           e.Length,
                Source:           e.Source,
                SourceOffset:     e.SourceOffset,
                IsVideo:          e.IsVideo,
                AudioSubStreamID: e.AudioSubStreamID,
        }
}</span>

// ToSourceFile converts source.File to dedup SourceFile.
func ToSourceFile(sf source.File) SourceFile <span class="cov3" title="64">{
        return SourceFile{
                RelativePath: sf.RelativePath,
                Size:         sf.Size,
                Checksum:     sf.Checksum,
        }
}</span>
</pre>
		
		<pre class="file" id="file18" style="display: none">package dedup

import (
        "bytes"
        "encoding/binary"
        "fmt"
        "io"
        "sort"
        "sync"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/mmap"
        "github.com/stuckj/mkvdup/internal/source"
)

// Range map constants
const (
        RangeMapMagic = "RNGEMAPX" // 8 bytes
        // rangeMapCoarseStep is how many entries per coarse index slot.
        // Binary search the coarse index, then seek within a block.
        rangeMapCoarseStep = 1024
)

// RangeMapStreamHeader identifies a stream within the range map section.
type RangeMapStreamHeader struct {
        FileIndex   uint16 // Source file index (0-based)
        StreamType  uint8  // 0 = video, 1 = audio
        SubStreamID uint8  // For audio: sub-stream ID
        EntryCount  uint32 // Number of range entries for this stream
}

// rangeMapCoarseEntry is one slot in the coarse ESOffset index.
type rangeMapCoarseEntry struct {
        esOffset     int64 // ES offset at the start of this entry
        fileOffset   int64 // raw file offset of this entry
        entryIndex   int   // logical entry index
        entrySize    int   // payload size of this entry
        byteOff      int   // byte offset in compressed data for next decode
        rleRemaining int   // default entries remaining after this one in current RLE run
}

// rangeMapCursor tracks position during sequential access through a compressed range map.
type rangeMapCursor struct {
        esOff   int64
        fileOff int64
        size    int
        rleRem  int
        pos     int // position in compressed data
}

// StreamRangeMap provides random access to a stream's range map using
// compressed delta+varint+RLE encoded data and a coarse in-memory ESOffset index.
type StreamRangeMap struct {
        compressedData []byte // compressed range data (zero-copy slice from mmap)
        entryCount     int
        defaultGap     int64
        defaultSize    int
        coarse         []rangeMapCoarseEntry // coarse ESOffset index for binary search
        totalSize      int64                 // total ES size (sum of all entry sizes)

        // Sequential read cursor cache — avoids redundant binary search + seeking
        // for reads at or near the previous position (common in FUSE sequential reads).
        // Protected by cursorMu for concurrent FUSE read safety.
        cursorMu          sync.Mutex
        cachedCursor      rangeMapCursor
        cachedCursorValid bool
}

// TotalESSize returns the total size of the elementary stream.
func (sm *StreamRangeMap) TotalESSize() int64 <span class="cov2" title="14">{
        return sm.totalSize
}</span>

// --- Varint / Zigzag helpers ---

func zigzagEncode(v int64) uint64 <span class="cov3" title="46">{
        return uint64((v &lt;&lt; 1) ^ (v &gt;&gt; 63))
}</span>

func zigzagDecode(v uint64) int64 <span class="cov8" title="189194">{
        return int64(v&gt;&gt;1) ^ -int64(v&amp;1)
}</span>

// --- Compressed encoding ---

// findDefaultsSampleSize is the maximum number of entries to examine when
// determining the most common gap and size. For typical media streams the
// pattern is consistent throughout, so a small sample is sufficient and
// avoids O(N) map operations on streams with hundreds of millions of entries.
const findDefaultsSampleSize = 10000

// findDefaults finds the most common gap and size in a range sequence.
// Uses sampling for large inputs to avoid expensive map operations.
// Returns (0, 0) if ranges are too small or values don't fit in uint16.
func findDefaults(ranges []source.PESPayloadRange) (defaultGap int64, defaultSize int) <span class="cov3" title="32">{
        if len(ranges) &lt; 2 </span><span class="cov2" title="6">{
                if len(ranges) == 1 </span><span class="cov1" title="4">{
                        return 0, ranges[0].Size
                }</span>
                <span class="cov1" title="2">return 0, 0</span>
        }

        // Sample a prefix — patterns in PES streams are consistent throughout.
        <span class="cov2" title="26">sampleLen := len(ranges)
        if sampleLen &gt; findDefaultsSampleSize </span><span class="cov0" title="0">{
                sampleLen = findDefaultsSampleSize
        }</span>

        // Count gap frequencies (sample only)
        <span class="cov2" title="26">gapCounts := make(map[int64]int)
        for i := 1; i &lt; sampleLen; i++ </span><span class="cov6" title="20544">{
                prevEnd := ranges[i-1].FileOffset + int64(ranges[i-1].Size)
                gap := ranges[i].FileOffset - prevEnd
                gapCounts[gap]++
        }</span>

        <span class="cov2" title="26">var bestGap int64
        bestGapCount := 0
        for gap, count := range gapCounts </span><span class="cov3" title="36">{
                if count &gt; bestGapCount </span><span class="cov2" title="26">{
                        bestGap = gap
                        bestGapCount = count
                }</span>
        }

        // Count size frequencies (sample only)
        <span class="cov2" title="26">sizeCounts := make(map[int]int)
        for i := 0; i &lt; sampleLen; i++ </span><span class="cov6" title="20570">{
                sizeCounts[ranges[i].Size]++
        }</span>

        <span class="cov2" title="26">var bestSize int
        bestSizeCount := 0
        for size, count := range sizeCounts </span><span class="cov3" title="42">{
                if count &gt; bestSizeCount </span><span class="cov2" title="29">{
                        bestSize = size
                        bestSizeCount = count
                }</span>
        }

        // Clamp to uint16 range for on-disk storage; disable RLE if out of range
        <span class="cov2" title="26">if bestGap &lt; 0 || bestGap &gt; 65535 || bestSize &gt; 65535 </span><span class="cov0" title="0">{
                return 0, 0
        }</span>

        <span class="cov2" title="26">return bestGap, bestSize</span>
}

// encodeCompressedRanges encodes PES payload ranges using delta+varint+RLE.
//
// Format:
//   - First entry: fileOffset (uvarint) + size (uvarint)
//   - Subsequent entries:
//   - 0x00 + count (uvarint): RLE run of count default entries
//   - (zigzag(delta)+1) (uvarint) + size (uvarint): explicit entry
//
// The +1 shift ensures explicit entries never start with 0x00.
// offsetFunc, if non-nil, converts parser-relative FileOffset values to
// source-file-relative offsets (e.g., adding ISO base offset). The encoded
// data always stores converted offsets.
func encodeCompressedRanges(ranges []source.PESPayloadRange, defaultGap int64, defaultSize int, offsetFunc func(int64) int64) []byte <span class="cov2" title="26">{
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Use direct []byte append instead of bytes.Buffer to minimize overhead
        // in the hot loop. Initial capacity is generous for the header; the bulk
        // of the data compresses to very few bytes via RLE.
        <span class="cov2" title="26">out := make([]byte, 0, 256)
        var varintBuf [binary.MaxVarintLen64]byte

        // Resolve first entry's offset (apply conversion if needed)
        prevOff := ranges[0].FileOffset
        if offsetFunc != nil </span><span class="cov2" title="6">{
                prevOff = offsetFunc(prevOff)
        }</span>

        // First entry: always explicit
        <span class="cov2" title="26">n := binary.PutUvarint(varintBuf[:], uint64(prevOff))
        out = append(out, varintBuf[:n]...)
        n = binary.PutUvarint(varintBuf[:], uint64(ranges[0].Size))
        out = append(out, varintBuf[:n]...)

        // Subsequent entries: RLE or explicit
        rleCount := 0

        for i := 1; i &lt; len(ranges); i++ </span><span class="cov6" title="20538">{
                curOff := ranges[i].FileOffset
                if offsetFunc != nil </span><span class="cov2" title="12">{
                        curOff = offsetFunc(curOff)
                }</span>

                <span class="cov6" title="20538">prevEnd := prevOff + int64(ranges[i-1].Size)
                gap := curOff - prevEnd

                if gap == defaultGap &amp;&amp; ranges[i].Size == defaultSize </span><span class="cov6" title="20524">{
                        rleCount++
                }</span> else<span class="cov2" title="14"> {
                        // Flush pending RLE
                        if rleCount &gt; 0 </span><span class="cov1" title="4">{
                                out = append(out, 0x00)
                                n := binary.PutUvarint(varintBuf[:], uint64(rleCount))
                                out = append(out, varintBuf[:n]...)
                                rleCount = 0
                        }</span>

                        <span class="cov2" title="14">predicted := prevEnd + defaultGap
                        delta := curOff - predicted
                        encoded := zigzagEncode(delta) + 1

                        n := binary.PutUvarint(varintBuf[:], encoded)
                        out = append(out, varintBuf[:n]...)
                        n = binary.PutUvarint(varintBuf[:], uint64(ranges[i].Size))
                        out = append(out, varintBuf[:n]...)</span>
                }

                <span class="cov6" title="20538">prevOff = curOff</span>
        }

        // Flush final RLE
        <span class="cov2" title="26">if rleCount &gt; 0 </span><span class="cov2" title="22">{
                out = append(out, 0x00)
                n := binary.PutUvarint(varintBuf[:], uint64(rleCount))
                out = append(out, varintBuf[:n]...)
        }</span>

        <span class="cov2" title="26">return out</span>
}

// --- Compressed decoding ---

// buildStreamRangeMap creates a StreamRangeMap from compressed data.
// It decodes the entire stream once to build a coarse ESOffset index.
func buildStreamRangeMap(compressedData []byte, entryCount int, defaultGap int64, defaultSize int) (*StreamRangeMap, error) <span class="cov2" title="26">{
        if entryCount == 0 </span><span class="cov0" title="0">{
                return &amp;StreamRangeMap{entryCount: 0}, nil
        }</span>

        <span class="cov2" title="26">sm := &amp;StreamRangeMap{
                compressedData: compressedData,
                entryCount:     entryCount,
                defaultGap:     defaultGap,
                defaultSize:    defaultSize,
        }

        // Build coarse index by iterating through all entries
        coarseCount := (entryCount + rangeMapCoarseStep - 1) / rangeMapCoarseStep
        sm.coarse = make([]rangeMapCoarseEntry, 0, coarseCount)

        // Decode first entry
        pos := 0
        fo, n := binary.Uvarint(compressedData[pos:])
        if n &lt;= 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("truncated first entry fileOffset")
        }</span>
        <span class="cov2" title="26">pos += n
        sz, n := binary.Uvarint(compressedData[pos:])
        if n &lt;= 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("truncated first entry size")
        }</span>
        <span class="cov2" title="26">pos += n

        var esOff int64
        fileOff := int64(fo)
        entSize := int(sz)
        rleRem := 0

        // Record coarse entry for entry 0
        sm.coarse = append(sm.coarse, rangeMapCoarseEntry{
                esOffset: 0, fileOffset: fileOff, entryIndex: 0, entrySize: entSize,
                byteOff: pos, rleRemaining: 0,
        })

        // Iterate through entries 1..entryCount-1
        for i := 1; i &lt; entryCount; i++ </span><span class="cov10" title="4501985">{
                prevEnd := fileOff + int64(entSize)
                esOff += int64(entSize)

                if rleRem &gt; 0 </span><span class="cov9" title="4383976">{
                        // Still in RLE run
                        fileOff = prevEnd + defaultGap
                        entSize = defaultSize
                        rleRem--
                }</span> else<span class="cov7" title="118009"> if pos &lt; len(compressedData) &amp;&amp; compressedData[pos] == 0x00 </span><span class="cov7" title="39275">{
                        // RLE token
                        pos++
                        count, n := binary.Uvarint(compressedData[pos:])
                        if n &lt;= 0 </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("truncated RLE count at entry %d", i)
                        }</span>
                        <span class="cov7" title="39275">pos += n
                        fileOff = prevEnd + defaultGap
                        entSize = defaultSize
                        rleRem = int(count) - 1</span>
                } else<span class="cov7" title="78734"> if pos &lt; len(compressedData) </span><span class="cov7" title="78734">{
                        // Explicit entry
                        encoded, n := binary.Uvarint(compressedData[pos:])
                        if n &lt;= 0 </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("truncated explicit delta at entry %d", i)
                        }</span>
                        <span class="cov7" title="78734">pos += n
                        szv, n := binary.Uvarint(compressedData[pos:])
                        if n &lt;= 0 </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("truncated explicit size at entry %d", i)
                        }</span>
                        <span class="cov7" title="78734">pos += n
                        delta := zigzagDecode(encoded - 1)
                        fileOff = prevEnd + defaultGap + delta
                        entSize = int(szv)
                        rleRem = 0</span>
                } else<span class="cov0" title="0"> {
                        return nil, fmt.Errorf("unexpected end of compressed data at entry %d", i)
                }</span>

                <span class="cov10" title="4501985">if i%rangeMapCoarseStep == 0 </span><span class="cov5" title="4391">{
                        sm.coarse = append(sm.coarse, rangeMapCoarseEntry{
                                esOffset: esOff, fileOffset: fileOff, entryIndex: i, entrySize: entSize,
                                byteOff: pos, rleRemaining: rleRem,
                        })
                }</span>
        }

        <span class="cov2" title="26">sm.totalSize = esOff + int64(entSize)

        return sm, nil</span>
}

// advanceCursor moves the cursor forward by one entry.
func (sm *StreamRangeMap) advanceCursor(c *rangeMapCursor) error <span class="cov8" title="163313">{
        prevEnd := c.fileOff + int64(c.size)
        c.esOff += int64(c.size)

        if c.rleRem &gt; 0 </span><span class="cov0" title="0">{
                c.fileOff = prevEnd + sm.defaultGap
                c.size = sm.defaultSize
                c.rleRem--
                return nil
        }</span>

        <span class="cov8" title="163313">if c.pos &gt;= len(sm.compressedData) </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected end of compressed data")
        }</span>

        <span class="cov8" title="163313">if sm.compressedData[c.pos] == 0x00 </span><span class="cov7" title="52875">{
                c.pos++
                count, n := binary.Uvarint(sm.compressedData[c.pos:])
                if n &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("truncated RLE count")
                }</span>
                <span class="cov7" title="52875">c.pos += n
                c.fileOff = prevEnd + sm.defaultGap
                c.size = sm.defaultSize
                c.rleRem = int(count) - 1</span>
        } else<span class="cov7" title="110438"> {
                encoded, n := binary.Uvarint(sm.compressedData[c.pos:])
                if n &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("truncated explicit delta")
                }</span>
                <span class="cov7" title="110438">c.pos += n
                szv, n := binary.Uvarint(sm.compressedData[c.pos:])
                if n &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("truncated explicit size")
                }</span>
                <span class="cov7" title="110438">c.pos += n
                delta := zigzagDecode(encoded - 1)
                c.fileOff = prevEnd + sm.defaultGap + delta
                c.size = int(szv)
                c.rleRem = 0</span>
        }

        <span class="cov8" title="163313">return nil</span>
}

// seekTo positions a cursor at the entry containing esOffset.
// Uses the cached cursor for O(1) sequential reads, falling back to
// coarse index binary search + seek for random access.
func (sm *StreamRangeMap) seekTo(esOffset int64) (rangeMapCursor, error) <span class="cov7" title="74316">{
        // Fast path: check if cached cursor is at or before the target.
        // Lock to get a consistent snapshot of the cached cursor.
        sm.cursorMu.Lock()
        cachedValid := sm.cachedCursorValid
        var cc rangeMapCursor
        if cachedValid </span><span class="cov7" title="74296">{
                cc = sm.cachedCursor // Copy while holding lock
        }</span>
        <span class="cov7" title="74316">sm.cursorMu.Unlock()

        if cachedValid </span><span class="cov7" title="74296">{
                curEnd := cc.esOff + int64(cc.size)
                if esOffset &gt;= cc.esOff &amp;&amp; esOffset &lt; curEnd </span><span class="cov7" title="38057">{
                        // Target is within the cached entry — use directly
                        return cc, nil
                }</span>
                <span class="cov7" title="36239">if esOffset &gt;= curEnd </span><span class="cov7" title="35867">{
                        // Target is ahead of cached cursor — try seeking forward.
                        // Only use this path if the target is "close" (within ~2 coarse blocks).
                        maxForwardSeek := int64(rangeMapCoarseStep*2) * int64(sm.defaultSize+1)
                        if maxForwardSeek &gt; 0 &amp;&amp; esOffset-curEnd &lt; maxForwardSeek </span><span class="cov7" title="35739">{
                                cur := cc
                                for cur.esOff+int64(cur.size) &lt;= esOffset </span><span class="cov7" title="55117">{
                                        // RLE fast path: use arithmetic to skip directly to the target entry
                                        // instead of advancing one-by-one through the RLE run.
                                        if cur.rleRem &gt; 0 &amp;&amp; sm.defaultSize &gt; 0 </span><span class="cov5" title="2866">{
                                                afterCurrent := cur.esOff + int64(cur.size)
                                                maxRLEES := afterCurrent + int64(cur.rleRem)*int64(sm.defaultSize)
                                                if esOffset &lt; maxRLEES </span><span class="cov2" title="14">{
                                                        // k = entries to skip (1-based). k-1 in offset calc positions
                                                        // relative to afterCurrent (the start of entry 1 in the run).
                                                        k := int((esOffset-afterCurrent)/int64(sm.defaultSize)) + 1
                                                        if k &gt; cur.rleRem </span><span class="cov0" title="0">{
                                                                k = cur.rleRem
                                                        }</span>
                                                        <span class="cov2" title="14">stride := int64(sm.defaultSize) + sm.defaultGap
                                                        cur.esOff = afterCurrent + int64(k-1)*int64(sm.defaultSize)
                                                        cur.fileOff = cur.fileOff + int64(cur.size) + sm.defaultGap + int64(k-1)*stride
                                                        cur.size = sm.defaultSize
                                                        cur.rleRem -= k
                                                        continue</span>
                                                }
                                                <span class="cov5" title="2852">k := cur.rleRem
                                                stride := int64(sm.defaultSize) + sm.defaultGap
                                                cur.esOff = afterCurrent + int64(k-1)*int64(sm.defaultSize)
                                                cur.fileOff = cur.fileOff + int64(cur.size) + sm.defaultGap + int64(k-1)*stride
                                                cur.size = sm.defaultSize
                                                cur.rleRem = 0
                                                continue</span>
                                        }
                                        <span class="cov7" title="52251">if err := sm.advanceCursor(&amp;cur); err != nil </span><span class="cov0" title="0">{
                                                return rangeMapCursor{}, fmt.Errorf("seek to ES offset %d: %w", esOffset, err)
                                        }</span>
                                }
                                <span class="cov7" title="35739">return cur, nil</span>
                        }
                }
        }

        // Slow path: binary search the coarse index
        <span class="cov4" title="520">blockIdx := sort.Search(len(sm.coarse), func(i int) bool </span><span class="cov6" title="6120">{
                return sm.coarse[i].esOffset &gt; esOffset
        }</span>) - 1
        <span class="cov4" title="520">if blockIdx &lt; 0 </span><span class="cov0" title="0">{
                blockIdx = 0
        }</span>

        <span class="cov4" title="520">ce := &amp;sm.coarse[blockIdx]
        cur := rangeMapCursor{
                esOff:   ce.esOffset,
                fileOff: ce.fileOffset,
                size:    ce.entrySize,
                rleRem:  ce.rleRemaining,
                pos:     ce.byteOff,
        }

        for cur.esOff+int64(cur.size) &lt;= esOffset </span><span class="cov7" title="35896">{
                if cur.rleRem &gt; 0 &amp;&amp; sm.defaultSize &gt; 0 </span><span class="cov6" title="6630">{
                        afterCurrent := cur.esOff + int64(cur.size)
                        maxRLEES := afterCurrent + int64(cur.rleRem)*int64(sm.defaultSize)
                        if esOffset &lt; maxRLEES </span><span class="cov2" title="6">{
                                k := int((esOffset-afterCurrent)/int64(sm.defaultSize)) + 1
                                if k &gt; cur.rleRem </span><span class="cov0" title="0">{
                                        k = cur.rleRem
                                }</span>
                                <span class="cov2" title="6">stride := int64(sm.defaultSize) + sm.defaultGap
                                cur.esOff = afterCurrent + int64(k-1)*int64(sm.defaultSize)
                                cur.fileOff = cur.fileOff + int64(cur.size) + sm.defaultGap + int64(k-1)*stride
                                cur.size = sm.defaultSize
                                cur.rleRem -= k
                                continue</span>
                        }
                        <span class="cov6" title="6624">k := cur.rleRem
                        stride := int64(sm.defaultSize) + sm.defaultGap
                        cur.esOff = afterCurrent + int64(k-1)*int64(sm.defaultSize)
                        cur.fileOff = cur.fileOff + int64(cur.size) + sm.defaultGap + int64(k-1)*stride
                        cur.size = sm.defaultSize
                        cur.rleRem = 0
                        continue</span>
                }
                <span class="cov7" title="29266">if err := sm.advanceCursor(&amp;cur); err != nil </span><span class="cov0" title="0">{
                        return rangeMapCursor{}, fmt.Errorf("seek to ES offset %d: %w", esOffset, err)
                }</span>
        }

        <span class="cov4" title="520">return cur, nil</span>
}

// ReadData reads ES data at the given offset, copying into a new buffer.
// Uses the coarse index for fast binary search, RLE arithmetic for fast seeking.
func (sm *StreamRangeMap) ReadData(sourceData []byte, sourceSize int64, esOffset int64, size int) ([]byte, error) <span class="cov3" title="50">{
        if sm.entryCount == 0 </span><span class="cov1" title="2">{
                return nil, fmt.Errorf("empty range map")
        }</span>

        <span class="cov3" title="48">cur, err := sm.seekTo(esOffset)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Read data, potentially spanning multiple entries
        <span class="cov3" title="48">result := make([]byte, 0, size)
        remaining := size

        for remaining &gt; 0 </span><span class="cov3" title="50">{
                offsetInEntry := esOffset - cur.esOff
                if offsetInEntry &lt; 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("ES offset gap at ES %d", cur.esOff)
                }</span>

                <span class="cov3" title="50">available := int64(cur.size) - offsetInEntry
                toRead := int64(remaining)
                if toRead &gt; available </span><span class="cov1" title="4">{
                        toRead = available
                }</span>

                <span class="cov3" title="50">srcStart := cur.fileOff + offsetInEntry
                srcEnd := srcStart + toRead
                if srcEnd &gt; sourceSize </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("source read out of bounds: %d + %d &gt; %d", srcStart, toRead, sourceSize)
                }</span>
                <span class="cov3" title="50">result = append(result, sourceData[srcStart:srcEnd]...)

                remaining -= int(toRead)
                esOffset += toRead

                if remaining &gt; 0 </span><span class="cov1" title="4">{
                        // RLE batch path: batch-copy full entries using stride arithmetic.
                        if cur.rleRem &gt; 0 </span><span class="cov1" title="2">{
                                cur.esOff += int64(cur.size)
                                cur.fileOff += int64(cur.size) + sm.defaultGap
                                cur.size = sm.defaultSize
                                cur.rleRem--

                                stride := int64(sm.defaultSize) + sm.defaultGap
                                defSz := sm.defaultSize
                                defSz64 := int64(defSz)

                                // Calculate how many full entries we can batch-copy
                                batchCount := remaining / defSz
                                if maxRLE := cur.rleRem + 1; batchCount &gt; maxRLE </span><span class="cov0" title="0">{
                                        batchCount = maxRLE
                                }</span>

                                <span class="cov1" title="2">if batchCount &gt; 0 </span><span class="cov1" title="2">{
                                        lastSrcEnd := cur.fileOff + int64(batchCount-1)*stride + defSz64
                                        if lastSrcEnd &gt; sourceSize </span><span class="cov0" title="0">{
                                                return nil, fmt.Errorf("source read out of bounds: %d &gt; %d",
                                                        lastSrcEnd, sourceSize)
                                        }</span>
                                        <span class="cov1" title="2">off := len(result)
                                        result = result[:off+batchCount*defSz]
                                        stridedCopy(
                                                result[off:off+batchCount*defSz],
                                                sourceData[cur.fileOff:lastSrcEnd],
                                                batchCount, defSz, int(stride),
                                        )
                                        copied := batchCount * defSz
                                        remaining -= copied
                                        esOffset += int64(copied)
                                        if batchCount &gt; 1 </span><span class="cov1" title="2">{
                                                advance := batchCount - 1
                                                cur.esOff += int64(advance) * defSz64
                                                cur.fileOff += int64(advance) * stride
                                                cur.rleRem -= advance
                                        }</span>
                                }
                                <span class="cov1" title="2">continue</span>
                        }

                        <span class="cov1" title="2">if err := sm.advanceCursor(&amp;cur); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read spanning entries: %w", err)
                        }</span>
                }
        }

        // Update cached cursor for next sequential read
        <span class="cov3" title="48">sm.cursorMu.Lock()
        sm.cachedCursor = cur
        sm.cachedCursorValid = true
        sm.cursorMu.Unlock()

        return result, nil</span>
}

// ReadDataInto reads ES data at the given offset directly into dest, avoiding allocation.
// Returns the number of bytes written. Uses cached cursor for sequential reads.
//
// The source parameter provides read access to the source file. If source
// implements MmapData, the mmap'd byte slice is used for zero-copy reads.
// Otherwise, source.ReadAt is used (pread path for network filesystems).
func (sm *StreamRangeMap) ReadDataInto(source mmap.SourceFile, esOffset int64, dest []byte) (int, error) <span class="cov7" title="74268">{
        if sm.entryCount == 0 </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("empty range map")
        }</span>

        <span class="cov7" title="74268">sourceSize := source.Size()

        // Resolve mmap data once for the zero-copy fast path.
        var sourceData []byte
        if md, ok := source.(mmap.MmapData); ok </span><span class="cov7" title="74268">{
                sourceData = md.Data()
        }</span>

        <span class="cov7" title="74268">cur, err := sm.seekTo(esOffset)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        // Read data directly into dest, potentially spanning multiple entries
        <span class="cov7" title="74268">written := 0
        remaining := len(dest)

        for remaining &gt; 0 </span><span class="cov8" title="257357">{
                offsetInEntry := esOffset - cur.esOff
                if offsetInEntry &lt; 0 </span><span class="cov0" title="0">{
                        return written, fmt.Errorf("ES offset gap at ES %d", cur.esOff)
                }</span>

                <span class="cov8" title="257357">available := int64(cur.size) - offsetInEntry
                toRead := int64(remaining)
                if toRead &gt; available </span><span class="cov8" title="183268">{
                        toRead = available
                }</span>

                <span class="cov8" title="257357">srcStart := cur.fileOff + offsetInEntry
                srcEnd := srcStart + toRead
                if srcEnd &gt; sourceSize </span><span class="cov0" title="0">{
                        return written, fmt.Errorf("source read out of bounds: %d + %d &gt; %d", srcStart, toRead, sourceSize)
                }</span>
                <span class="cov8" title="257357">if sourceData != nil </span><span class="cov8" title="257357">{
                        copy(dest[written:], sourceData[srcStart:srcEnd])
                }</span> else<span class="cov0" title="0"> {
                        if n, err := source.ReadAt(dest[written:written+int(toRead)], srcStart); err != nil &amp;&amp; !(n == int(toRead) &amp;&amp; err == io.EOF) </span><span class="cov0" title="0">{
                                return written, fmt.Errorf("pread at %d: %w", srcStart, err)
                        }</span>
                }

                <span class="cov8" title="257357">written += int(toRead)
                remaining -= int(toRead)
                esOffset += toRead

                if remaining &gt; 0 </span><span class="cov8" title="183268">{
                        // RLE batch path: when the next entries are in an RLE run,
                        // batch-copy full entries using a single strided copy instead of
                        // calling copy()/advanceCursor per entry.
                        if cur.rleRem &gt; 0 </span><span class="cov7" title="101474">{
                                // Advance to next RLE entry (equivalent to one advanceCursor)
                                cur.esOff += int64(cur.size)
                                cur.fileOff += int64(cur.size) + sm.defaultGap
                                cur.size = sm.defaultSize
                                cur.rleRem--

                                stride := int64(sm.defaultSize) + sm.defaultGap
                                defSz := sm.defaultSize
                                defSz64 := int64(defSz)

                                // Calculate how many full entries we can batch-copy
                                batchCount := remaining / defSz
                                if maxRLE := cur.rleRem + 1; batchCount &gt; maxRLE </span><span class="cov0" title="0">{
                                        batchCount = maxRLE
                                }</span>

                                <span class="cov7" title="101474">if batchCount &gt; 0 </span><span class="cov7" title="66699">{
                                        // Bounds check the entire batch
                                        lastSrcEnd := cur.fileOff + int64(batchCount-1)*stride + defSz64
                                        if lastSrcEnd &gt; sourceSize </span><span class="cov0" title="0">{
                                                return written, fmt.Errorf("source read out of bounds: %d &gt; %d",
                                                        lastSrcEnd, sourceSize)
                                        }</span>
                                        <span class="cov7" title="66699">if sourceData != nil </span><span class="cov7" title="66699">{
                                                stridedCopy(
                                                        dest[written:written+batchCount*defSz],
                                                        sourceData[cur.fileOff:lastSrcEnd],
                                                        batchCount, defSz, int(stride),
                                                )
                                        }</span> else<span class="cov0" title="0"> {
                                                // Pread path: read the contiguous source region into a
                                                // temp buffer, then strided-copy into dest.
                                                // tmpSize is bounded by ~len(dest) * stride/defSz, which
                                                // for Blu-ray M2TS (192/188) is ≈1.02× the dest buffer.
                                                // Since dest comes from a FUSE read (typically 128KB, max
                                                // ~1MB), this allocation is small and short-lived. If
                                                // profiling shows GC pressure, consider a sync.Pool here.
                                                tmpSize := int(lastSrcEnd - cur.fileOff)
                                                tmp := make([]byte, tmpSize)
                                                if n, err := source.ReadAt(tmp, cur.fileOff); err != nil &amp;&amp; !(n == tmpSize &amp;&amp; err == io.EOF) </span><span class="cov0" title="0">{
                                                        return written, fmt.Errorf("pread batch at %d: %w", cur.fileOff, err)
                                                }</span>
                                                <span class="cov0" title="0">stridedCopy(
                                                        dest[written:written+batchCount*defSz],
                                                        tmp,
                                                        batchCount, defSz, int(stride),
                                                )</span>
                                        }
                                        <span class="cov7" title="66699">copied := batchCount * defSz
                                        written += copied
                                        remaining -= copied
                                        esOffset += int64(copied)
                                        // Position cursor at the last copied entry
                                        if batchCount &gt; 1 </span><span class="cov7" title="46077">{
                                                advance := batchCount - 1
                                                cur.esOff += int64(advance) * defSz64
                                                cur.fileOff += int64(advance) * stride
                                                cur.rleRem -= advance
                                        }</span>
                                }
                                <span class="cov7" title="101474">continue</span>
                        }

                        <span class="cov7" title="81794">if err := sm.advanceCursor(&amp;cur); err != nil </span><span class="cov0" title="0">{
                                return written, fmt.Errorf("read spanning entries: %w", err)
                        }</span>
                }
        }

        // Update cached cursor for next sequential read
        <span class="cov7" title="74268">sm.cursorMu.Lock()
        sm.cachedCursor = cur
        sm.cachedCursorValid = true
        sm.cursorMu.Unlock()

        return written, nil</span>
}

// --- Deserialization (for Reader) ---

// SourceRangeMaps holds parsed range maps for one source file.
type SourceRangeMaps struct {
        FileIndex uint16
        VideoMap  *StreamRangeMap
        AudioMaps map[byte]*StreamRangeMap // keyed by sub-stream ID
}

// readRangeMapSection parses the range map section from mmap'd data.
// The data slice should point to the start of the range map section.
// Compressed data is zero-copy sliced from the input.
func readRangeMapSection(data []byte) ([]SourceRangeMaps, error) <span class="cov1" title="5">{
        if len(data) &lt; 10 </span><span class="cov0" title="0">{ // magic (8) + source count (2)
                return nil, fmt.Errorf("range map section too small: %d bytes", len(data))
        }</span>

        // Verify magic
        <span class="cov1" title="5">if string(data[:8]) != RangeMapMagic </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid range map magic: %q", data[:8])
        }</span>
        <span class="cov1" title="5">off := 8

        // Source count
        sourceCount := int(binary.LittleEndian.Uint16(data[off : off+2]))
        off += 2

        result := make([]SourceRangeMaps, 0, sourceCount)

        for s := 0; s &lt; sourceCount; s++ </span><span class="cov1" title="5">{
                if off+3 &gt; len(data) </span><span class="cov0" title="0">{ // FileIndex (2) + StreamCount (1)
                        return nil, fmt.Errorf("truncated range map at source %d", s)
                }</span>

                <span class="cov1" title="5">fileIndex := binary.LittleEndian.Uint16(data[off : off+2])
                off += 2
                streamCount := int(data[off])
                off++

                src := SourceRangeMaps{
                        FileIndex: fileIndex,
                        AudioMaps: make(map[byte]*StreamRangeMap),
                }

                for st := 0; st &lt; streamCount; st++ </span><span class="cov2" title="10">{
                        if off+8 &gt; len(data) </span><span class="cov0" title="0">{ // StreamHeader size
                                return nil, fmt.Errorf("truncated stream header at source %d stream %d", s, st)
                        }</span>

                        // Parse stream header
                        <span class="cov2" title="10">var hdr RangeMapStreamHeader
                        _ = binary.LittleEndian.Uint16(data[off : off+2]) // per-stream FileIndex (already tracked per source)
                        hdr.StreamType = data[off+2]
                        hdr.SubStreamID = data[off+3]
                        hdr.EntryCount = binary.LittleEndian.Uint32(data[off+4 : off+8])
                        off += 8

                        // Read compression parameters
                        if off+8 &gt; len(data) </span><span class="cov0" title="0">{ // DefaultGap(2) + DefaultSize(2) + CompressedDataSize(4)
                                return nil, fmt.Errorf("truncated compression params at source %d stream %d", s, st)
                        }</span>
                        <span class="cov2" title="10">defGap := int64(binary.LittleEndian.Uint16(data[off : off+2]))
                        off += 2
                        defSize := int(binary.LittleEndian.Uint16(data[off : off+2]))
                        off += 2
                        compSize := int(binary.LittleEndian.Uint32(data[off : off+4]))
                        off += 4

                        if off+compSize &gt; len(data) </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("truncated compressed data at source %d stream %d: need %d bytes at offset %d, have %d total",
                                        s, st, compSize, off, len(data))
                        }</span>

                        // Zero-copy slice into mmap'd data
                        <span class="cov2" title="10">compData := data[off : off+compSize]
                        off += compSize

                        sm, err := buildStreamRangeMap(compData, int(hdr.EntryCount), defGap, defSize)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("build range map for source %d stream %d: %w", s, st, err)
                        }</span>

                        <span class="cov2" title="10">if hdr.StreamType == 0 </span><span class="cov1" title="5">{
                                src.VideoMap = sm
                        }</span> else<span class="cov1" title="5"> {
                                src.AudioMaps[hdr.SubStreamID] = sm
                        }</span>
                }

                <span class="cov1" title="5">result = append(result, src)</span>
        }

        <span class="cov1" title="5">return result, nil</span>
}

// --- Serialization (for Writer) ---

// RangeMapData holds the range map data for all streams of one source file,
// ready for serialization into the dedup file.
type RangeMapData struct {
        FileIndex    uint16
        VideoRanges  []source.PESPayloadRange
        AudioStreams []AudioRangeData
        OffsetFunc   func(int64) int64 // optional: converts parser-relative to source-file-relative FileOffset
}

// AudioRangeData holds range data for one audio sub-stream.
type AudioRangeData struct {
        SubStreamID byte
        Ranges      []source.PESPayloadRange
}

// encodeRangeMapSection encodes the entire range map section to a byte buffer.
// This is called before writing to determine the exact size and compute the checksum.
func encodeRangeMapSection(rangeMaps []RangeMapData) ([]byte, error) <span class="cov1" title="4">{
        var buf bytes.Buffer

        // Magic
        buf.Write([]byte(RangeMapMagic))

        // Source count
        var tmp [8]byte
        binary.LittleEndian.PutUint16(tmp[:2], uint16(len(rangeMaps)))
        buf.Write(tmp[:2])

        // Write each source's stream range maps
        for _, rm := range rangeMaps </span><span class="cov1" title="4">{
                // Count streams
                streamCount := uint8(0)
                if len(rm.VideoRanges) &gt; 0 </span><span class="cov1" title="4">{
                        streamCount++
                }</span>
                <span class="cov1" title="4">streamCount += uint8(len(rm.AudioStreams))

                binary.LittleEndian.PutUint16(tmp[:2], rm.FileIndex)
                buf.Write(tmp[:2])
                buf.WriteByte(streamCount)

                // Video stream
                if len(rm.VideoRanges) &gt; 0 </span><span class="cov1" title="4">{
                        writeCompressedStream(&amp;buf, rm.FileIndex, 0, 0, rm.VideoRanges, rm.OffsetFunc)
                }</span>

                // Audio streams
                <span class="cov1" title="4">for _, audio := range rm.AudioStreams </span><span class="cov1" title="4">{
                        writeCompressedStream(&amp;buf, rm.FileIndex, 1, audio.SubStreamID, audio.Ranges, rm.OffsetFunc)
                }</span>
        }

        <span class="cov1" title="4">return buf.Bytes(), nil</span>
}

// writeCompressedStream writes one stream's compressed range data.
// offsetFunc, if non-nil, converts parser-relative FileOffset values to
// source-file-relative offsets during encoding.
func writeCompressedStream(buf *bytes.Buffer, fileIndex uint16, streamType uint8, subStreamID byte, ranges []source.PESPayloadRange, offsetFunc func(int64) int64) <span class="cov2" title="8">{
        // Stream header: FileIndex(2) + StreamType(1) + SubStreamID(1) + EntryCount(4) = 8 bytes
        var hdrBuf [16]byte
        binary.LittleEndian.PutUint16(hdrBuf[0:2], fileIndex)
        hdrBuf[2] = streamType
        hdrBuf[3] = subStreamID
        binary.LittleEndian.PutUint32(hdrBuf[4:8], uint32(len(ranges)))
        buf.Write(hdrBuf[:8])

        // Find defaults (parser-relative offsets — gaps are the same in both domains
        // for the common non-boundary case, which dominates the mode calculation)
        defGap, defSize := findDefaults(ranges)

        // Compression parameters: DefaultGap(2) + DefaultSize(2) + CompressedDataSize(4) = 8 bytes
        binary.LittleEndian.PutUint16(hdrBuf[0:2], uint16(defGap))
        binary.LittleEndian.PutUint16(hdrBuf[2:4], uint16(defSize))

        // Encode compressed ranges (applies offsetFunc during encoding)
        compressed := encodeCompressedRanges(ranges, defGap, defSize, offsetFunc)

        binary.LittleEndian.PutUint32(hdrBuf[4:8], uint32(len(compressed)))
        buf.Write(hdrBuf[:8])
        buf.Write(compressed)
}</span>

// writeRangeMapSection writes a pre-encoded range map buffer and returns its checksum.
// Used by the writer to write the range map section to the dedup file.
func writeRangeMapSection(w io.Writer, rangeMapBuf []byte) (uint64, error) <span class="cov0" title="0">{
        hasher := xxhash.New()
        hasher.Write(rangeMapBuf)

        if _, err := w.Write(rangeMapBuf); err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov0" title="0">return hasher.Sum64(), nil</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">package dedup

import (
        "encoding/binary"
        "fmt"
        "io"
        "os"
        "sort"
        "sync"
        "time"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/mmap"
        "golang.org/x/sys/unix"
)

// blockSize is the block size for the block index.
// Each block maps an MKV offset range to an entry index for O(1) lookup.
// 64KB balances memory overhead vs scan distance.
const blockSize = 64 * 1024

// Reader reads .mkvdup files and provides data reconstruction.
// Reader is safe for concurrent use from multiple goroutines.
type Reader struct {
        file        *File
        dedupMmap   *mmap.File
        dedupPath   string
        sourceDir   string
        sourceFiles []mmap.SourceFile
        esReader    ESReader  // For ES-based sources (v1 only, deprecated in v2)
        entriesOnce sync.Once // For lazy entry access initialization
        entriesErr  error     // Error from entry access initialization

        // Direct mmap access to entries (no []Entry allocation)
        indexStart int64 // Byte offset where entries begin in file
        entryCount int   // Number of entries

        // Block index for fast entry lookup on cache miss.
        // Maps block_number (MKV offset / blockSize) → entry index for O(1)
        // narrowing, followed by bounded binary search within the block range.
        // Built once in initEntryAccess; immutable after that (no mutex needed).
        blockIndex []int

        // Last-entry cache for O(1) sequential read lookup
        // Protected by cacheMu for concurrent access safety
        cacheMu        sync.Mutex
        lastEntryIdx   int   // Index of last accessed entry (-1 if none)
        lastEntry      Entry // The cached parsed entry
        lastEntryValid bool  // Whether lastEntry is valid

        // V4 range map data (maps ES offsets to raw file offsets)
        rangeMapsByFile map[int]*SourceRangeMaps // file index -&gt; range maps
}

// ESReader interface for reading ES data from MPEG-PS sources.
type ESReader interface {
        ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error)
        ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error)
}

// NewReader opens a dedup file for reading with entry access initialized immediately.
// Use NewReaderLazy for faster initialization when entries can be accessed on first read.
func NewReader(dedupPath, sourceDir string) (*Reader, error) <span class="cov3" title="88">{
        r, err := NewReaderLazy(dedupPath, sourceDir)
        if err != nil </span><span class="cov2" title="13">{
                return nil, err
        }</span>

        // Force immediate entry access initialization
        <span class="cov3" title="75">if err := r.initEntryAccess(); err != nil </span><span class="cov0" title="0">{
                r.Close()
                return nil, fmt.Errorf("init entry access: %w", err)
        }</span>

        <span class="cov3" title="75">return r, nil</span>
}

// NewReaderLazy opens a dedup file but only reads the header.
// Entries are loaded lazily on first Read. Use this for fast mount times with many files.
func NewReaderLazy(dedupPath, sourceDir string) (*Reader, error) <span class="cov3" title="188">{
        f, err := os.Open(dedupPath)
        if err != nil </span><span class="cov2" title="9">{
                return nil, fmt.Errorf("open dedup file: %w", err)
        }</span>
        <span class="cov3" title="179">defer f.Close()

        file, err := parseHeaderOnly(f)
        if err != nil </span><span class="cov2" title="10">{
                return nil, fmt.Errorf("parse dedup header: %w", err)
        }</span>

        // Memory-map the dedup file
        <span class="cov3" title="169">dedupMmap, err := mmap.Open(dedupPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("mmap dedup file: %w", err)
        }</span>

        <span class="cov3" title="169">return &amp;Reader{
                file:         file,
                dedupMmap:    dedupMmap,
                dedupPath:    dedupPath,
                sourceDir:    sourceDir,
                lastEntryIdx: -1, // No entry cached yet
        }, nil</span>
}

// SetESReader sets the ES reader for ES-based sources.
func (r *Reader) SetESReader(esReader ESReader) <span class="cov1" title="2">{
        r.esReader = esReader
}</span>

// LoadSourceFiles memory-maps all source files.
func (r *Reader) LoadSourceFiles() error <span class="cov2" title="17">{
        r.sourceFiles = make([]mmap.SourceFile, len(r.file.SourceFiles))
        for i, sf := range r.file.SourceFiles </span><span class="cov2" title="17">{
                path := r.sourceDir + "/" + sf.RelativePath
                m, err := mmap.Open(path)
                if err != nil </span><span class="cov1" title="2">{
                        // Clean up already opened files
                        for j := 0; j &lt; i; j++ </span><span class="cov0" title="0">{
                                if r.sourceFiles[j] != nil </span><span class="cov0" title="0">{
                                        r.sourceFiles[j].Close()
                                }</span>
                        }
                        <span class="cov1" title="2">return fmt.Errorf("mmap source file %s: %w", sf.RelativePath, err)</span>
                }
                // Hint sequential access so the kernel does aggressive readahead
                // instead of handling individual 4KB page faults.
                <span class="cov2" title="15">m.Advise(unix.MADV_SEQUENTIAL)
                r.sourceFiles[i] = m</span>
        }
        <span class="cov2" title="15">return nil</span>
}

// LoadSourceFilesPread opens all source files using pread(2) instead of mmap.
// This is used for source files on network filesystems where mmap is unsafe.
func (r *Reader) LoadSourceFilesPread(timeout time.Duration) error <span class="cov1" title="1">{
        r.sourceFiles = make([]mmap.SourceFile, len(r.file.SourceFiles))
        for i, sf := range r.file.SourceFiles </span><span class="cov1" title="1">{
                path := r.sourceDir + "/" + sf.RelativePath
                pf, err := mmap.OpenPread(path, timeout)
                if err != nil </span><span class="cov0" title="0">{
                        // Clean up already opened files
                        for j := 0; j &lt; i; j++ </span><span class="cov0" title="0">{
                                if r.sourceFiles[j] != nil </span><span class="cov0" title="0">{
                                        r.sourceFiles[j].Close()
                                }</span>
                        }
                        <span class="cov0" title="0">return fmt.Errorf("open source file %s: %w", sf.RelativePath, err)</span>
                }
                <span class="cov1" title="1">r.sourceFiles[i] = pf</span>
        }
        <span class="cov1" title="1">return nil</span>
}

// Close releases all resources.
func (r *Reader) Close() error <span class="cov3" title="164">{
        if r.dedupMmap != nil </span><span class="cov3" title="164">{
                r.dedupMmap.Close()
        }</span>
        <span class="cov3" title="164">for _, sf := range r.sourceFiles </span><span class="cov2" title="11">{
                if sf != nil </span><span class="cov2" title="9">{
                        sf.Close()
                }</span>
        }
        <span class="cov3" title="164">return nil</span>
}

// initEntryAccess initializes direct mmap access to entries (no parsing into []Entry).
// This is called lazily on first entry access.
func (r *Reader) initEntryAccess() error <span class="cov6" title="8041">{
        r.entriesOnce.Do(func() </span><span class="cov3" title="120">{
                // Calculate index start offset
                r.indexStart = r.file.headerSize + r.calculateSourceFilesSize()
                r.entryCount = int(r.file.Header.EntryCount)

                // Validate mmap has enough data for all entries
                requiredSize := r.indexStart + int64(r.entryCount)*EntrySize
                if int64(r.dedupMmap.Size()) &lt; requiredSize </span><span class="cov0" title="0">{
                        r.entriesErr = fmt.Errorf("mmap too small: need %d, have %d",
                                requiredSize, r.dedupMmap.Size())
                        return
                }</span>

                // Build block index for fast random access lookup
                <span class="cov3" title="120">r.buildBlockIndex()

                // V4/V6/V8: parse range map section
                if r.file.Header.Version == VersionRangeMap || r.file.Header.Version == VersionRangeMapCreator || r.file.Header.Version == VersionRangeMapUsed </span><span class="cov1" title="1">{
                        if err := r.initRangeMaps(); err != nil </span><span class="cov0" title="0">{
                                r.entriesErr = fmt.Errorf("init range maps: %w", err)
                                return
                        }</span>
                }
        })
        <span class="cov6" title="8041">return r.entriesErr</span>
}

// initRangeMaps parses the range map section from the mmap'd dedup file.
func (r *Reader) initRangeMaps() error <span class="cov1" title="1">{
        // Range map section is between delta and footer
        rangeMapOffset := r.file.DeltaOffset + r.file.Header.DeltaSize
        fileSize := r.dedupMmap.Size()
        rangeMapSize := int(fileSize) - FooterV4Size - int(rangeMapOffset)

        if rangeMapSize &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no range map section found (offset %d, file size %d)", rangeMapOffset, fileSize)
        }</span>

        <span class="cov1" title="1">data := r.dedupMmap.Slice(rangeMapOffset, rangeMapSize)
        if data == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("range map slice out of bounds")
        }</span>

        <span class="cov1" title="1">sources, err := readRangeMapSection(data)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse range map section: %w", err)
        }</span>

        <span class="cov1" title="1">r.rangeMapsByFile = make(map[int]*SourceRangeMaps, len(sources))
        for i := range sources </span><span class="cov1" title="1">{
                r.rangeMapsByFile[int(sources[i].FileIndex)] = &amp;sources[i]
        }</span>

        <span class="cov1" title="1">return nil</span>
}

// HasRangeMaps returns true if this dedup file uses V4/V6/V8 range maps.
// This checks the header version (available immediately after NewReaderLazy)
// rather than the lazily-loaded range map data, so it's safe to call
// before the first ReadAt.
func (r *Reader) HasRangeMaps() bool <span class="cov1" title="1">{
        return r.file.Header.Version == VersionRangeMap || r.file.Header.Version == VersionRangeMapCreator || r.file.Header.Version == VersionRangeMapUsed
}</span>

// HasSourceUsedFlags returns true if the dedup file has per-source-file Used flags (V7/V8).
func (r *Reader) HasSourceUsedFlags() bool <span class="cov1" title="4">{
        return r.file.Header.Version == VersionUsed || r.file.Header.Version == VersionRangeMapUsed
}</span>

// buildBlockIndex creates a mapping from block numbers to entry indices.
// Each block represents a fixed-size range of MKV offsets. The index maps
// block_number → the entry index whose region covers or precedes that block's
// start offset. This narrows binary search from O(log N) over all entries
// to O(log B) within a single block's entries.
//
// Algorithm: single pass over all entries, filling block slots as we go.
// Time: O(entryCount + blockCount), Space: O(blockCount).
func (r *Reader) buildBlockIndex() <span class="cov3" title="120">{
        originalSize := r.file.Header.OriginalSize
        if originalSize &lt;= 0 || r.entryCount == 0 </span><span class="cov2" title="21">{
                return
        }</span>

        <span class="cov3" title="99">blockCount := int((originalSize + blockSize - 1) / blockSize)
        r.blockIndex = make([]int, blockCount)

        entryIdx := 0
        for b := range blockCount </span><span class="cov7" title="176681">{
                blockStart := int64(b) * blockSize
                // Advance entryIdx to the last entry whose MkvOffset &lt;= blockStart.
                // For block 0 (blockStart=0), this stays at 0 since no entry precedes it.
                for entryIdx+1 &lt; r.entryCount </span><span class="cov9" title="7472388">{
                        nextOffset, ok := r.getMkvOffset(entryIdx + 1)
                        if !ok || nextOffset &gt; blockStart </span><span class="cov7" title="175462">{
                                break</span>
                        }
                        <span class="cov9" title="7296926">entryIdx++</span>
                }
                <span class="cov7" title="176681">r.blockIndex[b] = entryIdx</span>
        }
}

// getEntry returns the entry at the given index by parsing from mmap.
// Uses cache for O(1) sequential access. Safe for concurrent use.
func (r *Reader) getEntry(idx int) (Entry, bool) <span class="cov8" title="1258492">{
        if idx &lt; 0 || idx &gt;= r.entryCount </span><span class="cov2" title="10">{
                return Entry{}, false
        }</span>

        // Check cache first (with lock)
        <span class="cov8" title="1258482">r.cacheMu.Lock()
        if r.lastEntryValid &amp;&amp; r.lastEntryIdx == idx </span><span class="cov6" title="7848">{
                entry := r.lastEntry
                r.cacheMu.Unlock()
                return entry, true
        }</span>
        <span class="cov8" title="1250634">r.cacheMu.Unlock()

        // Parse entry from mmap using RawEntry (no lock needed - mmap is read-only)
        offset := r.indexStart + int64(idx)*EntrySize
        data := r.dedupMmap.Slice(offset, EntrySize)
        if len(data) &lt; EntrySize </span><span class="cov0" title="0">{
                return Entry{}, false
        }</span>

        // Parse using RawEntry for portable unaligned access
        // Layout: MkvOffset(8) + Length(8) + Source(2) + SourceOffset(8) + ESFlags(1) + AudioSubStreamID(1) = 28
        <span class="cov8" title="1250634">var raw RawEntry
        copy(raw.MkvOffset[:], data[0:8])
        copy(raw.Length[:], data[8:16])
        copy(raw.Source[:], data[16:18])
        copy(raw.SourceOffset[:], data[18:26])
        raw.ESFlags = data[26]
        raw.AudioSubStreamID = data[27]

        entry := raw.ToEntry()

        // Update cache (with lock)
        r.cacheMu.Lock()
        r.lastEntryIdx = idx
        r.lastEntry = entry
        r.lastEntryValid = true
        r.cacheMu.Unlock()

        return entry, true</span>
}

// getMkvOffset returns just the MkvOffset for entry at idx (for binary search).
// This avoids full entry parsing when only the offset is needed.
func (r *Reader) getMkvOffset(idx int) (int64, bool) <span class="cov10" title="7472784">{
        if idx &lt; 0 || idx &gt;= r.entryCount </span><span class="cov1" title="4">{
                return 0, false
        }</span>

        <span class="cov9" title="7472780">offset := r.indexStart + int64(idx)*EntrySize
        data := r.dedupMmap.Slice(offset, 8) // Only read MkvOffset field (first 8 bytes)
        if len(data) &lt; 8 </span><span class="cov0" title="0">{
                return 0, false
        }</span>

        <span class="cov9" title="7472780">return int64(binary.LittleEndian.Uint64(data)), true</span>
}

// getEntryLength returns just the Length for entry at idx (for binary search).
// This avoids full entry parsing when only offset and length are needed.
func (r *Reader) getEntryLength(idx int) (int64, bool) <span class="cov4" title="396">{
        if idx &lt; 0 || idx &gt;= r.entryCount </span><span class="cov1" title="4">{
                return 0, false
        }</span>

        // Length is at offset 8 within each entry (after MkvOffset)
        <span class="cov4" title="392">offset := r.indexStart + int64(idx)*EntrySize + 8
        data := r.dedupMmap.Slice(offset, 8)
        if len(data) &lt; 8 </span><span class="cov0" title="0">{
                return 0, false
        }</span>

        <span class="cov4" title="392">return int64(binary.LittleEndian.Uint64(data)), true</span>
}

// OriginalSize returns the size of the original MKV file.
func (r *Reader) OriginalSize() int64 <span class="cov2" title="33">{
        return r.file.Header.OriginalSize
}</span>

// OriginalChecksum returns the checksum of the original MKV file.
func (r *Reader) OriginalChecksum() uint64 <span class="cov1" title="2">{
        return r.file.Header.OriginalChecksum
}</span>

// SourceFiles returns the list of source files.
func (r *Reader) SourceFiles() []SourceFile <span class="cov2" title="16">{
        return r.file.SourceFiles
}</span>

// EntryCount returns the number of index entries.
// Returns 0 if entry access initialization failed. Use InitEntryAccess() to check for errors.
func (r *Reader) EntryCount() int <span class="cov2" title="14">{
        r.initEntryAccess() // Ensure entryCount is initialized
        return r.entryCount
}</span>

// GetEntry returns the entry at the given index.
// Returns false if the index is out of range or if entry access initialization failed.
func (r *Reader) GetEntry(idx int) (Entry, bool) <span class="cov2" title="8">{
        if err := r.initEntryAccess(); err != nil </span><span class="cov0" title="0">{
                return Entry{}, false
        }</span>
        <span class="cov2" title="8">return r.getEntry(idx)</span>
}

// InitEntryAccess explicitly initializes entry access and returns any error.
// This is useful when you need to check for initialization errors before calling
// methods like EntryCount() or Info() that silently return zero/empty on error.
func (r *Reader) InitEntryAccess() error <span class="cov1" title="4">{
        return r.initEntryAccess()
}</span>

// UsesESOffsets returns true if this dedup file uses ES offsets.
func (r *Reader) UsesESOffsets() bool <span class="cov2" title="12">{
        return r.file.UsesESOffsets
}</span>

// ReadAt reads reconstructed MKV data at the given offset.
func (r *Reader) ReadAt(buf []byte, offset int64) (int, error) <span class="cov6" title="7892">{
        // Initialize entry access on first read (lazy initialization)
        if err := r.initEntryAccess(); err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("init entry access: %w", err)
        }</span>

        <span class="cov6" title="7892">if offset &gt;= r.file.Header.OriginalSize </span><span class="cov2" title="6">{
                return 0, io.EOF
        }</span>

        <span class="cov6" title="7886">totalRead := 0
        remaining := len(buf)
        originalOffset := offset // Preserve original offset for buffer position calculation

        // Limit read to file size
        if offset+int64(remaining) &gt; r.file.Header.OriginalSize </span><span class="cov0" title="0">{
                remaining = int(r.file.Header.OriginalSize - offset)
        }</span>

        <span class="cov6" title="7886">endOffset := offset + int64(remaining)

        // Find starting entry index (zero-allocation inline lookup)
        startIdx := r.findStartEntry(offset)

        // Iterate entries directly — no []Entry allocation
        for i := startIdx; i &lt; r.entryCount &amp;&amp; remaining &gt; 0; i++ </span><span class="cov8" title="1256206">{
                entry, ok := r.getEntry(i)
                if !ok || entry.MkvOffset &gt;= endOffset </span><span class="cov0" title="0">{
                        break</span>
                }

                // Calculate overlap
                <span class="cov8" title="1256206">entryEnd := entry.MkvOffset + entry.Length
                readStart := offset
                if readStart &lt; entry.MkvOffset </span><span class="cov0" title="0">{
                        readStart = entry.MkvOffset
                }</span>
                <span class="cov8" title="1256206">readEnd := offset + int64(remaining)
                if readEnd &gt; entryEnd </span><span class="cov8" title="1248323">{
                        readEnd = entryEnd
                }</span>

                <span class="cov8" title="1256206">readLen := int(readEnd - readStart)
                if readLen &lt;= 0 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Calculate offset within entry
                <span class="cov8" title="1256206">offsetInEntry := readStart - entry.MkvOffset
                sourceOffset := entry.SourceOffset + offsetInEntry

                // Calculate buffer position
                bufOffset := int(readStart - originalOffset)

                // Read data from appropriate source
                if entry.Source == 0 </span><span class="cov7" title="221395">{
                        // Read from delta section (zero-copy mmap slice)
                        data, err := r.readDelta(sourceOffset, readLen)
                        if err != nil </span><span class="cov0" title="0">{
                                return totalRead, fmt.Errorf("read at offset %d: %w", readStart, err)
                        }</span>
                        <span class="cov7" title="221395">copy(buf[bufOffset:], data)</span>
                } else<span class="cov8" title="1034811"> if r.rangeMapsByFile != nil </span><span class="cov7" title="74268">{
                        // V4: Read via range map directly into output buffer (no allocation)
                        fileIndex := int(entry.Source - 1)
                        if err := r.readViaRangeMapInto(fileIndex, entry, sourceOffset, buf[bufOffset:bufOffset+readLen]); err != nil </span><span class="cov0" title="0">{
                                return totalRead, fmt.Errorf("read at offset %d: %w", readStart, err)
                        }</span>
                } else<span class="cov8" title="960543"> if r.file.UsesESOffsets &amp;&amp; r.esReader != nil </span><span class="cov0" title="0">{
                        // V1: Read from ES via external reader
                        var data []byte
                        var err error
                        if entry.IsVideo </span><span class="cov0" title="0">{
                                data, err = r.esReader.ReadESData(sourceOffset, readLen, true)
                        }</span> else<span class="cov0" title="0"> {
                                data, err = r.esReader.ReadAudioSubStreamData(entry.AudioSubStreamID, sourceOffset, readLen)
                        }</span>
                        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                                return totalRead, fmt.Errorf("read at offset %d: %w", readStart, err)
                        }</span>
                        <span class="cov0" title="0">copy(buf[bufOffset:], data)</span>
                } else<span class="cov8" title="960543"> {
                        // V3: Read from raw source file
                        fileIndex := int(entry.Source - 1)
                        if err := r.readSourceInto(fileIndex, sourceOffset, buf[bufOffset:bufOffset+readLen]); err != nil </span><span class="cov0" title="0">{
                                return totalRead, fmt.Errorf("read at offset %d: %w", readStart, err)
                        }</span>
                }

                <span class="cov8" title="1256206">totalRead += readLen
                remaining -= readLen
                offset = readEnd</span>
        }

        <span class="cov6" title="7886">if totalRead == 0 &amp;&amp; len(buf) &gt; 0 </span><span class="cov1" title="1">{
                return 0, io.EOF
        }</span>

        <span class="cov6" title="7885">return totalRead, nil</span>
}

// findStartEntry returns the index of the first entry whose range covers offset.
// Uses the entry cache for O(1) sequential access, block index for O(1) narrowing,
// then bounded binary search. Zero allocations.
func (r *Reader) findStartEntry(offset int64) int <span class="cov6" title="7886">{
        // Fast path: check if offset is within cached entry
        r.cacheMu.Lock()
        if r.lastEntryValid &amp;&amp; r.lastEntryIdx &gt;= 0 &amp;&amp; r.lastEntryIdx &lt; r.entryCount </span><span class="cov6" title="7868">{
                if offset &gt;= r.lastEntry.MkvOffset &amp;&amp; offset &lt; r.lastEntry.MkvOffset+r.lastEntry.Length </span><span class="cov6" title="7828">{
                        idx := r.lastEntryIdx
                        r.cacheMu.Unlock()
                        return idx
                }</span>
        }
        <span class="cov3" title="58">r.cacheMu.Unlock()

        // Use block index to narrow binary search range
        var lo, hi int
        if r.blockIndex != nil </span><span class="cov3" title="57">{
                blockNum := int(offset / blockSize)
                if blockNum &gt;= len(r.blockIndex) </span><span class="cov0" title="0">{
                        blockNum = len(r.blockIndex) - 1
                }</span>
                <span class="cov3" title="57">lo = r.blockIndex[blockNum]

                if blockNum+1 &lt; len(r.blockIndex) </span><span class="cov3" title="56">{
                        hi = r.blockIndex[blockNum+1] + 1
                        if hi &gt; r.entryCount </span><span class="cov0" title="0">{
                                hi = r.entryCount
                        }</span>
                } else<span class="cov1" title="1"> {
                        hi = r.entryCount
                }</span>
        } else<span class="cov1" title="1"> {
                lo = 0
                hi = r.entryCount
        }</span>

        // Binary search within [lo, hi) for first entry whose range covers offset
        <span class="cov3" title="58">return lo + sort.Search(hi-lo, func(i int) bool </span><span class="cov4" title="330">{
                mkvOffset, ok := r.getMkvOffset(lo + i)
                if !ok </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov4" title="330">entryLen, ok := r.getEntryLength(lo + i)
                if !ok </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov4" title="330">return mkvOffset+entryLen &gt; offset</span>
        })
}

func (r *Reader) findEntriesForRange(offset, length int64) []Entry <span class="cov2" title="10">{
        if r.entryCount == 0 </span><span class="cov1" title="2">{
                return nil
        }</span>

        <span class="cov2" title="8">endOffset := offset + length

        // Fast path: check if offset is within cached entry (with lock)
        r.cacheMu.Lock()
        if r.lastEntryValid &amp;&amp; r.lastEntryIdx &gt;= 0 &amp;&amp; r.lastEntryIdx &lt; r.entryCount </span><span class="cov0" title="0">{
                if offset &gt;= r.lastEntry.MkvOffset &amp;&amp; offset &lt; r.lastEntry.MkvOffset+r.lastEntry.Length </span><span class="cov0" title="0">{
                        // Cache hit - start from cached entry
                        startIdx := r.lastEntryIdx
                        r.cacheMu.Unlock()

                        var result []Entry
                        for i := startIdx; i &lt; r.entryCount; i++ </span><span class="cov0" title="0">{
                                entry, ok := r.getEntry(i)
                                if !ok || entry.MkvOffset &gt;= endOffset </span><span class="cov0" title="0">{
                                        break</span>
                                }
                                <span class="cov0" title="0">result = append(result, entry)</span>
                        }
                        <span class="cov0" title="0">return result</span>
                }
        }
        <span class="cov2" title="8">r.cacheMu.Unlock()

        // Cache miss - use block index to narrow binary search range
        var lo, hi int
        if r.blockIndex != nil </span><span class="cov2" title="8">{
                blockNum := int(offset / blockSize)
                if blockNum &gt;= len(r.blockIndex) </span><span class="cov0" title="0">{
                        blockNum = len(r.blockIndex) - 1
                }</span>
                <span class="cov2" title="8">lo = r.blockIndex[blockNum]

                // Upper bound: start of next block's entries (or entryCount)
                if blockNum+1 &lt; len(r.blockIndex) </span><span class="cov2" title="8">{
                        // Search up to 1 past the next block's start entry to handle
                        // entries that span block boundaries
                        hi = r.blockIndex[blockNum+1] + 1
                        if hi &gt; r.entryCount </span><span class="cov0" title="0">{
                                hi = r.entryCount
                        }</span>
                } else<span class="cov0" title="0"> {
                        hi = r.entryCount
                }</span>
        } else<span class="cov0" title="0"> {
                lo = 0
                hi = r.entryCount
        }</span>

        // Binary search within [lo, hi) for first entry whose range covers offset
        <span class="cov2" title="8">idx := lo + sort.Search(hi-lo, func(i int) bool </span><span class="cov3" title="56">{
                mkvOffset, ok := r.getMkvOffset(lo + i)
                if !ok </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov3" title="56">entryLen, ok := r.getEntryLength(lo + i)
                if !ok </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov3" title="56">return mkvOffset+entryLen &gt; offset</span>
        })

        <span class="cov2" title="8">var result []Entry
        for i := idx; i &lt; r.entryCount; i++ </span><span class="cov2" title="16">{
                entry, ok := r.getEntry(i)
                if !ok || entry.MkvOffset &gt;= endOffset </span><span class="cov2" title="6">{
                        break</span>
                }
                <span class="cov2" title="10">result = append(result, entry)</span>
        }

        <span class="cov2" title="8">return result</span>
}

func (r *Reader) readDelta(offset int64, size int) ([]byte, error) <span class="cov7" title="221395">{
        fileOffset := r.file.DeltaOffset + offset
        // Zero-copy slice from mmap'd data
        data := r.dedupMmap.Slice(fileOffset, size)
        if data == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("delta offset out of range")
        }</span>
        <span class="cov7" title="221395">return data, nil</span>
}

// readViaRangeMapInto reads via range map directly into dest, avoiding allocation.
func (r *Reader) readViaRangeMapInto(fileIndex int, entry Entry, sourceOffset int64, dest []byte) error <span class="cov7" title="74268">{
        src, ok := r.rangeMapsByFile[fileIndex]
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("no range map for source file %d", fileIndex)
        }</span>

        <span class="cov7" title="74268">if fileIndex &lt; 0 || fileIndex &gt;= len(r.sourceFiles) || r.sourceFiles[fileIndex] == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("source file %d not loaded for range map read", fileIndex)
        }</span>

        <span class="cov7" title="74268">sf := r.sourceFiles[fileIndex]

        if entry.IsVideo </span><span class="cov6" title="33426">{
                if src.VideoMap == nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("no video range map for source file %d", fileIndex)
                }</span>
                <span class="cov6" title="33426">_, err := src.VideoMap.ReadDataInto(sf, sourceOffset, dest)
                return err</span>
        }

        <span class="cov7" title="40842">audioMap, ok := src.AudioMaps[entry.AudioSubStreamID]
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("no audio sub-stream %d range map for source file %d", entry.AudioSubStreamID, fileIndex)
        }</span>
        <span class="cov7" title="40842">_, err := audioMap.ReadDataInto(sf, sourceOffset, dest)
        return err</span>
}

// readSourceInto reads source file data directly into dest.
func (r *Reader) readSourceInto(fileIndex int, offset int64, dest []byte) error <span class="cov8" title="960543">{
        if fileIndex &lt; 0 || fileIndex &gt;= len(r.sourceFiles) </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid file index: %d", fileIndex)
        }</span>
        <span class="cov8" title="960543">if r.sourceFiles[fileIndex] == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("source file %d not loaded", fileIndex)
        }</span>

        <span class="cov8" title="960543">n, err := r.sourceFiles[fileIndex].ReadAt(dest, offset)
        if n == len(dest) </span><span class="cov8" title="960543">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="960543">return err</span>
        }
        // Short read: surface as unexpected EOF so FUSE returns EIO
        // instead of silently truncating.
        <span class="cov0" title="0">if err == nil || err == io.EOF </span><span class="cov0" title="0">{
                return io.ErrUnexpectedEOF
        }</span>
        <span class="cov0" title="0">return err</span>
}

// parseHeaderOnly parses just the header and source files (not entries) for fast initialization.
func parseHeaderOnly(r io.Reader) (*File, error) <span class="cov3" title="179">{
        file := &amp;File{}

        // Read and verify magic
        magic := make([]byte, MagicSize)
        if _, err := io.ReadFull(r, magic); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read magic: %w", err)
        }</span>
        <span class="cov3" title="179">if string(magic) != Magic </span><span class="cov1" title="2">{
                return nil, fmt.Errorf("invalid magic: %s", magic)
        }</span>
        <span class="cov3" title="177">copy(file.Header.Magic[:], magic)

        // Read version
        if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.Version); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read version: %w", err)
        }</span>
        // Support versions 3-8. Older versions must be recreated.
        <span class="cov3" title="177">switch file.Header.Version </span>{
        case Version, VersionRangeMap, VersionCreator, VersionRangeMapCreator, VersionUsed, VersionRangeMapUsed:<span class="cov3" title="171"></span>
                // OK
        case 1:<span class="cov1" title="2">
                return nil, fmt.Errorf("unsupported version 1 (uses ES offsets); please recreate with 'mkvdup create'")</span>
        case 2:<span class="cov1" title="2">
                return nil, fmt.Errorf("unsupported version 2 (uses uint8 source index); please recreate with 'mkvdup create'")</span>
        default:<span class="cov1" title="2">
                return nil, fmt.Errorf("unsupported version: %d (expected 3-8)", file.Header.Version)</span>
        }

        // Read flags
        <span class="cov3" title="171">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.Flags); err != nil </span><span class="cov1" title="2">{
                return nil, fmt.Errorf("read flags: %w", err)
        }</span>

        // Read original size
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.OriginalSize); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read original size: %w", err)
        }</span>

        // Read original checksum
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.OriginalChecksum); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read original checksum: %w", err)
        }</span>

        // Read source type
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.SourceType); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read source type: %w", err)
        }</span>

        // Read uses ES offsets flag
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.UsesESOffsets); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read uses ES offsets: %w", err)
        }</span>
        <span class="cov3" title="169">file.UsesESOffsets = file.Header.UsesESOffsets == 1

        // Read source file count
        if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.SourceFileCount); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read source file count: %w", err)
        }</span>

        // Read entry count
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.EntryCount); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read entry count: %w", err)
        }</span>

        // Read delta offset
        <span class="cov3" title="169">if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.DeltaOffset); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read delta offset: %w", err)
        }</span>
        <span class="cov3" title="169">file.DeltaOffset = file.Header.DeltaOffset

        // Read delta size
        if err := binary.Read(r, binary.LittleEndian, &amp;file.Header.DeltaSize); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read delta size: %w", err)
        }</span>

        // Read creator version string (V5/V6 only)
        <span class="cov3" title="169">file.headerSize = int64(HeaderSize)
        if file.Header.Version &gt;= VersionCreator </span><span class="cov2" title="16">{
                var versionLen uint16
                if err := binary.Read(r, binary.LittleEndian, &amp;versionLen); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("read creator version length: %w", err)
                }</span>
                <span class="cov2" title="16">if versionLen &gt; MaxCreatorVersionLen </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("creator version length %d exceeds maximum (%d)", versionLen, MaxCreatorVersionLen)
                }</span>
                <span class="cov2" title="16">if versionLen &gt; 0 </span><span class="cov2" title="16">{
                        versionBytes := make([]byte, versionLen)
                        if _, err := io.ReadFull(r, versionBytes); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read creator version: %w", err)
                        }</span>
                        <span class="cov2" title="16">file.CreatorVersion = string(versionBytes)</span>
                }
                <span class="cov2" title="16">file.headerSize = int64(HeaderSize) + 2 + int64(versionLen)</span>
        }

        // Read source files
        <span class="cov3" title="169">file.SourceFiles = make([]SourceFile, file.Header.SourceFileCount)
        for i := range file.SourceFiles </span><span class="cov3" title="141">{
                var pathLen uint16
                if err := binary.Read(r, binary.LittleEndian, &amp;pathLen); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("read path length: %w", err)
                }</span>

                <span class="cov3" title="141">path := make([]byte, pathLen)
                if _, err := io.ReadFull(r, path); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("read path: %w", err)
                }</span>
                <span class="cov3" title="141">file.SourceFiles[i].RelativePath = string(path)

                if err := binary.Read(r, binary.LittleEndian, &amp;file.SourceFiles[i].Size); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("read file size: %w", err)
                }</span>

                <span class="cov3" title="141">if err := binary.Read(r, binary.LittleEndian, &amp;file.SourceFiles[i].Checksum); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("read file checksum: %w", err)
                }</span>

                // V7/V8: read used flag
                <span class="cov3" title="141">if file.Header.Version == VersionUsed || file.Header.Version == VersionRangeMapUsed </span><span class="cov2" title="14">{
                        var used uint8
                        if err := binary.Read(r, binary.LittleEndian, &amp;used); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read file used flag: %w", err)
                        }</span>
                        <span class="cov2" title="14">file.SourceFiles[i].Used = used == 1</span>
                }
        }

        // Entries are accessed directly from mmap via Reader.getEntry()
        <span class="cov3" title="169">return file, nil</span>
}

// VerifyIntegrity verifies the dedup file checksums.
func (r *Reader) VerifyIntegrity() error <span class="cov2" title="25">{
        // Initialize entry access to get entryCount
        if err := r.initEntryAccess(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("init entry access: %w", err)
        }</span>

        <span class="cov2" title="25">hasRangeMaps := r.file.Header.Version == VersionRangeMap || r.file.Header.Version == VersionRangeMapCreator || r.file.Header.Version == VersionRangeMapUsed
        footerSz := int64(FooterSize)
        if hasRangeMaps </span><span class="cov0" title="0">{
                footerSz = int64(FooterV4Size)
        }</span>

        <span class="cov2" title="25">fileSize := r.dedupMmap.Size()

        // Read footer from mmap
        footerOffset := fileSize - footerSz
        footerData := r.dedupMmap.Slice(footerOffset, int(footerSz))
        if footerData == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("footer slice out of range")
        }</span>

        <span class="cov2" title="25">var footer Footer
        off := 0
        footer.IndexChecksum = binary.LittleEndian.Uint64(footerData[off : off+8])
        off += 8
        footer.DeltaChecksum = binary.LittleEndian.Uint64(footerData[off : off+8])
        off += 8
        if hasRangeMaps </span><span class="cov0" title="0">{
                footer.RangeMapChecksum = binary.LittleEndian.Uint64(footerData[off : off+8])
                off += 8
        }</span>
        <span class="cov2" title="25">if string(footerData[off:off+MagicSize]) != Magic </span><span class="cov1" title="4">{
                return fmt.Errorf("invalid footer magic")
        }</span>

        // Calculate and verify index checksum (zero-copy)
        <span class="cov2" title="21">indexSize := int(int64(r.entryCount) * EntrySize)
        indexData := r.dedupMmap.Slice(r.indexStart, indexSize)
        if indexData == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("read index for checksum: slice out of range")
        }</span>
        <span class="cov2" title="21">if xxhash.Sum64(indexData) != footer.IndexChecksum </span><span class="cov0" title="0">{
                return fmt.Errorf("index checksum mismatch")
        }</span>

        // Calculate and verify delta checksum (zero-copy)
        <span class="cov2" title="21">deltaData := r.dedupMmap.Slice(r.file.DeltaOffset, int(r.file.Header.DeltaSize))
        if deltaData == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("read delta for checksum: slice out of range")
        }</span>
        <span class="cov2" title="21">if xxhash.Sum64(deltaData) != footer.DeltaChecksum </span><span class="cov1" title="2">{
                return fmt.Errorf("delta checksum mismatch")
        }</span>

        // V4/V6: verify range map checksum
        <span class="cov2" title="19">if hasRangeMaps </span><span class="cov0" title="0">{
                rangeMapOffset := r.file.DeltaOffset + r.file.Header.DeltaSize
                rangeMapSize := int(footerOffset - rangeMapOffset)
                if rangeMapSize &gt; 0 </span><span class="cov0" title="0">{
                        rangeMapData := r.dedupMmap.Slice(rangeMapOffset, rangeMapSize)
                        if rangeMapData == nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("read range map for checksum: slice out of range")
                        }</span>
                        <span class="cov0" title="0">if xxhash.Sum64(rangeMapData) != footer.RangeMapChecksum </span><span class="cov0" title="0">{
                                return fmt.Errorf("range map checksum mismatch")
                        }</span>
                }
        }

        <span class="cov2" title="19">return nil</span>
}

func (r *Reader) calculateSourceFilesSize() int64 <span class="cov3" title="120">{
        var size int64
        hasUsed := r.file.Header.Version == VersionUsed || r.file.Header.Version == VersionRangeMapUsed
        for _, sf := range r.file.SourceFiles </span><span class="cov3" title="90">{
                size += 2 + int64(len(sf.RelativePath)) + 8 + 8
                if hasUsed </span><span class="cov2" title="12">{
                        size += 1
                }</span>
        }
        <span class="cov3" title="120">return size</span>
}

// Info returns a summary of the dedup file.
// If entry access initialization failed, the "error" key will contain the error message
// and "entry_count" will be 0.
func (r *Reader) Info() map[string]any <span class="cov2" title="23">{
        err := r.initEntryAccess() // Ensure entryCount is initialized
        info := map[string]any{
                "version":           r.file.Header.Version,
                "original_size":     r.file.Header.OriginalSize,
                "original_checksum": r.file.Header.OriginalChecksum,
                "source_type":       r.file.Header.SourceType,
                "uses_es_offsets":   r.file.UsesESOffsets,
                "has_range_maps":    r.rangeMapsByFile != nil,
                "source_file_count": len(r.file.SourceFiles),
                "entry_count":       r.entryCount,
                "delta_size":        r.file.Header.DeltaSize,
                "creator_version":   r.file.CreatorVersion,
        }
        if err != nil </span><span class="cov0" title="0">{
                info["error"] = err.Error()
        }</span>
        <span class="cov2" title="23">return info</span>
}
</pre>
		
		<pre class="file" id="file20" style="display: none">package dedup

// stridedCopy copies count blocks of payloadSize bytes from src into
// contiguous dst. Blocks in src are separated by stride bytes
// (stride &gt;= payloadSize). This avoids per-block copy() call overhead
// when extracting many small payloads (e.g. 184-byte M2TS PES payloads
// at 192-byte stride).
func stridedCopy(dst, src []byte, count, payloadSize, stride int) <span class="cov7" title="66701">{
        dp := 0
        sp := 0
        for i := 0; i &lt; count; i++ </span><span class="cov10" title="4328720">{
                copy(dst[dp:dp+payloadSize], src[sp:sp+payloadSize])
                dp += payloadSize
                sp += stride
        }</span>
}
</pre>
		
		<pre class="file" id="file21" style="display: none">package dedup

import (
        "bufio"
        "encoding/binary"
        "fmt"
        "io"
        "os"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/matcher"
        "github.com/stuckj/mkvdup/internal/source"
)

// Writer creates .mkvdup files.
type Writer struct {
        file           *os.File
        header         Header
        sourceFiles    []SourceFile
        entries        []Entry
        deltaData      []byte               // In-memory delta (for tests / small files)
        deltaFile      *matcher.DeltaWriter // File-backed delta (for large files)
        rangeMaps      []RangeMapData       // V4/V6: per-source-file range maps (nil for V3/V5)
        rangeMapBuf    []byte               // Pre-encoded range map section (set by EncodeRangeMaps)
        creatorVersion string               // Version string to embed in the file
}

// NewWriter creates a new dedup file writer.
func NewWriter(path string) (*Writer, error) <span class="cov4" title="96">{
        f, err := os.Create(path)
        if err != nil </span><span class="cov1" title="2">{
                return nil, fmt.Errorf("create file: %w", err)
        }</span>
        <span class="cov4" title="94">return &amp;Writer{file: f}, nil</span>
}

// SetCreatorVersion sets the version string to embed in the file.
// When set, the writer produces V7 (or V8 if range maps are also set).
func (w *Writer) SetCreatorVersion(v string) <span class="cov2" title="10">{
        if len(v) &gt; MaxCreatorVersionLen </span><span class="cov0" title="0">{
                v = v[:MaxCreatorVersionLen]
        }</span>
        <span class="cov2" title="10">w.creatorVersion = v</span>
}

// SetHeader sets the header information.
func (w *Writer) SetHeader(originalSize int64, originalChecksum uint64, sourceType source.Type) <span class="cov4" title="90">{
        copy(w.header.Magic[:], Magic)
        w.header.Version = Version // Default V3; upgraded to V7/V8 in resolveVersion()
        w.header.Flags = 0
        w.header.OriginalSize = originalSize
        w.header.OriginalChecksum = originalChecksum
        w.header.UsesESOffsets = 0 // v2 always uses raw offsets

        switch sourceType </span>{
        case source.TypeDVD:<span class="cov3" title="80">
                w.header.SourceType = SourceTypeDVD</span>
        case source.TypeBluray:<span class="cov2" title="10">
                w.header.SourceType = SourceTypeBluray</span>
        }
}

// SetSourceFiles sets the source file list.
func (w *Writer) SetSourceFiles(files []source.File) <span class="cov3" title="56">{
        w.sourceFiles = make([]SourceFile, len(files))
        for i, sf := range files </span><span class="cov3" title="64">{
                w.sourceFiles[i] = ToSourceFile(sf)
        }</span>
        <span class="cov3" title="56">w.header.SourceFileCount = uint16(len(files))</span>
}

// SetRangeMaps sets the range map data for V4 format.
// When range maps are set, ES-offset entries are preserved (not converted to raw offsets)
// and a range map section is written to the dedup file for mapping ES offsets to
// raw file positions at read time.
func (w *Writer) SetRangeMaps(rangeMaps []RangeMapData) <span class="cov0" title="0">{
        w.rangeMaps = rangeMaps
        w.header.Version = VersionRangeMap // Default V4; upgraded to V8 in resolveVersion()
        w.header.UsesESOffsets = 1
}</span>

// resolveVersion sets the final file version based on configured features.
func (w *Writer) resolveVersion() <span class="cov4" title="88">{
        if w.rangeMaps != nil </span><span class="cov0" title="0">{
                if w.creatorVersion != "" </span><span class="cov0" title="0">{
                        w.header.Version = VersionRangeMapUsed // V8
                }</span> else<span class="cov0" title="0"> {
                        w.header.Version = VersionRangeMap // V4
                }</span>
        } else<span class="cov4" title="88"> {
                if w.creatorVersion != "" </span><span class="cov2" title="10">{
                        w.header.Version = VersionUsed // V7
                }</span> else<span class="cov3" title="78"> {
                        w.header.Version = Version // V3
                }</span>
        }
}

// computeUsedFlags scans entries and marks which source files are referenced.
func (w *Writer) computeUsedFlags() <span class="cov4" title="88">{
        for i := range w.sourceFiles </span><span class="cov3" title="64">{
                w.sourceFiles[i].Used = false
        }</span>
        <span class="cov4" title="88">for _, e := range w.entries </span><span class="cov10" title="553779">{
                if e.Source &gt; 0 </span><span class="cov9" title="479912">{
                        idx := int(e.Source - 1)
                        if idx &lt; len(w.sourceFiles) </span><span class="cov9" title="475898">{
                                w.sourceFiles[idx].Used = true
                        }</span>
                }
        }
}

// EncodeRangeMaps pre-encodes the range map section. Call this before
// WriteWithProgress to avoid a CPU-intensive encoding phase with no progress
// output. Returns the encoded size. If range maps are nil, this is a no-op.
func (w *Writer) EncodeRangeMaps() (int64, error) <span class="cov0" title="0">{
        if w.rangeMaps == nil </span><span class="cov0" title="0">{
                return 0, nil
        }</span>
        <span class="cov0" title="0">buf, err := encodeRangeMapSection(w.rangeMaps)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("encode range maps: %w", err)
        }</span>
        <span class="cov0" title="0">w.rangeMapBuf = buf
        return int64(len(buf)), nil</span>
}

// SetMatchResult sets the match result (entries and delta).
// If esConverters is provided and non-empty, ES-offset entries will be converted
// to raw-offset entries, potentially splitting entries that span multiple ranges.
func (w *Writer) SetMatchResult(result *matcher.Result, esConverters []source.ESRangeConverter) error <span class="cov4" title="90">{
        // Convert matcher entries to dedup entries
        entries := make([]Entry, len(result.Entries))
        for i, e := range result.Entries </span><span class="cov9" title="152047">{
                entries[i] = FromMatcherEntry(e)
        }</span>

        // Convert ES offsets to raw offsets if we have converters.
        // Skip conversion for V4 (range maps handle the mapping at read time).
        <span class="cov4" title="90">if len(esConverters) &gt; 0 &amp;&amp; w.rangeMaps == nil </span><span class="cov2" title="7">{
                var err error
                entries, err = w.convertESToRawOffsets(entries, esConverters)
                if err != nil </span><span class="cov1" title="2">{
                        return fmt.Errorf("convert ES to raw offsets: %w", err)
                }</span>
        }

        <span class="cov4" title="88">w.entries = entries
        w.header.EntryCount = uint64(len(w.entries))

        if result.DeltaFile != nil </span><span class="cov1" title="1">{
                w.deltaFile = result.DeltaFile
                w.header.DeltaSize = result.DeltaFile.Size()
        }</span> else<span class="cov4" title="87"> {
                w.deltaData = result.DeltaData
                w.header.DeltaSize = int64(len(result.DeltaData))
        }</span>
        <span class="cov4" title="88">return nil</span>
}

// convertESToRawOffsets converts ES-offset entries to raw-offset entries.
// Entries that span multiple PES payload ranges are split into multiple entries.
func (w *Writer) convertESToRawOffsets(entries []Entry, esConverters []source.ESRangeConverter) ([]Entry, error) <span class="cov2" title="7">{
        // Pre-allocate with ~2x capacity since entries typically expand to multiple raw ranges
        result := make([]Entry, 0, len(entries)*2)

        for _, entry := range entries </span><span class="cov9" title="147986">{
                if entry.Source == 0 </span><span class="cov8" title="73820">{
                        // Delta entry - no conversion needed
                        result = append(result, entry)
                        continue</span>
                }

                // Get the ES converter for this source file
                <span class="cov8" title="74166">fileIndex := int(entry.Source - 1)
                if fileIndex &gt;= len(esConverters) || esConverters[fileIndex] == nil </span><span class="cov0" title="0">{
                        // No converter available - assume raw offsets already
                        result = append(result, entry)
                        continue</span>
                }
                <span class="cov8" title="74166">converter := esConverters[fileIndex]

                // Get raw ranges for this ES region
                var rawRanges []source.RawRange
                var err error
                if entry.IsVideo </span><span class="cov8" title="33506">{
                        rawRanges, err = converter.RawRangesForESRegion(entry.SourceOffset, int(entry.Length), true)
                }</span> else<span class="cov8" title="40660"> {
                        rawRanges, err = converter.RawRangesForAudioSubStream(entry.AudioSubStreamID, entry.SourceOffset, int(entry.Length))
                }</span>
                <span class="cov8" title="74166">if err != nil </span><span class="cov1" title="2">{
                        return nil, fmt.Errorf("convert entry at MKV offset %d: %w", entry.MkvOffset, err)
                }</span>

                // Create one entry per raw range
                <span class="cov8" title="74164">mkvOffset := entry.MkvOffset
                for _, rr := range rawRanges </span><span class="cov9" title="475898">{
                        result = append(result, Entry{
                                MkvOffset:        mkvOffset,
                                Length:           int64(rr.Size),
                                Source:           entry.Source,
                                SourceOffset:     rr.FileOffset, // Raw file offset!
                                IsVideo:          entry.IsVideo,
                                AudioSubStreamID: entry.AudioSubStreamID,
                        })
                        mkvOffset += int64(rr.Size)
                }</span>
        }

        <span class="cov2" title="5">return result, nil</span>
}

// WriteProgressFunc is called to report write progress.
type WriteProgressFunc func(written, total int64)

// Write writes the dedup file.
func (w *Writer) Write() error <span class="cov4" title="86">{
        return w.WriteWithProgress(nil)
}</span>

// WriteWithProgress writes the dedup file with progress reporting.
func (w *Writer) WriteWithProgress(progress WriteProgressFunc) error <span class="cov4" title="88">{
        // Determine final file version based on configured features.
        w.resolveVersion()
        w.computeUsedFlags()

        // Use pre-encoded range maps if available (from EncodeRangeMaps),
        // otherwise encode now.
        rangeMapBuf := w.rangeMapBuf
        if rangeMapBuf == nil &amp;&amp; w.rangeMaps != nil </span><span class="cov0" title="0">{
                var err error
                rangeMapBuf, err = encodeRangeMapSection(w.rangeMaps)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("encode range maps: %w", err)
                }</span>
        }

        // Calculate offsets and total size
        <span class="cov4" title="88">sourceFilesSize := w.calculateSourceFilesSize()
        cvSize := creatorVersionSize(w.creatorVersion)
        indexSize := int64(len(w.entries)) * EntrySize
        deltaOffset := int64(HeaderSize) + cvSize + sourceFilesSize + indexSize
        w.header.DeltaOffset = deltaOffset

        footerSize := int64(FooterSize)
        if rangeMapBuf != nil </span><span class="cov0" title="0">{
                footerSize = FooterV4Size
        }</span>

        <span class="cov4" title="88">totalSize := deltaOffset + w.header.DeltaSize + int64(len(rangeMapBuf)) + footerSize
        var written int64

        // Write header (includes creator version for V5/V6)
        if err := w.writeHeader(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write header: %w", err)
        }</span>
        <span class="cov4" title="88">written += int64(HeaderSize) + cvSize

        // Write source files section
        if err := w.writeSourceFiles(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write source files: %w", err)
        }</span>
        <span class="cov4" title="88">written += sourceFilesSize

        // Write index entries and calculate checksum
        indexChecksum, err := w.writeEntriesWithProgress(progress, &amp;written, totalSize)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write entries: %w", err)
        }</span>

        // Write delta data and calculate checksum
        <span class="cov4" title="88">deltaChecksum, err := w.writeDeltaWithProgress(progress, &amp;written, totalSize)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write delta: %w", err)
        }</span>

        // Write range map section (V4 only)
        <span class="cov4" title="88">var rangeMapChecksum uint64
        if rangeMapBuf != nil </span><span class="cov0" title="0">{
                rangeMapChecksum, err = writeRangeMapSection(w.file, rangeMapBuf)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("write range map: %w", err)
                }</span>
                <span class="cov0" title="0">written += int64(len(rangeMapBuf))
                if progress != nil </span><span class="cov0" title="0">{
                        progress(written, totalSize)
                }</span>
        }

        // Write footer
        <span class="cov4" title="88">if err := w.writeFooter(indexChecksum, deltaChecksum, rangeMapChecksum); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write footer: %w", err)
        }</span>

        <span class="cov4" title="88">if progress != nil </span><span class="cov1" title="2">{
                progress(totalSize, totalSize)
        }</span>

        <span class="cov4" title="88">return nil</span>
}

// Close closes the writer.
func (w *Writer) Close() error <span class="cov4" title="96">{
        if w.file != nil </span><span class="cov4" title="96">{
                return w.file.Close()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (w *Writer) calculateSourceFilesSize() int64 <span class="cov4" title="88">{
        var size int64
        hasUsed := w.header.Version == VersionUsed || w.header.Version == VersionRangeMapUsed
        for _, sf := range w.sourceFiles </span><span class="cov3" title="64">{
                // PathLen (2) + Path (variable) + Size (8) + Checksum (8) [+ Used (1)]
                size += 2 + int64(len(sf.RelativePath)) + 8 + 8
                if hasUsed </span><span class="cov2" title="8">{
                        size += 1
                }</span>
        }
        <span class="cov4" title="88">return size</span>
}

func (w *Writer) writeHeader() error <span class="cov4" title="88">{
        // Write magic
        if _, err := w.file.Write([]byte(Magic)); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write version
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.Version); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write flags
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.Flags); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write original size
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.OriginalSize); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write original checksum
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.OriginalChecksum); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write source type
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.SourceType); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write uses ES offsets flag
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.UsesESOffsets); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write source file count
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.SourceFileCount); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write entry count
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.EntryCount); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write delta offset
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.DeltaOffset); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write delta size
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, w.header.DeltaSize); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write creator version string (V5/V6)
        <span class="cov4" title="88">if w.creatorVersion != "" </span><span class="cov2" title="10">{
                versionLen := uint16(len(w.creatorVersion))
                if err := binary.Write(w.file, binary.LittleEndian, versionLen); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov2" title="10">if _, err := w.file.Write([]byte(w.creatorVersion)); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }

        <span class="cov4" title="88">return nil</span>
}

func (w *Writer) writeSourceFiles() error <span class="cov4" title="88">{
        hasUsed := w.header.Version == VersionUsed || w.header.Version == VersionRangeMapUsed
        for _, sf := range w.sourceFiles </span><span class="cov3" title="64">{
                // Write path length
                pathLen := uint16(len(sf.RelativePath))
                if err := binary.Write(w.file, binary.LittleEndian, pathLen); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Write path
                <span class="cov3" title="64">if _, err := w.file.Write([]byte(sf.RelativePath)); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Write size
                <span class="cov3" title="64">if err := binary.Write(w.file, binary.LittleEndian, sf.Size); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Write checksum
                <span class="cov3" title="64">if err := binary.Write(w.file, binary.LittleEndian, sf.Checksum); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Write used flag (V7/V8)
                <span class="cov3" title="64">if hasUsed </span><span class="cov2" title="8">{
                        var used uint8
                        if sf.Used </span><span class="cov1" title="4">{
                                used = 1
                        }</span>
                        <span class="cov2" title="8">if err := binary.Write(w.file, binary.LittleEndian, used); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                }
        }
        <span class="cov4" title="88">return nil</span>
}

func (w *Writer) writeEntriesWithProgress(progress WriteProgressFunc, written *int64, total int64) (uint64, error) <span class="cov4" title="88">{
        hasher := xxhash.New()
        // Use buffered writer to batch syscalls (64KB buffer)
        bufWriter := bufio.NewWriterSize(w.file, 64*1024)
        writer := io.MultiWriter(bufWriter, hasher)

        entryCount := len(w.entries)
        lastProgress := 0

        // Reusable buffer for entry serialization (allocation-free per entry)
        var entryBuf [EntrySize]byte

        for i, entry := range w.entries </span><span class="cov10" title="553779">{
                // Serialize entry to buffer using allocation-free Put* functions
                binary.LittleEndian.PutUint64(entryBuf[0:8], uint64(entry.MkvOffset))
                binary.LittleEndian.PutUint64(entryBuf[8:16], uint64(entry.Length))
                binary.LittleEndian.PutUint16(entryBuf[16:18], entry.Source)
                binary.LittleEndian.PutUint64(entryBuf[18:26], uint64(entry.SourceOffset))

                // ES flags byte: bit 0 = IsVideo
                var esFlags uint8
                if entry.IsVideo </span><span class="cov9" title="426238">{
                        esFlags = 1
                }</span>
                <span class="cov10" title="553779">entryBuf[26] = esFlags
                entryBuf[27] = entry.AudioSubStreamID

                // Single write per entry
                if _, err := writer.Write(entryBuf[:]); err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>

                <span class="cov10" title="553779">*written += EntrySize

                // Report progress every 1% or 10000 entries
                if progress != nil &amp;&amp; entryCount &gt; 0 </span><span class="cov1" title="4">{
                        pct := (i + 1) * 100 / entryCount
                        if pct &gt; lastProgress || (i+1)%10000 == 0 </span><span class="cov1" title="4">{
                                progress(*written, total)
                                lastProgress = pct
                        }</span>
                }
        }

        // Flush buffered writer
        <span class="cov4" title="88">if err := bufWriter.Flush(); err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov4" title="88">return hasher.Sum64(), nil</span>
}

func (w *Writer) writeDeltaWithProgress(progress WriteProgressFunc, written *int64, total int64) (uint64, error) <span class="cov4" title="88">{
        hasher := xxhash.New()
        const chunkSize = 64 * 1024 // 64KB chunks
        lastProgress := 0

        if w.deltaFile != nil </span><span class="cov1" title="1">{
                // Read from temp file and write to output
                f := w.deltaFile.File()
                if _, err := f.Seek(0, 0); err != nil </span><span class="cov0" title="0">{
                        return 0, fmt.Errorf("seek delta file: %w", err)
                }</span>

                <span class="cov1" title="1">buf := make([]byte, chunkSize)
                for </span><span class="cov3" title="69">{
                        n, err := f.Read(buf)
                        if n &gt; 0 </span><span class="cov3" title="68">{
                                chunk := buf[:n]
                                if _, werr := w.file.Write(chunk); werr != nil </span><span class="cov0" title="0">{
                                        return 0, werr
                                }</span>
                                <span class="cov3" title="68">hasher.Write(chunk)
                                *written += int64(n)

                                if progress != nil &amp;&amp; w.header.DeltaSize &gt; 0 </span><span class="cov0" title="0">{
                                        pct := int((*written * 100) / total)
                                        if pct &gt; lastProgress </span><span class="cov0" title="0">{
                                                progress(*written, total)
                                                lastProgress = pct
                                        }</span>
                                }
                        }
                        <span class="cov3" title="69">if err == io.EOF </span><span class="cov1" title="1">{
                                break</span>
                        }
                        <span class="cov3" title="68">if err != nil </span><span class="cov0" title="0">{
                                return 0, err
                        }</span>
                }
        } else<span class="cov4" title="87"> {
                // In-memory path (for tests / small files)
                data := w.deltaData
                for len(data) &gt; 0 </span><span class="cov5" title="453">{
                        chunk := data
                        if len(chunk) &gt; chunkSize </span><span class="cov5" title="376">{
                                chunk = data[:chunkSize]
                        }</span>
                        <span class="cov5" title="453">data = data[len(chunk):]

                        if _, err := w.file.Write(chunk); err != nil </span><span class="cov0" title="0">{
                                return 0, err
                        }</span>
                        <span class="cov5" title="453">hasher.Write(chunk)
                        *written += int64(len(chunk))

                        if progress != nil &amp;&amp; w.header.DeltaSize &gt; 0 </span><span class="cov1" title="2">{
                                pct := int((*written * 100) / total)
                                if pct &gt; lastProgress </span><span class="cov1" title="2">{
                                        progress(*written, total)
                                        lastProgress = pct
                                }</span>
                        }
                }
        }

        <span class="cov4" title="88">return hasher.Sum64(), nil</span>
}

func (w *Writer) writeFooter(indexChecksum, deltaChecksum, rangeMapChecksum uint64) error <span class="cov4" title="88">{
        // Write index checksum
        if err := binary.Write(w.file, binary.LittleEndian, indexChecksum); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write delta checksum
        <span class="cov4" title="88">if err := binary.Write(w.file, binary.LittleEndian, deltaChecksum); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Write range map checksum (V4 only)
        <span class="cov4" title="88">if w.rangeMaps != nil </span><span class="cov0" title="0">{
                if err := binary.Write(w.file, binary.LittleEndian, rangeMapChecksum); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }

        // Write magic
        <span class="cov4" title="88">if _, err := w.file.Write([]byte(Magic)); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov4" title="88">return nil</span>
}
</pre>
		
		<pre class="file" id="file22" style="display: none">package fuse

import (
        "fmt"
        "time"

        "github.com/stuckj/mkvdup/internal/dedup"
        "github.com/stuckj/mkvdup/internal/source"
)

// Ensure adapters implement interfaces
var _ ReaderInitializer = (*dedupReaderAdapter)(nil)
var _ ReaderFactory = (*DefaultReaderFactory)(nil)
var _ ConfigReader = (*DefaultConfigReader)(nil)

// dedupReaderAdapter wraps dedup.Reader to implement ReaderInitializer interface.
type dedupReaderAdapter struct {
        reader      *dedup.Reader
        readTimeout time.Duration // pread timeout for network FS sources
        // index stores the source index for cleanup when using ES offsets.
        // This is nil when using raw source files.
        index *source.Index
}

func (a *dedupReaderAdapter) OriginalSize() int64 <span class="cov4" title="23">{
        return a.reader.OriginalSize()
}</span>

func (a *dedupReaderAdapter) UsesESOffsets() bool <span class="cov1" title="2">{
        return a.reader.UsesESOffsets()
}</span>

func (a *dedupReaderAdapter) InitializeForReading(sourceDir string) error <span class="cov3" title="8">{
        if a.reader.UsesESOffsets() &amp;&amp; !a.reader.HasRangeMaps() </span><span class="cov0" title="0">{
                // Legacy guard: ES offsets without range maps would need a full
                // ES reader. No current format hits this path — DVD formats
                // (V3/V5/V7) use raw file offsets, and Blu-ray formats (V4/V6/V8)
                // always have range maps. Kept for safety against future formats.
                indexer, err := source.NewIndexer(sourceDir, source.DefaultWindowSize)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("create indexer: %w", err)
                }</span>
                <span class="cov0" title="0">if err := indexer.Build(nil); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("build index: %w", err)
                }</span>
                <span class="cov0" title="0">index := indexer.Index()
                if len(index.ESReaders) &gt; 0 </span><span class="cov0" title="0">{
                        a.reader.SetESReader(index.ESReaders[0])
                }</span>
                // Store index for cleanup in Close()
                <span class="cov0" title="0">a.index = index</span>
        } else<span class="cov3" title="8"> if isNetworkFS(sourceDir) </span><span class="cov1" title="1">{
                // Network FS: use pread with retry instead of mmap to avoid SIGBUS.
                if err := a.reader.LoadSourceFilesPread(a.readTimeout); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("load source files (pread): %w", err)
                }</span>
        } else<span class="cov3" title="7"> {
                // Local FS: mmap for zero-copy performance.
                // Range maps handle ES-to-raw translation at read time.
                if err := a.reader.LoadSourceFiles(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("load source files: %w", err)
                }</span>
        }
        <span class="cov3" title="8">return nil</span>
}

func (a *dedupReaderAdapter) SourceFileInfo() []SourceFileInfo <span class="cov0" title="0">{
        sourceFiles := a.reader.SourceFiles()
        hasUsedFlags := a.reader.HasSourceUsedFlags()
        var infos []SourceFileInfo
        for _, sf := range sourceFiles </span><span class="cov0" title="0">{
                if hasUsedFlags &amp;&amp; !sf.Used </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">infos = append(infos, SourceFileInfo{
                        RelativePath: sf.RelativePath,
                        Size:         sf.Size,
                        Checksum:     sf.Checksum,
                })</span>
        }
        <span class="cov0" title="0">return infos</span>
}

func (a *dedupReaderAdapter) ReadAt(p []byte, off int64) (n int, err error) <span class="cov10" title="6274">{
        return a.reader.ReadAt(p, off)
}</span>

func (a *dedupReaderAdapter) Close() error <span class="cov4" title="31">{
        var errs []error
        if err := a.reader.Close(); err != nil </span><span class="cov0" title="0">{
                errs = append(errs, err)
        }</span>
        <span class="cov4" title="31">if a.index != nil </span><span class="cov1" title="2">{
                if err := a.index.Close(); err != nil </span><span class="cov0" title="0">{
                        errs = append(errs, err)
                }</span>
        }
        <span class="cov4" title="31">if len(errs) &gt; 0 </span><span class="cov0" title="0">{
                return errs[0]
        }</span>
        <span class="cov4" title="31">return nil</span>
}

// DefaultReaderFactory is the default implementation of ReaderFactory.
type DefaultReaderFactory struct {
        ReadTimeout time.Duration // pread timeout for network FS sources
}

func (f *DefaultReaderFactory) NewReaderLazy(dedupPath, sourceDir string) (ReaderInitializer, error) <span class="cov4" title="30">{
        reader, err := dedup.NewReaderLazy(dedupPath, sourceDir)
        if err != nil </span><span class="cov1" title="2">{
                return nil, err
        }</span>
        <span class="cov4" title="28">return &amp;dedupReaderAdapter{reader: reader, readTimeout: f.ReadTimeout}, nil</span>
}

// DefaultConfigReader is the default implementation of ConfigReader.
type DefaultConfigReader struct{}

func (r *DefaultConfigReader) ReadConfig(path string) (*Config, error) <span class="cov3" title="7">{
        config, err := dedup.ReadConfig(path)
        if err != nil </span><span class="cov2" title="4">{
                return nil, err
        }</span>
        <span class="cov2" title="3">return &amp;Config{
                Name:      config.Name,
                DedupFile: config.DedupFile,
                SourceDir: config.SourceDir,
        }, nil</span>
}
</pre>
		
		<pre class="file" id="file23" style="display: none">// Package fuse provides a FUSE filesystem for accessing deduplicated MKV files.
package fuse

import (
        "sync"
        "sync/atomic"

        "github.com/hanwen/go-fuse/v2/fs"
)

// MKVFile represents a virtual MKV file backed by a dedup file.
type MKVFile struct {
        Name      string
        DedupPath string
        SourceDir string
        Size      int64
        reader    DedupReader
        mu        sync.RWMutex

        // disabled is set when a source file change is detected and the
        // configured action is "disable" or "checksum" (with mismatch).
        // When true, Open/Read return EIO. Reset to false on reload.
        disabled bool

        // Factory for lazy initialization (injected from root)
        readerFactory ReaderFactory
}

// MKVFSRoot is the root node of the FUSE filesystem.
type MKVFSRoot struct {
        fs.Inode

        // Directory tree for hierarchical file organization
        rootDir *MKVFSDirNode

        // Flat map for O(1) lookup by full path (kept for backwards compatibility)
        files map[string]*MKVFile

        mu      sync.RWMutex
        verbose bool

        // mounted is set to true after fs.Mount() succeeds. FUSE kernel
        // notifications (NotifyDelete, NotifyEntry, NotifyContent) are only
        // safe to call when the filesystem is mounted — the go-fuse bridge
        // is nil before mount, causing panics.
        mounted atomic.Bool

        // Factories for dependency injection (allows mocking in tests)
        readerFactory ReaderFactory
        configReader  ConfigReader

        // Permission store for chmod/chown support
        permStore *PermissionStore
}

// MKVFSNode represents a file node in the FUSE filesystem.
type MKVFSNode struct {
        fs.Inode
        file      *MKVFile
        path      string // full path for permission lookups
        verbose   bool
        permStore *PermissionStore
}

// MKVFSDirNode represents a directory node in the FUSE filesystem.
type MKVFSDirNode struct {
        fs.Inode
        name    string                   // basename (e.g., "Action")
        path    string                   // full path from root (e.g., "Movies/Action")
        files   map[string]*MKVFile      // files directly in this directory
        subdirs map[string]*MKVFSDirNode // child directories
        mu      sync.RWMutex
        verbose bool

        // Factory for creating file nodes (injected from root)
        readerFactory ReaderFactory

        // Permission store for chmod/chown support
        permStore *PermissionStore
}

// Ensure interfaces are implemented
var _ fs.InodeEmbedder = (*MKVFSRoot)(nil)
var _ fs.InodeEmbedder = (*MKVFSNode)(nil)
var _ fs.InodeEmbedder = (*MKVFSDirNode)(nil)
var _ fs.NodeReaddirer = (*MKVFSRoot)(nil)
var _ fs.NodeLookuper = (*MKVFSRoot)(nil)
var _ fs.NodeGetattrer = (*MKVFSRoot)(nil)
var _ fs.NodeReaddirer = (*MKVFSDirNode)(nil)
var _ fs.NodeLookuper = (*MKVFSDirNode)(nil)
var _ fs.NodeGetattrer = (*MKVFSDirNode)(nil)
var _ fs.NodeMkdirer = (*MKVFSDirNode)(nil)
var _ fs.NodeRmdirer = (*MKVFSDirNode)(nil)
var _ fs.NodeUnlinker = (*MKVFSDirNode)(nil)
var _ fs.NodeCreater = (*MKVFSDirNode)(nil)
var _ fs.NodeOpener = (*MKVFSNode)(nil)
var _ fs.NodeReader = (*MKVFSNode)(nil)
var _ fs.NodeGetattrer = (*MKVFSNode)(nil)
var _ fs.NodeSetattrer = (*MKVFSNode)(nil)
var _ fs.NodeSetattrer = (*MKVFSDirNode)(nil)

// getFilePerms returns file permissions from the store, or defaults if store is nil.
func getFilePerms(store *PermissionStore, path string) (uid, gid, mode uint32) <span class="cov10" title="25134">{
        if store != nil </span><span class="cov4" title="55">{
                return store.GetFilePerms(path)
        }</span>
        <span class="cov9" title="25079">return 0, 0, 0444</span>
}

// getDirPerms returns directory permissions from the store, or defaults if store is nil.
func getDirPerms(store *PermissionStore, path string) (uid, gid, mode uint32) <span class="cov5" title="114">{
        if store != nil </span><span class="cov4" title="49">{
                return store.GetDirPerms(path)
        }</span>
        <span class="cov4" title="65">return 0, 0, 0555</span>
}
</pre>
		
		<pre class="file" id="file24" style="display: none">package fuse

import (
        "context"
        "log"
        "sort"
        "syscall"
        "time"

        "github.com/hanwen/go-fuse/v2/fs"
        "github.com/hanwen/go-fuse/v2/fuse"
)

// --- MKVFSDirNode interface implementations ---

// Readdir implements fs.NodeReaddirer - lists files and subdirectories.
func (d *MKVFSDirNode) Readdir(ctx context.Context) (fs.DirStream, syscall.Errno) <span class="cov5" title="6">{
        // Permission checks are handled by the kernel via default_permissions mount option.
        return d.readdirInternal(ctx)
}</span>

// readdirInternal performs the directory listing. It does not perform any permission
// checks itself (those are handled by the kernel via default_permissions) and is
// shared by both MKVFSRoot.Readdir and MKVFSDirNode.Readdir.
func (d *MKVFSDirNode) readdirInternal(ctx context.Context) (fs.DirStream, syscall.Errno) <span class="cov7" title="12">{
        d.mu.RLock()
        defer d.mu.RUnlock()

        if d.verbose </span><span class="cov1" title="1">{
                log.Printf("Readdir: %s (files=%d, subdirs=%d)", d.path, len(d.files), len(d.subdirs))
        }</span>

        <span class="cov7" title="12">entries := make([]fuse.DirEntry, 0, len(d.files)+len(d.subdirs))

        // Collect and sort subdirectory names for deterministic ordering
        subdirNames := make([]string, 0, len(d.subdirs))
        for name := range d.subdirs </span><span class="cov7" title="13">{
                subdirNames = append(subdirNames, name)
        }</span>
        <span class="cov7" title="12">sort.Strings(subdirNames)

        // Add subdirectories first (sorted)
        for _, name := range subdirNames </span><span class="cov7" title="13">{
                if d.verbose </span><span class="cov0" title="0">{
                        log.Printf("Readdir: adding subdir %s", name)
                }</span>
                <span class="cov7" title="13">entries = append(entries, fuse.DirEntry{
                        Name: name,
                        Mode: fuse.S_IFDIR,
                })</span>
        }

        // Collect and sort file names for deterministic ordering
        <span class="cov7" title="12">fileNames := make([]string, 0, len(d.files))
        for name := range d.files </span><span class="cov8" title="17">{
                fileNames = append(fileNames, name)
        }</span>
        <span class="cov7" title="12">sort.Strings(fileNames)

        // Add files (sorted)
        for _, name := range fileNames </span><span class="cov8" title="17">{
                if d.verbose </span><span class="cov1" title="1">{
                        log.Printf("Readdir: adding file %s", name)
                }</span>
                <span class="cov8" title="17">entries = append(entries, fuse.DirEntry{
                        Name: name,
                        Mode: fuse.S_IFREG,
                })</span>
        }

        <span class="cov7" title="12">return fs.NewListDirStream(entries), 0</span>
}

// Lookup implements fs.NodeLookuper - looks up a file or subdirectory by name.
func (d *MKVFSDirNode) Lookup(ctx context.Context, name string, out *fuse.EntryOut) (*fs.Inode, syscall.Errno) <span class="cov7" title="10">{
        // Permission checks are handled by the kernel via default_permissions mount option.

        d.mu.RLock()
        defer d.mu.RUnlock()

        // Check subdirectories first
        if subdir, ok := d.subdirs[name]; ok </span><span class="cov4" title="4">{
                if d.verbose </span><span class="cov0" title="0">{
                        log.Printf("Lookup: found subdir %s in %s", name, d.path)
                }</span>

                // Lock subdir to safely access its fields
                <span class="cov4" title="4">subdir.mu.RLock()
                subdirCount := len(subdir.subdirs)
                subdir.mu.RUnlock()

                uid, gid, mode := getDirPerms(d.permStore, subdir.path)

                now := time.Now()
                out.Mode = fuse.S_IFDIR | mode
                out.Uid = uid
                out.Gid = gid
                out.Atime = uint64(now.Unix())
                out.Mtime = uint64(now.Unix())
                out.Ctime = uint64(now.Unix())
                out.Nlink = 2 + uint32(subdirCount)

                stable := fs.StableAttr{
                        Mode: fuse.S_IFDIR,
                        Ino:  hashString(subdir.path),
                }
                child := d.NewPersistentInode(ctx, subdir, stable)
                return child, 0</span>
        }

        // Check files
        <span class="cov5" title="6">if file, ok := d.files[name]; ok </span><span class="cov4" title="4">{
                if d.verbose </span><span class="cov0" title="0">{
                        log.Printf("Lookup: found file %s in %s (size=%d)", name, d.path, file.Size)
                }</span>

                <span class="cov4" title="4">var filePath string
                if d.path == "" </span><span class="cov0" title="0">{
                        filePath = name
                }</span> else<span class="cov4" title="4"> {
                        filePath = d.path + "/" + name
                }</span>

                <span class="cov4" title="4">uid, gid, mode := getFilePerms(d.permStore, filePath)

                now := time.Now()
                out.Size = uint64(file.Size)
                out.Mode = fuse.S_IFREG | mode
                out.Uid = uid
                out.Gid = gid
                out.Atime = uint64(now.Unix())
                out.Mtime = uint64(now.Unix())
                out.Ctime = uint64(now.Unix())
                out.Nlink = 1

                node := &amp;MKVFSNode{file: file, path: filePath, verbose: d.verbose, permStore: d.permStore}
                stable := fs.StableAttr{
                        Mode: fuse.S_IFREG,
                        Ino:  hashString(filePath),
                }
                child := d.NewInode(ctx, node, stable)
                return child, 0</span>
        }

        <span class="cov2" title="2">if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Lookup: not found %s in %s", name, d.path)
        }</span>
        <span class="cov2" title="2">return nil, syscall.ENOENT</span>
}

// Getattr implements fs.NodeGetattrer - returns directory attributes.
func (d *MKVFSDirNode) Getattr(ctx context.Context, fh fs.FileHandle, out *fuse.AttrOut) syscall.Errno <span class="cov10" title="31">{
        d.mu.RLock()
        defer d.mu.RUnlock()

        now := time.Now()

        uid, gid, mode := getDirPerms(d.permStore, d.path)

        out.Mode = fuse.S_IFDIR | mode
        out.Uid = uid
        out.Gid = gid
        out.Atime = uint64(now.Unix())
        out.Mtime = uint64(now.Unix())
        out.Ctime = uint64(now.Unix())
        out.Nlink = 2 + uint32(len(d.subdirs))
        return 0
}</span>

// Setattr implements fs.NodeSetattrer - handles chmod/chown on directories.
func (d *MKVFSDirNode) Setattr(ctx context.Context, fh fs.FileHandle, in *fuse.SetAttrIn, out *fuse.AttrOut) syscall.Errno <span class="cov7" title="13">{
        if d.permStore == nil </span><span class="cov2" title="2">{
                // No permission store - can't change permissions
                return syscall.EROFS
        }</span>

        // Only UID, GID, and mode changes are supported. All other setattr operations
        // (e.g. size truncation, atime/mtime updates) must fail on this read-only FS.
        <span class="cov7" title="11">supportedMask := uint32(fuse.FATTR_UID | fuse.FATTR_GID | fuse.FATTR_MODE)
        if in.Valid&amp;^supportedMask != 0 </span><span class="cov0" title="0">{
                return syscall.EROFS
        }</span>

        // Get current permissions and caller
        <span class="cov7" title="11">dirUID, dirGID, dirMode := getDirPerms(d.permStore, d.path)
        caller, ok := GetCaller(ctx)
        if !ok </span><span class="cov0" title="0">{
                return syscall.EACCES
        }</span>

        <span class="cov7" title="11">var newUID, newGID, newMode *uint32

        // Check which fields are being changed
        if in.Valid&amp;fuse.FATTR_UID != 0 </span><span class="cov5" title="6">{
                newUID = &amp;in.Uid
        }</span>
        <span class="cov7" title="11">if in.Valid&amp;fuse.FATTR_GID != 0 </span><span class="cov4" title="4">{
                newGID = &amp;in.Gid
        }</span>
        <span class="cov7" title="11">if in.Valid&amp;fuse.FATTR_MODE != 0 </span><span class="cov5" title="5">{
                mode := in.Mode &amp; 0777 // Only permission bits
                newMode = &amp;mode
        }</span>

        // Normalize no-op changes to nil to avoid unnecessary disk writes
        <span class="cov7" title="11">if newUID != nil &amp;&amp; *newUID == dirUID </span><span class="cov0" title="0">{
                newUID = nil
        }</span>
        <span class="cov7" title="11">if newGID != nil &amp;&amp; *newGID == dirGID </span><span class="cov0" title="0">{
                newGID = nil
        }</span>
        <span class="cov7" title="11">if newMode != nil &amp;&amp; *newMode == dirMode </span><span class="cov0" title="0">{
                newMode = nil
        }</span>

        // Permission checks for chown
        <span class="cov7" title="11">if newUID != nil || newGID != nil </span><span class="cov5" title="6">{
                if errno := CheckChown(caller, dirUID, dirGID, newUID, newGID); errno != 0 </span><span class="cov2" title="2">{
                        if d.verbose </span><span class="cov0" title="0">{
                                log.Printf("Setattr: chown permission denied for %s (caller uid=%d)", d.path, caller.Uid)
                        }</span>
                        <span class="cov2" title="2">return errno</span>
                }
        }

        // Permission checks for chmod
        <span class="cov6" title="9">if newMode != nil </span><span class="cov5" title="5">{
                if errno := CheckChmod(caller, dirUID); errno != 0 </span><span class="cov2" title="2">{
                        if d.verbose </span><span class="cov0" title="0">{
                                log.Printf("Setattr: chmod permission denied for %s (caller uid=%d)", d.path, caller.Uid)
                        }</span>
                        <span class="cov2" title="2">return errno</span>
                }
        }

        // Update permission store
        <span class="cov6" title="7">if err := d.permStore.SetDirPerms(d.path, newUID, newGID, newMode); err != nil </span><span class="cov0" title="0">{
                if d.verbose </span><span class="cov0" title="0">{
                        log.Printf("Setattr error: %s: %v", d.path, err)
                }</span>
                <span class="cov0" title="0">return syscall.EIO</span>
        }

        <span class="cov6" title="7">if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Setattr: %s uid=%v gid=%v mode=%v", d.path, newUID, newGID, newMode)
        }</span>

        // Return updated attributes
        <span class="cov6" title="7">return d.Getattr(ctx, fh, out)</span>
}

// --- Read-only filesystem error handlers ---
// These return EROFS (Read-only file system) for write operations.

// Mkdir implements fs.NodeMkdirer - rejects directory creation.
func (d *MKVFSDirNode) Mkdir(ctx context.Context, name string, mode uint32, out *fuse.EntryOut) (*fs.Inode, syscall.Errno) <span class="cov3" title="3">{
        if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Mkdir: rejected (read-only) %s in %s", name, d.path)
        }</span>
        <span class="cov3" title="3">return nil, syscall.EROFS</span>
}

// Rmdir implements fs.NodeRmdirer - rejects directory removal.
func (d *MKVFSDirNode) Rmdir(ctx context.Context, name string) syscall.Errno <span class="cov2" title="2">{
        if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Rmdir: rejected (read-only) %s in %s", name, d.path)
        }</span>
        <span class="cov2" title="2">return syscall.EROFS</span>
}

// Unlink implements fs.NodeUnlinker - rejects file deletion.
func (d *MKVFSDirNode) Unlink(ctx context.Context, name string) syscall.Errno <span class="cov3" title="3">{
        if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Unlink: rejected (read-only) %s in %s", name, d.path)
        }</span>
        <span class="cov3" title="3">return syscall.EROFS</span>
}

// Create implements fs.NodeCreater - rejects file creation.
func (d *MKVFSDirNode) Create(ctx context.Context, name string, flags uint32, mode uint32, out *fuse.EntryOut) (node *fs.Inode, fh fs.FileHandle, fuseFlags uint32, errno syscall.Errno) <span class="cov3" title="3">{
        if d.verbose </span><span class="cov0" title="0">{
                log.Printf("Create: rejected (read-only) %s in %s", name, d.path)
        }</span>
        <span class="cov3" title="3">return nil, nil, 0, syscall.EROFS</span>
}
</pre>
		
		<pre class="file" id="file25" style="display: none">package fuse

import (
        "fmt"
        "log"
        "path/filepath"

        "github.com/stuckj/mkvdup/internal/dedup"
)

// MKVFSOptions contains options for creating an MKVFS filesystem.
type MKVFSOptions struct {
        Verbose         bool
        PermissionsPath string
        // Defaults holds the default permissions to use when a PermissionStore is configured.
        // If nil, DefaultPerms() is used. Set to a non-nil value to use specific defaults.
        // Note: explicit-zero defaults only work when provided programmatically here;
        // they are not persisted to or loaded from the permissions YAML file.
        Defaults *Defaults
}

// NewMKVFS creates a new MKVFS root from a list of config files.
// Config files are resolved recursively (includes and virtual_files are expanded).
// Set verbose=true to enable debug logging.
func NewMKVFS(configPaths []string, verbose bool) (*MKVFSRoot, error) <span class="cov6" title="11">{
        configs, _, err := dedup.ResolveConfigs(configPaths)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resolve configs: %w", err)
        }</span>
        <span class="cov6" title="11">return NewMKVFSFromConfigs(configs, verbose, &amp;DefaultReaderFactory{}, nil)</span>
}

// NewMKVFSWithPermissions creates a new MKVFS root with a permission store.
// Config files are resolved recursively (includes and virtual_files are expanded).
func NewMKVFSWithPermissions(configPaths []string, verbose bool, permStore *PermissionStore) (*MKVFSRoot, error) <span class="cov0" title="0">{
        configs, _, err := dedup.ResolveConfigs(configPaths)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resolve configs: %w", err)
        }</span>
        <span class="cov0" title="0">return NewMKVFSFromConfigs(configs, verbose, &amp;DefaultReaderFactory{}, permStore)</span>
}

// NewMKVFSWithOptions creates a new MKVFS root with the given options.
// Config files are resolved recursively (includes and virtual_files are expanded).
func NewMKVFSWithOptions(configPaths []string, opts MKVFSOptions) (*MKVFSRoot, error) <span class="cov4" title="5">{
        var permStore *PermissionStore
        if opts.PermissionsPath != "" </span><span class="cov4" title="5">{
                defaults := DefaultPerms()
                if opts.Defaults != nil </span><span class="cov4" title="4">{
                        defaults = *opts.Defaults
                }</span>
                <span class="cov4" title="5">permStore = NewPermissionStore(opts.PermissionsPath, defaults, opts.Verbose)
                if err := permStore.Load(); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("load permissions: %w", err)
                }</span>
        }
        <span class="cov4" title="5">configs, _, err := dedup.ResolveConfigs(configPaths)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resolve configs: %w", err)
        }</span>
        <span class="cov4" title="5">return NewMKVFSFromConfigs(configs, opts.Verbose, &amp;DefaultReaderFactory{}, permStore)</span>
}

// NewMKVFSWithFactories creates a new MKVFS root with custom factories.
// This allows injecting mock implementations for testing.
func NewMKVFSWithFactories(configPaths []string, verbose bool, readerFactory ReaderFactory, configReader ConfigReader, permStore *PermissionStore) (*MKVFSRoot, error) <span class="cov7" title="16">{
        root := &amp;MKVFSRoot{
                files:         make(map[string]*MKVFile),
                verbose:       verbose,
                readerFactory: readerFactory,
                configReader:  configReader,
                permStore:     permStore,
        }

        if verbose </span><span class="cov0" title="0">{
                log.Printf("Creating MKVFS with %d config files", len(configPaths))
        }</span>

        <span class="cov7" title="16">for _, configPath := range configPaths </span><span class="cov8" title="22">{
                if verbose </span><span class="cov0" title="0">{
                        log.Printf("Reading config: %s", configPath)
                }</span>
                <span class="cov8" title="22">config, err := root.configReader.ReadConfig(configPath)
                if err != nil </span><span class="cov2" title="2">{
                        return nil, fmt.Errorf("read config %s: %w", configPath, err)
                }</span>
                <span class="cov8" title="20">if verbose </span><span class="cov0" title="0">{
                        log.Printf("Config: name=%s, dedup=%s, source=%s", config.Name, config.DedupFile, config.SourceDir)
                }</span>

                // Resolve relative paths
                <span class="cov8" title="20">configDir := filepath.Dir(configPath)
                dedupPath := config.DedupFile
                if !filepath.IsAbs(dedupPath) </span><span class="cov2" title="2">{
                        dedupPath = filepath.Join(configDir, dedupPath)
                }</span>
                <span class="cov8" title="20">sourceDir := config.SourceDir
                if !filepath.IsAbs(sourceDir) </span><span class="cov2" title="2">{
                        sourceDir = filepath.Join(configDir, sourceDir)
                }</span>

                // Open dedup file to get size (lazy loading - only reads header)
                <span class="cov8" title="20">if verbose </span><span class="cov0" title="0">{
                        log.Printf("Opening dedup file: %s", dedupPath)
                }</span>
                <span class="cov8" title="20">reader, err := root.readerFactory.NewReaderLazy(dedupPath, sourceDir)
                if err != nil </span><span class="cov2" title="2">{
                        if verbose </span><span class="cov0" title="0">{
                                log.Printf("Failed to open dedup file: %v", err)
                        }</span>
                        <span class="cov2" title="2">return nil, fmt.Errorf("open dedup file %s: %w", dedupPath, err)</span>
                }

                <span class="cov8" title="18">mkvFile := &amp;MKVFile{
                        Name:          config.Name,
                        DedupPath:     dedupPath,
                        SourceDir:     sourceDir,
                        Size:          reader.OriginalSize(),
                        readerFactory: root.readerFactory,
                }

                // Don't keep reader open - we'll open it lazily
                reader.Close()

                root.files[config.Name] = mkvFile
                if verbose </span><span class="cov0" title="0">{
                        log.Printf("Added file: %s (size=%d)", config.Name, mkvFile.Size)
                }</span>
        }

        <span class="cov7" title="12">if verbose </span><span class="cov0" title="0">{
                log.Printf("Total files: %d", len(root.files))
        }</span>

        // Build directory tree from collected files
        <span class="cov7" title="12">fileList := make([]*MKVFile, 0, len(root.files))
        for _, f := range root.files </span><span class="cov8" title="18">{
                fileList = append(fileList, f)
        }</span>
        <span class="cov7" title="12">root.rootDir = BuildDirectoryTree(fileList, verbose, readerFactory, permStore)

        // Clean up stale permission entries if we have a permission store
        if permStore != nil </span><span class="cov2" title="2">{
                validFiles, validDirs := root.collectValidPaths()
                removed := permStore.CleanupStale(validFiles, validDirs)
                if removed &gt; 0 </span><span class="cov0" title="0">{
                        if verbose </span><span class="cov0" title="0">{
                                log.Printf("Cleaned up %d stale permission entries", removed)
                        }</span>
                        <span class="cov0" title="0">if err := permStore.Save(); err != nil </span><span class="cov0" title="0">{
                                log.Printf("Warning: failed to save permissions after cleanup: %v", err)
                        }</span>
                }
        }

        <span class="cov7" title="12">if verbose </span><span class="cov0" title="0">{
                log.Printf("Directory tree built with %d root entries", len(root.rootDir.files)+len(root.rootDir.subdirs))
        }</span>

        <span class="cov7" title="12">return root, nil</span>
}

// NewMKVFSFromConfigs creates a new MKVFS root from already-resolved configs.
// Paths in configs must already be absolute (as returned by dedup.ResolveConfigs).
func NewMKVFSFromConfigs(configs []dedup.Config, verbose bool, readerFactory ReaderFactory, permStore *PermissionStore) (*MKVFSRoot, error) <span class="cov9" title="34">{
        root := &amp;MKVFSRoot{
                files:         make(map[string]*MKVFile),
                verbose:       verbose,
                readerFactory: readerFactory,
                permStore:     permStore,
        }

        if verbose </span><span class="cov1" title="1">{
                log.Printf("Creating MKVFS with %d resolved configs", len(configs))
        }</span>

        <span class="cov9" title="34">for _, config := range configs </span><span class="cov10" title="40">{
                if verbose </span><span class="cov1" title="1">{
                        log.Printf("Config: name=%s, dedup=%s, source=%s", config.Name, config.DedupFile, config.SourceDir)
                }</span>

                // Open dedup file to get size (lazy loading - only reads header)
                <span class="cov10" title="40">if verbose </span><span class="cov1" title="1">{
                        log.Printf("Opening dedup file: %s", config.DedupFile)
                }</span>
                <span class="cov10" title="40">reader, err := root.readerFactory.NewReaderLazy(config.DedupFile, config.SourceDir)
                if err != nil </span><span class="cov0" title="0">{
                        if verbose </span><span class="cov0" title="0">{
                                log.Printf("Failed to open dedup file: %v", err)
                        }</span>
                        <span class="cov0" title="0">return nil, fmt.Errorf("open dedup file %s: %w", config.DedupFile, err)</span>
                }

                <span class="cov10" title="40">mkvFile := &amp;MKVFile{
                        Name:          config.Name,
                        DedupPath:     config.DedupFile,
                        SourceDir:     config.SourceDir,
                        Size:          reader.OriginalSize(),
                        readerFactory: root.readerFactory,
                }

                // Don't keep reader open - we'll open it lazily
                reader.Close()

                root.files[config.Name] = mkvFile
                if verbose </span><span class="cov1" title="1">{
                        log.Printf("Added file: %s (size=%d)", config.Name, mkvFile.Size)
                }</span>
        }

        <span class="cov9" title="34">if verbose </span><span class="cov1" title="1">{
                log.Printf("Total files: %d", len(root.files))
        }</span>

        // Build directory tree from collected files
        <span class="cov9" title="34">fileList := make([]*MKVFile, 0, len(root.files))
        for _, f := range root.files </span><span class="cov10" title="40">{
                fileList = append(fileList, f)
        }</span>
        <span class="cov9" title="34">root.rootDir = BuildDirectoryTree(fileList, verbose, readerFactory, permStore)

        // Clean up stale permission entries if we have a permission store
        if permStore != nil </span><span class="cov4" title="5">{
                validFiles, validDirs := root.collectValidPaths()
                removed := permStore.CleanupStale(validFiles, validDirs)
                if removed &gt; 0 </span><span class="cov0" title="0">{
                        if verbose </span><span class="cov0" title="0">{
                                log.Printf("Cleaned up %d stale permission entries", removed)
                        }</span>
                        <span class="cov0" title="0">if err := permStore.Save(); err != nil </span><span class="cov0" title="0">{
                                log.Printf("Warning: failed to save permissions after cleanup: %v", err)
                        }</span>
                }
        }

        <span class="cov9" title="34">if verbose </span><span class="cov1" title="1">{
                log.Printf("Directory tree built with %d root entries", len(root.rootDir.files)+len(root.rootDir.subdirs))
        }</span>

        <span class="cov9" title="34">return root, nil</span>
}
</pre>
		
		<pre class="file" id="file26" style="display: none">package fuse

import (
        "context"
        "fmt"
        "log"
        "syscall"
        "time"

        "github.com/hanwen/go-fuse/v2/fs"
        "github.com/hanwen/go-fuse/v2/fuse"
)

// Getattr implements fs.NodeGetattrer - returns file attributes.
func (n *MKVFSNode) Getattr(ctx context.Context, fh fs.FileHandle, out *fuse.AttrOut) syscall.Errno <span class="cov10" title="25093">{
        now := time.Now()
        out.Size = uint64(n.file.Size)

        uid, gid, mode := getFilePerms(n.permStore, n.path)

        out.Mode = fuse.S_IFREG | mode
        out.Uid = uid
        out.Gid = gid
        out.Atime = uint64(now.Unix())
        out.Mtime = uint64(now.Unix())
        out.Ctime = uint64(now.Unix())
        out.Nlink = 1
        return 0
}</span>

// Setattr implements fs.NodeSetattrer - handles chmod/chown on files.
func (n *MKVFSNode) Setattr(ctx context.Context, fh fs.FileHandle, in *fuse.SetAttrIn, out *fuse.AttrOut) syscall.Errno <span class="cov3" title="24">{
        if n.permStore == nil </span><span class="cov1" title="2">{
                // No permission store - can't change permissions
                return syscall.EROFS
        }</span>

        // Only UID, GID, and mode changes are supported. All other setattr operations
        // (e.g. size truncation, atime/mtime updates) must fail on this read-only FS.
        <span class="cov3" title="22">supportedMask := uint32(fuse.FATTR_UID | fuse.FATTR_GID | fuse.FATTR_MODE)
        if in.Valid&amp;^supportedMask != 0 </span><span class="cov0" title="0">{
                return syscall.EROFS
        }</span>

        // Get current permissions and caller
        <span class="cov3" title="22">fileUID, fileGID, fileMode := getFilePerms(n.permStore, n.path)
        caller, ok := GetCaller(ctx)
        if !ok </span><span class="cov0" title="0">{
                return syscall.EACCES
        }</span>

        <span class="cov3" title="22">var newUID, newGID, newMode *uint32

        // Check which fields are being changed
        if in.Valid&amp;fuse.FATTR_UID != 0 </span><span class="cov2" title="7">{
                newUID = &amp;in.Uid
        }</span>
        <span class="cov3" title="22">if in.Valid&amp;fuse.FATTR_GID != 0 </span><span class="cov3" title="11">{
                newGID = &amp;in.Gid
        }</span>
        <span class="cov3" title="22">if in.Valid&amp;fuse.FATTR_MODE != 0 </span><span class="cov2" title="7">{
                mode := in.Mode &amp; 0777 // Only permission bits
                newMode = &amp;mode
        }</span>

        // Normalize no-op changes to nil to avoid unnecessary disk writes
        <span class="cov3" title="22">if newUID != nil &amp;&amp; *newUID == fileUID </span><span class="cov0" title="0">{
                newUID = nil
        }</span>
        <span class="cov3" title="22">if newGID != nil &amp;&amp; *newGID == fileGID </span><span class="cov0" title="0">{
                newGID = nil
        }</span>
        <span class="cov3" title="22">if newMode != nil &amp;&amp; *newMode == fileMode </span><span class="cov0" title="0">{
                newMode = nil
        }</span>

        // Permission checks for chown
        <span class="cov3" title="22">if newUID != nil || newGID != nil </span><span class="cov3" title="15">{
                if errno := CheckChown(caller, fileUID, fileGID, newUID, newGID); errno != 0 </span><span class="cov2" title="6">{
                        if n.verbose </span><span class="cov0" title="0">{
                                log.Printf("Setattr: chown permission denied for %s (caller uid=%d)", n.path, caller.Uid)
                        }</span>
                        <span class="cov2" title="6">return errno</span>
                }
        }

        // Permission checks for chmod
        <span class="cov3" title="16">if newMode != nil </span><span class="cov2" title="7">{
                if errno := CheckChmod(caller, fileUID); errno != 0 </span><span class="cov1" title="2">{
                        if n.verbose </span><span class="cov0" title="0">{
                                log.Printf("Setattr: chmod permission denied for %s (caller uid=%d)", n.path, caller.Uid)
                        }</span>
                        <span class="cov1" title="2">return errno</span>
                }
        }

        // Update permission store
        <span class="cov3" title="14">if err := n.permStore.SetFilePerms(n.path, newUID, newGID, newMode); err != nil </span><span class="cov0" title="0">{
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Setattr error: %s: %v", n.path, err)
                }</span>
                <span class="cov0" title="0">return syscall.EIO</span>
        }

        <span class="cov3" title="14">if n.verbose </span><span class="cov0" title="0">{
                log.Printf("Setattr: %s uid=%v gid=%v mode=%v", n.path, newUID, newGID, newMode)
        }</span>

        // Return updated attributes
        <span class="cov3" title="14">return n.Getattr(ctx, fh, out)</span>
}

// Open implements fs.NodeOpener - opens a file for reading.
func (n *MKVFSNode) Open(ctx context.Context, flags uint32) (fs.FileHandle, uint32, syscall.Errno) <span class="cov3" title="15">{
        // This is a read-only filesystem - reject any write access or operations
        // that would modify the filesystem. Note: O_RDONLY|O_APPEND is a valid
        // read-only open on Linux (positions at EOF), so we only check access mode.
        accMode := flags &amp; syscall.O_ACCMODE
        if accMode != syscall.O_RDONLY || flags&amp;(syscall.O_TRUNC|syscall.O_CREAT) != 0 </span><span class="cov0" title="0">{
                return nil, 0, syscall.EROFS
        }</span>

        // Permission checks are handled by the kernel via default_permissions mount option.

        // Check if file was disabled due to source file change
        <span class="cov3" title="15">n.file.mu.RLock()
        disabled := n.file.disabled
        n.file.mu.RUnlock()
        if disabled </span><span class="cov2" title="4">{
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Open: %s: source file changed, file disabled", n.file.Name)
                }</span>
                <span class="cov2" title="4">return nil, 0, syscall.EIO</span>
        }

        <span class="cov3" title="11">if n.verbose </span><span class="cov0" title="0">{
                log.Printf("Open: %s", n.file.Name)
        }</span>
        // Initialize reader lazily if needed
        <span class="cov3" title="11">if err := n.ensureReader(); err != nil </span><span class="cov1" title="2">{
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Open error: %s: %v", n.file.Name, err)
                }</span>
                <span class="cov1" title="2">return nil, 0, syscall.EIO</span>
        }
        <span class="cov2" title="9">return nil, fuse.FOPEN_KEEP_CACHE | fuse.FOPEN_CACHE_DIR, 0</span>
}

// Read implements fs.NodeReader - reads data from the file.
func (n *MKVFSNode) Read(ctx context.Context, fh fs.FileHandle, dest []byte, off int64) (fuse.ReadResult, syscall.Errno) <span class="cov8" title="6283">{
        // Permission checks are handled by the kernel via default_permissions mount option.

        n.file.mu.RLock()
        defer n.file.mu.RUnlock()

        if n.file.disabled </span><span class="cov1" title="2">{
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Read error: %s: source file changed, file disabled", n.file.Name)
                }</span>
                <span class="cov1" title="2">return nil, syscall.EIO</span>
        }

        <span class="cov8" title="6281">if n.file.reader == nil </span><span class="cov1" title="2">{
                // Reader not initialized
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Read error: %s: reader not initialized", n.file.Name)
                }</span>
                <span class="cov1" title="2">return nil, syscall.EIO</span>
        }

        // Clamp read to file size
        <span class="cov8" title="6279">if off &gt;= n.file.Size </span><span class="cov1" title="2">{
                return fuse.ReadResultData(nil), 0
        }</span>

        <span class="cov8" title="6277">endOff := off + int64(len(dest))
        if endOff &gt; n.file.Size </span><span class="cov1" title="1">{
                dest = dest[:n.file.Size-off]
        }</span>

        // Read from dedup reader
        <span class="cov8" title="6277">nRead, err := n.file.reader.ReadAt(dest, off)
        if err != nil &amp;&amp; nRead == 0 </span><span class="cov0" title="0">{
                if n.verbose </span><span class="cov0" title="0">{
                        log.Printf("Read error: %s at offset %d: %v", n.file.Name, off, err)
                }</span>
                <span class="cov0" title="0">return nil, syscall.EIO</span>
        }

        <span class="cov8" title="6277">if n.verbose </span><span class="cov0" title="0">{
                log.Printf("Read: %s offset=%d len=%d read=%d", n.file.Name, off, len(dest), nRead)
        }</span>

        <span class="cov8" title="6277">return fuse.ReadResultData(dest[:nRead]), 0</span>
}

// ensureReader ensures the dedup reader is initialized.
func (n *MKVFSNode) ensureReader() error <span class="cov3" title="13">{
        n.file.mu.Lock()
        defer n.file.mu.Unlock()

        if n.file.reader != nil </span><span class="cov1" title="2">{
                return nil
        }</span>

        // Open dedup file with lazy loading using the factory
        <span class="cov3" title="11">reader, err := n.file.readerFactory.NewReaderLazy(n.file.DedupPath, n.file.SourceDir)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open dedup file: %w", err)
        }</span>

        // Initialize the reader for reading (handles ES vs raw internally)
        <span class="cov3" title="11">if err := reader.InitializeForReading(n.file.SourceDir); err != nil </span><span class="cov1" title="2">{
                reader.Close()
                return fmt.Errorf("initialize reader: %w", err)
        }</span>

        <span class="cov2" title="9">n.file.reader = reader
        return nil</span>
}

// Disable marks the file as disabled (source changed). Subsequent reads
// return EIO. Closes any active reader. Thread-safe.
func (f *MKVFile) Disable() <span class="cov3" title="18">{
        f.mu.Lock()
        defer f.mu.Unlock()
        f.disabled = true
        if f.reader != nil </span><span class="cov2" title="4">{
                f.reader.Close()
                f.reader = nil
        }</span>
}

// Enable re-enables a previously disabled file (e.g., after checksum
// verification confirms the source is OK). The reader will be lazily
// re-initialized on next Open.
func (f *MKVFile) Enable() <span class="cov2" title="6">{
        f.mu.Lock()
        defer f.mu.Unlock()
        f.disabled = false
}</span>

// Close cleans up the file's resources.
func (f *MKVFile) Close() <span class="cov2" title="4">{
        f.mu.Lock()
        defer f.mu.Unlock()

        if f.reader != nil </span><span class="cov1" title="2">{
                f.reader.Close()
                f.reader = nil
        }</span>
}

// updateFrom copies data fields from src into f. If the underlying dedup file
// changed, any active reader is closed since it's no longer valid.
// The caller must hold f.mu (write lock).
func (f *MKVFile) updateFrom(src *MKVFile) <span class="cov4" title="32">{
        // Close reader if the underlying file changed — it's no longer valid
        if f.reader != nil &amp;&amp; (f.DedupPath != src.DedupPath || f.SourceDir != src.SourceDir) </span><span class="cov1" title="2">{
                f.reader.Close()
                f.reader = nil
        }</span>
        <span class="cov4" title="32">f.Name = src.Name
        f.DedupPath = src.DedupPath
        f.SourceDir = src.SourceDir
        f.Size = src.Size
        f.readerFactory = src.readerFactory
        // Reset disabled flag — reload re-validates source files
        f.disabled = false</span>
}

// hashString creates a stable inode number from a string.
func hashString(s string) uint64 <span class="cov4" title="43">{
        var h uint64 = 5381
        for _, c := range s </span><span class="cov6" title="372">{
                h = ((h &lt;&lt; 5) + h) + uint64(c)
        }</span>
        <span class="cov4" title="43">return h</span>
}
</pre>
		
		<pre class="file" id="file27" style="display: none">package fuse

import (
        "context"
        "log"
        "path"
        "strings"
        "syscall"
        "time"

        "github.com/hanwen/go-fuse/v2/fs"
        "github.com/hanwen/go-fuse/v2/fuse"
        "github.com/stuckj/mkvdup/internal/dedup"
)

// reloadNotification captures a pending FUSE kernel notification to emit
// after all locks are released (go-fuse notifications must not be called
// while holding filesystem locks, as the kernel may call back into the FS).
type reloadNotification struct {
        parent   *fs.Inode
        child    *fs.Inode // non-nil for deletions (if kernel had cached the inode)
        name     string
        isDelete bool
}

// findParentInode walks the directory tree to find the parent inode for a
// given file path (e.g., "Movies/Action/film.mkv"). Returns the parent's
// go-fuse Inode and the basename, or (nil, "") if the parent directory
// doesn't exist in the tree.
//
// For root-level files (no directory component), returns r.Inode.
// Caller must NOT hold directory locks — this method acquires them.
func (r *MKVFSRoot) findParentInode(filePath string) (*fs.Inode, string) <span class="cov8" title="34">{
        cleaned := path.Clean(filePath)
        parts := strings.Split(cleaned, "/")
        // Filter empty parts (handles leading slashes)
        valid := make([]string, 0, len(parts))
        for _, p := range parts </span><span class="cov10" title="56">{
                if p != "" &amp;&amp; p != "." </span><span class="cov10" title="56">{
                        valid = append(valid, p)
                }</span>
        }
        <span class="cov8" title="34">if len(valid) == 0 </span><span class="cov0" title="0">{
                return nil, ""
        }</span>

        <span class="cov8" title="34">basename := valid[len(valid)-1]
        dirParts := valid[:len(valid)-1]

        if len(dirParts) == 0 </span><span class="cov7" title="16">{
                // File is at root level — parent is the root inode
                return &amp;r.Inode, basename
        }</span>

        // Walk directory tree to find parent
        <span class="cov7" title="18">current := r.rootDir
        for _, part := range dirParts </span><span class="cov7" title="22">{
                current.mu.RLock()
                subdir, ok := current.subdirs[part]
                current.mu.RUnlock()
                if !ok </span><span class="cov4" title="4">{
                        return nil, ""
                }</span>
                <span class="cov7" title="18">current = subdir</span>
        }

        // Newly created directories from mergeDirectoryTree have uninitialized
        // fs.Inode (never registered with go-fuse via NewPersistentInode).
        // The kernel doesn't know about them, so notifications would panic.
        // Return nil — the kernel will discover the directory via Lookup.
        <span class="cov6" title="14">if current.Inode.StableAttr().Ino == 0 </span><span class="cov6" title="14">{
                return nil, ""
        }</span>

        <span class="cov0" title="0">return &amp;current.Inode, basename</span>
}

// markAncestorDirs walks from inode up to (and including) the root,
// adding each ancestor to changedDirs so their readdir caches are
// invalidated. This is necessary because a file addition or removal
// in a deeply nested virtual directory may cause intermediate
// directories to be created or removed by the tree merge.
func markAncestorDirs(inode *fs.Inode, changedDirs map[*fs.Inode]bool) <span class="cov6" title="10">{
        for node := inode; ; </span><span class="cov6" title="10">{
                _, ancestor := node.Parent()
                if ancestor == nil </span><span class="cov6" title="10">{
                        break</span>
                }
                <span class="cov0" title="0">if changedDirs[ancestor] </span><span class="cov0" title="0">{
                        break</span> // already marked — ancestors above must be too
                }
                <span class="cov0" title="0">changedDirs[ancestor] = true
                node = ancestor</span>
        }
}

// Reload updates the filesystem with new configs. It updates existing MKVFile
// objects in place to preserve pointer identity for cached FUSE inodes, and
// merges the directory tree structure (required because go-fuse caches
// persistent inode objects by inode number).
//
// After the merge, FUSE kernel notifications are emitted:
//   - NotifyDelete for removed files (sends IN_DELETE to inotify watchers)
//   - NotifyEntry for added files (invalidates kernel dentry cache)
//   - NotifyContent on changed directories (invalidates readdir cache)
//
// Note: The FUSE protocol has no NOTIFY_CREATE, so added files don't
// generate proactive inotify events. Media servers should use periodic
// scanning in addition to inotify watching.
//
// Semantics:
//   - New files become immediately visible
//   - Removed files disappear from listings
//   - Modified mappings update existing MKVFile objects in place; active readers
//     are closed if the underlying dedup path changed (re-opened lazily on next read)
//   - Permissions are reloaded from disk and stale entries cleaned up
//     (cleanup is skipped if permission reload fails, to avoid overwriting
//     a temporarily unreadable permissions file)
func (r *MKVFSRoot) Reload(configs []dedup.Config, logFn func(string, ...interface{})) error <span class="cov7" title="20">{
        if logFn == nil </span><span class="cov7" title="18">{
                logFn = func(string, ...interface{}) </span>{<span class="cov7" title="18">}</span>
        }

        // Build new file set from configs
        <span class="cov7" title="20">newFiles := make(map[string]*MKVFile)
        for _, config := range configs </span><span class="cov8" title="26">{
                reader, err := r.readerFactory.NewReaderLazy(config.DedupFile, config.SourceDir)
                if err != nil </span><span class="cov2" title="2">{
                        logFn("warning: skipping %s: %v", config.Name, err)
                        continue</span>
                }

                <span class="cov8" title="24">mkvFile := &amp;MKVFile{
                        Name:          config.Name,
                        DedupPath:     config.DedupFile,
                        SourceDir:     config.SourceDir,
                        Size:          reader.OriginalSize(),
                        readerFactory: r.readerFactory,
                }
                reader.Close()
                if existing, ok := newFiles[config.Name]; ok </span><span class="cov0" title="0">{
                        logFn("warning: duplicate name %q (dedup: %s replaced by %s)", config.Name, existing.DedupPath, mkvFile.DedupPath)
                }</span>
                <span class="cov8" title="24">newFiles[config.Name] = mkvFile</span>
        }

        // Snapshot old file names for change detection
        <span class="cov7" title="20">r.mu.RLock()
        oldFileNames := make(map[string]bool, len(r.files))
        for name := range r.files </span><span class="cov8" title="24">{
                oldFileNames[name] = true
        }</span>
        <span class="cov7" title="20">r.mu.RUnlock()

        // Before merge: capture child inodes for files being removed. We need
        // these for NotifyDelete (sends IN_DELETE inotify event), and the child
        // inode won't be reachable after tree merge removes it. We do NOT
        // capture parent inodes here because the merge may delete parent
        // directories, leaving stale inode pointers that crash go-fuse.
        deletedChildren := make(map[string]*fs.Inode) // filePath → child inode
        for name := range oldFileNames </span><span class="cov8" title="24">{
                if _, inNew := newFiles[name]; !inNew </span><span class="cov6" title="10">{
                        parentInode, basename := r.findParentInode(name)
                        if parentInode != nil </span><span class="cov5" title="6">{
                                if child := parentInode.GetChild(basename); child != nil </span><span class="cov0" title="0">{
                                        deletedChildren[name] = child
                                }</span>
                        }
                }
        }

        // Build new directory tree
        <span class="cov7" title="20">fileList := make([]*MKVFile, 0, len(newFiles))
        for _, f := range newFiles </span><span class="cov8" title="24">{
                fileList = append(fileList, f)
        }</span>
        <span class="cov7" title="20">newTree := BuildDirectoryTree(fileList, r.verbose, r.readerFactory, r.permStore)

        // Update flat files map in place (preserves pointer identity for cached inodes)
        r.mu.Lock()
        for name := range r.files </span><span class="cov8" title="24">{
                if _, inNew := newFiles[name]; !inNew </span><span class="cov6" title="10">{
                        delete(r.files, name)
                }</span>
        }
        <span class="cov7" title="20">for name, newFile := range newFiles </span><span class="cov8" title="24">{
                if existingFile, ok := r.files[name]; ok </span><span class="cov6" title="14">{
                        existingFile.mu.Lock()
                        existingFile.updateFrom(newFile)
                        existingFile.mu.Unlock()
                }</span> else<span class="cov6" title="10"> {
                        r.files[name] = newFile
                }</span>
        }
        <span class="cov7" title="20">r.mu.Unlock()

        // Merge new tree into existing tree in place
        mergeDirectoryTree(r.rootDir, newTree)

        // After merge: capture all notifications using the post-merge tree.
        // Parent inodes are now resolved against the live tree, so we never
        // reference deleted directory inodes. If a parent directory was removed
        // by the merge, findParentInode returns nil and we skip the notification
        // — the directory removal already invalidates its children in the kernel.
        var notifications []reloadNotification
        changedDirs := make(map[*fs.Inode]bool)
        for name := range oldFileNames </span><span class="cov8" title="24">{
                if _, inNew := newFiles[name]; !inNew </span><span class="cov6" title="10">{
                        parentInode, basename := r.findParentInode(name)
                        if parentInode != nil </span><span class="cov5" title="6">{
                                notifications = append(notifications, reloadNotification{
                                        parent:   parentInode,
                                        child:    deletedChildren[name],
                                        name:     basename,
                                        isDelete: true,
                                })
                                changedDirs[parentInode] = true
                                markAncestorDirs(parentInode, changedDirs)
                        }</span>
                }
        }
        <span class="cov7" title="20">for name := range newFiles </span><span class="cov8" title="24">{
                if !oldFileNames[name] </span><span class="cov6" title="10">{
                        parentInode, basename := r.findParentInode(name)
                        if parentInode != nil </span><span class="cov4" title="4">{
                                notifications = append(notifications, reloadNotification{
                                        parent:   parentInode,
                                        name:     basename,
                                        isDelete: false,
                                })
                                changedDirs[parentInode] = true
                                markAncestorDirs(parentInode, changedDirs)
                        }</span>
                }
        }

        // Reload permissions and clean up stale entries
        <span class="cov7" title="20">if r.permStore != nil </span><span class="cov0" title="0">{
                if err := r.permStore.Load(); err != nil </span><span class="cov0" title="0">{
                        logFn("warning: failed to reload permissions: %v", err)
                }</span> else<span class="cov0" title="0"> {
                        validFiles, validDirs := r.collectValidPaths()
                        removed := r.permStore.CleanupStale(validFiles, validDirs)
                        if removed &gt; 0 </span><span class="cov0" title="0">{
                                logFn("cleaned up %d stale permission entries", removed)
                                if err := r.permStore.Save(); err != nil </span><span class="cov0" title="0">{
                                        logFn("warning: failed to save permissions after cleanup: %v", err)
                                }</span>
                        }
                }
        }

        <span class="cov7" title="20">logFn("reload complete: %d files", len(newFiles))

        // Emit FUSE kernel notifications. Must be called after all filesystem
        // locks are released — go-fuse may call back into the FS during
        // notification processing, which would deadlock if locks were held.
        r.emitReloadNotifications(notifications, changedDirs, logFn)

        return nil</span>
}

// Files returns a snapshot of the current file set. Used by SourceWatcher
// to build reverse mappings from source files to virtual files. Returns a
// defensive copy to avoid data races with concurrent Reload() calls.
func (r *MKVFSRoot) Files() map[string]*MKVFile <span class="cov0" title="0">{
        r.mu.RLock()
        defer r.mu.RUnlock()
        out := make(map[string]*MKVFile, len(r.files))
        for k, v := range r.files </span><span class="cov0" title="0">{
                out[k] = v
        }</span>
        <span class="cov0" title="0">return out</span>
}

// SetMounted marks the filesystem as mounted, enabling FUSE kernel
// notifications during config reload. Must be called after fs.Mount()
// succeeds.
func (r *MKVFSRoot) SetMounted() <span class="cov0" title="0">{
        r.mounted.Store(true)
}</span>

// emitReloadNotifications sends FUSE kernel notifications for files that
// were added or removed during a config reload.
func (r *MKVFSRoot) emitReloadNotifications(notifications []reloadNotification, changedDirs map[*fs.Inode]bool, logFn func(string, ...interface{})) <span class="cov7" title="20">{
        if len(notifications) == 0 || !r.mounted.Load() </span><span class="cov7" title="20">{
                return
        }</span>

        <span class="cov0" title="0">var deleted, invalidated int
        for _, n := range notifications </span><span class="cov0" title="0">{
                if n.isDelete </span><span class="cov0" title="0">{
                        if n.child != nil </span><span class="cov0" title="0">{
                                // NotifyDelete sends a real IN_DELETE inotify event
                                if errno := n.parent.NotifyDelete(n.name, n.child); errno == 0 </span><span class="cov0" title="0">{
                                        deleted++
                                }</span>
                        } else<span class="cov0" title="0"> {
                                // Child inode was never cached by kernel — just invalidate entry
                                if errno := n.parent.NotifyEntry(n.name); errno == 0 </span><span class="cov0" title="0">{
                                        invalidated++
                                }</span>
                        }
                } else<span class="cov0" title="0"> {
                        // NotifyEntry invalidates the kernel's dentry cache so the
                        // new file is visible on next lookup/readdir.
                        if errno := n.parent.NotifyEntry(n.name); errno == 0 </span><span class="cov0" title="0">{
                                invalidated++
                        }</span>
                }
        }

        // Invalidate readdir cache for all directories that had changes.
        // Skip uninitialized inodes (Ino==0) as a safety net — these should
        // not appear here after the findParentInode fix, but guard anyway.
        <span class="cov0" title="0">for dirInode := range changedDirs </span><span class="cov0" title="0">{
                if dirInode.StableAttr().Ino != 0 </span><span class="cov0" title="0">{
                        dirInode.NotifyContent(0, 0)
                }</span>
        }

        <span class="cov0" title="0">if deleted &gt; 0 || invalidated &gt; 0 </span><span class="cov0" title="0">{
                logFn("kernel notifications: %d deleted, %d invalidated, %d dirs", deleted, invalidated, len(changedDirs))
        }</span>
}

// collectValidPaths returns maps of all valid file and directory paths.
func (r *MKVFSRoot) collectValidPaths() (files, dirs map[string]bool) <span class="cov5" title="7">{
        files = make(map[string]bool)
        dirs = make(map[string]bool)

        if r.rootDir == nil </span><span class="cov0" title="0">{
                return files, dirs
        }</span>

        <span class="cov5" title="7">r.collectPathsRecursive(r.rootDir, files, dirs)
        return files, dirs</span>
}

func (r *MKVFSRoot) collectPathsRecursive(node *MKVFSDirNode, files, dirs map[string]bool) <span class="cov6" title="10">{
        node.mu.RLock()
        defer node.mu.RUnlock()

        // Add this directory (including root with empty path)
        dirs[node.path] = true

        // Add files
        for name := range node.files </span><span class="cov5" title="7">{
                var filePath string
                if node.path == "" </span><span class="cov4" title="4">{
                        filePath = name
                }</span> else<span class="cov3" title="3"> {
                        filePath = node.path + "/" + name
                }</span>
                <span class="cov5" title="7">files[filePath] = true</span>
        }

        // Recurse into subdirectories
        <span class="cov6" title="10">for _, subdir := range node.subdirs </span><span class="cov3" title="3">{
                r.collectPathsRecursive(subdir, files, dirs)
        }</span>
}

// Getattr implements fs.NodeGetattrer - returns attributes for the root directory.
// This ensures the root directory uses permissions from the permission store,
// consistent with all subdirectories.
func (r *MKVFSRoot) Getattr(ctx context.Context, fh fs.FileHandle, out *fuse.AttrOut) syscall.Errno <span class="cov10" title="56">{
        now := time.Now()

        uid, gid, mode := getDirPerms(r.permStore, "")

        out.Mode = fuse.S_IFDIR | mode
        out.Uid = uid
        out.Gid = gid
        out.Atime = uint64(now.Unix())
        out.Mtime = uint64(now.Unix())
        out.Ctime = uint64(now.Unix())
        out.Nlink = 2
        if r.rootDir != nil </span><span class="cov10" title="56">{
                r.rootDir.mu.RLock()
                out.Nlink += uint32(len(r.rootDir.subdirs))
                r.rootDir.mu.RUnlock()
        }</span>
        <span class="cov10" title="56">return 0</span>
}

// Readdir implements fs.NodeReaddirer - lists files in the root directory.
// Delegates to the directory tree for hierarchical listing.
func (r *MKVFSRoot) Readdir(ctx context.Context) (fs.DirStream, syscall.Errno) <span class="cov5" title="8">{
        // Permission checks are handled by the kernel via default_permissions mount option.
        // This properly checks supplementary groups and matches real filesystem behavior.

        if r.rootDir != nil </span><span class="cov5" title="6">{
                return r.rootDir.readdirInternal(ctx)
        }</span>

        // Fallback to flat listing if no directory tree (shouldn't happen)
        <span class="cov2" title="2">r.mu.RLock()
        defer r.mu.RUnlock()

        if r.verbose </span><span class="cov0" title="0">{
                log.Printf("Readdir: listing %d files (flat)", len(r.files))
        }</span>

        <span class="cov2" title="2">entries := make([]fuse.DirEntry, 0, len(r.files))
        for name := range r.files </span><span class="cov4" title="4">{
                if r.verbose </span><span class="cov0" title="0">{
                        log.Printf("Readdir: adding %s", name)
                }</span>
                <span class="cov4" title="4">entries = append(entries, fuse.DirEntry{
                        Name: name,
                        Mode: fuse.S_IFREG,
                })</span>
        }
        <span class="cov2" title="2">return fs.NewListDirStream(entries), 0</span>
}

// Lookup implements fs.NodeLookuper - looks up a file or directory by name.
// Uses the directory tree for hierarchical lookup.
func (r *MKVFSRoot) Lookup(ctx context.Context, name string, out *fuse.EntryOut) (*fs.Inode, syscall.Errno) <span class="cov8" title="29">{
        // Permission checks are handled by the kernel via default_permissions mount option.

        if r.rootDir != nil </span><span class="cov8" title="27">{
                r.rootDir.mu.RLock()
                defer r.rootDir.mu.RUnlock()

                // Check subdirectories first
                if subdir, ok := r.rootDir.subdirs[name]; ok </span><span class="cov6" title="12">{
                        if r.verbose </span><span class="cov0" title="0">{
                                log.Printf("Lookup: found subdir %s at root", name)
                        }</span>

                        // Lock subdir to safely access its fields
                        <span class="cov6" title="12">subdir.mu.RLock()
                        subdirCount := len(subdir.subdirs)
                        subdir.mu.RUnlock()

                        uid, gid, mode := getDirPerms(r.permStore, subdir.path)

                        now := time.Now()
                        out.Mode = fuse.S_IFDIR | mode
                        out.Uid = uid
                        out.Gid = gid
                        out.Atime = uint64(now.Unix())
                        out.Mtime = uint64(now.Unix())
                        out.Ctime = uint64(now.Unix())
                        out.Nlink = 2 + uint32(subdirCount)

                        stable := fs.StableAttr{
                                Mode: fuse.S_IFDIR,
                                Ino:  hashString(subdir.path),
                        }
                        child := r.NewPersistentInode(ctx, subdir, stable)
                        return child, 0</span>
                }

                // Check files
                <span class="cov7" title="15">if file, ok := r.rootDir.files[name]; ok </span><span class="cov7" title="15">{
                        if r.verbose </span><span class="cov0" title="0">{
                                log.Printf("Lookup: found file %s at root (size=%d)", name, file.Size)
                        }</span>

                        <span class="cov7" title="15">uid, gid, mode := getFilePerms(r.permStore, name)

                        now := time.Now()
                        out.Size = uint64(file.Size)
                        out.Mode = fuse.S_IFREG | mode
                        out.Uid = uid
                        out.Gid = gid
                        out.Atime = uint64(now.Unix())
                        out.Mtime = uint64(now.Unix())
                        out.Ctime = uint64(now.Unix())
                        out.Nlink = 1

                        node := &amp;MKVFSNode{file: file, path: name, verbose: r.verbose, permStore: r.permStore}
                        stable := fs.StableAttr{
                                Mode: fuse.S_IFREG,
                                Ino:  hashString(name),
                        }
                        child := r.NewInode(ctx, node, stable)
                        return child, 0</span>
                }

                <span class="cov0" title="0">if r.verbose </span><span class="cov0" title="0">{
                        log.Printf("Lookup: not found %s at root", name)
                }</span>
                <span class="cov0" title="0">return nil, syscall.ENOENT</span>
        }

        // Fallback to flat lookup if no directory tree (shouldn't happen)
        <span class="cov2" title="2">r.mu.RLock()
        file, ok := r.files[name]
        r.mu.RUnlock()

        if !ok </span><span class="cov2" title="2">{
                if r.verbose </span><span class="cov0" title="0">{
                        log.Printf("Lookup: file not found: %s", name)
                }</span>
                <span class="cov2" title="2">return nil, syscall.ENOENT</span>
        }

        <span class="cov0" title="0">if r.verbose </span><span class="cov0" title="0">{
                log.Printf("Lookup: %s (size=%d)", name, file.Size)
        }</span>

        <span class="cov0" title="0">uid, gid, mode := getFilePerms(r.permStore, name)

        // Create a new file node
        node := &amp;MKVFSNode{file: file, path: name, verbose: r.verbose, permStore: r.permStore}

        // Set attributes
        now := time.Now()
        out.Size = uint64(file.Size)
        out.Mode = fuse.S_IFREG | mode
        out.Uid = uid
        out.Gid = gid
        out.Atime = uint64(now.Unix())
        out.Mtime = uint64(now.Unix())
        out.Ctime = uint64(now.Unix())

        // Create inode with stable ID based on filename
        stable := fs.StableAttr{
                Mode: fuse.S_IFREG,
                Ino:  hashString(name),
        }

        child := r.NewInode(ctx, node, stable)
        return child, 0</span>
}
</pre>
		
		<pre class="file" id="file28" style="display: none">package fuse

import (
        "context"
        "fmt"
        "os/exec"
        "strings"
        "sync"
        "time"

        "al.essio.dev/pkg/shellescape"
        "github.com/stuckj/mkvdup/internal/dedup"
)

// ErrorEvent describes a source integrity issue detected by the watcher.
type ErrorEvent struct {
        SourcePath    string   // absolute path of the changed source file
        AffectedFiles []string // virtual file names affected
        Event         string   // "changed", "missing", "size_changed", "checksum_mismatch", "read_error", "checksum_queue_full"
}

// ErrorNotifier batches integrity error events and executes an external
// command with placeholder substitution. Events are collected for a
// configurable batch interval; when the interval expires, the command
// is executed once with all accumulated events.
type ErrorNotifier struct {
        config dedup.ErrorCommandConfig
        logFn  func(string, ...interface{})

        mu      sync.Mutex
        pending []ErrorEvent
        timer   *time.Timer
        stopped bool
}

// NewErrorNotifier creates a notifier from the given config.
func NewErrorNotifier(config dedup.ErrorCommandConfig, logFn func(string, ...interface{})) *ErrorNotifier <span class="cov7" title="14">{
        if logFn == nil </span><span class="cov0" title="0">{
                logFn = func(string, ...interface{}) </span>{<span class="cov0" title="0">}</span>
        }
        <span class="cov7" title="14">return &amp;ErrorNotifier{
                config: config,
                logFn:  logFn,
        }</span>
}

// Notify adds an error event to the batch. If this is the first event in
// the batch, a timer is started. Subsequent events reset the timer so that
// rapid bursts are coalesced into a single command execution.
func (n *ErrorNotifier) Notify(event ErrorEvent) <span class="cov8" title="16">{
        n.mu.Lock()
        defer n.mu.Unlock()

        if n.stopped </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="16">n.pending = append(n.pending, event)

        // Start or reset the debounce timer.
        if n.timer == nil </span><span class="cov7" title="14">{
                n.timer = time.AfterFunc(n.config.BatchInterval, n.flush)
        }</span> else<span class="cov2" title="2"> {
                n.timer.Reset(n.config.BatchInterval)
        }</span>
}

// Stop flushes any pending events and prevents future notifications.
func (n *ErrorNotifier) Stop() <span class="cov4" title="4">{
        n.mu.Lock()
        n.stopped = true
        if n.timer != nil </span><span class="cov2" title="2">{
                n.timer.Stop()
                n.timer = nil
        }</span>
        <span class="cov4" title="4">events := n.pending
        n.pending = nil
        n.mu.Unlock()

        if len(events) &gt; 0 </span><span class="cov2" title="2">{
                n.executeCommand(events)
        }</span>
}

// flush is called when the debounce timer fires.
func (n *ErrorNotifier) flush() <span class="cov7" title="12">{
        n.mu.Lock()
        if n.stopped </span><span class="cov0" title="0">{
                n.mu.Unlock()
                return
        }</span>
        <span class="cov7" title="12">events := n.pending
        n.pending = nil
        n.timer = nil
        n.mu.Unlock()

        if len(events) &gt; 0 </span><span class="cov7" title="12">{
                n.executeCommand(events)
        }</span>
}

// executeCommand runs the configured external command with placeholders
// substituted from the batched events. The command runs with a timeout
// and its output is logged on failure.
func (n *ErrorNotifier) executeCommand(events []ErrorEvent) <span class="cov7" title="14">{
        if len(n.config.Command.Args) == 0 </span><span class="cov0" title="0">{
                n.logFn("source-watch: on_error_command: no command configured, skipping")
                return
        }</span>

        <span class="cov7" title="14">ctx, cancel := context.WithTimeout(context.Background(), n.config.Timeout)
        defer cancel()

        var cmd *exec.Cmd
        if n.config.Command.IsShell </span><span class="cov7" title="12">{
                // String form: run via sh -c with shell-escaped placeholder values
                cmdStr := substitutePlaceholders(n.config.Command.Args[0], events, true)
                cmd = exec.CommandContext(ctx, "sh", "-c", cmdStr)
        }</span> else<span class="cov2" title="2"> {
                // List form: substitute placeholders in each argument (no escaping needed)
                args := make([]string, len(n.config.Command.Args))
                for i, arg := range n.config.Command.Args </span><span class="cov5" title="6">{
                        args[i] = substitutePlaceholders(arg, events, false)
                }</span>
                <span class="cov2" title="2">cmd = exec.CommandContext(ctx, args[0], args[1:]...)</span>
        }

        <span class="cov7" title="14">output, err := cmd.CombinedOutput()
        if err != nil </span><span class="cov1" title="1">{
                n.logFn("source-watch: on_error_command failed: %v (output: %s)", err, strings.TrimSpace(string(output)))
        }</span>
}

// substitutePlaceholders replaces %source%, %files%, and %event% in s
// with values derived from the batched events. When shellEscape is true,
// placeholder values are shell-escaped for safe use in sh -c commands.
func substitutePlaceholders(s string, events []ErrorEvent, shellEscape bool) string <span class="cov9" title="26">{
        // Build source list (newline-separated, deduplicated)
        sourceSet := make(map[string]bool)
        var sources []string
        for _, e := range events </span><span class="cov9" title="30">{
                if !sourceSet[e.SourcePath] </span><span class="cov9" title="30">{
                        sourceSet[e.SourcePath] = true
                        sources = append(sources, e.SourcePath)
                }</span>
        }

        // Build file list (comma-separated, deduplicated)
        <span class="cov9" title="26">fileSet := make(map[string]bool)
        var files []string
        for _, e := range events </span><span class="cov9" title="30">{
                for _, f := range e.AffectedFiles </span><span class="cov10" title="34">{
                        if !fileSet[f] </span><span class="cov9" title="32">{
                                fileSet[f] = true
                                files = append(files, f)
                        }</span>
                }
        }

        // Build event list
        <span class="cov9" title="26">var eventStrs []string
        if len(events) == 1 </span><span class="cov8" title="22">{
                eventStrs = append(eventStrs, events[0].Event)
        }</span> else<span class="cov4" title="4"> {
                for _, e := range events </span><span class="cov6" title="8">{
                        eventStrs = append(eventStrs, fmt.Sprintf("%s: %s", e.SourcePath, e.Event))
                }</span>
        }

        <span class="cov9" title="26">sourceVal := strings.Join(sources, "\n")
        filesVal := strings.Join(files, ", ")
        eventVal := strings.Join(eventStrs, "\n")

        if shellEscape </span><span class="cov8" title="16">{
                sourceVal = shellescape.Quote(sourceVal)
                filesVal = shellescape.Quote(filesVal)
                eventVal = shellescape.Quote(eventVal)
        }</span>

        <span class="cov9" title="26">s = strings.ReplaceAll(s, "%source%", sourceVal)
        s = strings.ReplaceAll(s, "%files%", filesVal)
        s = strings.ReplaceAll(s, "%event%", eventVal)
        return s</span>
}
</pre>
		
		<pre class="file" id="file29" style="display: none">// Package fuse provides a FUSE filesystem for accessing deduplicated MKV files.
package fuse

import (
        "context"
        "fmt"
        "log"
        "os"
        "os/user"
        "path/filepath"
        "strconv"
        "sync"
        "syscall"

        "github.com/hanwen/go-fuse/v2/fuse"
        "gopkg.in/yaml.v3"
)

// Perms holds uid, gid, and mode for a file or directory.
// Nil values indicate the field should inherit from defaults.
type Perms struct {
        UID  *uint32 `yaml:"uid,omitempty"`
        GID  *uint32 `yaml:"gid,omitempty"`
        Mode *uint32 `yaml:"mode,omitempty"`
}

// Defaults holds default permissions for files and directories.
type Defaults struct {
        FileUID  uint32 `yaml:"file_uid"`
        FileGID  uint32 `yaml:"file_gid"`
        FileMode uint32 `yaml:"file_mode"`
        DirUID   uint32 `yaml:"dir_uid"`
        DirGID   uint32 `yaml:"dir_gid"`
        DirMode  uint32 `yaml:"dir_mode"`
}

// DefaultPerms returns the default permission values.
func DefaultPerms() Defaults <span class="cov7" title="59">{
        return Defaults{
                FileUID:  0,
                FileGID:  0,
                FileMode: 0444,
                DirUID:   0,
                DirGID:   0,
                DirMode:  0555,
        }
}</span>

// permissionsFile is the structure of the permissions YAML file.
type permissionsFile struct {
        Defaults    Defaults          `yaml:"defaults"`
        Files       map[string]*Perms `yaml:"files,omitempty"`
        Directories map[string]*Perms `yaml:"directories,omitempty"`
}

// PermissionStore manages file/directory permissions with persistence.
type PermissionStore struct {
        path     string
        defaults Defaults
        files    map[string]*Perms
        dirs     map[string]*Perms
        mu       sync.RWMutex
        verbose  bool
}

// NewPermissionStore creates a new permission store.
// If path is empty, permissions will not be persisted.
func NewPermissionStore(path string, defaults Defaults, verbose bool) *PermissionStore <span class="cov7" title="75">{
        return &amp;PermissionStore{
                path:     path,
                defaults: defaults,
                files:    make(map[string]*Perms),
                dirs:     make(map[string]*Perms),
                verbose:  verbose,
        }
}</span>

// Load loads permissions from the file.
// If the file doesn't exist, the store remains empty (using defaults).
func (s *PermissionStore) Load() error <span class="cov4" title="9">{
        if s.path == "" </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov4" title="9">data, err := os.ReadFile(s.path)
        if err != nil </span><span class="cov4" title="7">{
                if os.IsNotExist(err) </span><span class="cov4" title="7">{
                        if s.verbose </span><span class="cov0" title="0">{
                                log.Printf("Permissions file %s does not exist, using defaults", s.path)
                        }</span>
                        <span class="cov4" title="7">return nil</span>
                }
                <span class="cov0" title="0">return fmt.Errorf("read permissions file: %w", err)</span>
        }

        <span class="cov2" title="2">var pf permissionsFile
        if err := yaml.Unmarshal(data, &amp;pf); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse permissions file: %w", err)
        }</span>

        <span class="cov2" title="2">s.mu.Lock()
        defer s.mu.Unlock()

        // Override defaults if specified in file
        if pf.Defaults.FileMode != 0 || pf.Defaults.FileUID != 0 || pf.Defaults.FileGID != 0 ||
                pf.Defaults.DirMode != 0 || pf.Defaults.DirUID != 0 || pf.Defaults.DirGID != 0 </span><span class="cov2" title="2">{
                // Only override non-zero values from file
                if pf.Defaults.FileMode != 0 </span><span class="cov2" title="2">{
                        s.defaults.FileMode = pf.Defaults.FileMode
                }</span>
                <span class="cov2" title="2">if pf.Defaults.FileUID != 0 </span><span class="cov0" title="0">{
                        s.defaults.FileUID = pf.Defaults.FileUID
                }</span>
                <span class="cov2" title="2">if pf.Defaults.FileGID != 0 </span><span class="cov0" title="0">{
                        s.defaults.FileGID = pf.Defaults.FileGID
                }</span>
                <span class="cov2" title="2">if pf.Defaults.DirMode != 0 </span><span class="cov2" title="2">{
                        s.defaults.DirMode = pf.Defaults.DirMode
                }</span>
                <span class="cov2" title="2">if pf.Defaults.DirUID != 0 </span><span class="cov0" title="0">{
                        s.defaults.DirUID = pf.Defaults.DirUID
                }</span>
                <span class="cov2" title="2">if pf.Defaults.DirGID != 0 </span><span class="cov0" title="0">{
                        s.defaults.DirGID = pf.Defaults.DirGID
                }</span>
        }

        <span class="cov2" title="2">if pf.Files != nil </span><span class="cov2" title="2">{
                s.files = pf.Files
        }</span>
        <span class="cov2" title="2">if pf.Directories != nil </span><span class="cov2" title="2">{
                s.dirs = pf.Directories
        }</span>

        <span class="cov2" title="2">if s.verbose </span><span class="cov0" title="0">{
                log.Printf("Loaded permissions: %d files, %d directories", len(s.files), len(s.dirs))
        }</span>

        <span class="cov2" title="2">return nil</span>
}

// Save saves permissions to the file.
func (s *PermissionStore) Save() error <span class="cov9" title="277">{
        if s.path == "" </span><span class="cov9" title="264">{
                return nil
        }</span>

        <span class="cov5" title="13">s.mu.RLock()
        // Deep copy the maps to avoid data races during marshalling.
        // We copy both the map and the Perms values to ensure complete isolation.
        pf := permissionsFile{
                Defaults: s.defaults,
        }
        if s.files != nil </span><span class="cov5" title="13">{
                pf.Files = make(map[string]*Perms, len(s.files))
                for k, v := range s.files </span><span class="cov4" title="10">{
                        if v != nil </span><span class="cov4" title="10">{
                                permsCopy := *v // copy the Perms struct
                                pf.Files[k] = &amp;permsCopy
                        }</span>
                }
        }
        <span class="cov5" title="13">if s.dirs != nil </span><span class="cov5" title="13">{
                pf.Directories = make(map[string]*Perms, len(s.dirs))
                for k, v := range s.dirs </span><span class="cov3" title="5">{
                        if v != nil </span><span class="cov3" title="5">{
                                permsCopy := *v // copy the Perms struct
                                pf.Directories[k] = &amp;permsCopy
                        }</span>
                }
        }
        <span class="cov5" title="13">s.mu.RUnlock()

        // Create parent directory if needed
        dir := filepath.Dir(s.path)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create permissions directory: %w", err)
        }</span>

        <span class="cov5" title="13">data, err := yaml.Marshal(&amp;pf)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("marshal permissions: %w", err)
        }</span>

        <span class="cov5" title="13">if err := os.WriteFile(s.path, data, 0644); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("write permissions file: %w", err)
        }</span>

        <span class="cov5" title="13">if s.verbose </span><span class="cov0" title="0">{
                log.Printf("Saved permissions to %s", s.path)
        }</span>

        <span class="cov5" title="13">return nil</span>
}

// GetFilePerms returns the effective permissions for a file.
// Returns uid, gid, mode with defaults applied for any unset values.
func (s *PermissionStore) GetFilePerms(path string) (uid, gid, mode uint32) <span class="cov10" title="289">{
        s.mu.RLock()
        defer s.mu.RUnlock()

        uid = s.defaults.FileUID
        gid = s.defaults.FileGID
        mode = s.defaults.FileMode

        if p, ok := s.files[path]; ok </span><span class="cov9" title="262">{
                if p.UID != nil </span><span class="cov9" title="253">{
                        uid = *p.UID
                }</span>
                <span class="cov9" title="262">if p.GID != nil </span><span class="cov5" title="21">{
                        gid = *p.GID
                }</span>
                <span class="cov9" title="262">if p.Mode != nil </span><span class="cov5" title="19">{
                        mode = *p.Mode
                }</span>
        }

        <span class="cov10" title="289">return uid, gid, mode</span>
}

// GetDirPerms returns the effective permissions for a directory.
// Returns uid, gid, mode with defaults applied for any unset values.
func (s *PermissionStore) GetDirPerms(path string) (uid, gid, mode uint32) <span class="cov7" title="67">{
        s.mu.RLock()
        defer s.mu.RUnlock()

        uid = s.defaults.DirUID
        gid = s.defaults.DirGID
        mode = s.defaults.DirMode

        if p, ok := s.dirs[path]; ok </span><span class="cov6" title="29">{
                if p.UID != nil </span><span class="cov5" title="16">{
                        uid = *p.UID
                }</span>
                <span class="cov6" title="29">if p.GID != nil </span><span class="cov4" title="8">{
                        gid = *p.GID
                }</span>
                <span class="cov6" title="29">if p.Mode != nil </span><span class="cov5" title="13">{
                        mode = *p.Mode
                }</span>
        }

        <span class="cov7" title="67">return uid, gid, mode</span>
}

// SetFilePerms sets permissions for a file.
// Only non-nil values are updated; nil values leave existing values unchanged.
// Automatically saves to disk.
func (s *PermissionStore) SetFilePerms(path string, uid, gid *uint32, mode *uint32) error <span class="cov9" title="252">{
        s.mu.Lock()

        // If all values are nil, nothing to do
        if uid == nil &amp;&amp; gid == nil &amp;&amp; mode == nil </span><span class="cov0" title="0">{
                s.mu.Unlock()
                return nil
        }</span>

        <span class="cov9" title="252">p, ok := s.files[path]
        if !ok </span><span class="cov7" title="44">{
                p = &amp;Perms{}
                s.files[path] = p
        }</span>

        // Only update non-nil values; copy values so the store owns their lifetime.
        <span class="cov9" title="252">if uid != nil </span><span class="cov9" title="239">{
                v := *uid
                p.UID = &amp;v
        }</span>
        <span class="cov9" title="252">if gid != nil </span><span class="cov5" title="13">{
                v := *gid
                p.GID = &amp;v
        }</span>
        <span class="cov9" title="252">if mode != nil </span><span class="cov5" title="15">{
                v := *mode
                p.Mode = &amp;v
        }</span>

        <span class="cov9" title="252">s.mu.Unlock()

        if s.verbose </span><span class="cov0" title="0">{
                log.Printf("SetFilePerms: %s uid=%v gid=%v mode=%v", path, uid, gid, mode)
        }</span>

        <span class="cov9" title="252">return s.Save()</span>
}

// RemoveFilePerms removes all permission overrides for a file.
// The file will use default permissions. Automatically saves to disk.
func (s *PermissionStore) RemoveFilePerms(path string) error <span class="cov2" title="2">{
        s.mu.Lock()
        delete(s.files, path)
        s.mu.Unlock()

        if s.verbose </span><span class="cov0" title="0">{
                log.Printf("RemoveFilePerms: %s", path)
        }</span>

        <span class="cov2" title="2">return s.Save()</span>
}

// SetDirPerms sets permissions for a directory.
// Only non-nil values are updated; nil values leave existing values unchanged.
// Automatically saves to disk.
func (s *PermissionStore) SetDirPerms(path string, uid, gid *uint32, mode *uint32) error <span class="cov5" title="23">{
        s.mu.Lock()

        // If all values are nil, nothing to do
        if uid == nil &amp;&amp; gid == nil &amp;&amp; mode == nil </span><span class="cov0" title="0">{
                s.mu.Unlock()
                return nil
        }</span>

        <span class="cov5" title="23">p, ok := s.dirs[path]
        if !ok </span><span class="cov5" title="21">{
                p = &amp;Perms{}
                s.dirs[path] = p
        }</span>

        // Only update non-nil values; copy values so the store owns their lifetime.
        <span class="cov5" title="23">if uid != nil </span><span class="cov5" title="14">{
                v := *uid
                p.UID = &amp;v
        }</span>
        <span class="cov5" title="23">if gid != nil </span><span class="cov3" title="4">{
                v := *gid
                p.GID = &amp;v
        }</span>
        <span class="cov5" title="23">if mode != nil </span><span class="cov4" title="9">{
                v := *mode
                p.Mode = &amp;v
        }</span>

        <span class="cov5" title="23">s.mu.Unlock()

        if s.verbose </span><span class="cov0" title="0">{
                log.Printf("SetDirPerms: %s uid=%v gid=%v mode=%v", path, uid, gid, mode)
        }</span>

        <span class="cov5" title="23">return s.Save()</span>
}

// RemoveDirPerms removes all permission overrides for a directory.
// The directory will use default permissions. Automatically saves to disk.
func (s *PermissionStore) RemoveDirPerms(path string) error <span class="cov0" title="0">{
        s.mu.Lock()
        delete(s.dirs, path)
        s.mu.Unlock()

        if s.verbose </span><span class="cov0" title="0">{
                log.Printf("RemoveDirPerms: %s", path)
        }</span>

        <span class="cov0" title="0">return s.Save()</span>
}

// CleanupStale removes entries for paths that don't exist in the mounted filesystem.
// validFiles and validDirs are maps of valid paths (value is ignored, just checking keys).
// Returns the number of stale entries removed.
func (s *PermissionStore) CleanupStale(validFiles, validDirs map[string]bool) int <span class="cov4" title="9">{
        s.mu.Lock()
        defer s.mu.Unlock()

        removed := 0

        // Clean up stale file entries
        for path := range s.files </span><span class="cov3" title="4">{
                if !validFiles[path] </span><span class="cov2" title="2">{
                        delete(s.files, path)
                        removed++
                        if s.verbose </span><span class="cov0" title="0">{
                                log.Printf("Removed stale file permission entry: %s", path)
                        }</span>
                }
        }

        // Clean up stale directory entries
        <span class="cov4" title="9">for path := range s.dirs </span><span class="cov3" title="4">{
                if !validDirs[path] </span><span class="cov2" title="2">{
                        delete(s.dirs, path)
                        removed++
                        if s.verbose </span><span class="cov0" title="0">{
                                log.Printf("Removed stale directory permission entry: %s", path)
                        }</span>
                }
        }

        <span class="cov4" title="9">return removed</span>
}

// Defaults returns the current default permissions.
func (s *PermissionStore) Defaults() Defaults <span class="cov2" title="2">{
        s.mu.RLock()
        defer s.mu.RUnlock()
        return s.defaults
}</span>

// ResolvePermissionsPath determines which permissions file to use.
// Priority:
//  1. explicitPath (from --permissions-file flag)
//  2. ~/.config/mkvdup/permissions.yaml (if exists) - for both root and non-root
//  3. /etc/mkvdup/permissions.yaml (if exists AND running as root)
//  4. Default based on euid: root uses /etc/, non-root uses ~/.config/
//
// Non-root users always get a user-writable path (unless explicitly overridden)
// to avoid EACCES errors when saving permission changes.
func ResolvePermissionsPath(explicitPath string) string <span class="cov3" title="4">{
        if explicitPath != "" </span><span class="cov2" title="2">{
                return explicitPath
        }</span>

        <span class="cov2" title="2">home, err := os.UserHomeDir()
        userPath := ""
        if err == nil </span><span class="cov2" title="2">{
                userPath = filepath.Join(home, ".config", "mkvdup", "permissions.yaml")
        }</span>

        // Check user config - takes priority for both root and non-root
        <span class="cov2" title="2">if userPath != "" </span><span class="cov2" title="2">{
                if _, err := os.Stat(userPath); err == nil </span><span class="cov0" title="0">{
                        return userPath
                }</span>
        }

        <span class="cov2" title="2">systemPath := "/etc/mkvdup/permissions.yaml"

        // For root: check system config, then default to system path
        if os.Geteuid() == 0 </span><span class="cov1" title="1">{
                if _, err := os.Stat(systemPath); err == nil </span><span class="cov0" title="0">{
                        return systemPath
                }</span>
                <span class="cov1" title="1">return systemPath</span>
        }

        // For non-root: always use user path to ensure writability.
        // Do NOT use system path even if it exists, as non-root users
        // typically cannot write to /etc/ and chmod/chown operations
        // would fail with EACCES.
        <span class="cov1" title="1">if userPath != "" </span><span class="cov1" title="1">{
                return userPath
        }</span>

        // Fallback if no home directory (unusual for non-root)
        <span class="cov0" title="0">return systemPath</span>
}

// CallerInfo represents the calling process's credentials.
type CallerInfo struct {
        Uid uint32
        Gid uint32
}

// testCallerHook is set by test code to allow injecting caller credentials.
// This is nil in production, ensuring only real FUSE contexts are trusted.
var testCallerHook func(context.Context) (CallerInfo, bool)

// GetCaller extracts caller credentials from the FUSE context.
// Returns (caller, true) if credentials are available, (zero, false) otherwise.
// Callers should deny access when ok is false to fail closed.
func GetCaller(ctx context.Context) (CallerInfo, bool) <span class="cov7" title="45">{
        if caller, ok := fuse.FromContext(ctx); ok </span><span class="cov2" title="3">{
                return CallerInfo{Uid: caller.Uid, Gid: caller.Gid}, true
        }</span>
        // Check for test-injected caller (only available in tests)
        <span class="cov6" title="42">if testCallerHook != nil </span><span class="cov6" title="42">{
                if caller, ok := testCallerHook(ctx); ok </span><span class="cov6" title="38">{
                        return caller, true
                }</span>
        }
        // Fail closed: return zero value and false to indicate no credentials
        <span class="cov3" title="4">return CallerInfo{}, false</span>
}

// IsRoot returns true if the caller is root (uid 0).
func (c CallerInfo) IsRoot() bool <span class="cov7" title="82">{
        return c.Uid == 0
}</span>

// CheckChown verifies the caller can change file ownership.
// Returns 0 if allowed, syscall.EPERM if denied.
// Only root can change UID. Only root or file owner can change GID.
// Non-root owners can change GID to any group they are a member of
// (primary or supplementary). No-op changes (newUID == fileUID or
// newGID == fileGID) are always allowed.
func CheckChown(caller CallerInfo, fileUID, fileGID uint32, newUID, newGID *uint32) syscall.Errno <span class="cov7" title="51">{
        // Only root can change UID to a different user
        if newUID != nil &amp;&amp; *newUID != fileUID &amp;&amp; !caller.IsRoot() </span><span class="cov4" title="10">{
                return syscall.EPERM
        }</span>

        // GID changes:
        // - No-op (nil or same as current) is always allowed
        // - Root can change to any GID
        // - Non-root owner can change to any group they belong to
        <span class="cov6" title="41">if newGID != nil &amp;&amp; *newGID != fileGID </span><span class="cov6" title="29">{
                if caller.IsRoot() </span><span class="cov4" title="11">{
                        return 0
                }</span>
                // Non-root: must be owner AND must be a member of target group
                <span class="cov5" title="18">if caller.Uid != fileUID || !isGroupMember(caller.Uid, caller.Gid, *newGID) </span><span class="cov4" title="8">{
                        return syscall.EPERM
                }</span>
        }

        <span class="cov5" title="22">return 0</span>
}

// groupMembershipFunc is the function used to check group membership.
// It can be overridden in tests to avoid OS-level lookups.
var groupMembershipFunc = defaultGroupMembership

// isGroupMember checks if a user is a member of the given group.
// This checks the primary GID and supplementary groups.
func isGroupMember(uid, primaryGID, targetGID uint32) bool <span class="cov5" title="14">{
        return groupMembershipFunc(uid, primaryGID, targetGID)
}</span>

// defaultGroupMembership checks group membership by looking up the user's
// groups from the OS.
func defaultGroupMembership(uid, primaryGID, targetGID uint32) bool <span class="cov0" title="0">{
        // Primary GID is always a member
        if targetGID == primaryGID </span><span class="cov0" title="0">{
                return true
        }</span>

        // Look up supplementary groups from the OS
        <span class="cov0" title="0">u, err := user.LookupId(strconv.FormatUint(uint64(uid), 10))
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">groupIDs, err := u.GroupIds()
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">targetStr := strconv.FormatUint(uint64(targetGID), 10)
        for _, gid := range groupIDs </span><span class="cov0" title="0">{
                if gid == targetStr </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// CheckChmod verifies the caller can change file mode.
// Returns 0 if allowed, syscall.EPERM if denied.
// Only root or file owner can chmod.
func CheckChmod(caller CallerInfo, fileUID uint32) syscall.Errno <span class="cov5" title="22">{
        if caller.IsRoot() || caller.Uid == fileUID </span><span class="cov5" title="14">{
                return 0
        }</span>
        <span class="cov4" title="8">return syscall.EPERM</span>
}
</pre>
		
		<pre class="file" id="file30" style="display: none">package fuse

import (
        "log"
        "path"
        "strings"
)

// BuildDirectoryTree creates a directory tree from files with path-containing names.
// Directories are auto-created for each path component.
// Files with names like "Movies/Action/film.mkv" will create the directory hierarchy.
//
// Path handling:
//   - Leading slashes are stripped (absolute paths become relative)
//   - Paths are cleaned (e.g., "foo//bar" becomes "foo/bar")
//   - Only forward slashes (/) are treated as path separators
//   - Paths containing ".." components are rejected
//   - Empty filenames are rejected
//
// Conflicts:
//   - Duplicate paths: later file wins, warning logged
//   - File/directory collision: directory wins, file skipped with warning
func BuildDirectoryTree(files []*MKVFile, verbose bool, readerFactory ReaderFactory, permStore *PermissionStore) *MKVFSDirNode <span class="cov4" title="94">{
        root := &amp;MKVFSDirNode{
                name:          "",
                path:          "",
                files:         make(map[string]*MKVFile),
                subdirs:       make(map[string]*MKVFSDirNode),
                verbose:       verbose,
                readerFactory: readerFactory,
                permStore:     permStore,
        }

        for _, file := range files </span><span class="cov9" title="20132">{
                insertFile(root, file, verbose, readerFactory, permStore)
        }</span>

        <span class="cov4" title="94">return root</span>
}

// insertFile inserts a file into the directory tree, creating directories as needed.
func insertFile(root *MKVFSDirNode, file *MKVFile, verbose bool, readerFactory ReaderFactory, permStore *PermissionStore) <span class="cov9" title="20132">{
        // Validate: reject paths with ".." components (security)
        if strings.Contains(file.Name, "..") </span><span class="cov1" title="2">{
                log.Printf("Warning: skipping file with invalid path (contains '..'): %s", file.Name)
                return
        }</span>

        // Clean and split the path
        <span class="cov9" title="20130">cleanPath := path.Clean(file.Name)
        parts := strings.Split(cleanPath, "/")

        // Filter out empty parts (handles leading slashes and multiple slashes)
        validParts := make([]string, 0, len(parts))
        for _, p := range parts </span><span class="cov10" title="60206">{
                if p != "" &amp;&amp; p != "." </span><span class="cov9" title="60202">{
                        validParts = append(validParts, p)
                }</span>
        }

        // Validate: reject empty filenames
        <span class="cov9" title="20130">if len(validParts) == 0 </span><span class="cov1" title="2">{
                log.Printf("Warning: skipping file with empty name: %q", file.Name)
                return
        }</span>

        <span class="cov9" title="20128">fileName := validParts[len(validParts)-1]
        if fileName == "" </span><span class="cov0" title="0">{
                log.Printf("Warning: skipping file with empty filename: %q", file.Name)
                return
        }</span>

        // Navigate/create directories for each path component except the last (filename)
        <span class="cov9" title="20128">current := root
        for i := 0; i &lt; len(validParts)-1; i++ </span><span class="cov9" title="40072">{
                dirName := validParts[i]

                current.mu.Lock()
                // Check for file/directory collision: if a file exists with this name, skip
                if _, fileExists := current.files[dirName]; fileExists </span><span class="cov1" title="2">{
                        log.Printf("Warning: path component %q conflicts with existing file, skipping: %s", dirName, file.Name)
                        current.mu.Unlock()
                        return
                }</span>

                <span class="cov9" title="40070">subdir, exists := current.subdirs[dirName]
                if !exists </span><span class="cov7" title="2081">{
                        // Create new directory node
                        var newPath string
                        if current.path == "" </span><span class="cov4" title="52">{
                                newPath = dirName
                        }</span> else<span class="cov7" title="2029"> {
                                newPath = current.path + "/" + dirName
                        }</span>
                        <span class="cov7" title="2081">subdir = &amp;MKVFSDirNode{
                                name:          dirName,
                                path:          newPath,
                                files:         make(map[string]*MKVFile),
                                subdirs:       make(map[string]*MKVFSDirNode),
                                verbose:       verbose,
                                readerFactory: readerFactory,
                                permStore:     permStore,
                        }
                        current.subdirs[dirName] = subdir</span>
                }
                <span class="cov9" title="40070">current.mu.Unlock()
                current = subdir</span>
        }

        // Insert the file into the final directory
        <span class="cov9" title="20126">current.mu.Lock()
        defer current.mu.Unlock()

        // Check for file/directory collision: if a directory exists with this name, skip the file
        if _, dirExists := current.subdirs[fileName]; dirExists </span><span class="cov1" title="2">{
                log.Printf("Warning: file %q conflicts with existing directory, skipping", file.Name)
                return
        }</span>

        // Check for duplicate: warn if overwriting
        <span class="cov9" title="20124">if existing, exists := current.files[fileName]; exists </span><span class="cov1" title="2">{
                log.Printf("Warning: duplicate path %q, replacing %s with %s", file.Name, existing.DedupPath, file.DedupPath)
        }</span>

        <span class="cov9" title="20124">current.files[fileName] = file</span>
}

// mergeDirectoryTree merges newTree's contents into existing's maps in place.
// This is necessary because go-fuse caches persistent inode objects by inode
// number — swapping the root directory won't affect already-cached inodes.
// Instead, we update existing MKVFSDirNode objects' files and subdirs maps
// so cached inodes see the new data.
func mergeDirectoryTree(existing, newTree *MKVFSDirNode) <span class="cov3" title="32">{
        existing.mu.Lock()
        defer existing.mu.Unlock()

        // Remove files that are no longer present
        for name := range existing.files </span><span class="cov3" title="28">{
                if _, inNew := newTree.files[name]; !inNew </span><span class="cov2" title="10">{
                        delete(existing.files, name)
                }</span>
        }

        // Add or update files (update in place to preserve pointer identity for cached inodes)
        <span class="cov3" title="32">for name, newFile := range newTree.files </span><span class="cov3" title="26">{
                if existingFile, ok := existing.files[name]; ok </span><span class="cov3" title="18">{
                        existingFile.mu.Lock()
                        existingFile.updateFrom(newFile)
                        existingFile.mu.Unlock()
                }</span> else<span class="cov2" title="8"> {
                        existing.files[name] = newFile
                }</span>
        }

        // Remove subdirectories that are no longer present
        <span class="cov3" title="32">for name := range existing.subdirs </span><span class="cov2" title="8">{
                if _, inNew := newTree.subdirs[name]; !inNew </span><span class="cov2" title="6">{
                        delete(existing.subdirs, name)
                }</span>
        }

        // Add or recursively merge subdirectories
        <span class="cov3" title="32">for name, newSubdir := range newTree.subdirs </span><span class="cov2" title="10">{
                existingSubdir, exists := existing.subdirs[name]
                if !exists </span><span class="cov2" title="8">{
                        existing.subdirs[name] = newSubdir
                }</span> else<span class="cov1" title="2"> {
                        mergeDirectoryTree(existingSubdir, newSubdir)
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file31" style="display: none">package fuse

import (
        "fmt"
        "io"
        "os"
        "path/filepath"
        "strings"
        "sync"
        "time"

        "github.com/cespare/xxhash/v2"
        "github.com/fsnotify/fsnotify"
        "github.com/stuckj/mkvdup/internal/dedup"
)

// Default poll interval for network filesystems where inotify doesn't work.
const defaultPollInterval = 60 * time.Second

// checksumRequest is a queued checksum verification job.
type checksumRequest struct {
        absPath          string
        expectedChecksum uint64
        expectedSize     int64
        affected         []*MKVFile
        gen              uint64 // generation stamp; stale requests are skipped
}

// SourceWatcher monitors source files for changes and takes action when
// modifications are detected. It uses inotify for local filesystems and
// falls back to polling for network filesystems (NFS, CIFS/SMB).
type SourceWatcher struct {
        watcher *fsnotify.Watcher

        // reverse maps absolute source file paths to the virtual files that use them.
        reverse map[string][]*MKVFile

        // checksums maps absolute source file paths to expected xxhash values.
        checksums map[string]uint64

        // sizes maps absolute source file paths to expected file sizes.
        sizes map[string]int64

        // pollFiles maps absolute source file paths to their last known mtime
        // for directories that use polling instead of inotify.
        pollFiles map[string]time.Time

        action string // "warn", "disable", "checksum"
        logFn  func(string, ...interface{})
        mu     sync.RWMutex

        // checksumCh queues checksum verification requests so they run
        // sequentially in a single worker goroutine, avoiding I/O storms
        // when many source files change at once.
        checksumCh chan checksumRequest

        // checksumPending tracks source paths with a queued checksum request,
        // preventing duplicate queue entries for the same file. The worker
        // clears the flag when it starts processing, so new events that arrive
        // during verification are still queued.
        checksumPending map[string]bool

        // updateGen is incremented on each Update() call. Checksum requests
        // carry the generation they were created in; the worker skips requests
        // whose generation doesn't match, preventing stale verifications from
        // a previous config from disabling files after a reload.
        updateGen uint64

        pollInterval time.Duration // interval for network FS polling (0 = defaultPollInterval)

        notifier *ErrorNotifier // optional external command notifier

        stopCh chan struct{}
        wg     sync.WaitGroup
}

// NewSourceWatcher creates a new source file watcher with the given action.
// If pollInterval &lt;= 0, defaultPollInterval is used.
// If onErrorCommand is non-nil, an ErrorNotifier is created to execute the
// configured command when integrity issues are detected.
// The watcher is not started until Start() is called.
func NewSourceWatcher(action string, pollInterval time.Duration, onErrorCommand *dedup.ErrorCommandConfig, logFn func(string, ...interface{})) (*SourceWatcher, error) <span class="cov10" title="18">{
        watcher, err := fsnotify.NewWatcher()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("create fsnotify watcher: %w", err)
        }</span>

        <span class="cov10" title="18">if logFn == nil </span><span class="cov0" title="0">{
                logFn = func(string, ...interface{}) </span>{<span class="cov0" title="0">}</span>
        }

        <span class="cov10" title="18">if pollInterval &lt;= 0 </span><span class="cov10" title="18">{
                pollInterval = defaultPollInterval
        }</span>

        <span class="cov10" title="18">var notifier *ErrorNotifier
        if onErrorCommand != nil </span><span class="cov3" title="2">{
                notifier = NewErrorNotifier(*onErrorCommand, logFn)
        }</span>

        <span class="cov10" title="18">return &amp;SourceWatcher{
                watcher:         watcher,
                reverse:         make(map[string][]*MKVFile),
                checksums:       make(map[string]uint64),
                sizes:           make(map[string]int64),
                pollFiles:       make(map[string]time.Time),
                action:          action,
                logFn:           logFn,
                checksumCh:      make(chan checksumRequest, 256),
                checksumPending: make(map[string]bool),
                pollInterval:    pollInterval,
                notifier:        notifier,
                stopCh:          make(chan struct{}),
        }, nil</span>
}

// Update rebuilds the watcher's source file mappings from the current file set.
// It removes old watches and sets up new ones. Called on mount and after reload.
//
// For each MKVFile, the readerFactory is used to read the dedup file header
// (lazy read, no full initialization) to get the source file list.
//
// The method minimizes lock hold time: maps are built without the lock,
// swapped in briefly under the lock, and then inotify watches and os.Stat
// calls happen without the lock.
func (sw *SourceWatcher) Update(files map[string]*MKVFile, readerFactory ReaderFactory) <span class="cov3" title="2">{
        // Phase 1: Build new maps without holding the lock. This involves
        // I/O (reading dedup headers) that should not block event handling.
        newReverse := make(map[string][]*MKVFile)
        newChecksums := make(map[string]uint64)
        newSizes := make(map[string]int64)
        watchDirs := make(map[string]bool)

        for _, file := range files </span><span class="cov5" title="4">{
                reader, err := readerFactory.NewReaderLazy(file.DedupPath, file.SourceDir)
                if err != nil </span><span class="cov0" title="0">{
                        sw.logFn("source-watch: warning: cannot read dedup header for %s: %v", file.Name, err)
                        continue</span>
                }
                <span class="cov5" title="4">sourceFiles := reader.SourceFileInfo()
                reader.Close()

                cleanSourceDir := filepath.Clean(file.SourceDir)
                if cleanSourceDir[len(cleanSourceDir)-1] != filepath.Separator </span><span class="cov5" title="4">{
                        cleanSourceDir += string(filepath.Separator)
                }</span>
                <span class="cov5" title="4">for _, sf := range sourceFiles </span><span class="cov5" title="4">{
                        absPath := filepath.Clean(filepath.Join(file.SourceDir, sf.RelativePath))
                        if !strings.HasPrefix(absPath, cleanSourceDir) </span><span class="cov0" title="0">{
                                sw.logFn("source-watch: warning: skipping source file with path traversal: %s", sf.RelativePath)
                                continue</span>
                        }
                        <span class="cov5" title="4">newReverse[absPath] = append(newReverse[absPath], file)
                        newChecksums[absPath] = sf.Checksum
                        newSizes[absPath] = sf.Size
                        watchDirs[filepath.Dir(absPath)] = true</span>
                }
        }

        // Phase 2: Swap maps and drain stale checksum queue under the lock.
        <span class="cov3" title="2">sw.mu.Lock()
        oldDirs := sw.watchedDirs()

        // Drain any stale checksum requests from a previous configuration.
drain:
        for </span><span class="cov3" title="2">{
                select </span>{
                case &lt;-sw.checksumCh:<span class="cov0" title="0"></span>
                default:<span class="cov3" title="2">
                        break drain</span>
                }
        }
        <span class="cov3" title="2">sw.checksumPending = make(map[string]bool)
        sw.updateGen++

        sw.reverse = newReverse
        sw.checksums = newChecksums
        sw.sizes = newSizes
        sw.pollFiles = make(map[string]time.Time)
        sw.mu.Unlock()

        // Phase 3: Update inotify watches without the lock.
        // fsnotify.Watcher methods are thread-safe.
        for dir := range oldDirs </span><span class="cov0" title="0">{
                sw.watcher.Remove(dir)
        }</span>

        // Precompute files per directory so polling setup is O(files), not O(dirs×files).
        <span class="cov3" title="2">pathsByDir := make(map[string][]string)
        for absPath := range newReverse </span><span class="cov3" title="2">{
                dir := filepath.Dir(absPath)
                pathsByDir[dir] = append(pathsByDir[dir], absPath)
        }</span>

        <span class="cov3" title="2">newPollFiles := make(map[string]time.Time)
        for dir := range watchDirs </span><span class="cov3" title="2">{
                if isNetworkFS(dir) </span><span class="cov0" title="0">{
                        sw.logFn("source-watch: %s is on a network filesystem, using polling", dir)
                        for _, absPath := range pathsByDir[dir] </span><span class="cov0" title="0">{
                                if info, err := os.Stat(absPath); err == nil </span><span class="cov0" title="0">{
                                        newPollFiles[absPath] = info.ModTime()
                                }</span> else<span class="cov0" title="0"> {
                                        // File currently missing/unavailable — use zero mtime so
                                        // pollCheck detects it appearing (or triggers handleChange
                                        // via its stat-error path).
                                        newPollFiles[absPath] = time.Time{}
                                }</span>
                        }
                } else<span class="cov3" title="2"> {
                        if err := sw.watcher.Add(dir); err != nil </span><span class="cov0" title="0">{
                                sw.logFn("source-watch: warning: cannot watch %s: %v", dir, err)
                        }</span>
                }
        }

        // Phase 4: Set poll files under the lock.
        <span class="cov3" title="2">if len(newPollFiles) &gt; 0 </span><span class="cov0" title="0">{
                sw.mu.Lock()
                sw.pollFiles = newPollFiles
                sw.mu.Unlock()
        }</span>

        <span class="cov3" title="2">sw.logFn("source-watch: monitoring %d source files in %d directories (action=%s)",
                len(newReverse), len(watchDirs), sw.action)</span>
}

// watchedDirs returns the set of currently watched directories.
func (sw *SourceWatcher) watchedDirs() map[string]bool <span class="cov3" title="2">{
        dirs := make(map[string]bool)
        for path := range sw.reverse </span><span class="cov0" title="0">{
                dirs[filepath.Dir(path)] = true
        }</span>
        <span class="cov3" title="2">return dirs</span>
}

// Start begins the event processing loop. Must be called after Update().
func (sw *SourceWatcher) Start() <span class="cov0" title="0">{
        sw.wg.Add(1)
        go sw.eventLoop()

        // Start checksum worker (single goroutine processes queue sequentially)
        if sw.action == "checksum" </span><span class="cov0" title="0">{
                sw.wg.Add(1)
                go sw.checksumWorker()
        }</span>

        // Always start poller — it no-ops when pollFiles is empty, but must
        // be running so that network FS dirs added via Update() after reload
        // are polled without requiring a restart.
        <span class="cov0" title="0">sw.wg.Add(1)
        go sw.pollLoop()</span>
}

// Stop stops the watcher and waits for goroutines to exit.
// If a notifier is configured, it is stopped (flushing any pending events).
func (sw *SourceWatcher) Stop() <span class="cov0" title="0">{
        close(sw.stopCh)
        sw.watcher.Close()
        sw.wg.Wait()
        if sw.notifier != nil </span><span class="cov0" title="0">{
                sw.notifier.Stop()
        }</span>
}

// notify sends an error event to the notifier, if configured.
func (sw *SourceWatcher) notify(sourcePath, event string, names []string) <span class="cov8" title="12">{
        if sw.notifier != nil </span><span class="cov3" title="2">{
                sw.notifier.Notify(ErrorEvent{
                        SourcePath:    sourcePath,
                        AffectedFiles: names,
                        Event:         event,
                })
        }</span>
}

// eventLoop processes fsnotify events.
func (sw *SourceWatcher) eventLoop() <span class="cov0" title="0">{
        defer sw.wg.Done()

        for </span><span class="cov0" title="0">{
                select </span>{
                case event, ok := &lt;-sw.watcher.Events:<span class="cov0" title="0">
                        if !ok </span><span class="cov0" title="0">{
                                return
                        }</span>
                        // React to writes, creates (overwrites), renames, and removals
                        <span class="cov0" title="0">if event.Op&amp;(fsnotify.Write|fsnotify.Create|fsnotify.Rename|fsnotify.Remove) == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">sw.handleChange(event.Name)</span>

                case err, ok := &lt;-sw.watcher.Errors:<span class="cov0" title="0">
                        if !ok </span><span class="cov0" title="0">{
                                return
                        }</span>
                        <span class="cov0" title="0">sw.logFn("source-watch: watcher error: %v", err)</span>

                case &lt;-sw.stopCh:<span class="cov0" title="0">
                        return</span>
                }
        }
}

// pollLoop periodically checks files on network filesystems for changes.
func (sw *SourceWatcher) pollLoop() <span class="cov0" title="0">{
        defer sw.wg.Done()

        ticker := time.NewTicker(sw.pollInterval)
        defer ticker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        sw.pollCheck()</span>
                case &lt;-sw.stopCh:<span class="cov0" title="0">
                        return</span>
                }
        }
}

// pollCheck stats all poll-monitored files and triggers handleChange for
// any that have a different mtime than recorded. It snapshots the poll set
// under a read lock, performs os.Stat calls without the lock (network FS
// stats can block), then updates mtimes and processes changes.
func (sw *SourceWatcher) pollCheck() <span class="cov0" title="0">{
        // Snapshot under read lock so os.Stat doesn't block event handling.
        type polledFile struct {
                path      string
                lastMtime time.Time
        }
        sw.mu.RLock()
        snapshot := make([]polledFile, 0, len(sw.pollFiles))
        for absPath, lastMtime := range sw.pollFiles </span><span class="cov0" title="0">{
                snapshot = append(snapshot, polledFile{path: absPath, lastMtime: lastMtime})
        }</span>
        <span class="cov0" title="0">sw.mu.RUnlock()

        // Stat without holding the lock.
        type mtimeUpdate struct {
                path     string
                newMtime time.Time
        }
        var (
                updates      []mtimeUpdate
                changedPaths []string
        )
        for _, pf := range snapshot </span><span class="cov0" title="0">{
                info, err := os.Stat(pf.path)
                if err != nil </span><span class="cov0" title="0">{
                        sw.logFn("source-watch: poll: cannot stat %s: %v", pf.path, err)
                        changedPaths = append(changedPaths, pf.path)
                        continue</span>
                }
                <span class="cov0" title="0">if !info.ModTime().Equal(pf.lastMtime) </span><span class="cov0" title="0">{
                        updates = append(updates, mtimeUpdate{path: pf.path, newMtime: info.ModTime()})
                        changedPaths = append(changedPaths, pf.path)
                }</span>
        }

        // Update stored mtimes under the lock.
        <span class="cov0" title="0">if len(updates) &gt; 0 </span><span class="cov0" title="0">{
                sw.mu.Lock()
                for _, u := range updates </span><span class="cov0" title="0">{
                        if _, ok := sw.pollFiles[u.path]; ok </span><span class="cov0" title="0">{
                                sw.pollFiles[u.path] = u.newMtime
                        }</span>
                }
                <span class="cov0" title="0">sw.mu.Unlock()</span>
        }

        // Process changes — handleChange acquires the lock per-path.
        <span class="cov0" title="0">for _, absPath := range changedPaths </span><span class="cov0" title="0">{
                sw.handleChange(absPath)
        }</span>
}

// handleChange processes a source file change event.
func (sw *SourceWatcher) handleChange(absPath string) <span class="cov0" title="0">{
        sw.mu.Lock()
        defer sw.mu.Unlock()
        sw.handleChangeLocked(absPath)
}</span>

// handleChangeLocked processes a source file change. Caller must hold sw.mu.
func (sw *SourceWatcher) handleChangeLocked(absPath string) <span class="cov10" title="18">{
        affected, ok := sw.reverse[absPath]
        if !ok </span><span class="cov0" title="0">{
                return // Not a tracked source file
        }</span>

        <span class="cov10" title="18">names := make([]string, len(affected))
        for i, f := range affected </span><span class="cov10" title="18">{
                names[i] = f.Name
        }</span>

        <span class="cov10" title="18">switch sw.action </span>{
        case "warn":<span class="cov3" title="2">
                sw.logFn("source-watch: WARNING: source file changed: %s (affects: %v)", absPath, names)
                sw.notify(absPath, "changed", names)</span>

        case "disable":<span class="cov5" title="4">
                sw.logFn("source-watch: source file changed, disabling: %s (affects: %v)", absPath, names)
                for _, f := range affected </span><span class="cov5" title="4">{
                        f.Disable()
                }</span>
                <span class="cov5" title="4">sw.notify(absPath, "changed", names)</span>

        case "checksum":<span class="cov8" title="12">
                // Stat the source file to distinguish size changes from
                // timestamp-only changes (e.g., touch).
                info, err := os.Stat(absPath)
                if err != nil </span><span class="cov3" title="2">{
                        // File disappeared — disable immediately
                        sw.logFn("source-watch: source file missing, disabling: %s (affects: %v)", absPath, names)
                        for _, f := range affected </span><span class="cov3" title="2">{
                                f.Disable()
                        }</span>
                        <span class="cov3" title="2">sw.notify(absPath, "missing", names)
                        return</span>
                }

                <span class="cov8" title="10">expectedSize := sw.sizes[absPath]
                if info.Size() != expectedSize </span><span class="cov3" title="2">{
                        // Size changed — definitely corrupted, disable immediately
                        sw.logFn("source-watch: source file size changed (%d → %d), disabling: %s (affects: %v)",
                                expectedSize, info.Size(), absPath, names)
                        for _, f := range affected </span><span class="cov3" title="2">{
                                f.Disable()
                        }</span>
                        <span class="cov3" title="2">sw.notify(absPath, "size_changed", names)
                        return</span>
                }

                // Size matches — verify checksum in background. File remains
                // accessible during verification; only disabled on mismatch.
                <span class="cov7" title="8">if sw.checksumPending[absPath] </span><span class="cov3" title="2">{
                        return // Already queued
                }</span>
                <span class="cov6" title="6">sw.logFn("source-watch: source file modified, verifying checksum: %s (affects: %v)", absPath, names)
                affectedCopy := make([]*MKVFile, len(affected))
                copy(affectedCopy, affected)
                select </span>{
                case sw.checksumCh &lt;- checksumRequest{
                        absPath:          absPath,
                        expectedChecksum: sw.checksums[absPath],
                        expectedSize:     expectedSize,
                        affected:         affectedCopy,
                        gen:              sw.updateGen,
                }:<span class="cov6" title="6">
                        sw.checksumPending[absPath] = true</span>
                default:<span class="cov0" title="0">
                        // Queue full — disable as a safety measure
                        sw.logFn("source-watch: checksum queue full, disabling: %s (affects: %v)", absPath, names)
                        for _, f := range affected </span><span class="cov0" title="0">{
                                f.Disable()
                        }</span>
                        <span class="cov0" title="0">sw.notify(absPath, "checksum_queue_full", names)</span>
                }
        }
}

// checksumWorker processes checksum verification requests sequentially.
// Only one goroutine runs this, ensuring that bulk source changes don't
// spawn hundreds of parallel I/O-heavy hash operations.
func (sw *SourceWatcher) checksumWorker() <span class="cov5" title="4">{
        defer sw.wg.Done()

        for </span><span class="cov7" title="8">{
                select </span>{
                case req := &lt;-sw.checksumCh:<span class="cov5" title="4">
                        // Clear pending flag so new events for this path get queued.
                        // This must happen before verification so that changes during
                        // hashing trigger a fresh verification.
                        sw.mu.Lock()
                        delete(sw.checksumPending, req.absPath)
                        stale := req.gen != sw.updateGen
                        sw.mu.Unlock()

                        if stale </span><span class="cov0" title="0">{
                                continue</span> // Config was reloaded; skip stale request
                        }
                        <span class="cov5" title="4">sw.verifyChecksum(req.absPath, req.expectedChecksum, req.expectedSize, req.affected, req.gen)</span>
                case &lt;-sw.stopCh:<span class="cov5" title="4">
                        return</span>
                }
        }
}

// verifyChecksum re-hashes a source file in the background. Files remain
// accessible during verification. If the checksum mismatches, affected
// virtual files are disabled (recoverable via SIGHUP reload or a
// subsequent successful checksum). The gen parameter is checked before
// disabling or enabling so that a reload during verification prevents
// stale results from affecting files in the new configuration.
func (sw *SourceWatcher) verifyChecksum(absPath string, expectedChecksum uint64, expectedSize int64, affected []*MKVFile, gen uint64) <span class="cov5" title="4">{
        names := make([]string, len(affected))
        for i, f := range affected </span><span class="cov5" title="4">{
                names[i] = f.Name
        }</span>

        // disableIfCurrent disables affected files only if the watcher
        // generation hasn't changed (i.e., no reload occurred during verification).
        <span class="cov5" title="4">disableIfCurrent := func() </span><span class="cov3" title="2">{
                sw.mu.RLock()
                stale := gen != sw.updateGen
                sw.mu.RUnlock()
                if stale </span><span class="cov0" title="0">{
                        sw.logFn("source-watch: checksum: skipping disable for %s (config reloaded during verification)", absPath)
                        return
                }</span>
                <span class="cov3" title="2">for _, f := range affected </span><span class="cov3" title="2">{
                        f.Disable()
                }</span>
        }

        // Re-check size — it may have changed since the event was queued
        <span class="cov5" title="4">info, err := os.Stat(absPath)
        if err != nil </span><span class="cov0" title="0">{
                sw.logFn("source-watch: checksum: cannot stat %s: %v — disabling %v", absPath, err, names)
                disableIfCurrent()
                sw.notify(absPath, "missing", names)
                return
        }</span>
        <span class="cov5" title="4">if info.Size() != expectedSize </span><span class="cov0" title="0">{
                sw.logFn("source-watch: checksum: size changed for %s (%d → %d) — disabling %v",
                        absPath, expectedSize, info.Size(), names)
                disableIfCurrent()
                sw.notify(absPath, "size_changed", names)
                return
        }</span>

        // Full xxhash checksum
        <span class="cov5" title="4">f, err := os.Open(absPath)
        if err != nil </span><span class="cov0" title="0">{
                sw.logFn("source-watch: checksum: cannot open %s: %v — disabling %v", absPath, err, names)
                disableIfCurrent()
                sw.notify(absPath, "missing", names)
                return
        }</span>
        <span class="cov5" title="4">defer f.Close()

        h := xxhash.New()
        buf := make([]byte, 1&lt;&lt;20) // 1MB buffer
        for </span><span class="cov7" title="8">{
                // Check for shutdown between reads so large-file hashing
                // doesn't block Stop() indefinitely.
                select </span>{
                case &lt;-sw.stopCh:<span class="cov0" title="0">
                        return</span>
                default:<span class="cov7" title="8"></span>
                }

                <span class="cov7" title="8">n, readErr := f.Read(buf)
                if n &gt; 0 </span><span class="cov5" title="4">{
                        h.Write(buf[:n])
                }</span>
                <span class="cov7" title="8">if readErr != nil </span><span class="cov5" title="4">{
                        if readErr != io.EOF </span><span class="cov0" title="0">{
                                sw.logFn("source-watch: checksum: read error for %s: %v — disabling %v", absPath, readErr, names)
                                disableIfCurrent()
                                sw.notify(absPath, "read_error", names)
                                return
                        }</span>
                        <span class="cov5" title="4">break</span>
                }
        }
        <span class="cov5" title="4">actualChecksum := h.Sum64()

        if actualChecksum != expectedChecksum </span><span class="cov3" title="2">{
                sw.logFn("source-watch: checksum mismatch for %s (got %016x, expected %016x) — disabling %v",
                        absPath, actualChecksum, expectedChecksum, names)
                disableIfCurrent()
                sw.notify(absPath, "checksum_mismatch", names)
        }</span> else<span class="cov3" title="2"> {
                // Re-enable affected files so transient issues (e.g., network
                // glitches) auto-recover without requiring admin SIGHUP.
                //
                // NOTE: a virtual file can depend on multiple source files. A
                // passing checksum for one source could re-enable a file whose
                // other source is still bad. This is a known limitation; the
                // common case (single source per MKV) is handled correctly, and
                // SIGHUP is available as a fallback for multi-source edge cases.
                sw.mu.RLock()
                stale := gen != sw.updateGen
                sw.mu.RUnlock()
                if stale </span><span class="cov0" title="0">{
                        sw.logFn("source-watch: checksum: skipping re-enable for %s (config reloaded during verification)", absPath)
                        return
                }</span>
                <span class="cov3" title="2">sw.logFn("source-watch: checksum verified OK for %s — re-enabling %v", absPath, names)
                for _, f := range affected </span><span class="cov3" title="2">{
                        f.Enable()
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file32" style="display: none">//go:build linux

package fuse

import "golang.org/x/sys/unix"

// Filesystem type constants for network FS detection.
const (
        nfsSuperMagic   = 0x6969
        cifsMagicNum    = 0xFF534D42
        smb2MagicNum    = 0xFE534D42
        afsSuper        = 0x5346414F
        ncpfsSuperMagic = 0x564C
)

// IsNetworkFS checks if the given path is on a network filesystem.
// Exported for integration testing; internal callers use isNetworkFS.
func IsNetworkFS(path string) bool <span class="cov1" title="1">{
        return isNetworkFS(path)
}</span>

// isNetworkFS checks if the given path is on a network filesystem.
func isNetworkFS(path string) bool <span class="cov10" title="11">{
        var stat unix.Statfs_t
        if err := unix.Statfs(path, &amp;stat); err != nil </span><span class="cov0" title="0">{
                // Can't determine — assume local
                return false
        }</span>

        <span class="cov10" title="11">switch stat.Type </span>{
        case nfsSuperMagic, cifsMagicNum, smb2MagicNum, afsSuper, ncpfsSuperMagic:<span class="cov3" title="2">
                return true</span>
        }
        <span class="cov9" title="9">return false</span>
}
</pre>
		
		<pre class="file" id="file33" style="display: none">// Package matcher provides the core deduplication logic for matching MKV packets to source files.
package matcher

import (
        "bufio"
        "fmt"
        "os"
        "runtime"
        "sort"
        "strings"
        "sync"
        "sync/atomic"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/mmap"
        "github.com/stuckj/mkvdup/internal/source"
)

const (
        // MaxExpansionBytes is the maximum number of bytes to expand a match in each direction.
        // Set high to allow matching entire video keyframes which can be several MB.
        MaxExpansionBytes = 16 * 1024 * 1024 // 16MB

        // localityNearbyCount is the max number of nearby locations to try in Phase 1
        // of locality-aware matching before falling back to a full search.
        localityNearbyCount = 8

        // localityGoodMatchThreshold is the minimum match length (bytes) to accept
        // from a nearby location without trying all remaining locations.
        // At 4KB (64x the 64-byte window), a false positive is vanishingly unlikely.
        localityGoodMatchThreshold = 4096
)

// detectNALLengthSize determines the NAL unit length field size from an MKV track's
// codec ID and codec private data. Returns 0 for Annex B (start code) formats,
// or the length field size (1, 2, or 4) for AVCC/HVCC formats.
func detectNALLengthSize(codecID string, codecPrivate []byte) int <span class="cov2" title="9">{
        switch codecID </span>{
        case "V_MPEG4/ISO/AVC":<span class="cov1" title="3">
                // AVCC format: CodecPrivate is AVCDecoderConfigurationRecord
                // Byte 4 bits 0-1 = NAL length size - 1
                if len(codecPrivate) &gt;= 7 &amp;&amp; codecPrivate[0] == 1 </span><span class="cov1" title="2">{
                        return int(codecPrivate[4]&amp;0x03) + 1
                }</span>
                <span class="cov1" title="1">return 4</span> // Default for AVC if CodecPrivate is missing or malformed
        case "V_MPEGH/ISO/HEVC":<span class="cov1" title="2">
                // HVCC format: CodecPrivate is HEVCDecoderConfigurationRecord
                // Byte 0 = configurationVersion (must be 1)
                // Byte 21 bits 6-7 = reserved (must be 111111)
                // Byte 21 bits 0-1 = NAL length size - 1
                if len(codecPrivate) &gt;= 23 &amp;&amp; codecPrivate[0] == 1 </span><span class="cov1" title="1">{
                        b := codecPrivate[21]
                        // Upper 6 bits must be all 1s per ISO/IEC 23008-2
                        if b&amp;0xFC == 0xFC </span><span class="cov1" title="1">{
                                size := int(b&amp;0x03) + 1
                                // Valid NAL length sizes are 1, 2, or 4 bytes
                                if size == 1 || size == 2 || size == 4 </span><span class="cov1" title="1">{
                                        return size
                                }</span>
                        }
                }
                <span class="cov1" title="1">return 4</span> // Default for HEVC if CodecPrivate is missing or malformed
        default:<span class="cov1" title="4">
                return 0</span> // Annex B format (MPEG-2, etc.)
        }
}

// NALLengthSizeForTrack returns the NAL length size for a track, suitable for
// use by external callers like ExtractProbeHashes. Returns 0 for Annex B.
func NALLengthSizeForTrack(codecID string, codecPrivate []byte) int <span class="cov0" title="0">{
        return detectNALLengthSize(codecID, codecPrivate)
}</span>

// Entry represents a region in the MKV file and where its data comes from.
type Entry struct {
        MkvOffset        int64  // Start offset in the MKV file
        Length           int64  // Length of this region
        Source           uint16 // 0 = delta, 1+ = source file index + 1 (supports up to 65535 files)
        SourceOffset     int64  // Offset in source file (or ES offset for ES-based sources)
        IsVideo          bool   // For ES-based sources: whether this is video or audio data
        AudioSubStreamID byte   // For ES-based audio: sub-stream ID (0x80-0x87=AC3, etc.)
}

// Result contains the results of the matching process.
type Result struct {
        Entries        []Entry      // All entries covering the entire MKV file
        DeltaData      []byte       // Concatenated unique data (for small deltas / tests)
        DeltaFile      *DeltaWriter // File-backed delta data (for large files)
        MatchedBytes   int64        // Total bytes matched to source
        UnmatchedBytes int64        // Total bytes in delta
        MatchedPackets int          // Number of packets that matched
        TotalPackets   int          // Total number of packets processed
}

// DeltaSize returns the total size of delta data.
func (r *Result) DeltaSize() int64 <span class="cov0" title="0">{
        if r.DeltaFile != nil </span><span class="cov0" title="0">{
                return r.DeltaFile.Size()
        }</span>
        <span class="cov0" title="0">return int64(len(r.DeltaData))</span>
}

// Close cleans up resources held by the result (temp files).
func (r *Result) Close() <span class="cov0" title="0">{
        if r.DeltaFile != nil </span><span class="cov0" title="0">{
                r.DeltaFile.Close()
                r.DeltaFile = nil
        }</span>
}

// DeltaWriter writes delta data to a temp file to avoid heap accumulation.
type DeltaWriter struct {
        file     *os.File
        buffered *bufio.Writer
        size     int64
}

// NewDeltaWriter creates a DeltaWriter backed by a temp file.
func NewDeltaWriter() (*DeltaWriter, error) <span class="cov2" title="10">{
        f, err := os.CreateTemp("", "mkvdup-delta-*")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("create delta temp file: %w", err)
        }</span>
        <span class="cov2" title="10">return &amp;DeltaWriter{
                file:     f,
                buffered: bufio.NewWriterSize(f, 256*1024),
        }, nil</span>
}

// Write appends data to the delta file.
func (dw *DeltaWriter) Write(data []byte) error <span class="cov7" title="73830">{
        n, err := dw.buffered.Write(data)
        dw.size += int64(n)
        return err
}</span>

// Flush ensures all buffered data is written to disk.
func (dw *DeltaWriter) Flush() error <span class="cov2" title="10">{
        return dw.buffered.Flush()
}</span>

// Size returns the total bytes written.
func (dw *DeltaWriter) Size() int64 <span class="cov1" title="3">{
        return dw.size
}</span>

// File returns the underlying file for reading. Must call Flush() first.
func (dw *DeltaWriter) File() *os.File <span class="cov1" title="2">{
        return dw.file
}</span>

// Close removes the temp file.
func (dw *DeltaWriter) Close() <span class="cov2" title="9">{
        if dw.file != nil </span><span class="cov2" title="9">{
                name := dw.file.Name()
                dw.file.Close()
                os.Remove(name)
                dw.file = nil
        }</span>
}

// matchedRegion tracks a region that was matched to a source.
type matchedRegion struct {
        mkvStart         int64
        mkvEnd           int64
        fileIndex        uint16
        srcOffset        int64 // File offset or ES offset depending on source type
        isVideo          bool  // For ES-based sources
        audioSubStreamID byte  // For audio in MPEG-PS
}

// Matcher performs the deduplication matching.
// coverageChunkSize is the granularity for coverage tracking.
// Smaller values give more accurate coverage checks but use more memory.
const coverageChunkSize = 4096 // 4KB chunks

// trackCodecInfo stores per-track codec information for format-aware matching.
type trackCodecInfo struct {
        trackType     int
        nalLengthSize int // 0 = Annex B (start codes), 1/2/4 = AVCC/HVCC (length-prefixed NAL units)
}

type Matcher struct {
        sourceIndex    *source.Index
        mkvMmap        *mmap.File
        mkvData        []byte // Zero-copy mmap'd MKV data
        mkvSize        int64
        windowSize     int
        matchedRegions []matchedRegion
        regionsMu      sync.Mutex             // Protects matchedRegions for concurrent access
        trackTypes     map[int]int            // Map from track number to track type
        trackCodecs    map[int]trackCodecInfo // Map from track number to codec info
        numWorkers     int                    // Number of worker goroutines for parallel matching
        verbose        bool                   // Enable diagnostic output
        isAVCTrack     map[int]bool           // Per-track: whether this track uses H.264 NAL types
        // Coverage bitmap for O(1) coverage checks. Each bit represents a chunk.
        // A chunk is marked covered when a matched region fully contains it.
        coveredChunks []uint64 // Bitmap: bit i = chunk i is covered
        coverageMu    sync.RWMutex

        // Locality hint: shared across workers. Workers process near-sequential
        // packets so hints naturally stay roughly current. Stale values just mean
        // one wasted nearby search before falling back to the full location list.
        lastMatchFileIndex atomic.Uint32
        lastMatchOffset    atomic.Int64
        lastMatchValid     atomic.Bool

        // Diagnostic counters for investigating match failures
        diagVideoPacketsTotal       atomic.Int64 // Total video packets processed
        diagVideoPacketsCoverage    atomic.Int64 // Video packets skipped (coverage check)
        diagVideoNALsTotal          atomic.Int64 // Total video NAL sync points tried
        diagVideoNALsTooSmall       atomic.Int64 // NALs where window didn't fit
        diagVideoNALsHashNotFound   atomic.Int64 // NALs where hash wasn't in index
        diagVideoNALsVerifyFailed   atomic.Int64 // NALs where hash found but all verifications failed
        diagVideoNALsAllSkipped     atomic.Int64 // NALs where hash found but all locations skipped (e.g. isVideo mismatch)
        diagVideoNALsMatched        atomic.Int64 // NALs successfully matched
        diagVideoNALsMatchedBytes   atomic.Int64 // Total bytes from matched video NALs
        diagVideoNALsSkippedIsVideo atomic.Int64 // Locations skipped due to isVideo mismatch
        // Per-NAL-type diagnostics (H.264 NAL type = first byte &amp; 0x1F)
        diagNALTypeNotFound [32]atomic.Int64 // hash not found, by NAL type
        diagNALTypeMatched  [32]atomic.Int64 // matched, by NAL type
        diagNALTypeTotal    [32]atomic.Int64 // total attempted, by NAL type

        // NAL size bucket diagnostics (video only)
        // Buckets: 0=&lt;64, 1=64-127, 2=128-1023, 3=1K-32K, 4=32K+
        diagNALSizeMatched   [5]atomic.Int64
        diagNALSizeUnmatched [5]atomic.Int64

        // First few hash-not-found examples for debugging
        diagExamplesMu     sync.Mutex
        diagExamplesCount  int
        diagExamplesOutput []string
}

// nalSizeBucket returns the bucket index for a NAL size.
// Buckets: 0=&lt;64, 1=64-127, 2=128-1023, 3=1K-32K, 4=32K+
func nalSizeBucket(size int) int <span class="cov8" title="539592">{
        switch </span>{
        case size &lt; 64:<span class="cov0" title="0">
                return 0</span>
        case size &lt; 128:<span class="cov6" title="16063">
                return 1</span>
        case size &lt; 1024:<span class="cov7" title="139862">
                return 2</span>
        case size &lt; 32768:<span class="cov8" title="382147">
                return 3</span>
        default:<span class="cov5" title="1520">
                return 4</span>
        }
}

// NewMatcher creates a new Matcher with the given source index.
func NewMatcher(sourceIndex *source.Index) (*Matcher, error) <span class="cov2" title="8">{
        numWorkers := runtime.NumCPU() / 2
        if numWorkers &lt; 1 </span><span class="cov0" title="0">{
                numWorkers = 1
        }</span>
        <span class="cov2" title="8">return &amp;Matcher{
                sourceIndex: sourceIndex,
                windowSize:  sourceIndex.WindowSize,
                trackTypes:  make(map[int]int),
                trackCodecs: make(map[int]trackCodecInfo),
                isAVCTrack:  make(map[int]bool),
                numWorkers:  numWorkers,
        }, nil</span>
}

// SetVerbose enables or disables diagnostic output during matching.
func (m *Matcher) SetVerbose(v bool) <span class="cov0" title="0">{
        m.verbose = v
}</span>

// SetNumWorkers sets the number of worker goroutines for parallel matching.
func (m *Matcher) SetNumWorkers(n int) <span class="cov1" title="3">{
        if n &lt; 1 </span><span class="cov1" title="2">{
                n = 1
        }</span>
        <span class="cov1" title="3">m.numWorkers = n</span>
}

// Close releases resources.
func (m *Matcher) Close() error <span class="cov1" title="5">{
        if m.mkvMmap != nil </span><span class="cov1" title="1">{
                m.mkvMmap.Close()
        }</span>
        <span class="cov1" title="5">return nil</span>
}

// ProgressFunc is called to report matching progress.
type ProgressFunc func(processedPackets, totalPackets int)

// Match processes an MKV file and matches packets to the source.
func (m *Matcher) Match(mkvPath string, packets []mkv.Packet, tracks []mkv.Track, progress ProgressFunc) (*Result, error) <span class="cov1" title="1">{
        // Memory-map the MKV file for zero-copy access
        info, err := os.Stat(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("stat MKV: %w", err)
        }</span>
        <span class="cov1" title="1">m.mkvSize = info.Size()

        m.mkvMmap, err = mmap.Open(mkvPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("mmap MKV: %w", err)
        }</span>
        <span class="cov1" title="1">m.mkvData = m.mkvMmap.Data() // Store reference for zero-copy access

        // Reset per-run state in case Match() is called multiple times
        m.trackTypes = make(map[int]int)
        m.trackCodecs = make(map[int]trackCodecInfo)
        m.isAVCTrack = make(map[int]bool)
        m.diagVideoPacketsTotal.Store(0)
        m.diagVideoPacketsCoverage.Store(0)
        m.diagVideoNALsTotal.Store(0)
        m.diagVideoNALsTooSmall.Store(0)
        m.diagVideoNALsHashNotFound.Store(0)
        m.diagVideoNALsVerifyFailed.Store(0)
        m.diagVideoNALsAllSkipped.Store(0)
        m.diagVideoNALsMatched.Store(0)
        m.diagVideoNALsMatchedBytes.Store(0)
        m.diagVideoNALsSkippedIsVideo.Store(0)
        for i := range m.diagNALTypeNotFound </span><span class="cov2" title="32">{
                m.diagNALTypeNotFound[i].Store(0)
                m.diagNALTypeMatched[i].Store(0)
                m.diagNALTypeTotal[i].Store(0)
        }</span>
        <span class="cov1" title="1">for i := range m.diagNALSizeMatched </span><span class="cov1" title="5">{
                m.diagNALSizeMatched[i].Store(0)
                m.diagNALSizeUnmatched[i].Store(0)
        }</span>
        <span class="cov1" title="1">m.diagExamplesMu.Lock()
        m.diagExamplesCount = 0
        m.diagExamplesOutput = nil
        m.diagExamplesMu.Unlock()

        // Reset locality hint so matches from a previous MKV do not bias this run
        m.lastMatchFileIndex.Store(0)
        m.lastMatchOffset.Store(0)
        m.lastMatchValid.Store(false)

        // Build track type and codec info maps
        for _, t := range tracks </span><span class="cov1" title="2">{
                m.trackTypes[int(t.Number)] = t.Type
                nlSize := detectNALLengthSize(t.CodecID, t.CodecPrivate)
                m.trackCodecs[int(t.Number)] = trackCodecInfo{
                        trackType:     t.Type,
                        nalLengthSize: nlSize,
                }
                if t.Type == mkv.TrackTypeVideo &amp;&amp; strings.HasPrefix(t.CodecID, "V_MPEG4/ISO/AVC") </span><span class="cov0" title="0">{
                        m.isAVCTrack[int(t.Number)] = true
                }</span>
        }

        // Reset matched regions with pre-allocated capacity
        // Most packets will match, so estimate capacity as number of packets
        <span class="cov1" title="1">m.matchedRegions = make([]matchedRegion, 0, len(packets))

        // Initialize coverage bitmap
        // Each uint64 holds 64 chunk bits, so we need (numChunks + 63) / 64 uint64s
        numChunks := (m.mkvSize + coverageChunkSize - 1) / coverageChunkSize
        m.coveredChunks = make([]uint64, (numChunks+63)/64)

        // Pre-sort source locations by offset to enable binary search for
        // locality-aware matching. One-time cost before concurrent access.
        m.sourceIndex.SortLocationsByOffset()

        // Set appropriate madvise hints for matching access patterns.
        m.sourceIndex.AdviseForMatching()

        result := &amp;Result{
                TotalPackets: len(packets),
        }

        // Use parallel processing with worker pool
        result.MatchedPackets = m.matchParallel(packets, progress)

        if progress != nil </span><span class="cov0" title="0">{
                progress(len(packets), len(packets))
        }</span>

        // Print diagnostic summary (verbose only)
        <span class="cov1" title="1">if m.verbose </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "\n=== Video Matching Diagnostics ===\n")
                fmt.Fprintf(os.Stderr, "Video packets total:        %d\n", m.diagVideoPacketsTotal.Load())
                fmt.Fprintf(os.Stderr, "Video packets skip-covered: %d\n", m.diagVideoPacketsCoverage.Load())
                fmt.Fprintf(os.Stderr, "Video NALs total:           %d\n", m.diagVideoNALsTotal.Load())
                fmt.Fprintf(os.Stderr, "Video NALs too small:       %d\n", m.diagVideoNALsTooSmall.Load())
                fmt.Fprintf(os.Stderr, "Video NALs hash not found:  %d\n", m.diagVideoNALsHashNotFound.Load())
                fmt.Fprintf(os.Stderr, "Video NALs verify failed:   %d\n", m.diagVideoNALsVerifyFailed.Load())
                fmt.Fprintf(os.Stderr, "Video NALs all skipped:     %d\n", m.diagVideoNALsAllSkipped.Load())
                fmt.Fprintf(os.Stderr, "Video NALs matched:         %d\n", m.diagVideoNALsMatched.Load())
                fmt.Fprintf(os.Stderr, "Video NALs matched bytes:   %d (%.2f MB)\n",
                        m.diagVideoNALsMatchedBytes.Load(), float64(m.diagVideoNALsMatchedBytes.Load())/(1024*1024))
                fmt.Fprintf(os.Stderr, "Video NALs isVideo skips:   %d\n", m.diagVideoNALsSkippedIsVideo.Load())
                if len(m.isAVCTrack) &gt; 0 </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "\nPer-NAL-type breakdown (H.264, type: total / matched / not_found / miss%%):\n")
                        nalTypeNames := map[byte]string{
                                1: "non-IDR slice", 2: "slice A", 3: "slice B", 4: "slice C",
                                5: "IDR slice", 6: "SEI", 7: "SPS", 8: "PPS", 9: "AUD", 12: "filler",
                        }
                        for i := 0; i &lt; 32; i++ </span><span class="cov0" title="0">{
                                total := m.diagNALTypeTotal[i].Load()
                                if total == 0 </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov0" title="0">matched := m.diagNALTypeMatched[i].Load()
                                notFound := m.diagNALTypeNotFound[i].Load()
                                name := nalTypeNames[byte(i)]
                                if name == "" </span><span class="cov0" title="0">{
                                        name = "other"
                                }</span>
                                <span class="cov0" title="0">fmt.Fprintf(os.Stderr, "  type %2d (%14s): %8d / %8d / %8d (%.1f%% miss)\n",
                                        i, name, total, matched, notFound, float64(notFound)/float64(total)*100)</span>
                        }
                }
                // NAL size bucket breakdown
                <span class="cov0" title="0">nalSizeBucketNames := [5]string{"&lt;64B", "64-127B", "128B-1KB", "1KB-32KB", "32KB+"}
                fmt.Fprintf(os.Stderr, "\nVideo NAL size distribution (matched / unmatched):\n")
                for i := 0; i &lt; 5; i++ </span><span class="cov0" title="0">{
                        matched := m.diagNALSizeMatched[i].Load()
                        unmatched := m.diagNALSizeUnmatched[i].Load()
                        if matched &gt; 0 || unmatched &gt; 0 </span><span class="cov0" title="0">{
                                fmt.Fprintf(os.Stderr, "  %9s: %8d matched, %8d unmatched\n",
                                        nalSizeBucketNames[i], matched, unmatched)
                        }</span>
                }

                <span class="cov0" title="0">fmt.Fprintf(os.Stderr, "\nFirst hash-not-found examples:\n")
                for _, ex := range m.diagExamplesOutput </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "%s\n", ex)
                }</span>
                <span class="cov0" title="0">fmt.Fprintf(os.Stderr, "=================================\n")</span>
        }

        // Merge overlapping regions and build final entries
        <span class="cov1" title="1">m.mergeRegions()
        var buildErr error
        result.Entries, result.DeltaFile, buildErr = m.buildEntries()
        if buildErr != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("build entries: %w", buildErr)
        }</span>

        // Calculate statistics
        <span class="cov1" title="1">for _, e := range result.Entries </span><span class="cov7" title="147980">{
                if e.Source == 0 </span><span class="cov7" title="73818">{
                        result.UnmatchedBytes += e.Length
                }</span> else<span class="cov7" title="74162"> {
                        result.MatchedBytes += e.Length
                }</span>
        }

        <span class="cov1" title="1">return result, nil</span>
}

// ProbeHash represents a hash computed from a sync point in packet data.
type ProbeHash struct {
        Hash    uint64
        IsVideo bool
}

// ExtractProbeHashes extracts probe hashes from packet data using sync point detection.
// This is the same algorithm used by the matcher to find matching points.
// The data should be the first few KB of a packet (typically up to 4096 bytes).
// windowSize should match the source index window size (typically 64 bytes).
// nalLengthSize is 0 for Annex B video, or 1/2/4 for AVCC/HVCC video.
// Returns nil if no valid hashes could be extracted.
func ExtractProbeHashes(data []byte, isVideo bool, windowSize int, nalLengthSize int) []ProbeHash <span class="cov2" title="14">{
        if len(data) &lt; windowSize </span><span class="cov1" title="2">{
                return nil
        }</span>

        <span class="cov2" title="12">var hashes []ProbeHash

        // Find sync points within the packet data
        var syncPoints []int
        if isVideo </span><span class="cov2" title="8">{
                if nalLengthSize &gt; 0 </span><span class="cov1" title="1">{
                        syncPoints = source.FindAVCCNALStarts(data, nalLengthSize)
                }</span> else<span class="cov2" title="7"> {
                        syncPoints = source.FindVideoNALStarts(data)
                }</span>
        } else<span class="cov1" title="4"> {
                syncPoints = source.FindAudioSyncPoints(data)
        }</span>

        // Hash from sync points
        <span class="cov2" title="12">for _, syncOff := range syncPoints </span><span class="cov2" title="10">{
                if syncOff+windowSize &gt; len(data) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov2" title="10">hash := xxhash.Sum64(data[syncOff : syncOff+windowSize])
                hashes = append(hashes, ProbeHash{
                        Hash:    hash,
                        IsVideo: isVideo,
                })</span>
        }

        // If no sync points found, try from data start
        <span class="cov2" title="12">if len(hashes) == 0 </span><span class="cov1" title="4">{
                hash := xxhash.Sum64(data[:windowSize])
                hashes = append(hashes, ProbeHash{
                        Hash:    hash,
                        IsVideo: isVideo,
                })
        }</span>

        <span class="cov2" title="12">return hashes</span>
}

// mergeRegions merges overlapping matched regions.
// Regions from the same source with consistent offset mappings are merged into one.
// Overlapping regions from different sources (or inconsistent offsets) are clipped:
// the earlier region keeps its full range, the later region is trimmed to start
// after the earlier one ends.
func (m *Matcher) mergeRegions() <span class="cov2" title="13">{
        if len(m.matchedRegions) == 0 </span><span class="cov1" title="1">{
                return
        }</span>

        // Sort by start offset
        <span class="cov2" title="12">sort.Slice(m.matchedRegions, func(i, j int) bool </span><span class="cov10" title="10638972">{
                return m.matchedRegions[i].mkvStart &lt; m.matchedRegions[j].mkvStart
        }</span>)

        // Merge overlapping regions
        // Pre-allocate with capacity since merged will be at most len(matchedRegions)
        <span class="cov2" title="12">merged := make([]matchedRegion, 1, len(m.matchedRegions))
        merged[0] = m.matchedRegions[0]
        for i := 1; i &lt; len(m.matchedRegions); i++ </span><span class="cov8" title="580041">{
                curr := m.matchedRegions[i]
                last := &amp;merged[len(merged)-1]

                if curr.mkvStart &gt;= last.mkvEnd </span><span class="cov7" title="74121">{
                        // No overlap - add new region
                        merged = append(merged, curr)
                        continue</span>
                }

                // Regions overlap. Check if they're from the same source with consistent
                // offset mapping, meaning the overlapping bytes map to the same source bytes.
                <span class="cov8" title="505920">expectedSrcOffset := last.srcOffset + (curr.mkvStart - last.mkvStart)
                sameMapping := curr.fileIndex == last.fileIndex &amp;&amp;
                        curr.srcOffset == expectedSrcOffset &amp;&amp;
                        curr.isVideo == last.isVideo &amp;&amp;
                        curr.audioSubStreamID == last.audioSubStreamID

                if sameMapping </span><span class="cov8" title="505391">{
                        // Same source, consistent mapping - safe to extend since both regions
                        // were independently verified and the combined range maps correctly.
                        if curr.mkvEnd &gt; last.mkvEnd </span><span class="cov1" title="3">{
                                last.mkvEnd = curr.mkvEnd
                        }</span>
                } else<span class="cov4" title="529"> if curr.mkvEnd &gt; last.mkvEnd </span><span class="cov3" title="47">{
                        // Different source or inconsistent mapping. The earlier region (last)
                        // keeps priority. Clip curr to start where last ends.
                        overlap := last.mkvEnd - curr.mkvStart
                        curr.mkvStart = last.mkvEnd
                        curr.srcOffset += overlap
                        // After clipping, curr may have zero or negative length if the overlap
                        // equals or exceeds the original region size. Only keep valid regions.
                        if curr.mkvStart &lt; curr.mkvEnd </span><span class="cov3" title="47">{
                                merged = append(merged, curr)
                        }</span>
                }
                // If curr is fully contained in last, drop it (nothing to add).
        }

        <span class="cov2" title="12">m.matchedRegions = merged</span>
}

// buildEntries creates the final entry list and streams delta data to a temp file.
func (m *Matcher) buildEntries() ([]Entry, *DeltaWriter, error) <span class="cov2" title="10">{
        entries := make([]Entry, 0, len(m.matchedRegions)*2+1)

        deltaWriter, err := NewDeltaWriter()
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>

        <span class="cov2" title="10">deltaOffset := int64(0)
        pos := int64(0)
        regionIdx := 0

        for pos &lt; m.mkvSize </span><span class="cov7" title="148000">{
                var inRegion *matchedRegion
                if regionIdx &lt; len(m.matchedRegions) &amp;&amp; m.matchedRegions[regionIdx].mkvStart &lt;= pos </span><span class="cov7" title="74170">{
                        inRegion = &amp;m.matchedRegions[regionIdx]
                }</span>

                <span class="cov7" title="148000">if inRegion != nil &amp;&amp; pos &gt;= inRegion.mkvStart &amp;&amp; pos &lt; inRegion.mkvEnd </span><span class="cov7" title="74170">{
                        offsetInRegion := pos - inRegion.mkvStart
                        regionLen := inRegion.mkvEnd - pos

                        entries = append(entries, Entry{
                                MkvOffset:        pos,
                                Length:           regionLen,
                                Source:           uint16(inRegion.fileIndex + 1),
                                SourceOffset:     inRegion.srcOffset + offsetInRegion,
                                IsVideo:          inRegion.isVideo,
                                AudioSubStreamID: inRegion.audioSubStreamID,
                        })

                        pos = inRegion.mkvEnd
                        regionIdx++
                }</span> else<span class="cov7" title="73830"> {
                        gapEnd := m.mkvSize
                        if regionIdx &lt; len(m.matchedRegions) </span><span class="cov7" title="73823">{
                                gapEnd = m.matchedRegions[regionIdx].mkvStart
                        }</span>
                        <span class="cov7" title="73830">gapLen := gapEnd - pos

                        if gapEnd &lt;= m.mkvSize </span><span class="cov7" title="73830">{
                                entries = append(entries, Entry{
                                        MkvOffset:    pos,
                                        Length:       gapLen,
                                        Source:       0,
                                        SourceOffset: deltaOffset,
                                })
                                // Write gap data directly from mmap to temp file
                                if err := deltaWriter.Write(m.mkvData[pos:gapEnd]); err != nil </span><span class="cov0" title="0">{
                                        deltaWriter.Close()
                                        return nil, nil, fmt.Errorf("write delta: %w", err)
                                }</span>
                                <span class="cov7" title="73830">deltaOffset += gapLen</span>
                        }

                        <span class="cov7" title="73830">pos = gapEnd</span>
                }
        }

        <span class="cov2" title="10">if err := deltaWriter.Flush(); err != nil </span><span class="cov0" title="0">{
                deltaWriter.Close()
                return nil, nil, fmt.Errorf("flush delta: %w", err)
        }</span>

        <span class="cov2" title="10">return entries, deltaWriter, nil</span>
}
</pre>
		
		<pre class="file" id="file34" style="display: none">package matcher

import (
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

// expandChunkSize is the number of bytes to read at once during match expansion.
// Larger chunks reduce page faults when expanding across mmap'd source files.
const expandChunkSize = 4096

// tryVerifyAndExpand attempts to verify and expand a match, returning the matched region or nil.
func (m *Matcher) tryVerifyAndExpand(pkt mkv.Packet, loc source.Location, offsetInPacket int64, isVideo bool) *matchedRegion <span class="cov8" title="20961437">{
        // The MKV offset where this sync point is
        mkvSyncOffset := pkt.Offset + offsetInPacket

        // Verify the initial match (at least windowSize bytes)
        verifyLen := int64(m.windowSize)
        remainingInPacket := pkt.Size - offsetInPacket
        if verifyLen &gt; remainingInPacket </span><span class="cov0" title="0">{
                verifyLen = remainingInPacket
        }</span>

        // Zero-copy: slice directly into mmap'd data
        <span class="cov8" title="20961437">endOffset := mkvSyncOffset + verifyLen
        if endOffset &gt; m.mkvSize </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="20961437">mkvBuf := m.mkvData[mkvSyncOffset:endOffset]

        // Read source data - use ES reader for ES-based indexes, raw slice for zero-copy
        var srcBuf []byte
        var err error
        if m.sourceIndex.UsesESOffsets </span><span class="cov8" title="20961437">{
                srcBuf, err = m.sourceIndex.ReadESDataAt(loc, int(verifyLen))
                if err != nil || len(srcBuf) &lt; int(verifyLen) </span><span class="cov0" title="0">{
                        return nil
                }</span>
        } else<span class="cov0" title="0"> {
                // For raw indexes, use zero-copy slice
                srcBuf = m.sourceIndex.RawSlice(loc, int(verifyLen))
                if srcBuf == nil || len(srcBuf) &lt; int(verifyLen) </span><span class="cov0" title="0">{
                        return nil
                }</span>
        }

        // Check if bytes match
        <span class="cov8" title="20961437">for i := range mkvBuf </span><span class="cov9" title="1341531968">{
                if mkvBuf[i] != srcBuf[i] </span><span class="cov0" title="0">{
                        return nil
                }</span>
        }

        // Expand the match from the sync point
        <span class="cov8" title="20961437">mkvStart, srcStart, matchLen := m.expandMatch(
                mkvSyncOffset, loc, verifyLen,
        )

        return &amp;matchedRegion{
                mkvStart:         mkvStart,
                mkvEnd:           mkvStart + matchLen,
                fileIndex:        loc.FileIndex,
                srcOffset:        srcStart,
                isVideo:          isVideo,
                audioSubStreamID: loc.AudioSubStreamID,
        }</span>
}

// expandMatch expands a verified match in both directions.
func (m *Matcher) expandMatch(mkvOffset int64, loc source.Location, initialLen int64) (mkvStart, srcStart, length int64) <span class="cov8" title="20961437">{
        mkvStart = mkvOffset
        srcStart = loc.Offset
        length = initialLen

        // Get source size for bounds checking
        var srcSize int64
        if m.sourceIndex.UsesESOffsets &amp;&amp; int(loc.FileIndex) &lt; len(m.sourceIndex.ESReaders) </span><span class="cov8" title="20961437">{
                if loc.IsVideo </span><span class="cov8" title="20742951">{
                        srcSize = m.sourceIndex.ESReaders[loc.FileIndex].TotalESSize(true)
                }</span> else<span class="cov6" title="218486"> {
                        srcSize = m.sourceIndex.ESReaders[loc.FileIndex].AudioSubStreamESSize(loc.AudioSubStreamID)
                }</span>
        } else<span class="cov0" title="0"> {
                if int(loc.FileIndex) &lt; len(m.sourceIndex.Files) </span><span class="cov0" title="0">{
                        srcSize = m.sourceIndex.Files[loc.FileIndex].Size
                }</span>
        }

        <span class="cov8" title="20961437">if m.sourceIndex.UsesESOffsets </span><span class="cov8" title="20961437">{
                m.expandMatchES(mkvOffset, loc, srcSize, &amp;mkvStart, &amp;srcStart, &amp;length)
        }</span> else<span class="cov0" title="0"> {
                m.expandMatchRaw(mkvOffset, loc, srcSize, &amp;mkvStart, &amp;srcStart, &amp;length)
        }</span>

        <span class="cov8" title="20961437">return mkvStart, srcStart, length</span>
}

// expandMatchES expands a match using byte-by-byte ES reads with range hints.
// This is optimized for DVD MPEG-PS sources where ES data is non-contiguous.
func (m *Matcher) expandMatchES(mkvOffset int64, loc source.Location, srcSize int64, mkvStart, srcStart, length *int64) <span class="cov8" title="20961437">{
        // Expand backward
        backwardHint := -1
        backwardExpanded := int64(0)
        for *mkvStart &gt; 0 &amp;&amp; *srcStart &gt; 0 &amp;&amp; backwardExpanded &lt; MaxExpansionBytes </span><span class="cov10" title="2477888303">{
                mkvByte := m.mkvData[*mkvStart-1]
                readLoc := source.Location{
                        FileIndex:        loc.FileIndex,
                        Offset:           *srcStart - 1,
                        IsVideo:          loc.IsVideo,
                        AudioSubStreamID: loc.AudioSubStreamID,
                }
                srcByteVal, hint, ok := m.sourceIndex.ReadESByteWithHint(readLoc, backwardHint)
                backwardHint = hint
                if !ok || mkvByte != srcByteVal </span><span class="cov8" title="20961437">{
                        break</span>
                }
                <span class="cov9" title="2456926866">*mkvStart--
                *srcStart--
                *length++
                backwardExpanded++</span>
        }

        // Expand forward
        <span class="cov8" title="20961437">forwardHint := -1
        mkvEnd := *mkvStart + *length
        srcEnd := *srcStart + *length
        forwardExpanded := int64(0)
        for mkvEnd &lt; m.mkvSize &amp;&amp; srcEnd &lt; srcSize &amp;&amp; forwardExpanded &lt; MaxExpansionBytes </span><span class="cov9" title="2391178101">{
                mkvByte := m.mkvData[mkvEnd]
                readLoc := source.Location{
                        FileIndex:        loc.FileIndex,
                        Offset:           srcEnd,
                        IsVideo:          loc.IsVideo,
                        AudioSubStreamID: loc.AudioSubStreamID,
                }
                srcByteVal, hint, ok := m.sourceIndex.ReadESByteWithHint(readLoc, forwardHint)
                forwardHint = hint
                if !ok || mkvByte != srcByteVal </span><span class="cov8" title="20961437">{
                        break</span>
                }
                <span class="cov9" title="2370216664">mkvEnd++
                srcEnd++
                *length++
                forwardExpanded++</span>
        }
}

// expandMatchRaw expands a match using chunked reads from raw mmap'd source files.
// Reads 4KB chunks at a time to reduce page faults compared to byte-by-byte access.
func (m *Matcher) expandMatchRaw(mkvOffset int64, loc source.Location, srcSize int64, mkvStart, srcStart, length *int64) <span class="cov0" title="0">{
        // Expand backward in chunks
        backwardExpanded := int64(0)
        for *mkvStart &gt; 0 &amp;&amp; *srcStart &gt; 0 &amp;&amp; backwardExpanded &lt; MaxExpansionBytes </span><span class="cov0" title="0">{
                // Determine chunk size
                chunkLen := int64(expandChunkSize)
                if chunkLen &gt; *srcStart </span><span class="cov0" title="0">{
                        chunkLen = *srcStart
                }</span>
                <span class="cov0" title="0">if chunkLen &gt; *mkvStart </span><span class="cov0" title="0">{
                        chunkLen = *mkvStart
                }</span>
                <span class="cov0" title="0">if chunkLen &gt; MaxExpansionBytes-backwardExpanded </span><span class="cov0" title="0">{
                        chunkLen = MaxExpansionBytes - backwardExpanded
                }</span>
                <span class="cov0" title="0">if chunkLen &lt;= 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov0" title="0">srcChunk := m.sourceIndex.RawSlice(source.Location{
                        FileIndex: loc.FileIndex,
                        Offset:    *srcStart - chunkLen,
                }, int(chunkLen))
                if len(srcChunk) == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                // Compare backwards through the chunk
                <span class="cov0" title="0">mkvChunkStart := *mkvStart - int64(len(srcChunk))
                matched := int64(0)
                for i := len(srcChunk) - 1; i &gt;= 0; i-- </span><span class="cov0" title="0">{
                        if srcChunk[i] != m.mkvData[mkvChunkStart+int64(i)] </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">matched++</span>
                }

                <span class="cov0" title="0">if matched == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov0" title="0">*mkvStart -= matched
                *srcStart -= matched
                *length += matched
                backwardExpanded += matched

                if matched &lt; int64(len(srcChunk)) </span><span class="cov0" title="0">{
                        break</span>
                }
        }

        // Expand forward in chunks
        <span class="cov0" title="0">mkvEnd := *mkvStart + *length
        srcEnd := *srcStart + *length
        forwardExpanded := int64(0)
        for mkvEnd &lt; m.mkvSize &amp;&amp; srcEnd &lt; srcSize &amp;&amp; forwardExpanded &lt; MaxExpansionBytes </span><span class="cov0" title="0">{
                chunkLen := int64(expandChunkSize)
                if chunkLen &gt; srcSize-srcEnd </span><span class="cov0" title="0">{
                        chunkLen = srcSize - srcEnd
                }</span>
                <span class="cov0" title="0">if chunkLen &gt; m.mkvSize-mkvEnd </span><span class="cov0" title="0">{
                        chunkLen = m.mkvSize - mkvEnd
                }</span>
                <span class="cov0" title="0">if chunkLen &gt; MaxExpansionBytes-forwardExpanded </span><span class="cov0" title="0">{
                        chunkLen = MaxExpansionBytes - forwardExpanded
                }</span>
                <span class="cov0" title="0">if chunkLen &lt;= 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov0" title="0">srcChunk := m.sourceIndex.RawSlice(source.Location{
                        FileIndex: loc.FileIndex,
                        Offset:    srcEnd,
                }, int(chunkLen))
                if len(srcChunk) == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                // Compare forward through the chunk
                <span class="cov0" title="0">matched := int64(0)
                for i := 0; i &lt; len(srcChunk); i++ </span><span class="cov0" title="0">{
                        if srcChunk[i] != m.mkvData[mkvEnd+int64(i)] </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">matched++</span>
                }

                <span class="cov0" title="0">if matched == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov0" title="0">mkvEnd += matched
                srcEnd += matched
                *length += matched
                forwardExpanded += matched

                if matched &lt; int64(len(srcChunk)) </span><span class="cov0" title="0">{
                        break</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file35" style="display: none">package matcher

import (
        "fmt"
        "sync"
        "sync/atomic"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/mkv"
        "github.com/stuckj/mkvdup/internal/source"
)

// matchParallel processes packets in parallel using a worker pool.
func (m *Matcher) matchParallel(packets []mkv.Packet, progress ProgressFunc) int <span class="cov1" title="1">{
        var processedCount atomic.Int64
        var matchedCount atomic.Int64
        totalPackets := len(packets)

        // Create work channel
        workChan := make(chan mkv.Packet, m.numWorkers*2)

        // Start workers
        var wg sync.WaitGroup
        for i := 0; i &lt; m.numWorkers; i++ </span><span class="cov1" title="2">{
                wg.Add(1)
                go func() </span><span class="cov1" title="2">{
                        defer wg.Done()
                        for pkt := range workChan </span><span class="cov6" title="73486">{
                                matched := m.matchPacketParallel(pkt)
                                if matched </span><span class="cov6" title="73312">{
                                        matchedCount.Add(1)
                                }</span>
                                <span class="cov6" title="73486">count := processedCount.Add(1)
                                if progress != nil &amp;&amp; count%1000 == 0 </span><span class="cov0" title="0">{
                                        progress(int(count), totalPackets)
                                }</span>
                        }
                }()
        }

        // Send work to workers
        <span class="cov1" title="1">for _, pkt := range packets </span><span class="cov6" title="73486">{
                workChan &lt;- pkt
        }</span>
        <span class="cov1" title="1">close(workChan)

        // Wait for all workers to finish
        wg.Wait()

        return int(matchedCount.Load())</span>
}

// matchPacketParallel is the thread-safe version of matchPacket.
func (m *Matcher) matchPacketParallel(pkt mkv.Packet) bool <span class="cov6" title="73486">{
        // Determine if this is video or audio
        trackType := m.trackTypes[int(pkt.TrackNum)]
        isVideo := trackType == mkv.TrackTypeVideo

        if isVideo </span><span class="cov5" title="32661">{
                m.diagVideoPacketsTotal.Add(1)
        }</span>

        // Check if this region is already covered by a matched region
        // Note: This is a relaxed check - we may miss some coverage due to race conditions,
        // but that's okay since we merge overlapping regions at the end anyway
        <span class="cov6" title="73486">if m.isRangeCoveredParallel(pkt.Offset, pkt.Size) </span><span class="cov0" title="0">{
                if isVideo </span><span class="cov0" title="0">{
                        m.diagVideoPacketsCoverage.Add(1)
                }</span>
                <span class="cov0" title="0">return true</span>
        }

        // Read packet data to find sync points (zero-copy slice access)
        <span class="cov6" title="73486">readSize := pkt.Size
        if readSize &lt; int64(m.windowSize) </span><span class="cov1" title="1">{
                return false
        }</span>

        // For AVCC/HVCC video, use the full packet data. AVCC parsing is O(num_NALs)
        // not O(packet_size) — it reads 4-byte length fields and jumps, touching only
        // ~20 bytes for a typical frame with 5 NALs. Without this, large frames with
        // multiple slice NALs (common in 1080p Blu-ray) only match the first slice
        // since subsequent slices start past the truncated window.
        // For audio and Annex B video (linear scan), cap at 4096 to avoid waste.
        <span class="cov6" title="73485">var useFullPacket bool
        if isVideo </span><span class="cov5" title="32660">{
                codecInfo := m.trackCodecs[int(pkt.TrackNum)]
                if codecInfo.nalLengthSize &gt; 0 </span><span class="cov0" title="0">{
                        useFullPacket = true
                }</span>
        }
        <span class="cov6" title="73485">if !useFullPacket &amp;&amp; readSize &gt; 4096 </span><span class="cov5" title="27913">{
                readSize = 4096
        }</span>

        // Zero-copy: slice directly into mmap'd data
        <span class="cov6" title="73485">endOffset := pkt.Offset + readSize
        if endOffset &gt; m.mkvSize </span><span class="cov0" title="0">{
                endOffset = m.mkvSize
        }</span>
        <span class="cov6" title="73485">data := m.mkvData[pkt.Offset:endOffset]
        if len(data) &lt; m.windowSize </span><span class="cov0" title="0">{
                return false
        }</span>

        // Find sync points within the packet data
        <span class="cov6" title="73485">var syncPoints []int
        codecInfo := m.trackCodecs[int(pkt.TrackNum)]
        if isVideo </span><span class="cov5" title="32660">{
                if codecInfo.nalLengthSize &gt; 0 </span><span class="cov0" title="0">{
                        // AVCC/HVCC format: parse length-prefixed NAL units
                        syncPoints = source.FindAVCCNALStarts(data, codecInfo.nalLengthSize)
                }</span> else<span class="cov5" title="32660"> {
                        // Annex B format: find NAL starts after 00 00 01
                        syncPoints = source.FindVideoNALStarts(data)
                }</span>
        } else<span class="cov6" title="40825"> if trackType == mkv.TrackTypeSubtitle </span><span class="cov0" title="0">{
                syncPoints = source.FindPGSSyncPoints(data)
        }</span> else<span class="cov6" title="40825"> {
                syncPoints = source.FindAudioSyncPoints(data)
        }</span>

        // For AVCC/HVCC video, each NAL unit has different framing bytes than the
        // source (length prefix vs start code), so expansion stops at NAL boundaries.
        // We must match each NAL individually to cover the full packet.
        // For Annex B video (MPEG-2), expansion can cross start code boundaries
        // when the source data matches. However, shared structures like sequence
        // headers match many source locations with short expansions. We must
        // continue trying other sync points (e.g., slice headers) to find better
        // matches that cover the full packet.
        <span class="cov6" title="73485">anyMatched := false
        for i, syncOff := range syncPoints </span><span class="cov7" title="620808">{
                if syncOff+m.windowSize &gt; len(data) </span><span class="cov5" title="16913">{
                        if isVideo </span><span class="cov5" title="16310">{
                                m.diagVideoNALsTooSmall.Add(1)
                                m.diagNALSizeUnmatched[0].Add(1) // &lt;64B bucket
                        }</span>
                        <span class="cov5" title="16913">continue</span>
                }

                // Skip sync points whose chunk is already covered — the source data
                // for this region has already been verified byte-for-byte by a prior match.
                <span class="cov7" title="603895">if m.isChunkCoveredParallel(pkt.Offset + int64(syncOff)) </span><span class="cov6" title="121971">{
                        continue</span>
                }

                <span class="cov7" title="481924">if isVideo </span><span class="cov7" title="438185">{
                        m.diagVideoNALsTotal.Add(1)
                }</span>

                // Compute NAL size from distance to next sync point (minus length prefix).
                // For AVCC, consecutive sync points are separated by the length prefix of the
                // next NAL. For Annex B and non-video, use remaining data length.
                <span class="cov7" title="481924">nalSize := len(data) - syncOff
                if isVideo &amp;&amp; codecInfo.nalLengthSize &gt; 0 &amp;&amp; i+1 &lt; len(syncPoints) </span><span class="cov0" title="0">{
                        nalSize = syncPoints[i+1] - codecInfo.nalLengthSize - syncOff
                }</span>

                // Track NAL type for video diagnostics (H.264 only —
                // HEVC uses different NAL type encoding, MPEG-2 uses start code types)
                <span class="cov7" title="481924">var matched bool
                if isVideo &amp;&amp; m.isAVCTrack[int(pkt.TrackNum)] &amp;&amp; syncOff &lt; len(data) </span><span class="cov0" title="0">{
                        nalType := data[syncOff] &amp; 0x1F
                        m.diagNALTypeTotal[nalType].Add(1)
                        matched = m.tryMatchFromOffsetParallel(pkt, int64(syncOff), data[syncOff:], isVideo, nalSize, nalType)
                }</span> else<span class="cov7" title="481924"> {
                        matched = m.tryMatchFromOffsetParallel(pkt, int64(syncOff), data[syncOff:], isVideo, nalSize)
                }</span>

                <span class="cov7" title="481924">if matched </span><span class="cov7" title="479980">{
                        anyMatched = true
                        // Early return once the packet is fully covered
                        if m.isRangeCoveredParallel(pkt.Offset, pkt.Size) </span><span class="cov0" title="0">{
                                return true
                        }</span>
                }
        }

        // For Annex B video, if the first 4096 bytes didn't give full coverage,
        // scan the rest of the packet for additional sync points. This handles
        // cases where only shared structures (sequence headers) appear early
        // but unique slice data further in the packet would match.
        <span class="cov6" title="73485">if isVideo &amp;&amp; !useFullPacket &amp;&amp; !m.isRangeCoveredParallel(pkt.Offset, pkt.Size) &amp;&amp; pkt.Size &gt; 4096 </span><span class="cov5" title="27913">{
                fullEnd := pkt.Offset + pkt.Size
                if fullEnd &gt; m.mkvSize </span><span class="cov0" title="0">{
                        fullEnd = m.mkvSize
                }</span>
                <span class="cov5" title="27913">fullData := m.mkvData[pkt.Offset:fullEnd]
                moreSyncPoints := source.FindVideoNALStarts(fullData)
                for _, syncOff := range moreSyncPoints </span><span class="cov7" title="1071822">{
                        if syncOff &lt; int(readSize) </span><span class="cov7" title="396079">{
                                continue</span> // Already tried in the first pass
                        }
                        <span class="cov7" title="675743">if syncOff+m.windowSize &gt; len(fullData) </span><span class="cov4" title="1154">{
                                continue</span>
                        }
                        // Skip sync points whose chunk is already covered
                        <span class="cov7" title="674589">if m.isChunkCoveredParallel(pkt.Offset + int64(syncOff)) </span><span class="cov7" title="573190">{
                                continue</span>
                        }
                        <span class="cov6" title="101399">if m.tryMatchFromOffsetParallel(pkt, int64(syncOff), fullData[syncOff:], isVideo, len(fullData)-syncOff) </span><span class="cov6" title="100050">{
                                anyMatched = true
                                if m.isRangeCoveredParallel(pkt.Offset, pkt.Size) </span><span class="cov0" title="0">{
                                        return true
                                }</span>
                        }
                }
        }

        // Also try from packet start (in case it's already aligned)
        <span class="cov6" title="73485">if !anyMatched </span><span class="cov3" title="173">{
                if m.tryMatchFromOffsetParallel(pkt, 0, data, isVideo, len(data)) </span><span class="cov0" title="0">{
                        anyMatched = true
                }</span>
        }

        <span class="cov6" title="73485">return anyMatched</span>
}

// tryMatchFromOffsetParallel is a thread-safe version of tryMatchFromOffset.
// Uses two-phase locality-aware matching:
//   - Phase 1: If a locality hint exists, try the closest locations first.
//     If any produces a match &gt;= localityGoodMatchThreshold, accept immediately.
//   - Phase 2: Fall back to trying all remaining locations (handles scene changes,
//     chapter boundaries, multi-file sources).
func (m *Matcher) tryMatchFromOffsetParallel(pkt mkv.Packet, offsetInPacket int64, data []byte, isVideo bool, nalSize int, nalType ...byte) bool <span class="cov7" title="583496">{
        if len(data) &lt; m.windowSize </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov7" title="583496">window := data[:m.windowSize]
        hash := xxhash.Sum64(window)

        // Look up in source index (read-only, thread-safe)
        locations := m.sourceIndex.Lookup(hash)
        if len(locations) == 0 </span><span class="cov4" title="3466">{
                if isVideo </span><span class="cov4" title="3125">{
                        m.diagVideoNALsHashNotFound.Add(1)
                        m.diagNALSizeUnmatched[nalSizeBucket(nalSize)].Add(1)
                        if len(nalType) &gt; 0 </span><span class="cov0" title="0">{
                                m.diagNALTypeNotFound[nalType[0]].Add(1)
                        }</span>
                        // Capture first 20 examples
                        <span class="cov4" title="3125">if len(nalType) &gt; 0 </span><span class="cov0" title="0">{
                                m.diagExamplesMu.Lock()
                                if m.diagExamplesCount &lt; 20 </span><span class="cov0" title="0">{
                                        m.diagExamplesCount++
                                        example := fmt.Sprintf("  NAL type=%d, pktOff=%d, syncOff=%d, nalSize=%d, hash=%016x, first8bytes=%02x",
                                                nalType[0], pkt.Offset, offsetInPacket, nalSize, hash, data[:min(8, len(data))])
                                        m.diagExamplesOutput = append(m.diagExamplesOutput, example)
                                }</span>
                                <span class="cov0" title="0">m.diagExamplesMu.Unlock()</span>
                        }
                }
                <span class="cov4" title="3466">return false</span>
        }

        <span class="cov7" title="580030">var bestMatch *matchedRegion
        bestMatchLen := int64(0)
        triedVerify := false // whether any tryVerifyAndExpand was called

        // Track which location indices were tried in Phase 1 (small fixed-size array)
        var triedIndices [localityNearbyCount]int
        triedCount := 0

        // Phase 1: Locality-aware search — try nearby locations first
        if m.lastMatchValid.Load() &amp;&amp; len(locations) &gt; 1 </span><span class="cov6" title="62037">{
                hintFile := uint16(m.lastMatchFileIndex.Load())
                hintOffset := m.lastMatchOffset.Load()

                nearby := nearbyLocationIndices(locations, hintFile, hintOffset, localityNearbyCount)
                for _, idx := range nearby </span><span class="cov7" title="357722">{
                        triedIndices[triedCount] = idx
                        triedCount++
                        loc := locations[idx]

                        if m.sourceIndex.UsesESOffsets &amp;&amp; loc.IsVideo != isVideo </span><span class="cov0" title="0">{
                                if isVideo </span><span class="cov0" title="0">{
                                        m.diagVideoNALsSkippedIsVideo.Add(1)
                                }</span>
                                <span class="cov0" title="0">continue</span>
                        }

                        <span class="cov7" title="357722">triedVerify = true
                        region := m.tryVerifyAndExpand(pkt, loc, offsetInPacket, isVideo)
                        if region != nil </span><span class="cov7" title="357722">{
                                matchLen := region.mkvEnd - region.mkvStart
                                if matchLen &gt; bestMatchLen </span><span class="cov6" title="63837">{
                                        bestMatch = region
                                        bestMatchLen = matchLen
                                }</span>
                                // Short-circuit: a match this large is almost certainly the best
                                <span class="cov7" title="357722">if bestMatchLen &gt;= localityGoodMatchThreshold </span><span class="cov5" title="7926">{
                                        break</span>
                                }
                        }
                }
        }

        // Phase 2: Full search of remaining locations (skip if Phase 1 found a good match)
        <span class="cov7" title="580030">if bestMatchLen &lt; localityGoodMatchThreshold </span><span class="cov7" title="572104">{
                for i, loc := range locations </span><span class="cov9" title="20953104">{
                        // Skip indices already tried in Phase 1 (linear scan of small array)
                        alreadyTried := false
                        for t := 0; t &lt; triedCount; t++ </span><span class="cov10" title="162102195">{
                                if triedIndices[t] == i </span><span class="cov7" title="349389">{
                                        alreadyTried = true
                                        break</span>
                                }
                        }
                        <span class="cov9" title="20953104">if alreadyTried </span><span class="cov7" title="349389">{
                                continue</span>
                        }
                        <span class="cov9" title="20603715">if m.sourceIndex.UsesESOffsets &amp;&amp; loc.IsVideo != isVideo </span><span class="cov0" title="0">{
                                if isVideo </span><span class="cov0" title="0">{
                                        m.diagVideoNALsSkippedIsVideo.Add(1)
                                }</span>
                                <span class="cov0" title="0">continue</span>
                        }

                        <span class="cov9" title="20603715">triedVerify = true
                        region := m.tryVerifyAndExpand(pkt, loc, offsetInPacket, isVideo)
                        if region != nil </span><span class="cov9" title="20603715">{
                                matchLen := region.mkvEnd - region.mkvStart
                                if matchLen &gt; bestMatchLen </span><span class="cov7" title="530494">{
                                        bestMatch = region
                                        bestMatchLen = matchLen
                                }</span>
                        }
                }
        }

        <span class="cov7" title="580030">if bestMatch != nil </span><span class="cov7" title="580030">{
                m.regionsMu.Lock()
                m.matchedRegions = append(m.matchedRegions, *bestMatch)
                m.regionsMu.Unlock()
                // Mark chunks as covered for fast coverage checks
                m.markChunksCovered(bestMatch.mkvStart, bestMatch.mkvEnd)
                // Update locality hint with midpoint of matched source region
                m.lastMatchFileIndex.Store(uint32(bestMatch.fileIndex))
                m.lastMatchOffset.Store(bestMatch.srcOffset + bestMatchLen/2)
                m.lastMatchValid.Store(true)
                if isVideo </span><span class="cov7" title="536467">{
                        m.diagVideoNALsMatched.Add(1)
                        m.diagVideoNALsMatchedBytes.Add(bestMatchLen)
                        m.diagNALSizeMatched[nalSizeBucket(nalSize)].Add(1)
                        if len(nalType) &gt; 0 </span><span class="cov0" title="0">{
                                m.diagNALTypeMatched[nalType[0]].Add(1)
                        }</span>
                }
                <span class="cov7" title="580030">return true</span>
        }

        <span class="cov0" title="0">if isVideo </span><span class="cov0" title="0">{
                m.diagNALSizeUnmatched[nalSizeBucket(nalSize)].Add(1)
                if triedVerify </span><span class="cov0" title="0">{
                        m.diagVideoNALsVerifyFailed.Add(1)
                }</span> else<span class="cov0" title="0"> {
                        m.diagVideoNALsAllSkipped.Add(1)
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// nearbyLocationIndices returns up to N indices into locations that are closest
// to hintOffset within the same file as hintFileIndex. Locations must be pre-sorted
// by (FileIndex, Offset) via SortLocationsByOffset. Returns an empty slice if no
// locations are in the target file.
func nearbyLocationIndices(locations []source.Location, hintFileIndex uint16, hintOffset int64, maxCount int) []int <span class="cov6" title="62037">{
        n := len(locations)
        if n == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Binary search for the insertion point of (hintFileIndex, hintOffset)
        <span class="cov6" title="62037">lo, hi := 0, n
        for lo &lt; hi </span><span class="cov7" title="356885">{
                mid := lo + (hi-lo)/2
                loc := locations[mid]
                if loc.FileIndex &lt; hintFileIndex || (loc.FileIndex == hintFileIndex &amp;&amp; loc.Offset &lt; hintOffset) </span><span class="cov6" title="147161">{
                        lo = mid + 1
                }</span> else<span class="cov6" title="209724"> {
                        hi = mid
                }</span>
        }
        // lo is now the index of the first location &gt;= (hintFileIndex, hintOffset)

        // Radiate outward from lo to collect the closest locations in the same file
        <span class="cov6" title="62037">result := make([]int, 0, maxCount)
        left := lo - 1
        right := lo

        for len(result) &lt; maxCount &amp;&amp; (left &gt;= 0 || right &lt; n) </span><span class="cov7" title="398145">{
                // Pick the closer of left and right candidates
                useLeft := false
                useRight := false

                leftOK := left &gt;= 0 &amp;&amp; locations[left].FileIndex == hintFileIndex
                rightOK := right &lt; n &amp;&amp; locations[right].FileIndex == hintFileIndex

                if leftOK &amp;&amp; rightOK </span><span class="cov6" title="277949">{
                        leftDist := hintOffset - locations[left].Offset
                        rightDist := locations[right].Offset - hintOffset
                        if leftDist &lt; 0 </span><span class="cov0" title="0">{
                                leftDist = -leftDist
                        }</span>
                        <span class="cov6" title="277949">if rightDist &lt; 0 </span><span class="cov0" title="0">{
                                rightDist = -rightDist
                        }</span>
                        <span class="cov6" title="277949">if leftDist &lt;= rightDist </span><span class="cov6" title="137426">{
                                useLeft = true
                        }</span> else<span class="cov6" title="140523"> {
                                useRight = true
                        }</span>
                } else<span class="cov6" title="120196"> if leftOK </span><span class="cov5" title="29318">{
                        useLeft = true
                }</span> else<span class="cov6" title="90878"> if rightOK </span><span class="cov6" title="90878">{
                        useRight = true
                }</span> else<span class="cov0" title="0"> {
                        break</span> // No more candidates in the target file
                }

                <span class="cov7" title="398145">if useLeft </span><span class="cov6" title="166744">{
                        result = append(result, left)
                        left--
                }</span> else<span class="cov6" title="231401"> if useRight </span><span class="cov6" title="231401">{
                        result = append(result, right)
                        right++
                }</span>
        }

        <span class="cov6" title="62037">return result</span>
}

// isRangeCoveredParallel checks if a range is likely covered using a coverage bitmap.
// This is an O(1) check using chunk-level granularity. It may have false positives
// (multiple regions covering different chunks) but that's acceptable since we merge
// overlapping regions at the end anyway.
func (m *Matcher) isRangeCoveredParallel(offset, size int64) bool <span class="cov7" title="686194">{
        // Calculate chunk range
        startChunk := offset / coverageChunkSize
        endChunk := (offset + size - 1) / coverageChunkSize

        m.coverageMu.RLock()
        defer m.coverageMu.RUnlock()

        // Check if all chunks in the range are covered
        for chunk := startChunk; chunk &lt;= endChunk; chunk++ </span><span class="cov7" title="686451">{
                wordIdx := chunk / 64
                bitIdx := uint(chunk % 64)
                if wordIdx &gt;= int64(len(m.coveredChunks)) </span><span class="cov0" title="0">{
                        return false
                }</span>
                <span class="cov7" title="686451">if m.coveredChunks[wordIdx]&amp;(1&lt;&lt;bitIdx) == 0 </span><span class="cov7" title="686181">{
                        return false
                }</span>
        }
        <span class="cov2" title="13">return true</span>
}

// isChunkCoveredParallel checks if the chunk containing absOffset is already covered.
// This is used to skip sync points that fall within already-matched regions,
// avoiding redundant hash lookups and source reads.
func (m *Matcher) isChunkCoveredParallel(absOffset int64) bool <span class="cov7" title="1278484">{
        chunk := absOffset / coverageChunkSize
        wordIdx := chunk / 64
        bitIdx := uint(chunk % 64)

        m.coverageMu.RLock()
        defer m.coverageMu.RUnlock()

        if wordIdx &gt;= int64(len(m.coveredChunks)) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov7" title="1278484">return m.coveredChunks[wordIdx]&amp;(1&lt;&lt;bitIdx) != 0</span>
}

// markChunksCovered marks the chunks fully contained within a region as covered.
func (m *Matcher) markChunksCovered(start, end int64) <span class="cov7" title="580033">{
        // Only mark chunks that are fully contained within the region
        // First chunk that starts at or after 'start' and is fully contained
        firstFullChunk := (start + coverageChunkSize - 1) / coverageChunkSize
        // Last chunk that ends before 'end'
        lastFullChunk := (end / coverageChunkSize) - 1

        if firstFullChunk &gt; lastFullChunk </span><span class="cov6" title="287238">{
                // Region doesn't fully contain any chunks
                return
        }</span>

        <span class="cov6" title="292795">m.coverageMu.Lock()
        defer m.coverageMu.Unlock()

        for chunk := firstFullChunk; chunk &lt;= lastFullChunk; chunk++ </span><span class="cov7" title="1339212">{
                wordIdx := chunk / 64
                bitIdx := uint(chunk % 64)
                if wordIdx &lt; int64(len(m.coveredChunks)) </span><span class="cov7" title="1339212">{
                        m.coveredChunks[wordIdx] |= 1 &lt;&lt; bitIdx
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file36" style="display: none">// Package mkv provides functionality for parsing MKV (Matroska) files.
package mkv

import (
        "encoding/binary"
        "errors"
        "fmt"
        "io"
)

// EBML Element IDs (Matroska specification)
const (
        // EBML Header elements
        IDEBMLHeader        = 0x1A45DFA3
        IDEBMLVersion       = 0x4286
        IDEBMLReadVersion   = 0x42F7
        IDEBMLMaxIDLength   = 0x42F2
        IDEBMLMaxSizeLength = 0x42F3
        IDDocType           = 0x4282
        IDDocTypeVersion    = 0x4287
        IDDocTypeReadVer    = 0x4285

        // Segment and top-level elements
        IDSegment  = 0x18538067
        IDSeekHead = 0x114D9B74
        IDInfo     = 0x1549A966
        IDTracks   = 0x1654AE6B
        IDChapters = 0x1043A770
        IDCluster  = 0x1F43B675
        IDCues     = 0x1C53BB6B
        IDTags     = 0x1254C367

        // Cluster elements
        IDTimestamp   = 0xE7
        IDSimpleBlock = 0xA3
        IDBlockGroup  = 0xA0
        IDBlock       = 0xA1

        // Track elements
        IDTrackEntry   = 0xAE
        IDTrackNum     = 0xD7
        IDTrackUID     = 0x73C5
        IDTrackType    = 0x83
        IDCodecID      = 0x86
        IDCodecPrivate = 0x63A2
)

// Track types
const (
        TrackTypeVideo    = 1
        TrackTypeAudio    = 2
        TrackTypeComplex  = 3
        TrackTypeLogo     = 0x10
        TrackTypeSubtitle = 0x11
        TrackTypeButtons  = 0x12
        TrackTypeControl  = 0x20
)

// ErrInvalidEBML is returned when EBML parsing fails.
var ErrInvalidEBML = errors.New("invalid EBML data")

// Element represents a parsed EBML element.
type Element struct {
        ID         uint64 // Element ID (variable length)
        Size       int64  // Element size (-1 for unknown size)
        DataOffset int64  // Offset of element data in file
        HeaderSize int    // Size of ID + Size encoding
}

// ReadElementHeader reads an EBML element header (ID and size) from the reader.
// Returns the element info and any error encountered.
func ReadElementHeader(r io.Reader, offset int64) (Element, error) <span class="cov9" title="81885">{
        elem := Element{DataOffset: offset}

        // Read element ID (variable length, 1-4 bytes)
        id, idLen, err := readVINT(r, true)
        if err != nil </span><span class="cov1" title="2">{
                return elem, fmt.Errorf("read element ID: %w", err)
        }</span>
        <span class="cov9" title="81883">elem.ID = id
        elem.HeaderSize = idLen

        // Read element size (variable length, 1-8 bytes)
        size, sizeLen, err := readVINT(r, false)
        if err != nil </span><span class="cov0" title="0">{
                return elem, fmt.Errorf("read element size: %w", err)
        }</span>
        <span class="cov9" title="81883">elem.HeaderSize += sizeLen

        // Handle unknown size (all 1 bits after VINT marker)
        if isUnknownSize(size, sizeLen) </span><span class="cov1" title="3">{
                elem.Size = -1
        }</span> else<span class="cov9" title="81880"> {
                elem.Size = int64(size)
        }</span>

        <span class="cov9" title="81883">elem.DataOffset = offset + int64(elem.HeaderSize)

        return elem, nil</span>
}

// readVINT reads a variable-length integer (VINT) used in EBML.
// If keepMarker is true, the VINT marker bit is preserved (used for IDs).
// Returns the value, number of bytes read, and any error.
func readVINT(r io.Reader, keepMarker bool) (uint64, int, error) <span class="cov10" title="163783">{
        // Read first byte to determine length
        var firstByte [1]byte
        if _, err := io.ReadFull(r, firstByte[:]); err != nil </span><span class="cov1" title="1">{
                return 0, 0, err
        }</span>

        <span class="cov9" title="163782">b := firstByte[0]
        if b == 0 </span><span class="cov1" title="1">{
                return 0, 0, ErrInvalidEBML
        }</span>

        // Determine length from leading zeros
        <span class="cov9" title="163781">var length int
        var mask byte
        switch </span>{
        case b&amp;0x80 != 0:<span class="cov9" title="84678">
                length = 1
                mask = 0x7F</span>
        case b&amp;0x40 != 0:<span class="cov9" title="58751">
                length = 2
                mask = 0x3F</span>
        case b&amp;0x20 != 0:<span class="cov8" title="17535">
                length = 3
                mask = 0x1F</span>
        case b&amp;0x10 != 0:<span class="cov6" title="2805">
                length = 4
                mask = 0x0F</span>
        case b&amp;0x08 != 0:<span class="cov1" title="1">
                length = 5
                mask = 0x07</span>
        case b&amp;0x04 != 0:<span class="cov1" title="1">
                length = 6
                mask = 0x03</span>
        case b&amp;0x02 != 0:<span class="cov1" title="1">
                length = 7
                mask = 0x01</span>
        case b&amp;0x01 != 0:<span class="cov2" title="9">
                length = 8
                mask = 0x00</span>
        default:<span class="cov0" title="0">
                return 0, 0, ErrInvalidEBML</span>
        }

        // Build the value
        <span class="cov9" title="163781">var value uint64
        if keepMarker </span><span class="cov9" title="81888">{
                value = uint64(b)
        }</span> else<span class="cov9" title="81893"> {
                value = uint64(b &amp; mask)
        }</span>

        // Read remaining bytes
        <span class="cov9" title="163781">if length &gt; 1 </span><span class="cov9" title="79103">{
                remaining := make([]byte, length-1)
                if _, err := io.ReadFull(r, remaining); err != nil </span><span class="cov1" title="3">{
                        return 0, 0, err
                }</span>
                <span class="cov9" title="79100">for _, rb := range remaining </span><span class="cov9" title="102307">{
                        value = (value &lt;&lt; 8) | uint64(rb)
                }</span>
        }

        <span class="cov9" title="163778">return value, length, nil</span>
}

// isUnknownSize checks if a VINT value represents "unknown size".
// Unknown size is represented by all data bits being 1.
func isUnknownSize(value uint64, length int) bool <span class="cov9" title="81889">{
        // Unknown size values: 0x7F (1 byte), 0x3FFF (2 bytes), etc.
        maxValues := []uint64{
                0x7F,
                0x3FFF,
                0x1FFFFF,
                0x0FFFFFFF,
                0x07FFFFFFFF,
                0x03FFFFFFFFFF,
                0x01FFFFFFFFFFFF,
                0x00FFFFFFFFFFFFFF,
        }
        if length &lt; 1 || length &gt; 8 </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov9" title="81889">return value == maxValues[length-1]</span>
}

// ReadUint reads an unsigned integer element value.
func ReadUint(r io.Reader, size int64) (uint64, error) <span class="cov6" title="2802">{
        if size &lt; 0 || size &gt; 8 </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("invalid uint size: %d", size)
        }</span>
        <span class="cov6" title="2802">if size == 0 </span><span class="cov1" title="2">{
                return 0, nil
        }</span>

        <span class="cov6" title="2800">buf := make([]byte, size)
        if _, err := io.ReadFull(r, buf); err != nil </span><span class="cov1" title="1">{
                return 0, err
        }</span>

        <span class="cov6" title="2799">var value uint64
        for _, b := range buf </span><span class="cov7" title="8258">{
                value = (value &lt;&lt; 8) | uint64(b)
        }</span>
        <span class="cov6" title="2799">return value, nil</span>
}

// ReadInt reads a signed integer element value.
func ReadInt(r io.Reader, size int64) (int64, error) <span class="cov2" title="5">{
        u, err := ReadUint(r, size)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        // Sign extend if necessary
        <span class="cov2" title="5">if size &gt; 0 &amp;&amp; u&gt;&gt;(uint(size)*8-1) != 0 </span><span class="cov1" title="2">{
                // Negative number - extend sign
                mask := ^uint64(0) &lt;&lt; (uint(size) * 8)
                return int64(u | mask), nil
        }</span>
        <span class="cov1" title="3">return int64(u), nil</span>
}

// ReadString reads a string element value.
func ReadString(r io.Reader, size int64) (string, error) <span class="cov2" title="8">{
        if size &lt; 0 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("invalid string size: %d", size)
        }</span>
        <span class="cov2" title="8">if size == 0 </span><span class="cov1" title="1">{
                return "", nil
        }</span>

        <span class="cov2" title="7">buf := make([]byte, size)
        if _, err := io.ReadFull(r, buf); err != nil </span><span class="cov1" title="1">{
                return "", err
        }</span>

        // Trim null bytes
        <span class="cov2" title="6">for i := len(buf) - 1; i &gt;= 0 &amp;&amp; buf[i] == 0; i-- </span><span class="cov1" title="3">{
                buf = buf[:i]
        }</span>

        <span class="cov2" title="6">return string(buf), nil</span>
}

// ReadBinary reads binary data of the specified size.
func ReadBinary(r io.Reader, size int64) ([]byte, error) <span class="cov2" title="4">{
        if size &lt; 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid binary size: %d", size)
        }</span>
        <span class="cov2" title="4">if size == 0 </span><span class="cov1" title="1">{
                return nil, nil
        }</span>

        <span class="cov1" title="3">buf := make([]byte, size)
        if _, err := io.ReadFull(r, buf); err != nil </span><span class="cov1" title="1">{
                return nil, err
        }</span>
        <span class="cov1" title="2">return buf, nil</span>
}

// SimpleBlockHeader contains the decoded header of a SimpleBlock.
type SimpleBlockHeader struct {
        TrackNumber uint64
        Timestamp   int16 // Relative to cluster timestamp
        Flags       byte  // Keyframe, invisible, lacing, discardable
        HeaderSize  int   // Total header size in bytes
}

// Block flags
const (
        FlagKeyframe    = 0x80
        FlagInvisible   = 0x08
        FlagLacing      = 0x06 // Mask for lacing type
        FlagDiscardable = 0x01
)

// Lacing types
const (
        LacingNone  = 0x00
        LacingXiph  = 0x02
        LacingFixed = 0x04
        LacingEBML  = 0x06
)

// ParseSimpleBlockHeader parses the header of a SimpleBlock element.
// The data should start at the beginning of the SimpleBlock element data (after ID and size).
func ParseSimpleBlockHeader(data []byte) (SimpleBlockHeader, error) <span class="cov9" title="73492">{
        if len(data) &lt; 4 </span><span class="cov1" title="2">{
                return SimpleBlockHeader{}, fmt.Errorf("SimpleBlock too short: %d bytes", len(data))
        }</span>

        <span class="cov9" title="73490">var header SimpleBlockHeader
        offset := 0

        // Track number (VINT without marker)
        trackNum, trackLen := parseVINTFromBytes(data[offset:])
        header.TrackNumber = trackNum
        offset += trackLen

        if offset+3 &gt; len(data) </span><span class="cov0" title="0">{
                return SimpleBlockHeader{}, fmt.Errorf("SimpleBlock header truncated")
        }</span>

        // Timestamp (2 bytes, signed, big-endian)
        <span class="cov9" title="73490">header.Timestamp = int16(binary.BigEndian.Uint16(data[offset:]))
        offset += 2

        // Flags (1 byte)
        header.Flags = data[offset]
        offset++

        header.HeaderSize = offset
        return header, nil</span>
}

// parseVINTFromBytes parses a VINT from a byte slice (without marker preservation).
func parseVINTFromBytes(data []byte) (uint64, int) <span class="cov9" title="73494">{
        if len(data) == 0 </span><span class="cov1" title="1">{
                return 0, 0
        }</span>

        <span class="cov9" title="73493">b := data[0]
        if b == 0 </span><span class="cov1" title="1">{
                return 0, 0
        }</span>

        <span class="cov9" title="73492">var length int
        var mask byte
        switch </span>{
        case b&amp;0x80 != 0:<span class="cov9" title="73490">
                length = 1
                mask = 0x7F</span>
        case b&amp;0x40 != 0:<span class="cov1" title="2">
                length = 2
                mask = 0x3F</span>
        case b&amp;0x20 != 0:<span class="cov0" title="0">
                length = 3
                mask = 0x1F</span>
        case b&amp;0x10 != 0:<span class="cov0" title="0">
                length = 4
                mask = 0x0F</span>
        default:<span class="cov0" title="0">
                return 0, 0</span>
        }

        <span class="cov9" title="73492">if len(data) &lt; length </span><span class="cov0" title="0">{
                return 0, 0
        }</span>

        <span class="cov9" title="73492">var value uint64 = uint64(b &amp; mask)
        for i := 1; i &lt; length; i++ </span><span class="cov1" title="2">{
                value = (value &lt;&lt; 8) | uint64(data[i])
        }</span>

        <span class="cov9" title="73492">return value, length</span>
}

// IsKeyframe returns true if the SimpleBlock/Block is a keyframe.
func (h SimpleBlockHeader) IsKeyframe() bool <span class="cov9" title="73489">{
        return h.Flags&amp;FlagKeyframe != 0
}</span>

// LacingType returns the lacing type used in the block.
func (h SimpleBlockHeader) LacingType() byte <span class="cov9" title="73490">{
        return h.Flags &amp; FlagLacing
}</span>
</pre>
		
		<pre class="file" id="file37" style="display: none">package mkv

import (
        "bytes"
        "fmt"
        "io"
        "os"

        "github.com/stuckj/mkvdup/internal/mmap"
)

// Packet represents a codec data packet extracted from an MKV file.
type Packet struct {
        Offset    int64  // Offset in the MKV file where packet data starts
        Size      int64  // Size of packet data
        TrackNum  uint64 // Track number this packet belongs to
        Timestamp int64  // Absolute timestamp (cluster + block relative)
        Keyframe  bool   // Whether this is a keyframe
}

// Track represents an MKV track (video, audio, etc).
type Track struct {
        Number       uint64
        UID          uint64
        Type         int
        CodecID      string
        CodecPrivate []byte // Codec-specific init data (zero-copy slice into mmap'd data)
}

// Parser parses MKV files to extract codec packets.
type Parser struct {
        path     string
        mmapFile *mmap.File
        data     []byte // Zero-copy mmap'd data
        size     int64
        tracks   []Track
        packets  []Packet
}

// NewParser creates a new MKV parser for the given file.
func NewParser(path string) (*Parser, error) <span class="cov2" title="9">{
        info, err := os.Stat(path)
        if err != nil </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("stat file: %w", err)
        }</span>

        <span class="cov2" title="8">mmapFile, err := mmap.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("mmap file: %w", err)
        }</span>

        <span class="cov2" title="8">return &amp;Parser{
                path:     path,
                mmapFile: mmapFile,
                data:     mmapFile.Data(),
                size:     info.Size(),
        }, nil</span>
}

// Close releases resources used by the parser.
func (p *Parser) Close() error <span class="cov2" title="9">{
        if p.mmapFile != nil </span><span class="cov2" title="9">{
                return p.mmapFile.Close()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// Size returns the file size.
func (p *Parser) Size() int64 <span class="cov1" title="1">{
        return p.size
}</span>

// ProgressFunc is called to report parsing progress.
type ProgressFunc func(processed, total int64)

// Parse parses the MKV file and extracts all codec packets.
// If progress is non-nil, it will be called periodically.
func (p *Parser) Parse(progress ProgressFunc) error <span class="cov1" title="3">{
        offset := int64(0)

        // Parse EBML header
        elem, err := p.readElementAt(offset)
        if err != nil </span><span class="cov1" title="2">{
                return fmt.Errorf("read EBML header: %w", err)
        }</span>
        <span class="cov1" title="1">if elem.ID != IDEBMLHeader </span><span class="cov0" title="0">{
                return fmt.Errorf("expected EBML header, got 0x%X", elem.ID)
        }</span>
        <span class="cov1" title="1">offset = elem.DataOffset + elem.Size

        // Parse Segment
        elem, err = p.readElementAt(offset)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("read Segment: %w", err)
        }</span>
        <span class="cov1" title="1">if elem.ID != IDSegment </span><span class="cov0" title="0">{
                return fmt.Errorf("expected Segment, got 0x%X", elem.ID)
        }</span>

        <span class="cov1" title="1">segmentDataStart := elem.DataOffset
        segmentEnd := elem.DataOffset + elem.Size
        if elem.Size &lt; 0 </span><span class="cov0" title="0">{
                segmentEnd = p.size
        }</span>

        // Parse segment contents
        <span class="cov1" title="1">offset = segmentDataStart
        var clusterTimestamp int64

        for offset &lt; segmentEnd </span><span class="cov7" title="2788">{
                if progress != nil &amp;&amp; offset%(1024*1024) == 0 </span><span class="cov0" title="0">{
                        progress(offset, p.size)
                }</span>

                <span class="cov7" title="2788">elem, err = p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        if err == io.EOF </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">return fmt.Errorf("read element at %d: %w", offset, err)</span>
                }

                <span class="cov7" title="2788">switch elem.ID </span>{
                case IDTracks:<span class="cov1" title="1">
                        if err := p.parseTracks(elem); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse tracks: %w", err)
                        }</span>

                case IDCluster:<span class="cov7" title="2782">
                        if err := p.parseCluster(elem, &amp;clusterTimestamp); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse cluster at %d: %w", offset, err)
                        }</span>
                }

                // Move to next element
                <span class="cov7" title="2788">if elem.Size &lt; 0 </span><span class="cov0" title="0">{
                        // Unknown size - need to scan for next element
                        // For now, we'll just move past the header
                        offset = elem.DataOffset
                }</span> else<span class="cov7" title="2788"> {
                        offset = elem.DataOffset + elem.Size
                }</span>
        }

        <span class="cov1" title="1">if progress != nil </span><span class="cov0" title="0">{
                progress(p.size, p.size)
        }</span>

        <span class="cov1" title="1">return nil</span>
}

// readElementAt reads an EBML element header at the given offset.
func (p *Parser) readElementAt(offset int64) (Element, error) <span class="cov10" title="81881">{
        if offset &gt;= p.size </span><span class="cov1" title="1">{
                return Element{}, io.EOF
        }</span>

        // Zero-copy: create a bytes.Reader over the slice (no data copied)
        <span class="cov9" title="81880">r := bytes.NewReader(p.data[offset:])
        return ReadElementHeader(r, offset)</span>
}

// parseTracks parses the Tracks element to extract track information.
func (p *Parser) parseTracks(tracksElem Element) error <span class="cov1" title="2">{
        offset := tracksElem.DataOffset
        end := tracksElem.DataOffset + tracksElem.Size

        for offset &lt; end </span><span class="cov2" title="4">{
                elem, err := p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov2" title="4">if elem.ID == IDTrackEntry </span><span class="cov1" title="3">{
                        track, err := p.parseTrackEntry(elem)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse track entry: %w", err)
                        }</span>
                        <span class="cov1" title="3">p.tracks = append(p.tracks, track)</span>
                }

                <span class="cov2" title="4">offset = elem.DataOffset + elem.Size</span>
        }

        <span class="cov1" title="2">return nil</span>
}

// parseTrackEntry parses a TrackEntry element.
func (p *Parser) parseTrackEntry(trackElem Element) (Track, error) <span class="cov1" title="3">{
        var track Track
        offset := trackElem.DataOffset
        end := trackElem.DataOffset + trackElem.Size

        for offset &lt; end </span><span class="cov3" title="27">{
                elem, err := p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        return track, err
                }</span>

                // Zero-copy: create a bytes.Reader over the slice
                <span class="cov3" title="27">r := bytes.NewReader(p.data[elem.DataOffset : elem.DataOffset+elem.Size])

                switch elem.ID </span>{
                case IDTrackNum:<span class="cov1" title="3">
                        track.Number, _ = ReadUint(r, elem.Size)</span>
                case IDTrackUID:<span class="cov1" title="3">
                        track.UID, _ = ReadUint(r, elem.Size)</span>
                case IDTrackType:<span class="cov1" title="3">
                        t, _ := ReadUint(r, elem.Size)
                        track.Type = int(t)</span>
                case IDCodecID:<span class="cov1" title="3">
                        track.CodecID, _ = ReadString(r, elem.Size)</span>
                case IDCodecPrivate:<span class="cov1" title="1">
                        // Zero-copy: slice directly into mmap'd data
                        track.CodecPrivate = p.data[elem.DataOffset : elem.DataOffset+elem.Size]</span>
                }

                <span class="cov3" title="27">offset = elem.DataOffset + elem.Size</span>
        }

        <span class="cov1" title="3">return track, nil</span>
}

// parseCluster parses a Cluster element and extracts packets.
func (p *Parser) parseCluster(clusterElem Element, clusterTimestamp *int64) error <span class="cov7" title="2782">{
        offset := clusterElem.DataOffset
        end := clusterElem.DataOffset + clusterElem.Size
        if clusterElem.Size &lt; 0 </span><span class="cov0" title="0">{
                // Unknown size - parse until we hit another top-level element
                end = p.size
        }</span>

        <span class="cov7" title="2782">for offset &lt; end </span><span class="cov9" title="79050">{
                elem, err := p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        if err == io.EOF </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">return err</span>
                }

                // Check if we've hit a top-level element (end of cluster with unknown size)
                <span class="cov9" title="79050">if isTopLevelElement(elem.ID) &amp;&amp; clusterElem.Size &lt; 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov9" title="79050">switch elem.ID </span>{
                case IDTimestamp:<span class="cov7" title="2782">
                        // Zero-copy: create a bytes.Reader over the slice
                        r := bytes.NewReader(p.data[elem.DataOffset : elem.DataOffset+elem.Size])
                        ts, _ := ReadUint(r, elem.Size)
                        *clusterTimestamp = int64(ts)</span>

                case IDSimpleBlock:<span class="cov9" title="73486">
                        if err := p.parseSimpleBlock(elem, *clusterTimestamp); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse SimpleBlock: %w", err)
                        }</span>

                case IDBlockGroup:<span class="cov0" title="0">
                        if err := p.parseBlockGroup(elem, *clusterTimestamp); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse BlockGroup: %w", err)
                        }</span>
                }

                <span class="cov9" title="79050">offset = elem.DataOffset + elem.Size</span>
        }

        <span class="cov7" title="2782">return nil</span>
}

// parseSimpleBlock parses a SimpleBlock element and adds packets.
func (p *Parser) parseSimpleBlock(elem Element, clusterTimestamp int64) error <span class="cov9" title="73486">{
        // Zero-copy: read header bytes directly from mmap'd data
        readSize := elem.Size
        if readSize &gt; 16 </span><span class="cov9" title="73485">{
                readSize = 16 // More than enough for header
        }</span>

        <span class="cov9" title="73486">endOffset := elem.DataOffset + readSize
        if endOffset &gt; p.size </span><span class="cov0" title="0">{
                endOffset = p.size
        }</span>
        <span class="cov9" title="73486">headerBuf := p.data[elem.DataOffset:endOffset]
        if len(headerBuf) &lt; 4 </span><span class="cov0" title="0">{
                return fmt.Errorf("read SimpleBlock header: data too short")
        }</span>

        <span class="cov9" title="73486">header, err := ParseSimpleBlockHeader(headerBuf)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // The packet data follows the header
        <span class="cov9" title="73486">packetOffset := elem.DataOffset + int64(header.HeaderSize)
        packetSize := elem.Size - int64(header.HeaderSize)

        // Handle lacing if present
        if header.LacingType() != LacingNone </span><span class="cov0" title="0">{
                // For now, treat the entire laced data as one packet
                // A more complete implementation would parse individual frames
                p.packets = append(p.packets, Packet{
                        Offset:    packetOffset,
                        Size:      packetSize,
                        TrackNum:  header.TrackNumber,
                        Timestamp: clusterTimestamp + int64(header.Timestamp),
                        Keyframe:  header.IsKeyframe(),
                })
        }</span> else<span class="cov9" title="73486"> {
                p.packets = append(p.packets, Packet{
                        Offset:    packetOffset,
                        Size:      packetSize,
                        TrackNum:  header.TrackNumber,
                        Timestamp: clusterTimestamp + int64(header.Timestamp),
                        Keyframe:  header.IsKeyframe(),
                })
        }</span>

        <span class="cov9" title="73486">return nil</span>
}

// parseBlockGroup parses a BlockGroup element and adds packets.
func (p *Parser) parseBlockGroup(groupElem Element, clusterTimestamp int64) error <span class="cov0" title="0">{
        offset := groupElem.DataOffset
        end := groupElem.DataOffset + groupElem.Size

        for offset &lt; end </span><span class="cov0" title="0">{
                elem, err := p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">if elem.ID == IDBlock </span><span class="cov0" title="0">{
                        // Block has same format as SimpleBlock for the header
                        // Zero-copy: read header bytes directly from mmap'd data
                        readSize := elem.Size
                        if readSize &gt; 16 </span><span class="cov0" title="0">{
                                readSize = 16
                        }</span>

                        <span class="cov0" title="0">endOffset := elem.DataOffset + readSize
                        if endOffset &gt; p.size </span><span class="cov0" title="0">{
                                endOffset = p.size
                        }</span>
                        <span class="cov0" title="0">headerBuf := p.data[elem.DataOffset:endOffset]
                        if len(headerBuf) &lt; 4 </span><span class="cov0" title="0">{
                                return fmt.Errorf("read Block header: data too short")
                        }</span>

                        <span class="cov0" title="0">header, err := ParseSimpleBlockHeader(headerBuf)
                        if err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>

                        <span class="cov0" title="0">packetOffset := elem.DataOffset + int64(header.HeaderSize)
                        packetSize := elem.Size - int64(header.HeaderSize)

                        p.packets = append(p.packets, Packet{
                                Offset:    packetOffset,
                                Size:      packetSize,
                                TrackNum:  header.TrackNumber,
                                Timestamp: clusterTimestamp + int64(header.Timestamp),
                                Keyframe:  false, // Block doesn't have keyframe flag, would need ReferenceBlock
                        })</span>
                }

                <span class="cov0" title="0">offset = elem.DataOffset + elem.Size</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// isTopLevelElement returns true if the element ID is a top-level segment child.
func isTopLevelElement(id uint64) bool <span class="cov9" title="79060">{
        switch id </span>{
        case IDSeekHead, IDInfo, IDTracks, IDChapters, IDCluster, IDCues, IDTags:<span class="cov2" title="7">
                return true</span>
        }
        <span class="cov9" title="79053">return false</span>
}

// Packets returns all parsed packets.
func (p *Parser) Packets() []Packet <span class="cov1" title="3">{
        return p.packets
}</span>

// ParseTracksOnly parses only the track headers from the MKV file.
// This is much faster than Parse() since it stops as soon as the Tracks
// element is found, without scanning through clusters/packets.
func (p *Parser) ParseTracksOnly() error <span class="cov1" title="3">{
        offset := int64(0)

        // Parse EBML header
        elem, err := p.readElementAt(offset)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("read EBML header: %w", err)
        }</span>
        <span class="cov1" title="3">if elem.ID != IDEBMLHeader </span><span class="cov0" title="0">{
                return fmt.Errorf("expected EBML header, got 0x%X", elem.ID)
        }</span>
        <span class="cov1" title="3">offset = elem.DataOffset + elem.Size

        // Parse Segment
        elem, err = p.readElementAt(offset)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("read Segment: %w", err)
        }</span>
        <span class="cov1" title="3">if elem.ID != IDSegment </span><span class="cov0" title="0">{
                return fmt.Errorf("expected Segment, got 0x%X", elem.ID)
        }</span>

        <span class="cov1" title="3">segmentDataStart := elem.DataOffset
        segmentEnd := elem.DataOffset + elem.Size
        if elem.Size &lt; 0 </span><span class="cov1" title="1">{
                segmentEnd = p.size
        }</span>

        // Scan segment children until we find Tracks
        <span class="cov1" title="3">offset = segmentDataStart
        for offset &lt; segmentEnd </span><span class="cov1" title="2">{
                elem, err = p.readElementAt(offset)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("read element at %d: %w", offset, err)
                }</span>

                <span class="cov1" title="2">if elem.ID == IDTracks </span><span class="cov1" title="1">{
                        if err := p.parseTracks(elem); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("parse tracks: %w", err)
                        }</span>
                        <span class="cov1" title="1">return nil</span>
                }

                // Skip to next element
                <span class="cov1" title="1">if elem.Size &lt; 0 </span><span class="cov1" title="1">{
                        return fmt.Errorf("unsupported unknown-size element 0x%X before Tracks", elem.ID)
                }</span>
                <span class="cov0" title="0">offset = elem.DataOffset + elem.Size</span>
        }

        <span class="cov1" title="1">return fmt.Errorf("no Tracks element found")</span>
}

// Tracks returns all parsed tracks.
func (p *Parser) Tracks() []Track <span class="cov1" title="3">{
        return p.tracks
}</span>

// PacketCount returns the number of packets parsed.
func (p *Parser) PacketCount() int <span class="cov1" title="1">{
        return len(p.packets)
}</span>

// VideoPacketCount returns the number of video packets.
func (p *Parser) VideoPacketCount() int <span class="cov0" title="0">{
        count := 0
        videoTracks := make(map[uint64]bool)
        for _, t := range p.tracks </span><span class="cov0" title="0">{
                if t.Type == TrackTypeVideo </span><span class="cov0" title="0">{
                        videoTracks[t.Number] = true
                }</span>
        }
        <span class="cov0" title="0">for _, pkt := range p.packets </span><span class="cov0" title="0">{
                if videoTracks[pkt.TrackNum] </span><span class="cov0" title="0">{
                        count++
                }</span>
        }
        <span class="cov0" title="0">return count</span>
}

// AudioPacketCount returns the number of audio packets.
func (p *Parser) AudioPacketCount() int <span class="cov0" title="0">{
        count := 0
        audioTracks := make(map[uint64]bool)
        for _, t := range p.tracks </span><span class="cov0" title="0">{
                if t.Type == TrackTypeAudio </span><span class="cov0" title="0">{
                        audioTracks[t.Number] = true
                }</span>
        }
        <span class="cov0" title="0">for _, pkt := range p.packets </span><span class="cov0" title="0">{
                if audioTracks[pkt.TrackNum] </span><span class="cov0" title="0">{
                        count++
                }</span>
        }
        <span class="cov0" title="0">return count</span>
}

// ReadPacketData reads the data for a packet.
// Returns a slice into the mmap'd data (zero-copy).
// The returned slice is valid until Close() is called.
func (p *Parser) ReadPacketData(pkt Packet) ([]byte, error) <span class="cov0" title="0">{
        endOffset := pkt.Offset + pkt.Size
        if endOffset &gt; p.size </span><span class="cov0" title="0">{
                endOffset = p.size
        }</span>
        <span class="cov0" title="0">if pkt.Offset &gt;= p.size </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read packet data: offset out of range")
        }</span>
        // Zero-copy: return slice directly into mmap'd data
        <span class="cov0" title="0">return p.data[pkt.Offset:endOffset], nil</span>
}

// Data returns the raw mmap'd file data for zero-copy access.
// The returned slice is valid until Close() is called.
func (p *Parser) Data() []byte <span class="cov1" title="1">{
        return p.data
}</span>
</pre>
		
		<pre class="file" id="file38" style="display: none">// Package mmap provides zero-copy memory-mapped file access.
package mmap

import (
        "fmt"
        "io"
        "os"

        "golang.org/x/sys/unix"
)

// SourceFile provides read access to a source file, either via mmap or pread.
type SourceFile interface {
        io.ReaderAt
        Size() int64
        Close() error
}

// MmapData provides zero-copy access to a memory-mapped file's data.
// Types implementing this interface allow callers to use direct slice access
// instead of copying through ReadAt.
type MmapData interface {
        Data() []byte
}

// File provides zero-copy access to a memory-mapped file.
// Unlike golang.org/x/exp/mmap, this exposes the raw []byte slice
// allowing direct access without copying data.
type File struct {
        data []byte
        size int64
}

// Open opens a file and memory-maps it for reading.
// The returned File provides zero-copy access to the file contents.
func Open(path string) (*File, error) <span class="cov4" title="210">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov1" title="3">{
                return nil, fmt.Errorf("open file: %w", err)
        }</span>
        <span class="cov3" title="207">defer f.Close()

        info, err := f.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("stat file: %w", err)
        }</span>

        <span class="cov3" title="207">size := info.Size()
        if size == 0 </span><span class="cov1" title="4">{
                return &amp;File{data: nil, size: 0}, nil
        }</span>

        <span class="cov3" title="203">data, err := unix.Mmap(int(f.Fd()), 0, int(size), unix.PROT_READ, unix.MAP_SHARED)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("mmap: %w", err)
        }</span>

        <span class="cov3" title="203">return &amp;File{data: data, size: size}, nil</span>
}

// Data returns the raw byte slice for direct zero-copy access.
// The slice is valid until Close() is called.
func (m *File) Data() []byte <span class="cov7" title="74285">{
        return m.data
}</span>

// Size returns the size of the mapped file in bytes.
func (m *File) Size() int64 <span class="cov7" title="74416">{
        return m.size
}</span>

// Len returns the size of the mapped file as int (for compatibility).
func (m *File) Len() int <span class="cov1" title="2">{
        return int(m.size)
}</span>

// Slice returns a sub-slice of the mapped data without copying.
// Returns nil if the range is out of bounds.
func (m *File) Slice(offset int64, size int) []byte <span class="cov10" title="8945277">{
        if offset &lt; 0 || offset &gt;= m.size </span><span class="cov1" title="3">{
                return nil
        }</span>
        <span class="cov9" title="8945274">end := offset + int64(size)
        if end &gt; m.size </span><span class="cov1" title="1">{
                end = m.size
        }</span>
        <span class="cov9" title="8945274">return m.data[offset:end]</span>
}

// Advise provides hints to the kernel about expected access patterns.
// Use MADV_DONTNEED to release pages (they'll be re-faulted when accessed).
// Use MADV_SEQUENTIAL to hint sequential access pattern.
func (m *File) Advise(advice int) error <span class="cov2" title="22">{
        if len(m.data) == 0 </span><span class="cov1" title="1">{
                return nil
        }</span>
        <span class="cov2" title="21">return unix.Madvise(m.data, advice)</span>
}

// ReadAt implements io.ReaderAt by copying from the mmap'd data.
func (m *File) ReadAt(p []byte, off int64) (int, error) <span class="cov8" title="960549">{
        if len(p) == 0 </span><span class="cov1" title="1">{
                return 0, nil
        }</span>
        <span class="cov8" title="960548">if off &lt; 0 </span><span class="cov1" title="1">{
                return 0, os.ErrInvalid
        }</span>
        <span class="cov8" title="960547">if off &gt;= m.size </span><span class="cov1" title="2">{
                return 0, io.EOF
        }</span>
        <span class="cov8" title="960545">n := copy(p, m.data[off:])
        if n &lt; len(p) </span><span class="cov1" title="1">{
                return n, io.EOF
        }</span>
        <span class="cov8" title="960544">return n, nil</span>
}

// Close unmaps the file from memory.
func (m *File) Close() error <span class="cov3" title="197">{
        if m.data == nil </span><span class="cov2" title="8">{
                return nil
        }</span>

        <span class="cov3" title="189">if err := unix.Munmap(m.data); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov3" title="189">m.data = nil
        m.size = 0
        return nil</span>
}
</pre>
		
		<pre class="file" id="file39" style="display: none">package mmap

import (
        "errors"
        "fmt"
        "io"
        "os"
        "sync"
        "time"

        "golang.org/x/sys/unix"
)

// ReadTimeoutError is returned when a pread operation exceeds the configured timeout.
type ReadTimeoutError struct {
        Path    string
        Timeout time.Duration
}

func (e *ReadTimeoutError) Error() string <span class="cov1" title="1">{
        return fmt.Sprintf("pread timeout after %s: %s", e.Timeout, e.Path)
}</span>

// ReadBackpressureError is returned when all inflight read slots are occupied,
// indicating the network FS is likely stalled. This is distinct from
// ReadTimeoutError, which indicates a single read exceeded its deadline.
type ReadBackpressureError struct {
        Path string
}

func (e *ReadBackpressureError) Error() string <span class="cov1" title="1">{
        return fmt.Sprintf("pread backpressure: all %d inflight slots occupied: %s", maxInflight, e.Path)
}</span>

// maxInflight is the maximum number of concurrent in-flight read goroutines
// per PreadFile. This bounds memory/goroutine accumulation when an NFS mount
// is stalled and reads are timing out repeatedly.
const maxInflight = 16

// PreadFile provides pread(2)-based read access to a source file, with retry
// and stale handle recovery. This is used for source files on network
// filesystems (NFS, CIFS/SMB) where mmap is unsafe due to SIGBUS on
// page fault failures.
type PreadFile struct {
        mu         sync.Mutex // protects file and staleFiles
        file       *os.File
        path       string
        size       int64
        timeout    time.Duration // 0 = no timeout
        inflight   chan struct{} // semaphore bounding concurrent timeout goroutines
        staleFiles []*os.File    // old fds kept open until Close to avoid EBADF on in-flight reads
}

// OpenPread opens a file for pread-based access.
func OpenPread(path string, timeout time.Duration) (*PreadFile, error) <span class="cov9" title="10">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("open file: %w", err)
        }</span>

        <span class="cov8" title="9">info, err := f.Stat()
        if err != nil </span><span class="cov0" title="0">{
                f.Close()
                return nil, fmt.Errorf("stat file: %w", err)
        }</span>

        <span class="cov8" title="9">return &amp;PreadFile{
                file:     f,
                path:     path,
                size:     info.Size(),
                timeout:  timeout,
                inflight: make(chan struct{}, maxInflight),
        }, nil</span>
}

// Size returns the size of the file.
func (p *PreadFile) Size() int64 <span class="cov1" title="1">{
        return p.size
}</span>

// ReadAt reads len(buf) bytes from the file starting at byte offset off.
// If timeout is configured and the read takes too long, it returns a
// ReadTimeoutError. The underlying goroutine may continue until the kernel
// completes the I/O, but the caller is unblocked. The goroutine reads into
// a private buffer to prevent it from writing to buf after the caller has
// moved on. A per-file semaphore bounds the number of in-flight goroutines
// to prevent unbounded accumulation under a stalled NFS mount.
func (p *PreadFile) ReadAt(buf []byte, off int64) (int, error) <span class="cov10" title="12">{
        if len(buf) == 0 </span><span class="cov3" title="2">{
                return 0, nil
        }</span>

        <span class="cov9" title="10">if p.timeout &lt;= 0 </span><span class="cov8" title="7">{
                return p.readAtWithRetry(buf, off)
        }</span>

        // Acquire an inflight slot (non-blocking). If all slots are occupied
        // the NFS mount is likely stalled — fail fast instead of spawning
        // more goroutines.
        <span class="cov4" title="3">select </span>{
        case p.inflight &lt;- struct{}{}:<span class="cov4" title="3"></span>
        default:<span class="cov0" title="0">
                return 0, &amp;ReadBackpressureError{Path: p.path}</span>
        }

        <span class="cov4" title="3">type result struct {
                n   int
                err error
        }
        // Read into a private buffer so an abandoned goroutine (after timeout)
        // cannot write into buf while it is being reused by the caller.
        tmp := make([]byte, len(buf))
        ch := make(chan result, 1)
        go func() </span><span class="cov4" title="3">{
                defer func() </span><span class="cov4" title="3">{ &lt;-p.inflight }</span>()
                <span class="cov4" title="3">n, err := p.readAtWithRetry(tmp, off)
                ch &lt;- result{n, err}</span>
        }()

        <span class="cov4" title="3">timer := time.NewTimer(p.timeout)
        defer timer.Stop()

        select </span>{
        case r := &lt;-ch:<span class="cov4" title="3">
                copy(buf[:r.n], tmp[:r.n])
                return r.n, r.err</span>
        case &lt;-timer.C:<span class="cov0" title="0">
                return 0, &amp;ReadTimeoutError{Path: p.path, Timeout: p.timeout}</span>
        }
}

// readAtWithRetry performs a pread with one retry on retryable errors,
// reopening the file descriptor if needed. The mutex is only held briefly
// to copy the fd pointer — not during the pread syscall — so Close() and
// reopen() are never blocked by a stalled network read. Old fds from
// reopen are kept in staleFiles (not closed) to avoid EBADF on
// concurrent in-flight reads; they are cleaned up on Close().
func (p *PreadFile) readAtWithRetry(buf []byte, off int64) (int, error) <span class="cov9" title="10">{
        p.mu.Lock()
        f := p.file
        p.mu.Unlock()

        if f == nil </span><span class="cov0" title="0">{
                return 0, os.ErrClosed
        }</span>

        <span class="cov9" title="10">n, err := f.ReadAt(buf, off)
        if err != nil &amp;&amp; err != io.EOF &amp;&amp; isRetryableError(err) </span><span class="cov0" title="0">{
                if reopenErr := p.reopen(); reopenErr != nil </span><span class="cov0" title="0">{
                        return n, fmt.Errorf("pread retry failed (reopen: %w, original: %w)", reopenErr, err)
                }</span>

                <span class="cov0" title="0">p.mu.Lock()
                f = p.file
                p.mu.Unlock()

                if f == nil </span><span class="cov0" title="0">{
                        return 0, os.ErrClosed
                }</span>
                <span class="cov0" title="0">n, err = f.ReadAt(buf, off)</span>
        }
        <span class="cov9" title="10">return n, err</span>
}

// reopen opens a new fd and swaps it in. The old fd is not closed
// immediately because in-flight goroutines may still hold a reference
// to it (copied under the mutex before the pread syscall). Old fds are
// collected in staleFiles and cleaned up on Close().
//
// Fd accumulation is bounded in practice: reopens only occur on transient
// network errors (ESTALE, ETIMEDOUT, etc.), which are rare. Even under
// a flaky mount, each reopen adds just one fd, well within default ulimits.
func (p *PreadFile) reopen() error <span class="cov3" title="2">{
        p.mu.Lock()
        defer p.mu.Unlock()

        if p.file == nil </span><span class="cov0" title="0">{
                return os.ErrClosed
        }</span>

        <span class="cov3" title="2">newFile, err := os.Open(p.path)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("reopen: %w", err)
        }</span>

        <span class="cov3" title="2">info, err := newFile.Stat()
        if err != nil </span><span class="cov0" title="0">{
                newFile.Close()
                return fmt.Errorf("reopen stat: %w", err)
        }</span>

        <span class="cov3" title="2">if info.Size() != p.size </span><span class="cov1" title="1">{
                newFile.Close()
                return fmt.Errorf("reopen: size changed (%d → %d)", p.size, info.Size())
        }</span>

        <span class="cov1" title="1">p.staleFiles = append(p.staleFiles, p.file)
        p.file = newFile
        return nil</span>
}

// Close closes the current file and any stale fds from previous reopens.
func (p *PreadFile) Close() error <span class="cov9" title="10">{
        p.mu.Lock()
        defer p.mu.Unlock()

        var firstErr error
        if p.file != nil </span><span class="cov8" title="9">{
                firstErr = p.file.Close()
                p.file = nil
        }</span>
        <span class="cov9" title="10">for _, f := range p.staleFiles </span><span class="cov1" title="1">{
                if err := f.Close(); err != nil &amp;&amp; firstErr == nil </span><span class="cov0" title="0">{
                        firstErr = err
                }</span>
        }
        <span class="cov9" title="10">p.staleFiles = nil
        return firstErr</span>
}

// isRetryableError checks if an error is a transient network FS error
// that may succeed on retry (possibly after reopening the fd).
func isRetryableError(err error) bool <span class="cov10" title="12">{
        var errno unix.Errno
        if errors.As(err, &amp;errno) </span><span class="cov9" title="10">{
                switch errno </span>{
                case unix.ESTALE, unix.ETIMEDOUT, unix.ECONNRESET, unix.EIO:<span class="cov8" title="8">
                        return true</span>
                }
        }
        <span class="cov6" title="4">return false</span>
}
</pre>
		
		<pre class="file" id="file40" style="display: none">package source

// FindAudioSyncPoints finds all audio sync pattern positions in the data.
// Detects AC3, DTS, TrueHD, and MPEG Audio sync patterns.
// Returns offsets where sync patterns begin.
func FindAudioSyncPoints(data []byte) []int <span class="cov6" title="129870">{
        if len(data) &lt; 2 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov6" title="129870">var offsets []int

        for i := 0; i &lt;= len(data)-2; i++ </span><span class="cov10" title="205807311">{
                // AC3/E-AC3: 0B 77
                if data[i] == 0x0B &amp;&amp; data[i+1] == 0x77 </span><span class="cov6" title="240670">{
                        offsets = append(offsets, i)
                        continue</span>
                }

                // DTS/DTS-HD: 7F FE 80 01
                <span class="cov9" title="205566641">if i &lt;= len(data)-4 &amp;&amp;
                        data[i] == 0x7F &amp;&amp; data[i+1] == 0xFE &amp;&amp;
                        data[i+2] == 0x80 &amp;&amp; data[i+3] == 0x01 </span><span class="cov1" title="3">{
                        offsets = append(offsets, i)
                        continue</span>
                }

                // TrueHD: F8 72 6F BA
                <span class="cov9" title="205566638">if i &lt;= len(data)-4 &amp;&amp;
                        data[i] == 0xF8 &amp;&amp; data[i+1] == 0x72 &amp;&amp;
                        data[i+2] == 0x6F &amp;&amp; data[i+3] == 0xBA </span><span class="cov1" title="2">{
                        offsets = append(offsets, i)
                        continue</span>
                }

                // MPEG Audio / AAC ADTS: FF Fx (0xFF followed by 0xF0-0xFF)
                // The sync word is 11 bits of 1s, so we check for 0xFF followed by 0xFx.
                // Validate byte 2: bitrate index 1111 (upper nibble 0xF) is reserved/invalid.
                // This eliminates massive false positives from 0xFF adaptation field padding
                // in MPEG-TS, where every consecutive byte pair in a 0xFF run would match.
                <span class="cov9" title="205566636">if i &lt;= len(data)-3 &amp;&amp;
                        data[i] == 0xFF &amp;&amp; (data[i+1]&amp;0xF0) == 0xF0 &amp;&amp;
                        (data[i+2]&amp;0xF0) != 0xF0 </span><span class="cov6" title="61863">{
                        offsets = append(offsets, i)
                        continue</span>
                }
        }

        <span class="cov6" title="129870">return offsets</span>
}

// FindAudioSyncPointsInRange finds audio sync points within a specific range of data.
// This is useful for processing large files in chunks.
func FindAudioSyncPointsInRange(data []byte, startOffset int) []int <span class="cov1" title="1">{
        if len(data) &lt; 2 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov1" title="1">var offsets []int

        for i := 0; i &lt;= len(data)-2; i++ </span><span class="cov1" title="4">{
                // AC3/E-AC3: 0B 77
                if data[i] == 0x0B &amp;&amp; data[i+1] == 0x77 </span><span class="cov1" title="2">{
                        offsets = append(offsets, startOffset+i)
                        continue</span>
                }

                // DTS/DTS-HD: 7F FE 80 01
                <span class="cov1" title="2">if i &lt;= len(data)-4 &amp;&amp;
                        data[i] == 0x7F &amp;&amp; data[i+1] == 0xFE &amp;&amp;
                        data[i+2] == 0x80 &amp;&amp; data[i+3] == 0x01 </span><span class="cov0" title="0">{
                        offsets = append(offsets, startOffset+i)
                        continue</span>
                }

                // TrueHD: F8 72 6F BA
                <span class="cov1" title="2">if i &lt;= len(data)-4 &amp;&amp;
                        data[i] == 0xF8 &amp;&amp; data[i+1] == 0x72 &amp;&amp;
                        data[i+2] == 0x6F &amp;&amp; data[i+3] == 0xBA </span><span class="cov0" title="0">{
                        offsets = append(offsets, startOffset+i)
                        continue</span>
                }

                // MPEG Audio / AAC ADTS: FF Fx with valid bitrate index
                <span class="cov1" title="2">if i &lt;= len(data)-3 &amp;&amp;
                        data[i] == 0xFF &amp;&amp; (data[i+1]&amp;0xF0) == 0xF0 &amp;&amp;
                        (data[i+2]&amp;0xF0) != 0xF0 </span><span class="cov0" title="0">{
                        offsets = append(offsets, startOffset+i)
                        continue</span>
                }
        }

        <span class="cov1" title="1">return offsets</span>
}

// AC3FrameSize returns the frame size in bytes for an AC3 sync frame given
// the fscod (sample rate code, 2 bits) and frmsizecod (frame size code, 6 bits)
// from byte 4 of the sync frame. Returns 0 if the codes are invalid.
// Based on ATSC A/52 Table 5.18.
func AC3FrameSize(fscod, frmsizecod byte) int <span class="cov3" title="141">{
        if frmsizecod &gt;= 38 || fscod &gt;= 3 </span><span class="cov1" title="4">{
                return 0
        }</span>
        // Frame sizes in 16-bit words, indexed by [fscod][frmsizecod]
        <span class="cov3" title="137">var frameSizeWords = [3][38]int{
                // 48 kHz
                {64, 64, 80, 80, 96, 96, 112, 112, 128, 128, 160, 160, 192, 192, 224, 224, 256, 256, 320, 320, 384, 384, 448, 448, 512, 512, 640, 640, 768, 768, 896, 896, 1024, 1024, 1152, 1152, 1280, 1280},
                // 44.1 kHz
                {69, 70, 87, 88, 104, 105, 121, 122, 139, 140, 174, 175, 208, 209, 243, 244, 278, 279, 348, 349, 417, 418, 487, 488, 557, 558, 696, 697, 835, 836, 975, 976, 1114, 1115, 1253, 1254, 1393, 1394},
                // 32 kHz
                {96, 96, 120, 120, 144, 144, 168, 168, 192, 192, 240, 240, 288, 288, 336, 336, 384, 384, 480, 480, 576, 576, 672, 672, 768, 768, 960, 960, 1152, 1152, 1344, 1344, 1536, 1536, 1728, 1728, 1920, 1920},
        }
        return frameSizeWords[fscod][frmsizecod] * 2</span>
}

// FindAllSyncPoints finds both video start codes and audio sync patterns.
// Returns combined offsets sorted by position.
func FindAllSyncPoints(data []byte) []int <span class="cov1" title="1">{
        videoOffsets := FindVideoStartCodes(data)
        audioOffsets := FindAudioSyncPoints(data)

        // Combine and sort
        combined := make([]int, 0, len(videoOffsets)+len(audioOffsets))
        combined = append(combined, videoOffsets...)
        combined = append(combined, audioOffsets...)

        // Simple insertion sort since lists are already sorted
        // and we just need to merge them
        result := make([]int, 0, len(combined))
        vi, ai := 0, 0
        for vi &lt; len(videoOffsets) || ai &lt; len(audioOffsets) </span><span class="cov1" title="3">{
                if vi &gt;= len(videoOffsets) </span><span class="cov0" title="0">{
                        result = append(result, audioOffsets[ai])
                        ai++
                }</span> else<span class="cov1" title="3"> if ai &gt;= len(audioOffsets) </span><span class="cov1" title="1">{
                        result = append(result, videoOffsets[vi])
                        vi++
                }</span> else<span class="cov1" title="2"> if videoOffsets[vi] &lt;= audioOffsets[ai] </span><span class="cov1" title="1">{
                        result = append(result, videoOffsets[vi])
                        vi++
                }</span> else<span class="cov1" title="1"> {
                        result = append(result, audioOffsets[ai])
                        ai++
                }</span>
        }

        <span class="cov1" title="1">return result</span>
}
</pre>
		
		<pre class="file" id="file41" style="display: none">package source

import (
        "fmt"
        "os"
        "path/filepath"
        "strings"

        "github.com/stuckj/mkvdup/internal/mkv"
)

// CodecType represents a broad codec family.
type CodecType int

// Codec type constants.
const (
        CodecUnknown CodecType = iota
        CodecMPEG1Video
        CodecMPEG2Video
        CodecH264Video
        CodecH265Video
        CodecVC1Video
        CodecAC3Audio
        CodecEAC3Audio
        CodecDTSAudio
        CodecDTSHDAudio
        CodecTrueHDAudio
        CodecLPCMAudio
        CodecMPEGAudio
        CodecAACaudio
        CodecFLACAudio
        CodecOpusAudio
        CodecPGSSubtitle
)

// CodecTypeName returns a human-readable name for a codec type.
func CodecTypeName(ct CodecType) string <span class="cov7" title="20">{
        switch ct </span>{
        case CodecMPEG1Video:<span class="cov1" title="1">
                return "MPEG-1"</span>
        case CodecMPEG2Video:<span class="cov3" title="3">
                return "MPEG-2"</span>
        case CodecH264Video:<span class="cov3" title="3">
                return "H.264"</span>
        case CodecH265Video:<span class="cov1" title="1">
                return "H.265"</span>
        case CodecVC1Video:<span class="cov1" title="1">
                return "VC-1"</span>
        case CodecAC3Audio:<span class="cov1" title="1">
                return "AC3"</span>
        case CodecEAC3Audio:<span class="cov1" title="1">
                return "E-AC3"</span>
        case CodecDTSAudio:<span class="cov1" title="1">
                return "DTS"</span>
        case CodecDTSHDAudio:<span class="cov1" title="1">
                return "DTS-HD"</span>
        case CodecTrueHDAudio:<span class="cov1" title="1">
                return "TrueHD"</span>
        case CodecLPCMAudio:<span class="cov1" title="1">
                return "LPCM"</span>
        case CodecMPEGAudio:<span class="cov1" title="1">
                return "MPEG Audio"</span>
        case CodecAACaudio:<span class="cov1" title="1">
                return "AAC"</span>
        case CodecFLACAudio:<span class="cov1" title="1">
                return "FLAC"</span>
        case CodecOpusAudio:<span class="cov1" title="1">
                return "Opus"</span>
        case CodecPGSSubtitle:<span class="cov0" title="0">
                return "PGS"</span>
        default:<span class="cov1" title="1">
                return "Unknown"</span>
        }
}

// IsVideoCodec returns true if the codec type is a video codec.
func IsVideoCodec(ct CodecType) bool <span class="cov10" title="85">{
        switch ct </span>{
        case CodecMPEG1Video, CodecMPEG2Video, CodecH264Video, CodecH265Video, CodecVC1Video:<span class="cov8" title="34">
                return true</span>
        }
        <span class="cov8" title="51">return false</span>
}

// IsSubtitleCodec returns true if the codec type is a subtitle codec.
func IsSubtitleCodec(ct CodecType) bool <span class="cov9" title="55">{
        return ct == CodecPGSSubtitle
}</span>

// IsAudioCodec returns true if the codec type is an audio codec.
func IsAudioCodec(ct CodecType) bool <span class="cov9" title="69">{
        switch ct </span>{
        case CodecAC3Audio, CodecEAC3Audio, CodecDTSAudio, CodecDTSHDAudio,
                CodecTrueHDAudio, CodecLPCMAudio, CodecMPEGAudio, CodecAACaudio,
                CodecFLACAudio, CodecOpusAudio:<span class="cov8" title="48">
                return true</span>
        }
        <span class="cov7" title="21">return false</span>
}

// MKVCodecToType maps an MKV CodecID string to a CodecType.
func MKVCodecToType(codecID string) CodecType <span class="cov8" title="41">{
        switch </span>{
        case codecID == "V_MPEG1":<span class="cov2" title="2">
                return CodecMPEG1Video</span>
        case codecID == "V_MPEG2":<span class="cov3" title="3">
                return CodecMPEG2Video</span>
        case codecID == "V_MPEG4/ISO/AVC":<span class="cov3" title="3">
                return CodecH264Video</span>
        case codecID == "V_MPEGH/ISO/HEVC":<span class="cov1" title="1">
                return CodecH265Video</span>
        case codecID == "V_MS/VFW/FOURCC":<span class="cov2" title="2">
                // Could be VC-1 or other; can't determine without codec private data
                return CodecUnknown</span>
        case codecID == "A_AC3":<span class="cov4" title="6">
                return CodecAC3Audio</span>
        case codecID == "A_EAC3":<span class="cov1" title="1">
                return CodecEAC3Audio</span>
        case codecID == "A_DTS":<span class="cov2" title="2">
                return CodecDTSAudio</span>
        case strings.HasPrefix(codecID, "A_DTS/"):<span class="cov2" title="2">
                // A_DTS/EXPRESS, A_DTS/LOSSLESS, etc.
                return CodecDTSHDAudio</span>
        case codecID == "A_TRUEHD":<span class="cov1" title="1">
                return CodecTrueHDAudio</span>
        case strings.HasPrefix(codecID, "A_PCM/"):<span class="cov3" title="3">
                // A_PCM/INT/LIT, A_PCM/INT/BIG, A_PCM/FLOAT/IEEE
                return CodecLPCMAudio</span>
        case strings.HasPrefix(codecID, "A_MPEG/"):<span class="cov2" title="2">
                // A_MPEG/L2, A_MPEG/L3
                return CodecMPEGAudio</span>
        case strings.HasPrefix(codecID, "A_AAC"):<span class="cov2" title="2">
                // A_AAC, A_AAC/MPEG2/MAIN, etc.
                return CodecAACaudio</span>
        case codecID == "A_FLAC":<span class="cov3" title="3">
                return CodecFLACAudio</span>
        case codecID == "A_OPUS":<span class="cov1" title="1">
                return CodecOpusAudio</span>
        case codecID == "S_HDMV/PGS":<span class="cov3" title="3">
                return CodecPGSSubtitle</span>
        default:<span class="cov3" title="4">
                return CodecUnknown</span>
        }
}

// SourceCodecs describes the codecs found in a source media.
type SourceCodecs struct {
        VideoCodecs    []CodecType
        AudioCodecs    []CodecType
        SubtitleCodecs []CodecType
}

// CodecMismatch describes a detected codec mismatch between MKV and source.
type CodecMismatch struct {
        TrackType    string      // "video" or "audio"
        MKVCodecID   string      // e.g. "V_MPEG4/ISO/AVC"
        MKVCodecType CodecType   // resolved codec type
        SourceCodecs []CodecType // codecs found in source for this track type
}

// DetectSourceCodecs determines what codecs are present in the source media.
// For DVD sources, it extracts codec info from the already-parsed MPEG-PS data.
// For Blu-ray sources, it performs a lightweight PMT scan of the first M2TS file.
func DetectSourceCodecs(index *Index) (*SourceCodecs, error) <span class="cov0" title="0">{
        switch index.SourceType </span>{
        case TypeDVD:<span class="cov0" title="0">
                return detectDVDCodecs(index)</span>
        case TypeBluray:<span class="cov0" title="0">
                return detectBlurayCodecs(index)</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unknown source type")</span>
        }
}

// DetectSourceCodecsFromDir performs a lightweight codec detection from a source
// directory without building the full hash index. This allows codec compatibility
// checks to run before the expensive indexing step.
func DetectSourceCodecsFromDir(sourceDir string) (*SourceCodecs, error) <span class="cov5" title="9">{
        sourceType, err := DetectType(sourceDir)
        if err != nil </span><span class="cov5" title="9">{
                return nil, fmt.Errorf("detect source type: %w", err)
        }</span>

        <span class="cov0" title="0">files, err := EnumerateMediaFiles(sourceDir, sourceType)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("enumerate files: %w", err)
        }</span>
        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no media files found in %s", sourceDir)
        }</span>

        // Find the largest file (most likely the main feature)
        <span class="cov0" title="0">var largestFile string
        var largestSize int64
        for _, f := range files </span><span class="cov0" title="0">{
                fullPath := filepath.Join(sourceDir, f)
                info, err := os.Stat(fullPath)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">if info.Size() &gt; largestSize </span><span class="cov0" title="0">{
                        largestSize = info.Size()
                        largestFile = f
                }</span>
        }
        <span class="cov0" title="0">if largestFile == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no accessible media files found")
        }</span>

        <span class="cov0" title="0">fullPath := filepath.Join(sourceDir, largestFile)

        switch sourceType </span>{
        case TypeBluray:<span class="cov0" title="0">
                return detectBlurayCodecsFromFile(fullPath)</span>
        case TypeDVD:<span class="cov0" title="0">
                return detectDVDCodecsFromFile(fullPath)</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unknown source type")</span>
        }
}

// CheckCodecCompatibility compares MKV track codecs against source codecs.
// Returns nil if all codecs are compatible, or a list of mismatches.
func CheckCodecCompatibility(tracks []mkv.Track, sourceCodecs *SourceCodecs) []CodecMismatch <span class="cov6" title="12">{
        var mismatches []CodecMismatch

        for _, track := range tracks </span><span class="cov6" title="18">{
                ct := MKVCodecToType(track.CodecID)
                if ct == CodecUnknown </span><span class="cov3" title="3">{
                        continue</span> // Skip unknown codecs — no false alarms
                }

                <span class="cov6" title="15">if track.Type == mkv.TrackTypeVideo &amp;&amp; IsVideoCodec(ct) </span><span class="cov4" title="5">{
                        if len(sourceCodecs.VideoCodecs) == 0 </span><span class="cov1" title="1">{
                                continue</span> // No source video info available
                        }
                        <span class="cov3" title="4">if !codecFamilyMatch(ct, sourceCodecs.VideoCodecs) </span><span class="cov1" title="1">{
                                mismatches = append(mismatches, CodecMismatch{
                                        TrackType:    "video",
                                        MKVCodecID:   track.CodecID,
                                        MKVCodecType: ct,
                                        SourceCodecs: sourceCodecs.VideoCodecs,
                                })
                        }</span>
                } else<span class="cov5" title="10"> if track.Type == mkv.TrackTypeAudio &amp;&amp; IsAudioCodec(ct) </span><span class="cov5" title="8">{
                        if len(sourceCodecs.AudioCodecs) == 0 </span><span class="cov1" title="1">{
                                continue</span> // No source audio info available
                        }
                        <span class="cov4" title="7">if !codecFamilyMatch(ct, sourceCodecs.AudioCodecs) </span><span class="cov2" title="2">{
                                mismatches = append(mismatches, CodecMismatch{
                                        TrackType:    "audio",
                                        MKVCodecID:   track.CodecID,
                                        MKVCodecType: ct,
                                        SourceCodecs: sourceCodecs.AudioCodecs,
                                })
                        }</span>
                } else<span class="cov2" title="2"> if track.Type == mkv.TrackTypeSubtitle &amp;&amp; IsSubtitleCodec(ct) </span><span class="cov2" title="2">{
                        if len(sourceCodecs.SubtitleCodecs) == 0 </span><span class="cov1" title="1">{
                                continue</span> // No source subtitle info available
                        }
                        <span class="cov1" title="1">if !codecFamilyMatch(ct, sourceCodecs.SubtitleCodecs) </span><span class="cov0" title="0">{
                                mismatches = append(mismatches, CodecMismatch{
                                        TrackType:    "subtitle",
                                        MKVCodecID:   track.CodecID,
                                        MKVCodecType: ct,
                                        SourceCodecs: sourceCodecs.SubtitleCodecs,
                                })
                        }</span>
                }
        }

        <span class="cov6" title="12">return mismatches</span>
}

// codecFamilyMatch checks if a codec type is compatible with any codec in the list.
// Uses family-based matching (e.g., DTS is compatible with DTS-HD).
func codecFamilyMatch(ct CodecType, sourceCodecs []CodecType) bool <span class="cov6" title="12">{
        family := codecFamily(ct)
        for _, sc := range sourceCodecs </span><span class="cov6" title="13">{
                if codecFamily(sc) == family </span><span class="cov5" title="9">{
                        return true
                }</span>
        }
        <span class="cov3" title="3">return false</span>
}

// codecFamily returns the codec family for family-based matching.
// Related codecs map to the same family value.
func codecFamily(ct CodecType) int <span class="cov7" title="25">{
        switch ct </span>{
        case CodecMPEG1Video, CodecMPEG2Video:<span class="cov4" title="7">
                return 1</span>
        case CodecH264Video:<span class="cov1" title="1">
                return 2</span>
        case CodecH265Video:<span class="cov0" title="0">
                return 3</span>
        case CodecVC1Video:<span class="cov0" title="0">
                return 4</span>
        case CodecAC3Audio, CodecEAC3Audio:<span class="cov5" title="10">
                return 10</span>
        case CodecDTSAudio, CodecDTSHDAudio:<span class="cov3" title="3">
                return 11</span>
        case CodecTrueHDAudio:<span class="cov0" title="0">
                return 12</span>
        case CodecLPCMAudio:<span class="cov0" title="0">
                return 13</span>
        case CodecMPEGAudio:<span class="cov0" title="0">
                return 14</span>
        case CodecAACaudio:<span class="cov0" title="0">
                return 15</span>
        case CodecFLACAudio:<span class="cov2" title="2">
                return 16</span>
        case CodecOpusAudio:<span class="cov0" title="0">
                return 17</span>
        case CodecPGSSubtitle:<span class="cov2" title="2">
                return 20</span>
        default:<span class="cov0" title="0">
                return 0</span>
        }
}

// containsCodec checks if a codec type is already in the list.
func containsCodec(codecs []CodecType, ct CodecType) bool <span class="cov7" title="22">{
        for _, c := range codecs </span><span class="cov4" title="5">{
                if c == ct </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov7" title="22">return false</span>
}
</pre>
		
		<pre class="file" id="file42" style="display: none">package source

import "fmt"

// binarySearchRanges performs binary search on PES payload ranges to find the one
// containing the given ES offset. Returns the index, or -1 if not found.
func binarySearchRanges(ranges []PESPayloadRange, esOffset int64) int <span class="cov8" title="63080680">{
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return -1
        }</span>

        <span class="cov8" title="63080680">low, high := 0, len(ranges)-1
        for low &lt;= high </span><span class="cov10" title="1216671257">{
                mid := (low + high) / 2
                r := ranges[mid]
                if esOffset &lt; r.ESOffset </span><span class="cov9" title="577107200">{
                        high = mid - 1
                }</span> else<span class="cov9" title="639564057"> if esOffset &gt;= r.ESOffset+int64(r.Size) </span><span class="cov9" title="576483380">{
                        low = mid + 1
                }</span> else<span class="cov8" title="63080677"> {
                        return mid
                }</span>
        }
        <span class="cov1" title="3">return -1</span>
}

// readByteAt reads a single byte from data or multiRegion at the given file offset.
func readByteAt(data []byte, mr *multiRegionData, fileOffset int64) byte <span class="cov9" title="574099126">{
        if mr != nil </span><span class="cov1" title="5">{
                return mr.ByteAt(fileOffset)
        }</span>
        <span class="cov9" title="574099121">return data[fileOffset]</span>
}

// readByteWithHint reads a single byte from a set of PES payload ranges using a hint
// for O(1) sequential access. Returns the byte, the range index for the next hint,
// and success status. Pass rangeHint=-1 to force binary search.
// When mr is non-nil, byte reads use the multi-region data instead of data.
func readByteWithHint(data []byte, mr *multiRegionData, dataSize int64, ranges []PESPayloadRange, esOffset int64, rangeHint int) (byte, int, bool) <span class="cov9" title="574099126">{
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return 0, -1, false
        }</span>

        // Fast path: check if hint is still valid (O(1) check)
        <span class="cov9" title="574099126">if rangeHint &gt;= 0 &amp;&amp; rangeHint &lt; len(ranges) </span><span class="cov9" title="532176250">{
                r := ranges[rangeHint]
                if esOffset &gt;= r.ESOffset &amp;&amp; esOffset &lt; r.ESOffset+int64(r.Size) </span><span class="cov9" title="517420911">{
                        offsetInPayload := esOffset - r.ESOffset
                        fileOffset := r.FileOffset + offsetInPayload
                        if fileOffset &gt;= 0 &amp;&amp; fileOffset &lt; dataSize </span><span class="cov9" title="517420911">{
                                return readByteAt(data, mr, fileOffset), rangeHint, true
                        }</span>
                }
                // Check next range (common case when crossing boundaries forward)
                <span class="cov8" title="14755339">if rangeHint+1 &lt; len(ranges) </span><span class="cov8" title="14755337">{
                        r = ranges[rangeHint+1]
                        if esOffset &gt;= r.ESOffset &amp;&amp; esOffset &lt; r.ESOffset+int64(r.Size) </span><span class="cov7" title="3433363">{
                                offsetInPayload := esOffset - r.ESOffset
                                fileOffset := r.FileOffset + offsetInPayload
                                if fileOffset &gt;= 0 &amp;&amp; fileOffset &lt; dataSize </span><span class="cov7" title="3433363">{
                                        return readByteAt(data, mr, fileOffset), rangeHint + 1, true
                                }</span>
                        }
                }
                // Check previous range (common case when crossing boundaries backward)
                <span class="cov7" title="11321976">if rangeHint-1 &gt;= 0 </span><span class="cov7" title="11321974">{
                        r = ranges[rangeHint-1]
                        if esOffset &gt;= r.ESOffset &amp;&amp; esOffset &lt; r.ESOffset+int64(r.Size) </span><span class="cov7" title="11321974">{
                                offsetInPayload := esOffset - r.ESOffset
                                fileOffset := r.FileOffset + offsetInPayload
                                if fileOffset &gt;= 0 &amp;&amp; fileOffset &lt; dataSize </span><span class="cov7" title="11321974">{
                                        return readByteAt(data, mr, fileOffset), rangeHint - 1, true
                                }</span>
                        }
                }
        }

        // Slow path: binary search
        <span class="cov8" title="41922878">rangeIdx := binarySearchRanges(ranges, esOffset)
        if rangeIdx &lt; 0 </span><span class="cov1" title="2">{
                return 0, -1, false
        }</span>

        <span class="cov8" title="41922876">r := ranges[rangeIdx]
        offsetInPayload := esOffset - r.ESOffset
        fileOffset := r.FileOffset + offsetInPayload
        if fileOffset &gt;= 0 &amp;&amp; fileOffset &lt; dataSize </span><span class="cov8" title="41922876">{
                return readByteAt(data, mr, fileOffset), rangeIdx, true
        }</span>

        <span class="cov0" title="0">return 0, -1, false</span>
}

// readSliceAt reads a byte slice from data or multiRegion at the given file offset range.
func readSliceAt(data []byte, mr *multiRegionData, fileOffset, endOffset int64) []byte <span class="cov8" title="21477870">{
        if mr != nil </span><span class="cov1" title="5">{
                return mr.Slice(fileOffset, endOffset)
        }</span>
        <span class="cov8" title="21477865">return data[fileOffset:endOffset]</span>
}

// readFromRanges reads data from PES payload ranges starting at the given ES offset.
// Returns a zero-copy slice when data fits in a single range (common case),
// only copies when data spans multiple ranges.
// When mr is non-nil, data reads use the multi-region data instead of data.
func readFromRanges(data []byte, mr *multiRegionData, dataSize int64, ranges []PESPayloadRange, esOffset int64, size int) ([]byte, error) <span class="cov8" title="21083629">{
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no ranges available")
        }</span>

        // Use binary search to find starting range
        <span class="cov8" title="21083629">rangeIdx := binarySearchRanges(ranges, esOffset)
        if rangeIdx &lt; 0 </span><span class="cov0" title="0">{
                rangeIdx = 0
                for rangeIdx &lt; len(ranges) &amp;&amp; esOffset &gt;= ranges[rangeIdx].ESOffset+int64(ranges[rangeIdx].Size) </span><span class="cov0" title="0">{
                        rangeIdx++
                }</span>
        }

        <span class="cov8" title="21083629">if rangeIdx &gt;= len(ranges) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("ES offset %d not found in ranges", esOffset)
        }</span>

        <span class="cov8" title="21083629">r := ranges[rangeIdx]
        if esOffset &lt; r.ESOffset || esOffset &gt;= r.ESOffset+int64(r.Size) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("ES offset %d not in range [%d, %d)", esOffset, r.ESOffset, r.ESOffset+int64(r.Size))
        }</span>

        <span class="cov8" title="21083629">offsetInPayload := esOffset - r.ESOffset
        availableInRange := int64(r.Size) - offsetInPayload

        // Fast path: data fits entirely within this single range (zero-copy)
        if int64(size) &lt;= availableInRange </span><span class="cov8" title="20689447">{
                fileOffset := r.FileOffset + offsetInPayload
                endOffset := fileOffset + int64(size)
                if endOffset &gt; dataSize </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("file offset out of range")
                }</span>
                <span class="cov8" title="20689447">return readSliceAt(data, mr, fileOffset, endOffset), nil</span>
        }

        // Slow path: data spans multiple ranges — must copy
        <span class="cov6" title="394182">result := make([]byte, 0, size)
        remaining := size

        for remaining &gt; 0 &amp;&amp; rangeIdx &lt; len(ranges) </span><span class="cov6" title="788421">{
                r := ranges[rangeIdx]

                if esOffset &lt; r.ESOffset </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov6" title="788421">if esOffset &gt;= r.ESOffset+int64(r.Size) </span><span class="cov0" title="0">{
                        rangeIdx++
                        continue</span>
                }

                <span class="cov6" title="788421">offsetInPayload := esOffset - r.ESOffset
                availableInRange := int64(r.Size) - offsetInPayload
                toRead := remaining
                if int64(toRead) &gt; availableInRange </span><span class="cov6" title="394239">{
                        toRead = int(availableInRange)
                }</span>

                <span class="cov6" title="788421">fileOffset := r.FileOffset + offsetInPayload
                endOffset := fileOffset + int64(toRead)
                if endOffset &gt; dataSize </span><span class="cov0" title="0">{
                        if len(result) &gt; 0 </span><span class="cov0" title="0">{
                                return result, nil
                        }</span>
                        <span class="cov0" title="0">return nil, fmt.Errorf("failed to read ES data: offset out of range")</span>
                }

                <span class="cov6" title="788421">result = append(result, readSliceAt(data, mr, fileOffset, endOffset)...)
                esOffset += int64(toRead)
                remaining -= toRead
                rangeIdx++</span>
        }

        <span class="cov6" title="394182">return result, nil</span>
}

// rawRangesFromPESRanges enumerates raw file ranges for a given ES region.
func rawRangesFromPESRanges(ranges []PESPayloadRange, esOffset int64, size int) ([]RawRange, error) <span class="cov5" title="74172">{
        if len(ranges) == 0 </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("no ranges available")
        }</span>

        // Use binary search to find starting range
        <span class="cov5" title="74171">rangeIdx := binarySearchRanges(ranges, esOffset)
        if rangeIdx &lt; 0 </span><span class="cov1" title="1">{
                rangeIdx = 0
                for rangeIdx &lt; len(ranges) &amp;&amp; esOffset &gt;= ranges[rangeIdx].ESOffset+int64(ranges[rangeIdx].Size) </span><span class="cov1" title="1">{
                        rangeIdx++
                }</span>
        }

        <span class="cov5" title="74171">if rangeIdx &gt;= len(ranges) </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("ES offset %d not found in ranges", esOffset)
        }</span>

        <span class="cov5" title="74170">r := ranges[rangeIdx]
        if esOffset &lt; r.ESOffset || esOffset &gt;= r.ESOffset+int64(r.Size) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("ES offset %d not in range [%d, %d)", esOffset, r.ESOffset, r.ESOffset+int64(r.Size))
        }</span>

        <span class="cov5" title="74170">var result []RawRange
        remaining := size

        for remaining &gt; 0 &amp;&amp; rangeIdx &lt; len(ranges) </span><span class="cov6" title="475907">{
                r := ranges[rangeIdx]

                if esOffset &lt; r.ESOffset </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov6" title="475907">if esOffset &gt;= r.ESOffset+int64(r.Size) </span><span class="cov0" title="0">{
                        rangeIdx++
                        continue</span>
                }

                <span class="cov6" title="475907">offsetInPayload := esOffset - r.ESOffset
                availableInRange := int64(r.Size) - offsetInPayload
                toTake := remaining
                if int64(toTake) &gt; availableInRange </span><span class="cov6" title="401737">{
                        toTake = int(availableInRange)
                }</span>

                <span class="cov6" title="475907">fileOffset := r.FileOffset + offsetInPayload
                result = append(result, RawRange{
                        FileOffset: fileOffset,
                        Size:       toTake,
                })

                esOffset += int64(toTake)
                remaining -= toTake
                rangeIdx++</span>
        }

        <span class="cov5" title="74170">if remaining &gt; 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("could not map entire ES region: %d bytes remaining", remaining)
        }</span>

        <span class="cov5" title="74170">return result, nil</span>
}

// totalESSizeFromRanges returns the total ES size from a range list.
func totalESSizeFromRanges(ranges []PESPayloadRange) int64 <span class="cov8" title="20961478">{
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="20961478">last := ranges[len(ranges)-1]
        return last.ESOffset + int64(last.Size)</span>
}
</pre>
		
		<pre class="file" id="file43" style="display: none">package source

import (
        "fmt"
        "os"
        "path/filepath"
        "strings"

        "github.com/cespare/xxhash/v2"
        "github.com/stuckj/mkvdup/internal/mmap"
        "golang.org/x/sys/unix"
)

const (
        // DefaultWindowSize is the default number of bytes to hash at each sync point
        DefaultWindowSize = 64

        // MinWindowSize is the minimum allowed window size
        MinWindowSize = 32

        // MaxWindowSize is the maximum allowed window size
        MaxWindowSize = 4096
)

// Indexer builds a hash index from source media files.
type Indexer struct {
        sourceDir      string
        sourceType     Type
        windowSize     int
        index          *Index
        useRawIndexing bool // Force raw file indexing even for DVDs
        verbose        bool // Enable diagnostic output
}

// NewIndexer creates a new Indexer for the given source directory.
func NewIndexer(sourceDir string, windowSize int) (*Indexer, error) <span class="cov2" title="14">{
        return NewIndexerWithOptions(sourceDir, windowSize, false)
}</span>

// NewIndexerWithOptions creates a new Indexer with additional options.
// useRawIndexing forces raw file indexing even for DVDs (useful for finding
// content from any title/stream in the ISO).
func NewIndexerWithOptions(sourceDir string, windowSize int, useRawIndexing bool) (*Indexer, error) <span class="cov2" title="16">{
        sourceType, err := DetectType(sourceDir)
        if err != nil </span><span class="cov1" title="9">{
                return nil, fmt.Errorf("detect source type: %w", err)
        }</span>

        <span class="cov1" title="7">if windowSize &lt; MinWindowSize </span><span class="cov1" title="1">{
                windowSize = MinWindowSize
        }</span>
        <span class="cov1" title="7">if windowSize &gt; MaxWindowSize </span><span class="cov1" title="1">{
                windowSize = MaxWindowSize
        }</span>

        <span class="cov1" title="7">return &amp;Indexer{
                sourceDir:      sourceDir,
                sourceType:     sourceType,
                windowSize:     windowSize,
                index:          NewIndex(sourceDir, sourceType, windowSize),
                useRawIndexing: useRawIndexing,
        }, nil</span>
}

// SourceType returns the detected source type.
func (idx *Indexer) SourceType() Type <span class="cov1" title="4">{
        return idx.sourceType
}</span>

// SetVerbose enables or disables diagnostic output during indexing.
func (idx *Indexer) SetVerbose(v bool) <span class="cov0" title="0">{
        idx.verbose = v
}</span>

// SourceDir returns the source directory path.
func (idx *Indexer) SourceDir() string <span class="cov1" title="1">{
        return idx.sourceDir
}</span>

// ProgressFunc is called during indexing to report progress.
// processed is the number of bytes processed so far, total is the total bytes to process.
type ProgressFunc func(processed, total int64)

// Build scans all media files and builds the hash index.
// If progress is non-nil, it will be called periodically to report progress.
func (idx *Indexer) Build(progress ProgressFunc) error <span class="cov1" title="3">{
        files, err := EnumerateMediaFiles(idx.sourceDir, idx.sourceType)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("enumerate media files: %w", err)
        }</span>

        <span class="cov1" title="3">if len(files) == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no media files found in %s", idx.sourceDir)
        }</span>

        // Calculate total size for progress reporting
        <span class="cov1" title="3">var totalSize int64
        for _, relPath := range files </span><span class="cov1" title="3">{
                fullPath := filepath.Join(idx.sourceDir, relPath)
                size, err := GetFileInfo(fullPath)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("get file info for %s: %w", relPath, err)
                }</span>
                <span class="cov1" title="3">totalSize += size</span>
        }

        // Pre-allocate hash map to reduce reallocation
        // Estimate: ~1 sync point per 2KB of data on average
        <span class="cov1" title="3">estimatedSyncPoints := int(totalSize / 2048)
        if estimatedSyncPoints &lt; 10000 </span><span class="cov1" title="2">{
                estimatedSyncPoints = 10000
        }</span>
        <span class="cov1" title="3">idx.index.HashToLocations = make(map[uint64][]Location, estimatedSyncPoints)

        // For DVDs (MPEG-PS) and Blu-rays (MPEG-TS), use ES-based indexing
        // so the matcher works with continuous ES data.
        // Raw indexing is available as fallback for DVDs.
        if idx.sourceType == TypeDVD &amp;&amp; !idx.useRawIndexing </span><span class="cov1" title="1">{
                idx.index.UsesESOffsets = true
        }</span> else<span class="cov1" title="2"> if idx.sourceType == TypeBluray </span><span class="cov1" title="2">{
                idx.index.UsesESOffsets = true
        }</span>

        <span class="cov1" title="3">var processedSize int64

        // Process each file
        // fileIndex tracks the next available index for source file entries.
        // Most files produce one entry, but Blu-ray ISOs produce one per M2TS region.
        fileIndex := 0
        for _, relPath := range files </span><span class="cov1" title="3">{
                fullPath := filepath.Join(idx.sourceDir, relPath)

                size, err := GetFileInfo(fullPath)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("get file info for %s: %w", relPath, err)
                }</span>

                <span class="cov1" title="3">var checksum uint64
                if idx.sourceType == TypeDVD &amp;&amp; !idx.useRawIndexing </span><span class="cov1" title="1">{
                        checksum, err = idx.indexMPEGPSFile(uint16(fileIndex), fullPath, size, func(fileProcessed int64) </span><span class="cov3" title="686">{
                                if progress != nil </span><span class="cov0" title="0">{
                                        progress(processedSize+fileProcessed, totalSize)
                                }</span>
                        })
                } else<span class="cov1" title="2"> if idx.sourceType == TypeBluray &amp;&amp; isISOFile(relPath) </span><span class="cov1" title="2">{
                        // Blu-ray ISO: one ISO may contain multiple M2TS regions,
                        // each producing a separate source file entry.
                        var n int
                        n, _, err = idx.indexBlurayISOFile(uint16(fileIndex), fullPath, relPath, size, func(fileProcessed int64) </span><span class="cov1" title="6">{
                                if progress != nil </span><span class="cov0" title="0">{
                                        progress(processedSize+fileProcessed, totalSize)
                                }</span>
                        })
                        <span class="cov1" title="2">if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("index file %s: %w", relPath, err)
                        }</span>
                        // indexBlurayISOFile already added source file entries
                        <span class="cov1" title="2">fileIndex += n
                        processedSize += size
                        continue</span>
                } else<span class="cov0" title="0"> if idx.sourceType == TypeBluray </span><span class="cov0" title="0">{
                        checksum, err = idx.indexM2TSFile(uint16(fileIndex), fullPath, size, func(fileProcessed int64) </span><span class="cov0" title="0">{
                                if progress != nil </span><span class="cov0" title="0">{
                                        progress(processedSize+fileProcessed, totalSize)
                                }</span>
                        })
                } else<span class="cov0" title="0"> {
                        checksum, err = idx.indexRawFile(uint16(fileIndex), fullPath, size, func(fileProcessed int64) </span><span class="cov0" title="0">{
                                if progress != nil </span><span class="cov0" title="0">{
                                        progress(processedSize+fileProcessed, totalSize)
                                }</span>
                        })
                }
                <span class="cov1" title="1">if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("index file %s: %w", relPath, err)
                }</span>

                <span class="cov1" title="1">idx.index.Files = append(idx.index.Files, File{
                        RelativePath: relPath,
                        Size:         size,
                        Checksum:     checksum,
                })

                fileIndex++
                processedSize += size</span>
        }

        <span class="cov1" title="3">return nil</span>
}

// isISOFile returns true if the path has an .iso extension.
func isISOFile(path string) bool <span class="cov1" title="2">{
        return strings.HasSuffix(strings.ToLower(path), ".iso")
}</span>

// checksumWithProgress computes xxhash checksum of data in chunks, calling
// progress with the number of bytes processed so far after each chunk.
func checksumWithProgress(data []byte, progress func(int64)) uint64 <span class="cov1" title="3">{
        hasher := xxhash.New()
        const chunkSize = 16 * 1024 * 1024 // 16MB chunks
        for offset := 0; offset &lt; len(data); offset += chunkSize </span><span class="cov3" title="483">{
                end := offset + chunkSize
                if end &gt; len(data) </span><span class="cov1" title="3">{
                        end = len(data)
                }</span>
                <span class="cov3" title="483">hasher.Write(data[offset:end])
                if progress != nil </span><span class="cov3" title="483">{
                        progress(int64(end))
                }</span>
        }
        <span class="cov1" title="3">return hasher.Sum64()</span>
}

// indexMPEGPSFile processes an MPEG-PS file (DVD ISO) using ES-aware indexing.
// It extracts the elementary stream data and indexes sync points within it.
func (idx *Indexer) indexMPEGPSFile(fileIndex uint16, path string, size int64, progress func(int64)) (uint64, error) <span class="cov1" title="1">{
        // Memory-map the file with zero-copy access
        mmapFile, err := mmap.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("mmap open: %w", err)
        }</span>
        // Note: Don't close mmapFile - it's stored in MmapFiles for later use

        // Store the mmap file for cleanup
        <span class="cov1" title="1">idx.index.MmapFiles = append(idx.index.MmapFiles, mmapFile)

        // Parse MPEG-PS structure with progress reporting using zero-copy data
        parser := NewMPEGPSParser(mmapFile.Data())

        // Phase 1: Parse MPEG-PS structure (0% → 33%)
        if err := parser.ParseWithProgress(func(processed, total int64) </span><span class="cov2" title="74">{
                if progress != nil </span><span class="cov2" title="74">{
                        progress(processed / 3)
                }</span>
        }); err != nil <span class="cov0" title="0">{
                return 0, fmt.Errorf("parse MPEG-PS: %w", err)
        }</span>

        // Store parser for later use by matcher
        <span class="cov1" title="1">idx.index.ESReaders = append(idx.index.ESReaders, parser)

        // Phase 2: Checksum (33% → 66%)
        checksum := checksumWithProgress(mmapFile.Data(), func(processed int64) </span><span class="cov3" title="481">{
                if progress != nil </span><span class="cov3" title="481">{
                        progress(size/3 + processed/3)
                }</span>
        })

        // Phase 3: Index ES data (66% → 100%)
        <span class="cov1" title="1">videoESSize := parser.TotalESSize(true)
        if videoESSize &gt; 0 </span><span class="cov1" title="1">{
                indexProgress := func(fileOffset int64) </span><span class="cov3" title="130">{
                        if progress != nil </span><span class="cov3" title="130">{
                                progress(2*size/3 + fileOffset/3)
                        }</span>
                }
                <span class="cov1" title="1">if err := idx.indexESData(fileIndex, parser, true, videoESSize, indexProgress); err != nil </span><span class="cov0" title="0">{
                        return 0, fmt.Errorf("index video ES: %w", err)
                }</span>
        }

        // Index each audio sub-stream separately
        <span class="cov1" title="1">audioSubStreams := parser.AudioSubStreams()
        for _, subStreamID := range audioSubStreams </span><span class="cov2" title="24">{
                subStreamSize := parser.AudioSubStreamESSize(subStreamID)
                if subStreamSize &gt; 0 </span><span class="cov2" title="24">{
                        if err := idx.indexAudioSubStream(fileIndex, parser, subStreamID, subStreamSize); err != nil </span><span class="cov0" title="0">{
                                return 0, fmt.Errorf("index audio sub-stream 0x%02X: %w", subStreamID, err)
                        }</span>
                }
        }

        <span class="cov1" title="1">if progress != nil </span><span class="cov1" title="1">{
                progress(size)
        }</span>

        <span class="cov1" title="1">return checksum, nil</span>
}

// esDataProvider is the interface needed by indexESData and indexAudioSubStream.
// Both MPEGPSParser and MPEGTSParser implement this, as well as isoM2TSAdapter.
type esDataProvider interface {
        Data() []byte
        DataSlice(off int64, size int) []byte
        DataSize() int64
        FilteredVideoRanges() []PESPayloadRange
        FilteredAudioRanges(subStreamID byte) []PESPayloadRange
        ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error)
        ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error)
}

// indexESData indexes the elementary stream data from an ES-aware parser.
// Uses zero-copy iteration through PES payload ranges.
func (idx *Indexer) indexESData(fileIndex uint16, parser esDataProvider, isVideo bool, esSize int64, progress func(int64)) error <span class="cov1" title="3">{
        ranges := parser.FilteredVideoRanges()
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov1" title="3">dataSize := parser.DataSize()
        syncPointCount := 0
        var indexFastPath, indexSlowPath, indexSkipped int

        // Iterate through each PES payload range (zero-copy when within one region)
        for rangeIdx, r := range ranges </span><span class="cov7" title="1298356">{
                endOffset := r.FileOffset + int64(r.Size)
                if endOffset &gt; dataSize </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov7" title="1298356">rangeData := parser.DataSlice(r.FileOffset, r.Size)

                // Find NAL unit start positions (byte after 00 00 01)
                // Hashing from NAL header enables matching both Annex B and AVCC formats
                syncPoints := FindVideoNALStarts(rangeData)

                // Add each sync point to the index
                for _, offsetInRange := range syncPoints </span><span class="cov7" title="3867306">{
                        syncESOffset := r.ESOffset + int64(offsetInRange)

                        // Ensure we have enough data for the window
                        if syncESOffset+int64(idx.windowSize) &gt; esSize </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        // Check if window fits within this range (zero-copy fast path)
                        <span class="cov7" title="3867306">if offsetInRange+idx.windowSize &lt;= len(rangeData) </span><span class="cov7" title="3746556">{
                                window := rangeData[offsetInRange : offsetInRange+idx.windowSize]
                                hash := xxhash.Sum64(window)

                                idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                        FileIndex: fileIndex,
                                        Offset:    syncESOffset,
                                        IsVideo:   isVideo,
                                })
                                syncPointCount++
                                indexFastPath++
                        }</span> else<span class="cov6" title="120750"> {
                                // Window spans range boundary - use ReadESData (may copy)
                                window, err := parser.ReadESData(syncESOffset, idx.windowSize, isVideo)
                                if err != nil || len(window) &lt; idx.windowSize </span><span class="cov0" title="0">{
                                        indexSkipped++
                                        continue</span>
                                }
                                <span class="cov6" title="120750">hash := xxhash.Sum64(window)

                                idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                        FileIndex: fileIndex,
                                        Offset:    syncESOffset,
                                        IsVideo:   isVideo,
                                })
                                syncPointCount++
                                indexSlowPath++</span>
                        }

                }

                // Report progress periodically
                <span class="cov7" title="1298356">if rangeIdx%10000 == 0 &amp;&amp; progress != nil </span><span class="cov3" title="130">{
                        progress(r.FileOffset)
                }</span>
        }

        <span class="cov1" title="3">if idx.verbose </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "  [indexESData] video=%v: %d NALs indexed (fast=%d, slow/cross-range=%d, skipped=%d)\n",
                        isVideo, syncPointCount, indexFastPath, indexSlowPath, indexSkipped)
        }</span>

        <span class="cov1" title="3">return nil</span>
}

// syncPointFinder is a function that returns sync point offsets within data.
type syncPointFinder func(data []byte) []int

// indexAudioSubStream indexes a specific audio sub-stream.
func (idx *Indexer) indexAudioSubStream(fileIndex uint16, parser esDataProvider, subStreamID byte, esSize int64) error <span class="cov2" title="26">{
        return idx.indexSubStream(fileIndex, parser, subStreamID, esSize, FindAudioSyncPoints)
}</span>

// indexSubStream indexes a specific sub-stream using the provided sync point finder.
// Uses zero-copy iteration through PES payload ranges.
func (idx *Indexer) indexSubStream(fileIndex uint16, parser esDataProvider, subStreamID byte, esSize int64, findSyncPoints syncPointFinder) error <span class="cov2" title="26">{
        ranges := parser.FilteredAudioRanges(subStreamID)
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov2" title="26">dataSize := parser.DataSize()

        // Iterate through each PES payload range (zero-copy when within one region)
        for _, r := range ranges </span><span class="cov6" title="89027">{
                endOffset := r.FileOffset + int64(r.Size)
                if endOffset &gt; dataSize </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov6" title="89027">rangeData := parser.DataSlice(r.FileOffset, r.Size)

                // Find sync points in this range
                syncPoints := findSyncPoints(rangeData)

                // Add each sync point to the index
                for _, offsetInRange := range syncPoints </span><span class="cov6" title="258179">{
                        syncESOffset := r.ESOffset + int64(offsetInRange)

                        // Ensure we have enough data for the window
                        if syncESOffset+int64(idx.windowSize) &gt; esSize </span><span class="cov1" title="7">{
                                continue</span>
                        }

                        // Check if window fits within this range (zero-copy fast path)
                        <span class="cov6" title="258172">if offsetInRange+idx.windowSize &lt;= len(rangeData) </span><span class="cov6" title="256745">{
                                window := rangeData[offsetInRange : offsetInRange+idx.windowSize]
                                hash := xxhash.Sum64(window)

                                idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                        FileIndex:        fileIndex,
                                        Offset:           syncESOffset,
                                        IsVideo:          false,
                                        AudioSubStreamID: subStreamID,
                                })
                        }</span> else<span class="cov4" title="1427"> {
                                // Window spans range boundary - use ReadAudioSubStreamData (may copy)
                                window, err := parser.ReadAudioSubStreamData(subStreamID, syncESOffset, idx.windowSize)
                                if err != nil || len(window) &lt; idx.windowSize </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov4" title="1427">hash := xxhash.Sum64(window)

                                idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                        FileIndex:        fileIndex,
                                        Offset:           syncESOffset,
                                        IsVideo:          false,
                                        AudioSubStreamID: subStreamID,
                                })</span>
                        }
                }
        }

        <span class="cov2" title="26">return nil</span>
}

// mmapRawReader wraps mmap.File to implement RawReader interface.
type mmapRawReader struct {
        mmapFile *mmap.File
}

func (r *mmapRawReader) ReadAt(buf []byte, offset int64) (int, error) <span class="cov0" title="0">{
        data := r.mmapFile.Slice(offset, len(buf))
        if data == nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("offset out of range")
        }</span>
        <span class="cov0" title="0">copy(buf, data)
        return len(data), nil</span>
}

// Slice returns a zero-copy slice of the underlying mmap'd data.
func (r *mmapRawReader) Slice(offset int64, size int) []byte <span class="cov0" title="0">{
        return r.mmapFile.Slice(offset, size)
}</span>

func (r *mmapRawReader) Len() int <span class="cov0" title="0">{
        return r.mmapFile.Len()
}</span>

func (r *mmapRawReader) Close() error <span class="cov0" title="0">{
        return r.mmapFile.Close()
}</span>

// indexRawFile processes a raw file (for non-DVD, non-Blu-ray formats).
// Processes the file in a single pass: computes checksum and indexes sync points
// together in chunks, releasing mmap pages as they're processed.
func (idx *Indexer) indexRawFile(fileIndex uint16, path string, size int64, progress func(int64)) (uint64, error) <span class="cov0" title="0">{
        mmapFile, err := mmap.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("mmap open: %w", err)
        }</span>
        <span class="cov0" title="0">idx.index.RawReaders = append(idx.index.RawReaders, &amp;mmapRawReader{mmapFile: mmapFile})

        mmapFile.Advise(unix.MADV_SEQUENTIAL)
        data := mmapFile.Data()

        return idx.indexRawFileData(fileIndex, mmapFile, data, size, progress)</span>
}

// indexM2TSFile processes a Blu-ray M2TS file using ES-aware indexing.
// It parses the MPEG-TS structure to extract elementary stream data and
// indexes sync points within the continuous ES, matching what MKV files contain.
func (idx *Indexer) indexM2TSFile(fileIndex uint16, path string, size int64, progress func(int64)) (uint64, error) <span class="cov0" title="0">{
        mmapFile, err := mmap.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("mmap open: %w", err)
        }</span>
        // Note: Don't close mmapFile - it's stored in MmapFiles for later use
        <span class="cov0" title="0">idx.index.MmapFiles = append(idx.index.MmapFiles, mmapFile)

        mmapFile.Advise(unix.MADV_SEQUENTIAL)

        // Phase 1: Parse MPEG-TS structure (0% → 33%)
        parser := NewMPEGTSParser(mmapFile.Data())

        if err := parser.ParseWithProgress(func(processed, total int64) </span><span class="cov0" title="0">{
                if progress != nil </span><span class="cov0" title="0">{
                        progress(processed / 3)
                }</span>
        }); err != nil <span class="cov0" title="0">{
                return 0, fmt.Errorf("parse MPEG-TS: %w", err)
        }</span>

        // Store parser for later use by matcher
        <span class="cov0" title="0">idx.index.ESReaders = append(idx.index.ESReaders, parser)

        // Phase 2: Checksum (33% → 66%)
        checksum := checksumWithProgress(mmapFile.Data(), func(processed int64) </span><span class="cov0" title="0">{
                if progress != nil </span><span class="cov0" title="0">{
                        progress(size/3 + processed/3)
                }</span>
        })

        // Phase 3: Index ES data (66% → 100%)
        <span class="cov0" title="0">videoESSize := parser.TotalESSize(true)
        if videoESSize &gt; 0 </span><span class="cov0" title="0">{
                indexProgress := func(fileOffset int64) </span><span class="cov0" title="0">{
                        if progress != nil </span><span class="cov0" title="0">{
                                progress(2*size/3 + fileOffset/3)
                        }</span>
                }
                <span class="cov0" title="0">if err := idx.indexESData(fileIndex, parser, true, videoESSize, indexProgress); err != nil </span><span class="cov0" title="0">{
                        return 0, fmt.Errorf("index video ES: %w", err)
                }</span>
        }

        // Index each audio sub-stream separately
        <span class="cov0" title="0">subtitleIDs := parser.SubtitleSubStreams()
        subtitleSet := make(map[byte]bool, len(subtitleIDs))
        for _, id := range subtitleIDs </span><span class="cov0" title="0">{
                subtitleSet[id] = true
        }</span>
        <span class="cov0" title="0">for _, subStreamID := range parser.AudioSubStreams() </span><span class="cov0" title="0">{
                if subtitleSet[subStreamID] </span><span class="cov0" title="0">{
                        continue</span> // indexed below with subtitle-specific sync points
                }
                <span class="cov0" title="0">subStreamSize := parser.AudioSubStreamESSize(subStreamID)
                if subStreamSize &gt; 0 </span><span class="cov0" title="0">{
                        if err := idx.indexAudioSubStream(fileIndex, parser, subStreamID, subStreamSize); err != nil </span><span class="cov0" title="0">{
                                return 0, fmt.Errorf("index audio sub-stream %d: %w", subStreamID, err)
                        }</span>
                }
        }

        // Index subtitle sub-streams with PGS sync point detection
        <span class="cov0" title="0">for _, subStreamID := range subtitleIDs </span><span class="cov0" title="0">{
                subStreamSize := parser.AudioSubStreamESSize(subStreamID)
                if subStreamSize &gt; 0 </span><span class="cov0" title="0">{
                        if err := idx.indexSubStream(fileIndex, parser, subStreamID, subStreamSize, FindPGSSyncPoints); err != nil </span><span class="cov0" title="0">{
                                return 0, fmt.Errorf("index subtitle sub-stream %d: %w", subStreamID, err)
                        }</span>
                }
        }

        <span class="cov0" title="0">if progress != nil </span><span class="cov0" title="0">{
                progress(size)
        }</span>

        <span class="cov0" title="0">return checksum, nil</span>
}

// indexBlurayISOFile processes a Blu-ray ISO file by finding M2TS regions
// within the ISO9660 filesystem and indexing each as a separate source file entry.
// Returns the number of source file entries created and the ISO checksum.
func (idx *Indexer) indexBlurayISOFile(startFileIndex uint16, path, relPath string, size int64, progress func(int64)) (int, uint64, error) <span class="cov1" title="2">{
        // Find M2TS file extents within the ISO
        m2tsFiles, err := findBlurayM2TSInISO(path)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("find M2TS in ISO: %w", err)
        }</span>
        <span class="cov1" title="2">if len(m2tsFiles) == 0 </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("no M2TS files found in Blu-ray ISO")
        }</span>

        // Memory-map the entire ISO
        <span class="cov1" title="2">mmapFile, err := mmap.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("mmap open: %w", err)
        }</span>
        // Don't close — stored in MmapFiles for later use
        <span class="cov1" title="2">idx.index.MmapFiles = append(idx.index.MmapFiles, mmapFile)

        mmapFile.Advise(unix.MADV_SEQUENTIAL)
        isoData := mmapFile.Data()

        // Phase 1: Parse all M2TS regions (0% → 33%)
        type parsedM2TS struct {
                adapter *isoM2TSAdapter
                extent  isoFileExtent
        }
        var parsed []parsedM2TS

        for _, m2ts := range m2tsFiles </span><span class="cov1" title="2">{
                var adapter *isoM2TSAdapter

                if m2ts.Extents != nil </span><span class="cov0" title="0">{
                        // Multi-extent UDF file: create virtual contiguous view
                        // over the existing mmap sub-slices (zero-copy, no heap allocation)
                        mr := newMultiRegionData(m2ts.Extents, isoData)

                        parser := NewMPEGTSParserMultiRegion(mr)
                        if err := parser.ParseWithProgress(nil); err != nil </span><span class="cov0" title="0">{
                                if idx.verbose </span><span class="cov0" title="0">{
                                        fmt.Fprintf(os.Stderr, "  [indexBlurayISO] skipping %s: %v\n", m2ts.Name, err)
                                }</span>
                                <span class="cov0" title="0">continue</span>
                        }
                        <span class="cov0" title="0">adapter = newISOAdapterMultiExtent(parser, mr, m2ts.Extents)</span>
                } else<span class="cov1" title="2"> {
                        // Contiguous file: use sub-slice of mmap'd ISO
                        endOffset := m2ts.Offset + m2ts.Size
                        if endOffset &gt; int64(len(isoData)) </span><span class="cov0" title="0">{
                                if idx.verbose </span><span class="cov0" title="0">{
                                        fmt.Fprintf(os.Stderr, "  [indexBlurayISO] skipping %s: extent beyond ISO bounds (%d + %d &gt; %d)\n",
                                                m2ts.Name, m2ts.Offset, m2ts.Size, len(isoData))
                                }</span>
                                <span class="cov0" title="0">continue</span>
                        }

                        <span class="cov1" title="2">m2tsData := isoData[m2ts.Offset:endOffset]
                        parser := NewMPEGTSParser(m2tsData)
                        if err := parser.ParseWithProgress(nil); err != nil </span><span class="cov0" title="0">{
                                if idx.verbose </span><span class="cov0" title="0">{
                                        fmt.Fprintf(os.Stderr, "  [indexBlurayISO] skipping %s: %v\n", m2ts.Name, err)
                                }</span>
                                <span class="cov0" title="0">continue</span>
                        }
                        <span class="cov1" title="2">adapter = newISOAdapter(parser, isoData, m2ts.Offset)</span>
                }

                <span class="cov1" title="2">parsed = append(parsed, parsedM2TS{adapter: adapter, extent: m2ts})</span>
        }

        <span class="cov1" title="2">if len(parsed) == 0 </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("no valid M2TS streams found in Blu-ray ISO")
        }</span>

        <span class="cov1" title="2">if progress != nil </span><span class="cov1" title="2">{
                progress(size / 3)
        }</span>

        // Phase 2: Checksum the full ISO (33% → 66%)
        <span class="cov1" title="2">checksum := checksumWithProgress(isoData, func(processed int64) </span><span class="cov1" title="2">{
                if progress != nil </span><span class="cov1" title="2">{
                        progress(size/3 + processed/3)
                }</span>
        })

        // Phase 3: Index ES data from all M2TS regions (66% → 100%)
        <span class="cov1" title="2">entriesCreated := 0
        for _, p := range parsed </span><span class="cov1" title="2">{
                fileIndex := startFileIndex + uint16(entriesCreated)
                adapter := p.adapter

                // Store adapter as ESReader for this source file entry
                idx.index.ESReaders = append(idx.index.ESReaders, adapter)

                // Index video ES
                videoESSize := adapter.TotalESSize(true)
                if videoESSize &gt; 0 </span><span class="cov1" title="2">{
                        if err := idx.indexESData(fileIndex, adapter, true, videoESSize, nil); err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("index video ES for %s: %w", p.extent.Name, err)
                        }</span>
                }

                // Index audio sub-streams
                <span class="cov1" title="2">subtitleIDs := adapter.parser.SubtitleSubStreams()
                subtitleSet := make(map[byte]bool, len(subtitleIDs))
                for _, id := range subtitleIDs </span><span class="cov0" title="0">{
                        subtitleSet[id] = true
                }</span>
                <span class="cov1" title="2">for _, subStreamID := range adapter.AudioSubStreams() </span><span class="cov1" title="2">{
                        if subtitleSet[subStreamID] </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov1" title="2">subStreamSize := adapter.AudioSubStreamESSize(subStreamID)
                        if subStreamSize &gt; 0 </span><span class="cov1" title="2">{
                                if err := idx.indexAudioSubStream(fileIndex, adapter, subStreamID, subStreamSize); err != nil </span><span class="cov0" title="0">{
                                        return 0, 0, fmt.Errorf("index audio sub-stream %d for %s: %w", subStreamID, p.extent.Name, err)
                                }</span>
                        }
                }

                // Index subtitle sub-streams
                <span class="cov1" title="2">for _, subStreamID := range subtitleIDs </span><span class="cov0" title="0">{
                        subStreamSize := adapter.AudioSubStreamESSize(subStreamID)
                        if subStreamSize &gt; 0 </span><span class="cov0" title="0">{
                                if err := idx.indexSubStream(fileIndex, adapter, subStreamID, subStreamSize, FindPGSSyncPoints); err != nil </span><span class="cov0" title="0">{
                                        return 0, 0, fmt.Errorf("index subtitle sub-stream %d for %s: %w", subStreamID, p.extent.Name, err)
                                }</span>
                        }
                }

                // Add source file entry — all entries share the same ISO path, size, checksum
                <span class="cov1" title="2">idx.index.Files = append(idx.index.Files, File{
                        RelativePath: relPath,
                        Size:         size,
                        Checksum:     checksum,
                })

                entriesCreated++</span>
        }

        <span class="cov1" title="2">if progress != nil </span><span class="cov1" title="2">{
                progress(size)
        }</span>

        <span class="cov1" title="2">return entriesCreated, checksum, nil</span>
}

// indexRawFileData is the core of indexRawFile operating on already-opened mmap data.
// Used as a fallback when M2TS packet structure cannot be detected.
func (idx *Indexer) indexRawFileData(fileIndex uint16, mmapFile *mmap.File, data []byte, size int64, progress func(int64)) (uint64, error) <span class="cov0" title="0">{
        hasher := xxhash.New()
        const chunkSize = 64 * 1024 * 1024
        const overlap = 3
        pageSize := unix.Getpagesize()
        checksumPos := 0

        for chunkStart := 0; chunkStart &lt; len(data); </span><span class="cov0" title="0">{
                chunkEnd := chunkStart + chunkSize
                if chunkEnd &gt; len(data) </span><span class="cov0" title="0">{
                        chunkEnd = len(data)
                }</span>

                <span class="cov0" title="0">chunk := data[chunkStart:chunkEnd]

                if chunkEnd &gt; checksumPos </span><span class="cov0" title="0">{
                        hasher.Write(data[checksumPos:chunkEnd])
                        checksumPos = chunkEnd
                }</span>

                <span class="cov0" title="0">videoOffsets := FindVideoNALStartsInRange(chunk, chunkStart)
                audioOffsets := FindAudioSyncPointsInRange(chunk, chunkStart)

                for _, offset := range videoOffsets </span><span class="cov0" title="0">{
                        if offset+idx.windowSize &gt; len(data) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">window := data[offset : offset+idx.windowSize]
                        hash := xxhash.Sum64(window)
                        idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                FileIndex: fileIndex,
                                Offset:    int64(offset),
                        })</span>
                }

                <span class="cov0" title="0">for _, offset := range audioOffsets </span><span class="cov0" title="0">{
                        if offset+idx.windowSize &gt; len(data) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">window := data[offset : offset+idx.windowSize]
                        hash := xxhash.Sum64(window)
                        idx.index.HashToLocations[hash] = append(idx.index.HashToLocations[hash], Location{
                                FileIndex: fileIndex,
                                Offset:    int64(offset),
                        })</span>
                }

                <span class="cov0" title="0">if progress != nil </span><span class="cov0" title="0">{
                        progress(int64(chunkEnd))
                }</span>

                <span class="cov0" title="0">releaseUpTo := (chunkStart / pageSize) * pageSize
                if releaseUpTo &gt; 0 </span><span class="cov0" title="0">{
                        unix.Madvise(data[:releaseUpTo], unix.MADV_DONTNEED)
                }</span>

                <span class="cov0" title="0">if chunkEnd &gt;= len(data) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">chunkStart = chunkEnd - overlap</span>
        }

        <span class="cov0" title="0">checksum := hasher.Sum64()
        mmapFile.Advise(unix.MADV_RANDOM)
        return checksum, nil</span>
}

// Index returns the built index. Must call Build first.
func (idx *Indexer) Index() *Index <span class="cov1" title="4">{
        return idx.index
}</span>

// Lookup finds locations in the source that match the given hash.
func (idx *Index) Lookup(hash uint64) []Location <span class="cov6" title="583500">{
        return idx.HashToLocations[hash]
}</span>

// ReadESDataAt reads ES data at the given location.
// For sources that use ES offsets, this handles the translation.
// For audio locations, uses the sub-stream ID from the location.
func (idx *Index) ReadESDataAt(loc Location, size int) ([]byte, error) <span class="cov8" title="20961438">{
        if int(loc.FileIndex) &gt;= len(idx.ESReaders) || idx.ESReaders[loc.FileIndex] == nil </span><span class="cov1" title="1">{
                // No ES reader - this shouldn't happen for ES-based indexes
                return nil, fmt.Errorf("no ES reader for file %d", loc.FileIndex)
        }</span>
        <span class="cov8" title="20961437">if loc.IsVideo </span><span class="cov8" title="20742951">{
                return idx.ESReaders[loc.FileIndex].ReadESData(loc.Offset, size, true)
        }</span>
        // For audio, use the sub-stream specific reader
        <span class="cov6" title="218486">return idx.ESReaders[loc.FileIndex].ReadAudioSubStreamData(loc.AudioSubStreamID, loc.Offset, size)</span>
}

// hintedESReader is the interface for hint-based byte reading.
// Both MPEGPSParser and MPEGTSParser implement this.
type hintedESReader interface {
        ReadESByteWithHint(esOffset int64, isVideo bool, rangeHint int) (byte, int, bool)
        ReadAudioByteWithHint(subStreamID byte, esOffset int64, rangeHint int) (byte, int, bool)
}

// ReadESByteWithHint reads a single byte from the ES stream, using a range hint
// to avoid binary search when reading sequentially. Returns the byte, the new range
// hint for the next call, and success status. Pass rangeHint=-1 to force binary search.
// This is optimized for the expandMatch hot path where we read bytes sequentially.
func (idx *Index) ReadESByteWithHint(loc Location, rangeHint int) (byte, int, bool) <span class="cov10" title="574099108">{
        if int(loc.FileIndex) &gt;= len(idx.ESReaders) || idx.ESReaders[loc.FileIndex] == nil </span><span class="cov0" title="0">{
                return 0, -1, false
        }</span>

        // Try hint-based reading (fast path for MPEGPSParser and MPEGTSParser)
        <span class="cov10" title="574099108">if hinted, ok := idx.ESReaders[loc.FileIndex].(hintedESReader); ok </span><span class="cov10" title="574099108">{
                if loc.IsVideo </span><span class="cov9" title="501455193">{
                        return hinted.ReadESByteWithHint(loc.Offset, true, rangeHint)
                }</span>
                <span class="cov9" title="72643915">return hinted.ReadAudioByteWithHint(loc.AudioSubStreamID, loc.Offset, rangeHint)</span>
        }

        // Fallback: use ReadESData (allocates, but works for any ESReader)
        <span class="cov0" title="0">var data []byte
        var err error
        if loc.IsVideo </span><span class="cov0" title="0">{
                data, err = idx.ESReaders[loc.FileIndex].ReadESData(loc.Offset, 1, true)
        }</span> else<span class="cov0" title="0"> {
                data, err = idx.ESReaders[loc.FileIndex].ReadAudioSubStreamData(loc.AudioSubStreamID, loc.Offset, 1)
        }</span>
        <span class="cov0" title="0">if err != nil || len(data) == 0 </span><span class="cov0" title="0">{
                return 0, -1, false
        }</span>
        <span class="cov0" title="0">return data[0], -1, true</span>
}

// ComputeHash calculates the xxhash of the given data.
func ComputeHash(data []byte) uint64 <span class="cov1" title="6">{
        return xxhash.Sum64(data)
}</span>

// AdviseForMatching sets madvise hints on source mmap'd files before matching.
// For raw-indexed sources (Blu-ray with raw offsets), sets MADV_SEQUENTIAL since
// locality-aware matching produces largely sequential access.
// For ES-indexed sources (DVD MPEG-PS, Blu-ray M2TS with ES offsets), the ES reader
// translates ES offsets to scattered positions in the container file, so MADV_SEQUENTIAL
// would hurt. Uses MADV_NORMAL (default adaptive readahead) instead.
func (idx *Index) AdviseForMatching() <span class="cov1" title="1">{
        if idx.UsesESOffsets </span><span class="cov1" title="1">{
                // ES-based: access pattern in the raw file is not sequential
                // (ES offsets map to scattered PES packets). Use normal adaptive readahead.
                for _, mmapFile := range idx.MmapFiles </span><span class="cov1" title="1">{
                        if mmapFile != nil </span><span class="cov1" title="1">{
                                mmapFile.Advise(unix.MADV_NORMAL)
                        }</span>
                }
        } else<span class="cov0" title="0"> {
                // Raw-indexed: locality-aware matching produces sequential access
                for _, reader := range idx.RawReaders </span><span class="cov0" title="0">{
                        if rr, ok := reader.(*mmapRawReader); ok </span><span class="cov0" title="0">{
                                rr.mmapFile.Advise(unix.MADV_SEQUENTIAL)
                        }</span>
                }
        }
}

// Close releases resources held by the index.
func (idx *Index) Close() error <span class="cov1" title="7">{
        // Close all mmap files (these back the ESReaders and RawReaders)
        for _, mmapFile := range idx.MmapFiles </span><span class="cov1" title="3">{
                if mmapFile != nil </span><span class="cov1" title="3">{
                        mmapFile.Close()
                }</span>
        }
        // Close all raw readers (which also close their mmap files)
        <span class="cov1" title="7">for _, reader := range idx.RawReaders </span><span class="cov0" title="0">{
                if reader != nil </span><span class="cov0" title="0">{
                        reader.Close()
                }</span>
        }
        <span class="cov1" title="7">return nil</span>
}
</pre>
		
		<pre class="file" id="file44" style="display: none">package source

import (
        "errors"
        "fmt"
        "os"
        "strings"
)

// errNotISO9660 is returned when the image lacks a valid ISO9660 PVD,
// signaling the caller to try an alternative filesystem (e.g. UDF).
var errNotISO9660 = errors.New("not an ISO9660 image")

const isoSectorSize = 2048

// isoFileExtent represents a file within an ISO9660 filesystem.
type isoFileExtent struct {
        Name    string             // filename (uppercase, no version suffix)
        Offset  int64              // byte offset in ISO (first extent)
        Size    int64              // data length in bytes
        IsDir   bool               // true if this is a directory entry
        Extents []isoPhysicalRange // non-nil for multi-extent UDF files
}

// isoPhysicalRange describes one contiguous physical region within an ISO.
type isoPhysicalRange struct {
        ISOOffset int64 // byte offset in the ISO file
        Length    int64 // number of bytes
}

// findBlurayM2TSInISO parses an ISO9660 filesystem to find M2TS files
// under the BDMV/STREAM/ directory. Returns the files sorted by name.
func findBlurayM2TSInISO(isoPath string) ([]isoFileExtent, error) <span class="cov5" title="5">{
        f, err := os.Open(isoPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov5" title="5">defer f.Close()

        // Read root directory from PVD
        rootExtent, rootDataLen, err := readISOPVDRoot(f)
        if err != nil </span><span class="cov2" title="2">{
                if errors.Is(err, errNotISO9660) </span><span class="cov2" title="2">{
                        // No valid ISO9660 PVD, try UDF (Blu-ray ISOs from CloneBD)
                        return findBlurayM2TSInUDF(f)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("read ISO PVD: %w", err)</span>
        }

        // Navigate: root → BDMV → STREAM
        <span class="cov3" title="3">rootEntries, err := readISODirectory(f, rootExtent, rootDataLen)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read ISO root directory: %w", err)
        }</span>

        <span class="cov3" title="3">bdmv, err := findISOEntry(rootEntries, "BDMV")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("find BDMV directory: %w", err)
        }</span>

        <span class="cov3" title="3">bdmvEntries, err := readISODirectory(f, uint32(bdmv.Offset/isoSectorSize), uint32(bdmv.Size))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read BDMV directory: %w", err)
        }</span>

        <span class="cov3" title="3">stream, err := findISOEntry(bdmvEntries, "STREAM")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("find STREAM directory: %w", err)
        }</span>

        <span class="cov3" title="3">streamEntries, err := readISODirectory(f, uint32(stream.Offset/isoSectorSize), uint32(stream.Size))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read STREAM directory: %w", err)
        }</span>

        // Collect M2TS files
        <span class="cov3" title="3">var m2tsFiles []isoFileExtent
        for _, e := range streamEntries </span><span class="cov3" title="3">{
                if !e.IsDir &amp;&amp; strings.HasSuffix(e.Name, ".M2TS") </span><span class="cov3" title="3">{
                        m2tsFiles = append(m2tsFiles, e)
                }</span>
        }

        <span class="cov3" title="3">return m2tsFiles, nil</span>
}

// readISOPVDRoot reads the Primary Volume Descriptor and returns the root
// directory extent LBA and data length.
func readISOPVDRoot(f *os.File) (extentLBA uint32, dataLen uint32, err error) <span class="cov5" title="5">{
        const pvdOffset = 16 * isoSectorSize

        pvd := make([]byte, isoSectorSize)
        if _, err := f.ReadAt(pvd, pvdOffset); err != nil </span><span class="cov0" title="0">{
                return 0, 0, err
        }</span>

        // Verify PVD: type=1, signature="CD001"
        <span class="cov5" title="5">if pvd[0] != 1 || string(pvd[1:6]) != "CD001" </span><span class="cov2" title="2">{
                return 0, 0, fmt.Errorf("%w: invalid primary volume descriptor", errNotISO9660)
        }</span>

        // Root directory record at offset 156
        <span class="cov3" title="3">root := pvd[156:]
        if len(root) &lt; 34 </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("%w: root directory record too short", errNotISO9660)
        }</span>

        <span class="cov3" title="3">extentLBA = uint32(root[2]) | uint32(root[3])&lt;&lt;8 |
                uint32(root[4])&lt;&lt;16 | uint32(root[5])&lt;&lt;24
        dataLen = uint32(root[10]) | uint32(root[11])&lt;&lt;8 |
                uint32(root[12])&lt;&lt;16 | uint32(root[13])&lt;&lt;24

        return extentLBA, dataLen, nil</span>
}

// readISODirectory reads and parses an ISO9660 directory at the given extent.
func readISODirectory(f *os.File, extentLBA, dataLen uint32) ([]isoFileExtent, error) <span class="cov6" title="9">{
        // Cap directory read to 256KB to avoid huge allocations
        if dataLen &gt; 256*1024 </span><span class="cov0" title="0">{
                dataLen = 256 * 1024
        }</span>

        <span class="cov6" title="9">dirData := make([]byte, dataLen)
        if _, err := f.ReadAt(dirData, int64(extentLBA)*isoSectorSize); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov6" title="9">var entries []isoFileExtent
        offset := 0
        for offset &lt; len(dirData) </span><span class="cov10" title="36">{
                recLen := int(dirData[offset])
                if recLen == 0 </span><span class="cov6" title="9">{
                        // Padding at end of sector — skip to next sector boundary
                        nextSector := ((offset / isoSectorSize) + 1) * isoSectorSize
                        if nextSector &gt;= len(dirData) </span><span class="cov6" title="9">{
                                break</span>
                        }
                        <span class="cov0" title="0">offset = nextSector
                        continue</span>
                }
                <span class="cov9" title="27">if offset+recLen &gt; len(dirData) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov9" title="27">if offset+33 &gt; len(dirData) </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov9" title="27">nameLen := int(dirData[offset+32])
                if nameLen == 0 || offset+33+nameLen &gt; len(dirData) </span><span class="cov0" title="0">{
                        offset += recLen
                        continue</span>
                }

                <span class="cov9" title="27">name := string(dirData[offset+33 : offset+33+nameLen])

                // Skip "." and ".." entries (single byte 0x00 or 0x01)
                if nameLen == 1 &amp;&amp; (name[0] == 0x00 || name[0] == 0x01) </span><span class="cov8" title="18">{
                        offset += recLen
                        continue</span>
                }

                // Normalize: uppercase, strip version (";1") and trailing dot
                <span class="cov6" title="9">name = strings.ToUpper(name)
                if idx := strings.Index(name, ";"); idx &gt;= 0 </span><span class="cov0" title="0">{
                        name = name[:idx]
                }</span>
                <span class="cov6" title="9">name = strings.TrimSuffix(name, ".")

                // Extract extent LBA (bytes 2-5, little-endian)
                eLBA := uint32(dirData[offset+2]) | uint32(dirData[offset+3])&lt;&lt;8 |
                        uint32(dirData[offset+4])&lt;&lt;16 | uint32(dirData[offset+5])&lt;&lt;24
                // Extract data length (bytes 10-13, little-endian)
                eLen := uint32(dirData[offset+10]) | uint32(dirData[offset+11])&lt;&lt;8 |
                        uint32(dirData[offset+12])&lt;&lt;16 | uint32(dirData[offset+13])&lt;&lt;24

                // File flags byte 25: bit 1 = directory
                isDir := dirData[offset+25]&amp;0x02 != 0

                entries = append(entries, isoFileExtent{
                        Name:   name,
                        Offset: int64(eLBA) * isoSectorSize,
                        Size:   int64(eLen),
                        IsDir:  isDir,
                })

                offset += recLen</span>
        }

        <span class="cov6" title="9">return entries, nil</span>
}

// findISOEntry finds a named directory entry (case-insensitive).
func findISOEntry(entries []isoFileExtent, name string) (*isoFileExtent, error) <span class="cov5" title="6">{
        upper := strings.ToUpper(name)
        for i := range entries </span><span class="cov5" title="6">{
                if entries[i].Name == upper </span><span class="cov5" title="6">{
                        return &amp;entries[i], nil
                }</span>
        }
        <span class="cov0" title="0">return nil, fmt.Errorf("%q not found", name)</span>
}
</pre>
		
		<pre class="file" id="file45" style="display: none">package source

import "sort"

// isoM2TSAdapter wraps an MPEGTSParser to provide ISO-level integration
// for an M2TS region embedded within a Blu-ray ISO file. The parser operates
// on a sub-slice (contiguous) or virtual contiguous view (multi-extent) of
// the ISO data, producing FileOffset values relative to that view.
//
// The adapter handles two offset domains:
//   - Parser-relative: used by FilteredVideoRanges (zero-copy from parser),
//     DataSlice (adds baseOffset / resolves via multiRegionData internally),
//     and all ES-offset-based reads.
//   - ISO-relative: used by range maps stored in the dedup file. The
//     FileOffsetConverter method provides the conversion function, applied
//     lazily during range map encoding to avoid copying range arrays.
type isoM2TSAdapter struct {
        parser     *MPEGTSParser
        isoData    []byte // full ISO mmap data (contiguous case: used by Data/DataSlice)
        baseOffset int64  // M2TS region start offset within the ISO

        // For non-contiguous multi-extent files:
        mr        *multiRegionData // virtual contiguous view over mmap sub-slices
        extentMap []extentMapEntry // maps logical offset → ISO offset
}

// extentMapEntry maps a range of logical (assembled) offsets to physical ISO offsets.
type extentMapEntry struct {
        LogicalStart int64 // start offset in assembled data
        ISOOffset    int64 // corresponding offset in the ISO file
        Length       int64 // length of this extent
}

// newISOAdapter creates an adapter for an M2TS region within an ISO.
func newISOAdapter(parser *MPEGTSParser, isoData []byte, baseOffset int64) *isoM2TSAdapter <span class="cov6" title="6">{
        return &amp;isoM2TSAdapter{
                parser:     parser,
                isoData:    isoData,
                baseOffset: baseOffset,
        }
}</span>

// newISOAdapterMultiExtent creates an adapter for a non-contiguous M2TS region.
// mr provides a virtual contiguous view over the mmap sub-slices.
// extents describes the physical layout in the ISO.
func newISOAdapterMultiExtent(parser *MPEGTSParser, mr *multiRegionData, extents []isoPhysicalRange) *isoM2TSAdapter <span class="cov4" title="3">{
        // Build the extent map with cumulative logical offsets
        em := make([]extentMapEntry, len(extents))
        logicalOff := int64(0)
        for i, ext := range extents </span><span class="cov5" title="5">{
                em[i] = extentMapEntry{
                        LogicalStart: logicalOff,
                        ISOOffset:    ext.ISOOffset,
                        Length:       ext.Length,
                }
                logicalOff += ext.Length
        }</span>
        <span class="cov4" title="3">return &amp;isoM2TSAdapter{
                parser:    parser,
                mr:        mr,
                extentMap: em,
        }</span>
}

// --- esDataProvider interface (used by indexer) ---

// Data returns the backing data buffer. For contiguous files, this is the
// full ISO mmap. For multi-extent files, returns nil — use DataSlice instead.
func (a *isoM2TSAdapter) Data() []byte <span class="cov4" title="3">{
        if a.mr != nil </span><span class="cov1" title="1">{
                return nil
        }</span>
        <span class="cov3" title="2">return a.isoData</span>
}

// DataSlice returns a sub-slice of the backing data at the given offset and size.
// Offsets are parser-relative (from FilteredVideoRanges). The adapter handles
// the mapping to ISO data internally.
func (a *isoM2TSAdapter) DataSlice(off int64, size int) []byte <span class="cov10" title="19">{
        if a.mr != nil </span><span class="cov6" title="6">{
                // Multi-extent: parser-relative = assembled-relative, resolve via mr
                return a.mr.Slice(off, off+int64(size))
        }</span>
        // Contiguous: parser-relative + baseOffset = ISO-relative
        <span class="cov8" title="13">return a.isoData[off+a.baseOffset : off+a.baseOffset+int64(size)]</span>
}

// DataSize returns the parser's data size (for bounds checking parser-relative offsets).
func (a *isoM2TSAdapter) DataSize() int64 <span class="cov6" title="6">{
        return a.parser.DataSize()
}</span>

// FilteredVideoRanges returns the parser's filtered video ranges (zero-copy).
// FileOffset values are parser-relative. Use FileOffsetConverter to get
// ISO-relative offsets for range map encoding.
func (a *isoM2TSAdapter) FilteredVideoRanges() []PESPayloadRange <span class="cov5" title="5">{
        return a.parser.FilteredVideoRanges()
}</span>

// FilteredAudioRanges returns the parser's filtered audio ranges (zero-copy).
func (a *isoM2TSAdapter) FilteredAudioRanges(subStreamID byte) []PESPayloadRange <span class="cov3" title="2">{
        return a.parser.FilteredAudioRanges(subStreamID)
}</span>

func (a *isoM2TSAdapter) ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error) <span class="cov1" title="1">{
        return a.parser.ReadESData(esOffset, size, isVideo)
}</span>

func (a *isoM2TSAdapter) ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error) <span class="cov0" title="0">{
        return a.parser.ReadAudioSubStreamData(subStreamID, esOffset, size)
}</span>

// --- ESReader interface (used by matcher/reconstruction) ---

func (a *isoM2TSAdapter) ESOffsetToFileOffset(esOffset int64, isVideo bool) (fileOffset int64, remaining int) <span class="cov0" title="0">{
        fOff, rem := a.parser.ESOffsetToFileOffset(esOffset, isVideo)
        if a.mr != nil </span><span class="cov0" title="0">{
                // Multi-extent: parser offset is assembled-relative,
                // convert to ISO-relative for range maps / reconstruction.
                return a.logicalToISO(fOff), rem
        }</span>
        <span class="cov0" title="0">return fOff + a.baseOffset, rem</span>
}

func (a *isoM2TSAdapter) TotalESSize(isVideo bool) int64 <span class="cov3" title="2">{
        return a.parser.TotalESSize(isVideo)
}</span>

func (a *isoM2TSAdapter) AudioSubStreams() []byte <span class="cov3" title="2">{
        return a.parser.AudioSubStreams()
}</span>

func (a *isoM2TSAdapter) AudioSubStreamESSize(subStreamID byte) int64 <span class="cov3" title="2">{
        return a.parser.AudioSubStreamESSize(subStreamID)
}</span>

// --- PESRangeProvider interface (used for range map creation) ---
// FilteredVideoRanges and FilteredAudioRanges already defined above.
// AudioSubStreams already defined above.

// --- FileOffsetAdjuster interface ---

// FileOffsetConverter returns a function that converts parser-relative
// FileOffset values to ISO-relative offsets for range map storage.
func (a *isoM2TSAdapter) FileOffsetConverter() func(int64) int64 <span class="cov4" title="3">{
        if a.mr != nil </span><span class="cov1" title="1">{
                return a.logicalToISO
        }</span>
        <span class="cov3" title="2">baseOff := a.baseOffset
        return func(off int64) int64 </span><span class="cov6" title="6">{ return off + baseOff }</span>
}

// --- hintedESReader interface (used by matcher expand) ---

func (a *isoM2TSAdapter) ReadESByteWithHint(esOffset int64, isVideo bool, rangeHint int) (byte, int, bool) <span class="cov0" title="0">{
        return a.parser.ReadESByteWithHint(esOffset, isVideo, rangeHint)
}</span>

func (a *isoM2TSAdapter) ReadAudioByteWithHint(subStreamID byte, esOffset int64, rangeHint int) (byte, int, bool) <span class="cov0" title="0">{
        return a.parser.ReadAudioByteWithHint(subStreamID, esOffset, rangeHint)
}</span>

// --- ESRangeConverter interface (for V3 format — adds baseOffset to raw ranges) ---

func (a *isoM2TSAdapter) RawRangesForESRegion(esOffset int64, size int, isVideo bool) ([]RawRange, error) <span class="cov0" title="0">{
        ranges, err := a.parser.RawRangesForESRegion(esOffset, size, isVideo)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return a.adjustRawRanges(ranges), nil</span>
}

func (a *isoM2TSAdapter) RawRangesForAudioSubStream(subStreamID byte, esOffset int64, size int) ([]RawRange, error) <span class="cov0" title="0">{
        ranges, err := a.parser.RawRangesForAudioSubStream(subStreamID, esOffset, size)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return a.adjustRawRanges(ranges), nil</span>
}

// --- Internal helpers ---

// adjustRawRanges creates a copy of raw ranges with offsets adjusted.
// Raw ranges are small (per-match, not per-packet) so copying is fine.
func (a *isoM2TSAdapter) adjustRawRanges(ranges []RawRange) []RawRange <span class="cov0" title="0">{
        if a.mr != nil </span><span class="cov0" title="0">{
                // Multi-extent: convert assembled-relative offsets to ISO-relative
                // for range maps stored in the dedup file.
                return a.mapRawRangesToISO(ranges)
        }</span>
        <span class="cov0" title="0">adjusted := make([]RawRange, len(ranges))
        for i, r := range ranges </span><span class="cov0" title="0">{
                adjusted[i] = RawRange{
                        FileOffset: r.FileOffset + a.baseOffset,
                        Size:       r.Size,
                }
        }</span>
        <span class="cov0" title="0">return adjusted</span>
}

// logicalToISO converts a logical offset in the assembled data to the
// corresponding physical ISO offset using the extent map.
func (a *isoM2TSAdapter) logicalToISO(logicalOff int64) int64 <span class="cov4" title="3">{
        if len(a.extentMap) == 0 </span><span class="cov0" title="0">{
                return logicalOff
        }</span>
        // Binary search for the extent containing this offset
        <span class="cov4" title="3">idx := sort.Search(len(a.extentMap), func(i int) bool </span><span class="cov6" title="6">{
                return a.extentMap[i].LogicalStart+a.extentMap[i].Length &gt; logicalOff
        }</span>)
        <span class="cov4" title="3">if idx &gt;= len(a.extentMap) </span><span class="cov0" title="0">{
                // Shouldn't happen — fall back to last extent
                idx = len(a.extentMap) - 1
        }</span>
        <span class="cov4" title="3">e := a.extentMap[idx]
        return e.ISOOffset + (logicalOff - e.LogicalStart)</span>
}

// mapRawRangesToISO converts assembled-relative raw ranges to ISO-relative ranges.
// A single assembled range may span an extent boundary, so it may be split into
// multiple ISO ranges.
func (a *isoM2TSAdapter) mapRawRangesToISO(ranges []RawRange) []RawRange <span class="cov0" title="0">{
        var result []RawRange
        for _, r := range ranges </span><span class="cov0" title="0">{
                remaining := int64(r.Size)
                logOff := r.FileOffset
                for remaining &gt; 0 </span><span class="cov0" title="0">{
                        idx := sort.Search(len(a.extentMap), func(i int) bool </span><span class="cov0" title="0">{
                                return a.extentMap[i].LogicalStart+a.extentMap[i].Length &gt; logOff
                        }</span>)
                        <span class="cov0" title="0">if idx &gt;= len(a.extentMap) </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">e := a.extentMap[idx]
                        offsetInExtent := logOff - e.LogicalStart
                        available := e.Length - offsetInExtent
                        chunk := remaining
                        if chunk &gt; available </span><span class="cov0" title="0">{
                                chunk = available
                        }</span>
                        <span class="cov0" title="0">result = append(result, RawRange{
                                FileOffset: e.ISOOffset + offsetInExtent,
                                Size:       int(chunk),
                        })
                        logOff += chunk
                        remaining -= chunk</span>
                }
        }
        <span class="cov0" title="0">return result</span>
}
</pre>
		
		<pre class="file" id="file46" style="display: none">package source

import (
        "bytes"
        "encoding/binary"
        "fmt"
)

// MPEG-PS start codes
const (
        PackStartCode      = 0x000001BA
        SystemHeaderCode   = 0x000001BB
        ProgramEndCode     = 0x000001B9
        PrivateStream1Code = 0x000001BD
        PrivateStream2Code = 0x000001BF
        PaddingStreamCode  = 0x000001BE
        VideoStreamMinCode = 0x000001E0
        VideoStreamMaxCode = 0x000001EF
        AudioStreamMinCode = 0x000001C0
        AudioStreamMaxCode = 0x000001DF
)

// PESPacket represents a parsed PES packet from an MPEG-PS stream.
type PESPacket struct {
        StreamID      byte  // Stream identifier (E0-EF = video, C0-DF = audio, BD = private)
        SubStreamID   byte  // Sub-stream ID for Private Stream 1 (0x80-0x87 = AC3, 0x88-0x8F = DTS)
        Offset        int64 // Offset of the PES packet start in the file
        HeaderSize    int   // Total header size (start code + length + PES header + private header)
        PayloadOffset int64 // Offset of the actual audio/video payload
        PayloadSize   int   // Size of the payload
        IsVideo       bool  // True if this is a video stream
        IsAudio       bool  // True if this is an audio stream
}

// PESPayloadRange represents a contiguous range of elementary stream payload data.
type PESPayloadRange struct {
        FileOffset int64 // Offset in the MPEG-PS file
        Size       int   // Size of this payload chunk
        ESOffset   int64 // Logical offset in the elementary stream
}

// MPEGPSParser parses MPEG Program Stream files to extract PES packet information.
type MPEGPSParser struct {
        data        []byte // Direct mmap'd data - zero-copy access
        size        int64
        packets     []PESPacket
        videoRanges []PESPayloadRange
        audioRanges []PESPayloadRange
        // Filtered ranges exclude user_data sections for MKV-compatible matching
        filteredVideoRanges []PESPayloadRange
        // Filtered audio ranges per sub-stream ID - separates interleaved audio tracks
        // Each sub-stream (0x80, 0x81, etc.) gets its own filtered range set
        filteredAudioBySubStream map[byte][]PESPayloadRange
        // audioSubStreams lists the sub-stream IDs in order of appearance
        audioSubStreams []byte
        filterUserData  bool
}

// NewMPEGPSParser creates a parser for the given memory-mapped data.
// The data slice should be from a zero-copy mmap (unix.Mmap).
func NewMPEGPSParser(data []byte) *MPEGPSParser <span class="cov1" title="1">{
        return &amp;MPEGPSParser{
                data: data,
                size: int64(len(data)),
        }
}</span>

// MPEGPSProgressFunc is called to report MPEG-PS parsing progress.
type MPEGPSProgressFunc func(processed, total int64)

// Parse scans the file and extracts all PES packet information.
func (p *MPEGPSParser) Parse() error <span class="cov0" title="0">{
        return p.ParseWithProgress(nil)
}</span>

// ParseWithProgress scans the file with progress reporting.
func (p *MPEGPSParser) ParseWithProgress(progress MPEGPSProgressFunc) error <span class="cov1" title="1">{
        pos := int64(0)
        var videoESOffset, audioESOffset int64
        lastProgress := int64(0)

        // Pre-allocate slices to reduce reallocation churn
        // Estimate: average PES packet ~2KB, so ~size/2048 packets
        // We split roughly 60% video, 40% audio
        estimatedPackets := int(p.size / 2048)
        if estimatedPackets &lt; 1000 </span><span class="cov0" title="0">{
                estimatedPackets = 1000
        }</span>
        <span class="cov1" title="1">p.packets = make([]PESPacket, 0, estimatedPackets)
        p.videoRanges = make([]PESPayloadRange, 0, estimatedPackets*6/10)
        p.audioRanges = make([]PESPayloadRange, 0, estimatedPackets*4/10)

        for pos &lt; p.size-4 </span><span class="cov4" title="1922">{
                // Direct slice access - zero copy
                end := pos + 4*1024*1024 // Process in ~4MB logical chunks for progress
                if end &gt; p.size </span><span class="cov1" title="1">{
                        end = p.size
                }</span>
                <span class="cov4" title="1922">chunkData := p.data[pos:end]
                if len(chunkData) &lt; 4 </span><span class="cov0" title="0">{
                        break</span>
                }

                // Scan for start codes within this chunk
                <span class="cov4" title="1922">i := 0
                for i &lt; len(chunkData)-4 </span><span class="cov10" title="637120853">{
                        // Fast scan for 00 00 01 prefix
                        if chunkData[i] != 0 </span><span class="cov9" title="586130268">{
                                i++
                                continue</span>
                        }
                        <span class="cov8" title="50990585">if chunkData[i+1] != 0 </span><span class="cov8" title="25266964">{
                                i += 2
                                continue</span>
                        }
                        <span class="cov8" title="25723621">if chunkData[i+2] != 1 </span><span class="cov8" title="22775619">{
                                i++
                                continue</span>
                        }

                        // Found potential start code at pos + i
                        <span class="cov7" title="2948002">startCodePos := pos + int64(i)
                        startCode := uint32(0x00000100) | uint32(chunkData[i+3])

                        advance := int64(1)

                        switch </span>{
                        case startCode == PackStartCode:<span class="cov7" title="1392933">
                                packSize, err := p.parsePackHeader(startCodePos)
                                if err == nil </span><span class="cov7" title="1392933">{
                                        advance = int64(packSize)
                                }</span>

                        case startCode == SystemHeaderCode:<span class="cov5" title="8606">
                                headerLen, err := p.parseSystemHeader(startCodePos)
                                if err == nil </span><span class="cov5" title="8606">{
                                        advance = int64(headerLen)
                                }</span>

                        case startCode == ProgramEndCode:<span class="cov3" title="158">
                                // End of program stream - but DVDs can have multiple programs
                                // (menu, main feature, extras, etc.), so continue parsing
                                advance = 4</span>

                        case startCode == PaddingStreamCode:<span class="cov5" title="8645">
                                length, err := p.readPESLength(startCodePos + 4)
                                if err == nil </span><span class="cov5" title="8645">{
                                        advance = 6 + int64(length)
                                }</span>

                        case startCode == PrivateStream1Code:<span class="cov6" title="88899">
                                pkt, err := p.parsePESPacket(startCodePos, byte(startCode&amp;0xFF))
                                if err == nil </span><span class="cov6" title="88899">{
                                        pkt.IsAudio = true
                                        p.packets = append(p.packets, pkt)
                                        p.audioRanges = append(p.audioRanges, PESPayloadRange{
                                                FileOffset: pkt.PayloadOffset,
                                                Size:       pkt.PayloadSize,
                                                ESOffset:   audioESOffset,
                                        })
                                        audioESOffset += int64(pkt.PayloadSize)
                                        advance = int64(pkt.HeaderSize + pkt.PayloadSize)
                                }</span>

                        case startCode &gt;= VideoStreamMinCode &amp;&amp; startCode &lt;= VideoStreamMaxCode:<span class="cov7" title="1298906">
                                pkt, err := p.parsePESPacket(startCodePos, byte(startCode&amp;0xFF))
                                if err == nil </span><span class="cov7" title="1298906">{
                                        pkt.IsVideo = true
                                        p.packets = append(p.packets, pkt)
                                        p.videoRanges = append(p.videoRanges, PESPayloadRange{
                                                FileOffset: pkt.PayloadOffset,
                                                Size:       pkt.PayloadSize,
                                                ESOffset:   videoESOffset,
                                        })
                                        videoESOffset += int64(pkt.PayloadSize)
                                        advance = int64(pkt.HeaderSize + pkt.PayloadSize)
                                }</span>

                        case startCode &gt;= AudioStreamMinCode &amp;&amp; startCode &lt;= AudioStreamMaxCode:<span class="cov4" title="7816">
                                pkt, err := p.parsePESPacket(startCodePos, byte(startCode&amp;0xFF))
                                if err == nil </span><span class="cov4" title="7816">{
                                        pkt.IsAudio = true
                                        p.packets = append(p.packets, pkt)
                                        p.audioRanges = append(p.audioRanges, PESPayloadRange{
                                                FileOffset: pkt.PayloadOffset,
                                                Size:       pkt.PayloadSize,
                                                ESOffset:   audioESOffset,
                                        })
                                        audioESOffset += int64(pkt.PayloadSize)
                                        advance = int64(pkt.HeaderSize + pkt.PayloadSize)
                                }</span>
                        }

                        // Move forward by the packet size (or 1 if unknown)
                        <span class="cov7" title="2948002">newPos := startCodePos + advance
                        i = int(newPos - pos)</span>
                }

                // Move to next chunk, but back up slightly to catch start codes at boundaries
                <span class="cov4" title="1922">pos += int64(len(chunkData)) - 3
                if pos &lt; 0 </span><span class="cov0" title="0">{
                        pos = 0
                }</span>

                // Report progress
                <span class="cov4" title="1922">if progress != nil &amp;&amp; pos-lastProgress &gt; 100*1024*1024 </span><span class="cov2" title="73">{ // Every 100MB
                        progress(pos, p.size)
                        lastProgress = pos
                }</span>
        }

        <span class="cov1" title="1">if progress != nil </span><span class="cov1" title="1">{
                progress(p.size, p.size)
        }</span>

        // Build filtered video ranges that exclude user_data (B2) sections
        // This makes the ES compatible with what MKV tools produce
        <span class="cov1" title="1">if err := p.buildFilteredVideoRanges(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("build filtered video ranges: %w", err)
        }</span>

        // Build filtered audio ranges that strip Private Stream 1 headers
        // (sub-stream ID and 2-byte pointer, keeping frame count byte)
        <span class="cov1" title="1">if err := p.buildFilteredAudioRanges(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("build filtered audio ranges: %w", err)
        }</span>

        <span class="cov1" title="1">p.filterUserData = true

        return nil</span>
}

// buildFilteredVideoRanges scans the video ES and creates ranges that exclude user_data sections.
// User_data (00 00 01 B2) is used for closed captions etc. and is stripped by MKV tools.
// Optimized to use bytes.IndexByte for fast scanning (uses SIMD on x86).
func (p *MPEGPSParser) buildFilteredVideoRanges() error <span class="cov1" title="1">{
        if len(p.videoRanges) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Process each raw video range individually
        // This avoids complex chunk boundary handling
        // Pre-allocate with similar capacity to reduce reallocation
        <span class="cov1" title="1">filteredRanges := make([]PESPayloadRange, 0, len(p.videoRanges))
        var filteredESOffset int64

        for _, rawRange := range p.videoRanges </span><span class="cov7" title="1298906">{
                // Direct slice access - zero copy, no allocation
                endOffset := rawRange.FileOffset + int64(rawRange.Size)
                if endOffset &gt; p.size </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov7" title="1298906">data := p.data[rawRange.FileOffset:endOffset]

                // Scan for user_data sections within this PES payload
                // Use bytes.IndexByte to quickly find 0x01 bytes (SIMD optimized)
                i := 2 // Start at position 2 since we need at least 00 00 before 01
                rangeStart := 0
                for i &lt; len(data)-1 </span><span class="cov8" title="44511240">{
                        // Find next 0x01 byte
                        idx := bytes.IndexByte(data[i:], 0x01)
                        if idx &lt; 0 </span><span class="cov7" title="1256377">{
                                break</span>
                        }
                        <span class="cov8" title="43254863">pos := i + idx

                        // Check if this is a user_data start code (00 00 01 B2)
                        if pos &gt;= 2 &amp;&amp; pos &lt; len(data)-1 &amp;&amp;
                                data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 &amp;&amp; data[pos+1] == UserDataStartCode </span><span class="cov2" title="29">{
                                // Found user_data - emit range before it
                                startCodePos := pos - 2
                                if startCodePos &gt; rangeStart </span><span class="cov2" title="29">{
                                        filteredRanges = append(filteredRanges, PESPayloadRange{
                                                FileOffset: rawRange.FileOffset + int64(rangeStart),
                                                Size:       startCodePos - rangeStart,
                                                ESOffset:   filteredESOffset,
                                        })
                                        filteredESOffset += int64(startCodePos - rangeStart)
                                }</span>

                                // Skip user_data section to next start code using fast scan
                                <span class="cov2" title="29">i = pos + 2
                                for i &lt; len(data)-1 </span><span class="cov3" title="326">{
                                        idx := bytes.IndexByte(data[i:], 0x01)
                                        if idx &lt; 0 </span><span class="cov1" title="3">{
                                                i = len(data)
                                                break</span>
                                        }
                                        <span class="cov3" title="323">nextPos := i + idx
                                        if nextPos &gt;= 2 &amp;&amp; data[nextPos-1] == 0x00 &amp;&amp; data[nextPos-2] == 0x00 </span><span class="cov2" title="13">{
                                                // Found next start code
                                                i = nextPos - 2
                                                break</span>
                                        }
                                        <span class="cov3" title="310">i = nextPos + 1</span>
                                }
                                <span class="cov2" title="29">rangeStart = i</span>
                        } else<span class="cov8" title="43254834"> {
                                i = pos + 1
                        }</span>
                }

                // Emit remaining data in this PES payload
                <span class="cov7" title="1298906">if rangeStart &lt; len(data) </span><span class="cov7" title="1298321">{
                        filteredRanges = append(filteredRanges, PESPayloadRange{
                                FileOffset: rawRange.FileOffset + int64(rangeStart),
                                Size:       len(data) - rangeStart,
                                ESOffset:   filteredESOffset,
                        })
                        filteredESOffset += int64(len(data) - rangeStart)
                }</span>
        }

        <span class="cov1" title="1">p.filteredVideoRanges = filteredRanges
        return nil</span>
}

// buildFilteredAudioRanges creates ranges that strip Private Stream 1 headers
// and separates audio by sub-stream ID.
// DVD audio in Private Stream 1 has this structure:
//
//        Byte 0: sub-stream ID (0x80-0x87 = AC3, 0x88-0x8F = DTS, etc.)
//        Byte 1: number of audio frames
//        Bytes 2-3: first access unit pointer (offset to first audio frame)
//        Bytes 4+: audio data
//
// We strip the entire 4-byte header and keep only the raw audio data.
// Each sub-stream ID gets its own separate filtered ES to avoid interleaving issues.
func (p *MPEGPSParser) buildFilteredAudioRanges() error <span class="cov1" title="1">{
        if len(p.audioRanges) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Map to track ranges per sub-stream
        <span class="cov1" title="1">rangesBySubStream := make(map[byte][]PESPayloadRange)
        esOffsetBySubStream := make(map[byte]int64)
        seenSubStreams := make(map[byte]bool)

        for _, rawRange := range p.audioRanges </span><span class="cov6" title="96715">{
                if rawRange.Size &lt; 4 </span><span class="cov4" title="1296">{
                        // Too small to have the header structure
                        continue</span>
                }

                // Direct slice access - zero copy
                <span class="cov6" title="95419">if rawRange.FileOffset &gt;= p.size </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov6" title="95419">subStreamID := p.data[rawRange.FileOffset]

                // Check if this is AC3, DTS, or LPCM
                isAC3 := subStreamID &gt;= 0x80 &amp;&amp; subStreamID &lt;= 0x87
                isDTS := subStreamID &gt;= 0x88 &amp;&amp; subStreamID &lt;= 0x8F
                isLPCM := subStreamID &gt;= 0xA0 &amp;&amp; subStreamID &lt;= 0xA7

                if isAC3 || isDTS || isLPCM </span><span class="cov6" title="89025">{
                        // Track sub-stream order
                        if !seenSubStreams[subStreamID] </span><span class="cov2" title="24">{
                                seenSubStreams[subStreamID] = true
                                p.audioSubStreams = append(p.audioSubStreams, subStreamID)
                        }</span>

                        // Strip the entire 4-byte header, keep only raw audio data
                        <span class="cov6" title="89025">if rawRange.Size &gt; 4 </span><span class="cov6" title="89025">{
                                esOffset := esOffsetBySubStream[subStreamID]
                                rangesBySubStream[subStreamID] = append(rangesBySubStream[subStreamID], PESPayloadRange{
                                        FileOffset: rawRange.FileOffset + 4, // Skip header (1 + 1 + 2)
                                        Size:       rawRange.Size - 4,       // Rest is audio data
                                        ESOffset:   esOffset,
                                })
                                esOffsetBySubStream[subStreamID] += int64(rawRange.Size - 4)
                        }</span>
                }
                // Skip unknown sub-stream types (like subtitles 0x20-0x3F)
        }

        <span class="cov1" title="1">p.filteredAudioBySubStream = rangesBySubStream
        return nil</span>
}

// parsePackHeader parses an MPEG-2 pack header and returns its size.
func (p *MPEGPSParser) parsePackHeader(pos int64) (int, error) <span class="cov7" title="1392933">{
        // MPEG-2 pack header is 14 bytes minimum
        // Format: 00 00 01 BA + SCR (6 bytes) + mux_rate (3 bytes) + stuffing
        if pos+14 &gt; p.size </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to read pack header")
        }</span>
        <span class="cov7" title="1392933">buf := p.data[pos : pos+14]

        // Check if this is MPEG-2 (starts with 01) or MPEG-1 (starts with 0010)
        if buf[4]&amp;0xC0 == 0x40 </span><span class="cov7" title="1392822">{
                // MPEG-2 pack header
                stuffingLen := int(buf[13] &amp; 0x07)
                return 14 + stuffingLen, nil
        }</span>

        // MPEG-1 pack header is 12 bytes
        <span class="cov3" title="111">return 12, nil</span>
}

// parseSystemHeader parses a system header and returns its total size.
func (p *MPEGPSParser) parseSystemHeader(pos int64) (int, error) <span class="cov5" title="8606">{
        length, err := p.readPESLength(pos + 4)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov5" title="8606">return 6 + int(length), nil</span>
}

// readPESLength reads the 2-byte PES packet length field.
func (p *MPEGPSParser) readPESLength(pos int64) (uint16, error) <span class="cov7" title="1412872">{
        if pos+2 &gt; p.size </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to read PES length")
        }</span>
        <span class="cov7" title="1412872">return binary.BigEndian.Uint16(p.data[pos : pos+2]), nil</span>
}

// parsePESPacket parses a PES packet header and returns packet info.
func (p *MPEGPSParser) parsePESPacket(pos int64, streamID byte) (PESPacket, error) <span class="cov7" title="1395621">{
        pkt := PESPacket{
                StreamID: streamID,
                Offset:   pos,
        }

        // Read length field
        length, err := p.readPESLength(pos + 4)
        if err != nil </span><span class="cov0" title="0">{
                return pkt, err
        }</span>

        // PES packet structure after start code + stream ID + length:
        // - 2 bits: '10'
        // - 2 bits: PES_scrambling_control
        // - 1 bit: PES_priority
        // - 1 bit: data_alignment_indicator
        // - 1 bit: copyright
        // - 1 bit: original_or_copy
        // - 2 bits: PTS_DTS_flags
        // - 1 bit: ESCR_flag
        // - 1 bit: ES_rate_flag
        // - 1 bit: DSM_trick_mode_flag
        // - 1 bit: additional_copy_info_flag
        // - 1 bit: PES_CRC_flag
        // - 1 bit: PES_extension_flag
        // - 8 bits: PES_header_data_length
        // Then optional fields based on flags

        // Direct slice access for PES header fields
        <span class="cov7" title="1395621">if pos+9 &gt; p.size </span><span class="cov0" title="0">{
                return pkt, fmt.Errorf("failed to read PES header")
        }</span>
        <span class="cov7" title="1395621">buf := p.data[pos+6 : pos+9]

        // Check for MPEG-2 PES (starts with 10)
        if buf[0]&amp;0xC0 == 0x80 </span><span class="cov7" title="1386220">{
                // MPEG-2 PES header
                headerDataLen := int(buf[2])
                pkt.HeaderSize = 6 + 3 + headerDataLen // start code(4) + length(2) + flags(2) + header_len(1) + header_data
                pkt.PayloadOffset = pos + int64(pkt.HeaderSize)
                pkt.PayloadSize = int(length) - 3 - headerDataLen
        }</span> else<span class="cov5" title="9401"> {
                // MPEG-1 PES header - simpler structure
                // Skip stuffing bytes (0xFF) and find actual header
                headerLen := 0
                offset := pos + 6
                for </span><span class="cov5" title="12029">{
                        if offset+int64(headerLen) &gt;= p.size </span><span class="cov0" title="0">{
                                return pkt, fmt.Errorf("failed to read PES header: offset out of range")
                        }</span>
                        <span class="cov5" title="12029">b := p.data[offset+int64(headerLen)]
                        if b == 0xFF </span><span class="cov2" title="75">{
                                headerLen++
                                if headerLen &gt; 16 </span><span class="cov1" title="2">{ // Safety limit
                                        break</span>
                                }
                                <span class="cov2" title="73">continue</span>
                        }
                        <span class="cov5" title="11954">if b&amp;0xC0 == 0x40 </span><span class="cov4" title="2555">{
                                // STD buffer
                                headerLen += 2
                                continue</span>
                        }
                        <span class="cov5" title="9399">if b&amp;0xF0 == 0x20 </span><span class="cov3" title="562">{
                                // PTS only
                                headerLen += 5
                        }</span> else<span class="cov5" title="8837"> if b&amp;0xF0 == 0x30 </span><span class="cov3" title="581">{
                                // PTS + DTS
                                headerLen += 10
                        }</span> else<span class="cov5" title="8256"> if b == 0x0F </span><span class="cov2" title="43">{
                                // No timestamps
                                headerLen++
                        }</span>
                        <span class="cov5" title="9399">break</span>
                }
                <span class="cov5" title="9401">pkt.HeaderSize = 6 + headerLen
                pkt.PayloadOffset = pos + int64(pkt.HeaderSize)
                pkt.PayloadSize = int(length) - headerLen</span>
        }

        <span class="cov7" title="1395621">if pkt.PayloadSize &lt; 0 </span><span class="cov3" title="244">{
                pkt.PayloadSize = 0
        }</span>

        <span class="cov7" title="1395621">return pkt, nil</span>
}

// VideoRanges returns all video payload ranges found in the stream.
func (p *MPEGPSParser) VideoRanges() []PESPayloadRange <span class="cov0" title="0">{
        return p.videoRanges
}</span>

// FilteredVideoRangesCount returns the number of filtered video ranges.
func (p *MPEGPSParser) FilteredVideoRangesCount() int <span class="cov0" title="0">{
        return len(p.filteredVideoRanges)
}</span>

// RawVideoESSize returns the total size of raw (unfiltered) video ES.
func (p *MPEGPSParser) RawVideoESSize() int64 <span class="cov0" title="0">{
        if len(p.videoRanges) == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov0" title="0">last := p.videoRanges[len(p.videoRanges)-1]
        return last.ESOffset + int64(last.Size)</span>
}

// AudioRanges returns all audio payload ranges found in the stream.
func (p *MPEGPSParser) AudioRanges() []PESPayloadRange <span class="cov0" title="0">{
        return p.audioRanges
}</span>

// Packets returns all parsed PES packets.
func (p *MPEGPSParser) Packets() []PESPacket <span class="cov1" title="2">{
        return p.packets
}</span>

// FileOffsetToESOffset converts a file offset within a payload to an ES offset.
// Returns -1 if the offset is not within a known payload range.
func (p *MPEGPSParser) FileOffsetToESOffset(fileOffset int64, isVideo bool) int64 <span class="cov0" title="0">{
        ranges := p.audioRanges
        if isVideo </span><span class="cov0" title="0">{
                ranges = p.videoRanges
        }</span>

        <span class="cov0" title="0">for _, r := range ranges </span><span class="cov0" title="0">{
                if fileOffset &gt;= r.FileOffset &amp;&amp; fileOffset &lt; r.FileOffset+int64(r.Size) </span><span class="cov0" title="0">{
                        offsetInPayload := fileOffset - r.FileOffset
                        return r.ESOffset + offsetInPayload
                }</span>
        }
        <span class="cov0" title="0">return -1</span>
}

// ESOffsetToFileOffset converts an ES offset to a file offset.
// Returns the file offset and payload remaining size, or -1 if not found.
func (p *MPEGPSParser) ESOffsetToFileOffset(esOffset int64, isVideo bool) (fileOffset int64, remaining int) <span class="cov0" title="0">{
        ranges := p.audioRanges
        if isVideo </span><span class="cov0" title="0">{
                ranges = p.videoRanges
        }</span>

        <span class="cov0" title="0">for _, r := range ranges </span><span class="cov0" title="0">{
                if esOffset &gt;= r.ESOffset &amp;&amp; esOffset &lt; r.ESOffset+int64(r.Size) </span><span class="cov0" title="0">{
                        offsetInPayload := esOffset - r.ESOffset
                        return r.FileOffset + offsetInPayload, r.Size - int(offsetInPayload)
                }</span>
        }
        <span class="cov0" title="0">return -1, 0</span>
}

// TotalESSize returns the total size of the elementary stream.
// For video, returns filtered ES size when filtering is enabled.
// For audio, this returns 0 - use AudioSubStreamESSize instead.
func (p *MPEGPSParser) TotalESSize(isVideo bool) int64 <span class="cov8" title="20742954">{
        if !isVideo </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="20742954">if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov8" title="20742952">{
                return totalESSizeFromRanges(p.filteredVideoRanges)
        }</span>
        <span class="cov1" title="2">return totalESSizeFromRanges(p.videoRanges)</span>
}

// AudioSubStreams returns the list of audio sub-stream IDs in order of appearance.
func (p *MPEGPSParser) AudioSubStreams() []byte <span class="cov1" title="3">{
        return p.audioSubStreams
}</span>

// AudioSubStreamCount returns the number of audio sub-streams.
func (p *MPEGPSParser) AudioSubStreamCount() int <span class="cov0" title="0">{
        return len(p.audioSubStreams)
}</span>

// AudioSubStreamESSize returns the total ES size for a specific audio sub-stream.
func (p *MPEGPSParser) AudioSubStreamESSize(subStreamID byte) int64 <span class="cov6" title="218510">{
        return totalESSizeFromRanges(p.filteredAudioBySubStream[subStreamID])
}</span>

// FilteredVideoRanges returns the filtered video payload ranges for zero-copy iteration.
// Returns the raw video ranges if filtering is not enabled.
func (p *MPEGPSParser) FilteredVideoRanges() []PESPayloadRange <span class="cov1" title="1">{
        if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov1" title="1">{
                return p.filteredVideoRanges
        }</span>
        <span class="cov0" title="0">return p.videoRanges</span>
}

// FilteredAudioRanges returns the filtered audio payload ranges for a specific sub-stream.
// Returns nil if the sub-stream doesn't exist.
func (p *MPEGPSParser) FilteredAudioRanges(subStreamID byte) []PESPayloadRange <span class="cov2" title="24">{
        return p.filteredAudioBySubStream[subStreamID]
}</span>

// Data returns the raw mmap'd file data for zero-copy access.
func (p *MPEGPSParser) Data() []byte <span class="cov0" title="0">{
        return p.data
}</span>

// DataSlice returns a sub-slice of the backing data at the given offset and size.
func (p *MPEGPSParser) DataSlice(off int64, size int) []byte <span class="cov7" title="1387375">{
        return p.data[off : off+int64(size)]
}</span>

// DataSize returns the total size of the backing data.
func (p *MPEGPSParser) DataSize() int64 <span class="cov2" title="25">{
        return p.size
}</span>

// ReadESByteWithHint reads a single byte from the ES stream, using a range hint
// to avoid binary search when reading sequentially. Returns the byte, the range
// index where it was found (for use as hint on next call), and success status.
// Pass rangeHint=-1 to force binary search.
func (p *MPEGPSParser) ReadESByteWithHint(esOffset int64, isVideo bool, rangeHint int) (byte, int, bool) <span class="cov9" title="501455197">{
        if !isVideo </span><span class="cov0" title="0">{
                // Audio doesn't use this method - it goes through sub-stream reader
                return 0, -1, false
        }</span>
        <span class="cov9" title="501455197">var ranges []PESPayloadRange
        if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov9" title="501455197">{
                ranges = p.filteredVideoRanges
        }</span> else<span class="cov0" title="0"> {
                ranges = p.videoRanges
        }</span>
        <span class="cov9" title="501455197">return readByteWithHint(p.data, nil, p.size, ranges, esOffset, rangeHint)</span>
}

// ReadAudioByteWithHint reads a single byte from an audio sub-stream, using a range hint.
func (p *MPEGPSParser) ReadAudioByteWithHint(subStreamID byte, esOffset int64, rangeHint int) (byte, int, bool) <span class="cov9" title="72643916">{
        return readByteWithHint(p.data, nil, p.size, p.filteredAudioBySubStream[subStreamID], esOffset, rangeHint)
}</span>

// Video start codes that should be KEPT (not user_data)
const (
        UserDataStartCode = 0xB2 // This gets stripped by MKV tools
)

// RawRange represents a contiguous chunk of raw file data corresponding to
// part of an ES region. Used for converting ES offsets to raw file offsets.
type RawRange struct {
        FileOffset int64 // Offset in the raw file
        Size       int   // Size of this chunk
}

// RawRangesForESRegion returns the raw file ranges that contain the given ES region.
// For video streams only - audio should use RawRangesForAudioSubStream.
func (p *MPEGPSParser) RawRangesForESRegion(esOffset int64, size int, isVideo bool) ([]RawRange, error) <span class="cov5" title="33508">{
        if !isVideo </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("audio uses per-sub-stream methods, use RawRangesForAudioSubStream")
        }</span>
        <span class="cov5" title="33507">var ranges []PESPayloadRange
        if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov5" title="33506">{
                ranges = p.filteredVideoRanges
        }</span> else<span class="cov1" title="1"> {
                ranges = p.videoRanges
        }</span>
        <span class="cov5" title="33507">return rawRangesFromPESRanges(ranges, esOffset, size)</span>
}

// RawRangesForAudioSubStream returns the raw file ranges for audio data from a specific sub-stream.
func (p *MPEGPSParser) RawRangesForAudioSubStream(subStreamID byte, esOffset int64, size int) ([]RawRange, error) <span class="cov5" title="40663">{
        ranges, ok := p.filteredAudioBySubStream[subStreamID]
        if !ok </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("audio sub-stream 0x%02X not found", subStreamID)
        }</span>
        <span class="cov5" title="40662">return rawRangesFromPESRanges(ranges, esOffset, size)</span>
}

// ReadESData reads elementary stream data at the given ES offset.
// For video, returns FILTERED ES data (excludes user_data sections).
// For audio, returns error - use ReadAudioSubStreamData instead.
func (p *MPEGPSParser) ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error) <span class="cov8" title="20863701">{
        if !isVideo </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("audio uses per-sub-stream methods, use ReadAudioSubStreamData")
        }</span>
        <span class="cov8" title="20863701">var ranges []PESPayloadRange
        if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov8" title="20863701">{
                ranges = p.filteredVideoRanges
        }</span> else<span class="cov0" title="0"> {
                ranges = p.videoRanges
        }</span>
        <span class="cov8" title="20863701">return readFromRanges(p.data, nil, p.size, ranges, esOffset, size)</span>
}

// ReadAudioSubStreamData reads audio data from a specific sub-stream.
func (p *MPEGPSParser) ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error) <span class="cov6" title="219913">{
        ranges, ok := p.filteredAudioBySubStream[subStreamID]
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("audio sub-stream 0x%02X not found", subStreamID)
        }</span>
        <span class="cov6" title="219913">return readFromRanges(p.data, nil, p.size, ranges, esOffset, size)</span>
}
</pre>
		
		<pre class="file" id="file47" style="display: none">package source

import (
        "fmt"
        "io"
        "os"
        "strings"
)

// detectDVDCodecs extracts codec information from an already-indexed DVD source.
// The MPEG-PS parser has already identified video and audio streams during indexing.
func detectDVDCodecs(index *Index) (*SourceCodecs, error) <span class="cov1" title="2">{
        codecs := &amp;SourceCodecs{}

        for _, esReader := range index.ESReaders </span><span class="cov1" title="2">{
                parser, ok := esReader.(*MPEGPSParser)
                if !ok </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Video: DVD is MPEG-2 if video ranges exist
                <span class="cov1" title="2">if parser.TotalESSize(true) &gt; 0 </span><span class="cov1" title="2">{
                        if !containsCodec(codecs.VideoCodecs, CodecMPEG2Video) </span><span class="cov1" title="2">{
                                codecs.VideoCodecs = append(codecs.VideoCodecs, CodecMPEG2Video)
                        }</span>
                }

                // Audio from Private Stream 1 sub-streams
                <span class="cov1" title="2">for _, subStreamID := range parser.AudioSubStreams() </span><span class="cov1" title="2">{
                        var ct CodecType
                        switch </span>{
                        case subStreamID &gt;= 0x80 &amp;&amp; subStreamID &lt;= 0x87:<span class="cov1" title="1">
                                ct = CodecAC3Audio</span>
                        case subStreamID &gt;= 0x88 &amp;&amp; subStreamID &lt;= 0x8F:<span class="cov1" title="1">
                                ct = CodecDTSAudio</span>
                        case subStreamID &gt;= 0xA0 &amp;&amp; subStreamID &lt;= 0xA7:<span class="cov0" title="0">
                                ct = CodecLPCMAudio</span>
                        default:<span class="cov0" title="0">
                                continue</span>
                        }
                        <span class="cov1" title="2">if !containsCodec(codecs.AudioCodecs, ct) </span><span class="cov1" title="2">{
                                codecs.AudioCodecs = append(codecs.AudioCodecs, ct)
                        }</span>
                }

                // MPEG audio streams (stream IDs 0xC0-0xDF)
                <span class="cov1" title="2">for _, pkt := range parser.Packets() </span><span class="cov1" title="1">{
                        if pkt.StreamID &gt;= 0xC0 &amp;&amp; pkt.StreamID &lt;= 0xDF </span><span class="cov1" title="1">{
                                if !containsCodec(codecs.AudioCodecs, CodecMPEGAudio) </span><span class="cov1" title="1">{
                                        codecs.AudioCodecs = append(codecs.AudioCodecs, CodecMPEGAudio)
                                }</span>
                                <span class="cov1" title="1">break</span> // Only need to find one
                        }
                }
        }

        <span class="cov1" title="2">return codecs, nil</span>
}

// detectDVDCodecsFromFile performs a lightweight scan of an ISO file to detect
// MPEG-PS stream types without building the full MPEG-PS index.
func detectDVDCodecsFromFile(path string) (*SourceCodecs, error) <span class="cov3" title="5">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("open ISO file: %w", err)
        }</span>
        <span class="cov3" title="5">defer f.Close()

        // Find the main content VOB inside the ISO to avoid scanning menu VOBs
        // (which may have different audio codecs than the main feature).
        scanOffset := findMainVOBOffset(f)

        const scanSize = 4 * 1024 * 1024
        buf := make([]byte, scanSize)
        n, err := f.ReadAt(buf, scanOffset)
        if err == io.EOF || err == io.ErrUnexpectedEOF </span><span class="cov3" title="5">{
                buf = buf[:n]
        }</span> else<span class="cov0" title="0"> if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read ISO file: %w", err)
        }</span>
        <span class="cov3" title="5">if n == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no data at scan offset %d in %s", scanOffset, path)
        }</span>

        <span class="cov3" title="5">return scanPESCodecs(buf)</span>
}

// scanPESCodecs scans a byte buffer for MPEG-PS PES headers and extracts codec information.
func scanPESCodecs(buf []byte) (*SourceCodecs, error) <span class="cov3" title="7">{
        codecs := &amp;SourceCodecs{}

        // Scan for PES start codes: 0x00 0x00 0x01 &lt;stream_id&gt;
        for i := 0; i+3 &lt; len(buf); i++ </span><span class="cov10" title="819">{
                if buf[i] != 0x00 || buf[i+1] != 0x00 || buf[i+2] != 0x01 </span><span class="cov9" title="811">{
                        continue</span>
                }
                <span class="cov3" title="8">streamID := buf[i+3]

                switch </span>{
                case streamID &gt;= 0xE0 &amp;&amp; streamID &lt;= 0xEF:<span class="cov1" title="2">
                        // Video stream — DVD is MPEG-2
                        if !containsCodec(codecs.VideoCodecs, CodecMPEG2Video) </span><span class="cov1" title="2">{
                                codecs.VideoCodecs = append(codecs.VideoCodecs, CodecMPEG2Video)
                        }</span>

                case streamID == 0xBD:<span class="cov2" title="4">
                        // Private Stream 1 — contains AC3, DTS, LPCM sub-streams
                        // Parse the PES header to get to the sub-stream ID
                        if i+9 &lt; len(buf) </span><span class="cov2" title="4">{
                                pesHeaderLen := int(buf[i+8])
                                subStreamOffset := i + 9 + pesHeaderLen
                                if subStreamOffset &lt; len(buf) </span><span class="cov2" title="4">{
                                        subStreamID := buf[subStreamOffset]
                                        var ct CodecType
                                        switch </span>{
                                        case subStreamID &gt;= 0x80 &amp;&amp; subStreamID &lt;= 0x87:<span class="cov1" title="2">
                                                ct = CodecAC3Audio</span>
                                        case subStreamID &gt;= 0x88 &amp;&amp; subStreamID &lt;= 0x8F:<span class="cov1" title="1">
                                                ct = CodecDTSAudio</span>
                                        case subStreamID &gt;= 0xA0 &amp;&amp; subStreamID &lt;= 0xA7:<span class="cov1" title="1">
                                                ct = CodecLPCMAudio</span>
                                        }
                                        <span class="cov2" title="4">if ct != CodecUnknown &amp;&amp; !containsCodec(codecs.AudioCodecs, ct) </span><span class="cov2" title="4">{
                                                codecs.AudioCodecs = append(codecs.AudioCodecs, ct)
                                        }</span>
                                }
                        }

                case streamID &gt;= 0xC0 &amp;&amp; streamID &lt;= 0xDF:<span class="cov1" title="2">
                        // MPEG audio stream
                        if !containsCodec(codecs.AudioCodecs, CodecMPEGAudio) </span><span class="cov1" title="2">{
                                codecs.AudioCodecs = append(codecs.AudioCodecs, CodecMPEGAudio)
                        }</span>
                }
        }

        <span class="cov3" title="7">if len(codecs.VideoCodecs) == 0 &amp;&amp; len(codecs.AudioCodecs) == 0 </span><span class="cov1" title="2">{
                return nil, fmt.Errorf("no DVD codecs detected in scanned region")
        }</span>

        <span class="cov3" title="5">return codecs, nil</span>
}

// findMainVOBOffset navigates the ISO9660 filesystem to find the byte offset of
// the main content VOB (VTS_xx_1.VOB or larger). Returns 0 if navigation fails,
// falling back to scanning from the ISO start.
func findMainVOBOffset(f *os.File) int64 <span class="cov3" title="7">{
        const sectorSize = 2048

        // Read the primary volume descriptor at sector 16
        pvd := make([]byte, sectorSize)
        if _, err := f.ReadAt(pvd, 16*sectorSize); err != nil </span><span class="cov3" title="6">{
                return 0
        }</span>
        <span class="cov1" title="1">if pvd[0] != 1 || string(pvd[1:6]) != "CD001" </span><span class="cov0" title="0">{
                return 0
        }</span>

        // Root directory record at offset 156
        <span class="cov1" title="1">rootDirRecord := pvd[156:]
        if len(rootDirRecord) &lt; 34 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov1" title="1">rootExtent := uint32(rootDirRecord[2]) | uint32(rootDirRecord[3])&lt;&lt;8 |
                uint32(rootDirRecord[4])&lt;&lt;16 | uint32(rootDirRecord[5])&lt;&lt;24
        rootDataLen := uint32(rootDirRecord[10]) | uint32(rootDirRecord[11])&lt;&lt;8 |
                uint32(rootDirRecord[12])&lt;&lt;16 | uint32(rootDirRecord[13])&lt;&lt;24
        if rootDataLen &gt; 16*1024 </span><span class="cov0" title="0">{
                rootDataLen = 16 * 1024
        }</span>

        // Read root directory
        <span class="cov1" title="1">rootDir := make([]byte, rootDataLen)
        if _, err := f.ReadAt(rootDir, int64(rootExtent)*sectorSize); err != nil </span><span class="cov0" title="0">{
                return 0
        }</span>

        // Find VIDEO_TS directory entry
        <span class="cov1" title="1">videoTSExtent, videoTSLen := findDirEntry(rootDir, "VIDEO_TS", sectorSize)
        if videoTSExtent == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>

        // Read VIDEO_TS directory
        <span class="cov1" title="1">if videoTSLen &gt; 64*1024 </span><span class="cov0" title="0">{
                videoTSLen = 64 * 1024
        }</span>
        <span class="cov1" title="1">videoTSDir := make([]byte, videoTSLen)
        if _, err := f.ReadAt(videoTSDir, int64(videoTSExtent)*sectorSize); err != nil </span><span class="cov0" title="0">{
                return 0
        }</span>

        // Find the largest VTS content VOB (VTS_xx_1.VOB through VTS_xx_9.VOB).
        // These contain the main feature; VTS_xx_0.VOB is navigation-only.
        <span class="cov1" title="1">var bestExtent uint32
        var bestSize uint32
        offset := 0
        for offset &lt; len(videoTSDir) </span><span class="cov2" title="4">{
                recLen := int(videoTSDir[offset])
                if recLen == 0 </span><span class="cov1" title="1">{
                        nextSector := ((offset / sectorSize) + 1) * sectorSize
                        if nextSector &gt;= len(videoTSDir) </span><span class="cov1" title="1">{
                                break</span>
                        }
                        <span class="cov0" title="0">offset = nextSector
                        continue</span>
                }
                <span class="cov2" title="3">if offset+33 &gt; len(videoTSDir) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov2" title="3">nameLen := int(videoTSDir[offset+32])
                if offset+33+nameLen &gt; len(videoTSDir) || offset+recLen &gt; len(videoTSDir) </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov2" title="3">name := strings.ToUpper(string(videoTSDir[offset+33 : offset+33+nameLen]))
                if idx := strings.Index(name, ";"); idx &gt;= 0 </span><span class="cov0" title="0">{
                        name = name[:idx]
                }</span>

                // Match VTS_xx_N.VOB where N &gt;= 1 (content VOBs, not navigation)
                <span class="cov2" title="3">if strings.HasPrefix(name, "VTS_") &amp;&amp; strings.HasSuffix(name, ".VOB") </span><span class="cov1" title="2">{
                        // Check digit before .VOB: VTS_01_1.VOB → name[7] is the content number
                        if len(name) == 12 &amp;&amp; name[7] &gt;= '1' &amp;&amp; name[7] &lt;= '9' </span><span class="cov1" title="1">{
                                extent := uint32(videoTSDir[offset+2]) | uint32(videoTSDir[offset+3])&lt;&lt;8 |
                                        uint32(videoTSDir[offset+4])&lt;&lt;16 | uint32(videoTSDir[offset+5])&lt;&lt;24
                                size := uint32(videoTSDir[offset+10]) | uint32(videoTSDir[offset+11])&lt;&lt;8 |
                                        uint32(videoTSDir[offset+12])&lt;&lt;16 | uint32(videoTSDir[offset+13])&lt;&lt;24
                                if size &gt; bestSize </span><span class="cov1" title="1">{
                                        bestSize = size
                                        bestExtent = extent
                                }</span>
                        }
                }

                <span class="cov2" title="3">offset += recLen</span>
        }

        <span class="cov1" title="1">if bestExtent &gt; 0 </span><span class="cov1" title="1">{
                return int64(bestExtent) * sectorSize
        }</span>
        <span class="cov0" title="0">return 0</span>
}

// findDirEntry searches an ISO9660 directory for a named entry and returns its
// extent location and data length. Returns (0, 0) if not found.
func findDirEntry(dirData []byte, targetName string, sectorSize int) (uint32, uint32) <span class="cov3" title="5">{
        targetName = strings.ToUpper(targetName)
        offset := 0
        for offset &lt; len(dirData) </span><span class="cov3" title="8">{
                recLen := int(dirData[offset])
                if recLen == 0 </span><span class="cov1" title="1">{
                        nextSector := ((offset / sectorSize) + 1) * sectorSize
                        if nextSector &gt;= len(dirData) </span><span class="cov1" title="1">{
                                break</span>
                        }
                        <span class="cov0" title="0">offset = nextSector
                        continue</span>
                }
                <span class="cov3" title="7">if offset+33 &gt; len(dirData) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov3" title="7">nameLen := int(dirData[offset+32])
                if offset+33+nameLen &gt; len(dirData) || offset+recLen &gt; len(dirData) </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov3" title="7">name := strings.ToUpper(string(dirData[offset+33 : offset+33+nameLen]))
                if idx := strings.Index(name, ";"); idx &gt;= 0 </span><span class="cov1" title="1">{
                        name = name[:idx]
                }</span>
                <span class="cov3" title="7">name = strings.TrimSuffix(name, ".")

                if name == targetName </span><span class="cov2" title="4">{
                        extent := uint32(dirData[offset+2]) | uint32(dirData[offset+3])&lt;&lt;8 |
                                uint32(dirData[offset+4])&lt;&lt;16 | uint32(dirData[offset+5])&lt;&lt;24
                        dataLen := uint32(dirData[offset+10]) | uint32(dirData[offset+11])&lt;&lt;8 |
                                uint32(dirData[offset+12])&lt;&lt;16 | uint32(dirData[offset+13])&lt;&lt;24
                        return extent, dataLen
                }</span>

                <span class="cov2" title="3">offset += recLen</span>
        }
        <span class="cov1" title="1">return 0, 0</span>
}
</pre>
		
		<pre class="file" id="file48" style="display: none">package source

import (
        "bytes"
        "fmt"
        "log"
)

// MPEGTSParser parses MPEG Transport Stream (M2TS) files to extract elementary
// stream data. This is the Blu-ray equivalent of MPEGPSParser for DVDs.
//
// M2TS files use 192-byte packets: 4-byte timestamp + 188-byte TS packet.
// Each TS packet carries a fragment of a PES packet, identified by PID.
// PES packets span multiple TS packets and contain the actual codec data.
//
// The parser builds PES payload range tables that map ES offsets to raw file
// offsets, enabling the matcher to work with continuous ES data while the
// underlying file has TS headers interleaved.
type MPEGTSParser struct {
        data        []byte           // mmap'd file data (zero-copy); nil when using multiRegion
        multiRegion *multiRegionData // non-nil for multi-extent UDF files
        size        int64
        packetSize  int // 192 (M2TS) or 188 (standard TS)
        tsOffset    int // offset from packet start to TS sync byte (4 for M2TS, 0 for TS)

        // Stream PIDs from PMT
        videoPID   uint16
        audioPIDs  []uint16  // ordered by PMT appearance
        videoCodec CodecType // for user_data filtering decision

        // PES payload ranges (one entry per TS payload chunk for tracked PIDs)
        videoRanges         []PESPayloadRange
        filteredVideoRanges []PESPayloadRange // excludes user_data for MPEG-2 only
        audioBySubStream    map[byte][]PESPayloadRange

        // Audio PID → sub-stream ID mapping
        audioSubStreams []byte             // sequential IDs: 0, 1, 2, ...
        pidToSubStream  map[uint16]byte    // PID → sub-stream ID
        subStreamToPID  map[byte]uint16    // sub-stream ID → PID
        subStreamCodec  map[byte]CodecType // codec type per sub-stream

        filterUserData bool
}

// NewMPEGTSParser creates a parser for the given memory-mapped M2TS data.
func NewMPEGTSParser(data []byte) *MPEGTSParser <span class="cov4" title="22">{
        return &amp;MPEGTSParser{
                data:             data,
                size:             int64(len(data)),
                audioBySubStream: make(map[byte][]PESPayloadRange),
                pidToSubStream:   make(map[uint16]byte),
                subStreamToPID:   make(map[byte]uint16),
                subStreamCodec:   make(map[byte]CodecType),
        }
}</span>

// NewMPEGTSParserMultiRegion creates a parser for non-contiguous M2TS data
// from a multi-extent UDF file. The multiRegionData provides a virtual
// contiguous view over multiple mmap sub-slices.
func NewMPEGTSParserMultiRegion(mr *multiRegionData) *MPEGTSParser <span class="cov2" title="3">{
        return &amp;MPEGTSParser{
                multiRegion:      mr,
                size:             mr.Len(),
                audioBySubStream: make(map[byte][]PESPayloadRange),
                pidToSubStream:   make(map[uint16]byte),
                subStreamToPID:   make(map[byte]uint16),
                subStreamCodec:   make(map[byte]CodecType),
        }
}</span>

// dataSlice returns a sub-slice of the parser's data source.
// Uses multiRegion when available, otherwise direct slice of p.data.
func (p *MPEGTSParser) dataSlice(off, end int64) []byte <span class="cov4" title="19">{
        if p.multiRegion != nil </span><span class="cov0" title="0">{
                return p.multiRegion.Slice(off, end)
        }</span>
        <span class="cov4" title="19">return p.data[off:end]</span>
}

// MPEGTSProgressFunc is called to report MPEG-TS parsing progress.
type MPEGTSProgressFunc func(processed, total int64)

// Parse scans the file and extracts all PES payload ranges.
func (p *MPEGTSParser) Parse() error <span class="cov4" title="16">{
        return p.ParseWithProgress(nil)
}</span>

// ParseWithProgress scans the M2TS file with progress reporting.
func (p *MPEGTSParser) ParseWithProgress(progress MPEGTSProgressFunc) error <span class="cov4" title="21">{
        if p.multiRegion != nil </span><span class="cov1" title="1">{
                return p.parseMultiRegion(progress)
        }</span>

        // Step 1: Detect TS packet size
        <span class="cov4" title="20">detectLen := 192 * 16
        if detectLen &gt; len(p.data) </span><span class="cov4" title="20">{
                detectLen = len(p.data)
        }</span>
        <span class="cov4" title="20">packetSize, startOffset := detectTSPacketSize(p.data[:detectLen])
        if packetSize == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("cannot detect TS packet size")
        }</span>
        <span class="cov4" title="20">p.packetSize = packetSize
        if packetSize == 192 </span><span class="cov4" title="19">{
                p.tsOffset = 4
        }</span>

        // Step 2: Parse PAT/PMT to find stream PIDs
        <span class="cov4" title="20">scanLen := 2 * 1024 * 1024
        if scanLen &gt; len(p.data) </span><span class="cov4" title="20">{
                scanLen = len(p.data)
        }</span>
        <span class="cov4" title="20">if err := p.parsePATandPMT(p.data[:scanLen], startOffset); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse PAT/PMT: %w", err)
        }</span>

        // Step 3: Scan packets and build PES ranges
        <span class="cov4" title="20">ss := p.initScanState()
        p.scanPackets(p.data, startOffset, 0, ss, progress)

        if progress != nil </span><span class="cov1" title="1">{
                progress(p.size, p.size)
        }</span>

        <span class="cov4" title="20">return p.finalizeParse()</span>
}

// parseMultiRegion handles parsing when data comes from multiple non-contiguous
// mmap regions. Processes each region sequentially, handling TS packets that
// straddle region boundaries via a small carryover buffer.
func (p *MPEGTSParser) parseMultiRegion(progress MPEGTSProgressFunc) error <span class="cov1" title="1">{
        mr := p.multiRegion
        if len(mr.regions) == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no regions in multi-region data")
        }</span>

        // Step 1: Detect TS packet size from first region
        <span class="cov1" title="1">firstRegion := mr.regions[0].data
        detectLen := 192 * 16
        if detectLen &gt; len(firstRegion) </span><span class="cov1" title="1">{
                detectLen = len(firstRegion)
        }</span>
        <span class="cov1" title="1">packetSize, startOffset := detectTSPacketSize(firstRegion[:detectLen])
        if packetSize == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("cannot detect TS packet size")
        }</span>
        <span class="cov1" title="1">p.packetSize = packetSize
        if packetSize == 192 </span><span class="cov1" title="1">{
                p.tsOffset = 4
        }</span>

        // Step 2: Parse PAT/PMT from first region
        <span class="cov1" title="1">scanLen := 2 * 1024 * 1024
        if scanLen &gt; len(firstRegion) </span><span class="cov1" title="1">{
                scanLen = len(firstRegion)
        }</span>
        <span class="cov1" title="1">if err := p.parsePATandPMT(firstRegion[:scanLen], startOffset); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("parse PAT/PMT: %w", err)
        }</span>

        // Step 3: Scan packets across all regions
        <span class="cov1" title="1">ss := p.initScanState()

        var carryover []byte
        for i, reg := range mr.regions </span><span class="cov1" title="2">{
                chunk := reg.data
                logicalBase := reg.logicalStart
                chunkStart := 0

                if i == 0 </span><span class="cov1" title="1">{
                        // First region: skip to the initial start offset
                        chunkStart = startOffset
                }</span>

                // Handle carryover from previous region boundary
                <span class="cov1" title="2">if len(carryover) &gt; 0 </span><span class="cov0" title="0">{
                        needed := p.packetSize - len(carryover)
                        if needed &lt;= len(chunk) </span><span class="cov0" title="0">{
                                // Assemble the straddling packet and process it
                                bridgePkt := make([]byte, p.packetSize)
                                copy(bridgePkt, carryover)
                                copy(bridgePkt[len(carryover):], chunk[:needed])
                                bridgeBase := logicalBase - int64(len(carryover))
                                p.scanPackets(bridgePkt, 0, bridgeBase, ss, nil)
                                chunkStart = needed
                                carryover = nil
                        }</span> else<span class="cov0" title="0"> {
                                // Region too small to complete the packet — accumulate and continue
                                carryover = append(carryover, chunk...)
                                continue</span>
                        }
                }

                // Process complete packets in this region
                <span class="cov1" title="2">available := len(chunk) - chunkStart
                nComplete := (available / p.packetSize) * p.packetSize
                if nComplete &gt; 0 </span><span class="cov1" title="2">{
                        p.scanPackets(chunk[chunkStart:chunkStart+nComplete], 0, logicalBase+int64(chunkStart), ss, progress)
                }</span>

                // Save any remainder for the next region
                <span class="cov1" title="2">remainder := available - nComplete
                if remainder &gt; 0 </span><span class="cov0" title="0">{
                        carryover = make([]byte, remainder)
                        copy(carryover, chunk[chunkStart+nComplete:])
                }</span>
        }

        <span class="cov1" title="1">if len(carryover) &gt; 0 </span><span class="cov0" title="0">{
                log.Printf("mpegts: warning: discarding %d carryover bytes at end of multi-region data (incomplete TS packet)", len(carryover))
        }</span>

        <span class="cov1" title="1">if progress != nil </span><span class="cov0" title="0">{
                progress(p.size, p.size)
        }</span>

        <span class="cov1" title="1">return p.finalizeParse()</span>
}

// pesState tracks PES header parsing state across TS packets.
type pesState struct {
        headerBytesRemaining int
}

// scanState holds mutable state for the packet scanning loop.
type scanState struct {
        trackedPIDs    map[uint16]bool
        pesStates      map[uint16]*pesState
        videoESOffset  int64
        audioESOffsets map[byte]int64
        lastProgress   int64
}

// initScanState sets up PID tracking and PES state for scanning.
func (p *MPEGTSParser) initScanState() *scanState <span class="cov4" title="21">{
        if p.videoPID == 0 &amp;&amp; len(p.audioPIDs) == 0 </span><span class="cov1" title="1">{
                return nil
        }</span>

        <span class="cov4" title="20">trackedPIDs := make(map[uint16]bool)
        if p.videoPID != 0 </span><span class="cov4" title="20">{
                trackedPIDs[p.videoPID] = true
        }</span>
        <span class="cov4" title="20">for _, pid := range p.audioPIDs </span><span class="cov5" title="43">{
                trackedPIDs[pid] = true
        }</span>

        // Pre-allocate range slices
        <span class="cov4" title="20">estimatedPackets := int(p.size) / p.packetSize
        if p.videoPID != 0 </span><span class="cov4" title="20">{
                p.videoRanges = make([]PESPayloadRange, 0, estimatedPackets*7/10)
        }</span>
        <span class="cov4" title="20">for _, pid := range p.audioPIDs </span><span class="cov5" title="43">{
                subID := p.pidToSubStream[pid]
                p.audioBySubStream[subID] = make([]PESPayloadRange, 0, estimatedPackets/10/len(p.audioPIDs))
        }</span>

        <span class="cov4" title="20">pesStates := make(map[uint16]*pesState)
        for pid := range trackedPIDs </span><span class="cov6" title="63">{
                pesStates[pid] = &amp;pesState{}
        }</span>

        <span class="cov4" title="20">return &amp;scanState{
                trackedPIDs:    trackedPIDs,
                pesStates:      pesStates,
                audioESOffsets: make(map[byte]int64),
        }</span>
}

// scanPackets processes TS packets in a data buffer, recording PES payload ranges.
// logicalBase is added to all FileOffset values to produce logical (assembled) offsets.
func (p *MPEGTSParser) scanPackets(data []byte, startPos int, logicalBase int64, ss *scanState, progress MPEGTSProgressFunc) <span class="cov4" title="22">{
        if ss == nil </span><span class="cov1" title="1">{
                return
        }</span>

        <span class="cov4" title="21">for pos := startPos; pos+p.packetSize &lt;= len(data); pos += p.packetSize </span><span class="cov6" title="117">{
                tsStart := pos + p.tsOffset
                if tsStart &gt;= len(data) || data[tsStart] != 0x47 </span><span class="cov1" title="1">{
                        continue</span>
                }

                <span class="cov6" title="116">pid := uint16(data[tsStart+1]&amp;0x1F)&lt;&lt;8 | uint16(data[tsStart+2])
                if !ss.trackedPIDs[pid] </span><span class="cov5" title="50">{
                        continue</span>
                }

                <span class="cov6" title="66">pusi := data[tsStart+1]&amp;0x40 != 0
                adaptFieldCtrl := (data[tsStart+3] &gt;&gt; 4) &amp; 0x03

                // Find payload start
                payloadOff := tsStart + 4
                switch adaptFieldCtrl </span>{
                case 0x01:<span class="cov6" title="63"></span> // payload only
                case 0x03:<span class="cov1" title="2"> // adaptation field + payload
                        if payloadOff &lt; pos+p.packetSize </span><span class="cov1" title="2">{
                                adaptLen := int(data[payloadOff])
                                payloadOff += 1 + adaptLen
                        }</span>
                default:<span class="cov1" title="1"> // 0x02 = adaptation only, 0x00 = reserved
                        continue</span>
                }

                <span class="cov6" title="65">payloadEnd := pos + p.packetSize
                if payloadEnd &gt; len(data) </span><span class="cov0" title="0">{
                        payloadEnd = len(data)
                }</span>
                <span class="cov6" title="65">if payloadOff &gt;= payloadEnd </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov6" title="65">payload := data[payloadOff:payloadEnd]
                state := ss.pesStates[pid]

                // File offset in the logical (assembled) coordinate space
                logPayloadOff := logicalBase + int64(payloadOff)

                if pusi </span><span class="cov5" title="45">{
                        // New PES packet starts here
                        if len(payload) &lt; 9 || payload[0] != 0 || payload[1] != 0 || payload[2] != 1 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov5" title="45">pesHeaderDataLen := int(payload[8])
                        pesHeaderSize := 9 + pesHeaderDataLen

                        if pesHeaderSize &gt;= len(payload) </span><span class="cov1" title="1">{
                                state.headerBytesRemaining = pesHeaderSize - len(payload)
                                continue</span>
                        }

                        <span class="cov5" title="44">esPayload := payload[pesHeaderSize:]
                        fileOffset := logPayloadOff + int64(pesHeaderSize)

                        if pid == p.videoPID </span><span class="cov5" title="29">{
                                p.videoRanges = append(p.videoRanges, PESPayloadRange{
                                        FileOffset: fileOffset,
                                        Size:       len(esPayload),
                                        ESOffset:   ss.videoESOffset,
                                })
                                ss.videoESOffset += int64(len(esPayload))
                        }</span> else<span class="cov4" title="15"> {
                                subID := p.pidToSubStream[pid]
                                p.audioBySubStream[subID] = append(p.audioBySubStream[subID], PESPayloadRange{
                                        FileOffset: fileOffset,
                                        Size:       len(esPayload),
                                        ESOffset:   ss.audioESOffsets[subID],
                                })
                                ss.audioESOffsets[subID] += int64(len(esPayload))
                        }</span>
                        <span class="cov5" title="44">state.headerBytesRemaining = 0</span>
                } else<span class="cov4" title="20"> {
                        // Continuation packet
                        esPayload := payload
                        fileOffset := logPayloadOff

                        if state.headerBytesRemaining &gt; 0 </span><span class="cov1" title="1">{
                                if state.headerBytesRemaining &gt;= len(esPayload) </span><span class="cov0" title="0">{
                                        state.headerBytesRemaining -= len(esPayload)
                                        continue</span>
                                }
                                <span class="cov1" title="1">esPayload = esPayload[state.headerBytesRemaining:]
                                fileOffset += int64(state.headerBytesRemaining)
                                state.headerBytesRemaining = 0</span>
                        }

                        <span class="cov4" title="20">if len(esPayload) == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov4" title="20">if pid == p.videoPID </span><span class="cov4" title="16">{
                                p.videoRanges = append(p.videoRanges, PESPayloadRange{
                                        FileOffset: fileOffset,
                                        Size:       len(esPayload),
                                        ESOffset:   ss.videoESOffset,
                                })
                                ss.videoESOffset += int64(len(esPayload))
                        }</span> else<span class="cov2" title="4"> {
                                subID := p.pidToSubStream[pid]
                                p.audioBySubStream[subID] = append(p.audioBySubStream[subID], PESPayloadRange{
                                        FileOffset: fileOffset,
                                        Size:       len(esPayload),
                                        ESOffset:   ss.audioESOffsets[subID],
                                })
                                ss.audioESOffsets[subID] += int64(len(esPayload))
                        }</span>
                }

                // Report progress
                <span class="cov6" title="64">logPos := logicalBase + int64(pos)
                if progress != nil &amp;&amp; logPos-ss.lastProgress &gt; 100*1024*1024 </span><span class="cov0" title="0">{
                        progress(logPos, p.size)
                        ss.lastProgress = logPos
                }</span>
        }
}

// finalizeParse performs post-scan processing: video range filtering and
// TrueHD+AC3 stream splitting. Shared by contiguous and multi-region paths.
func (p *MPEGTSParser) finalizeParse() error <span class="cov4" title="21">{
        if p.videoPID == 0 &amp;&amp; len(p.audioPIDs) == 0 </span><span class="cov1" title="1">{
                return fmt.Errorf("no video or audio PIDs found in PMT")
        }</span>

        <span class="cov4" title="20">if err := p.buildFilteredVideoRanges(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("build filtered video ranges: %w", err)
        }</span>

        <span class="cov4" title="20">p.filterUserData = true
        p.splitTrueHDAC3Streams()

        return nil</span>
}

// parsePATandPMT finds the PAT and PMT in the first portion of the file
// and extracts video/audio PIDs and stream types.
func (p *MPEGTSParser) parsePATandPMT(data []byte, startOffset int) error <span class="cov4" title="21">{
        // Find PAT (PID 0) and extract PMT PID
        patSection, err := p.reassemblePSISection(data, startOffset, 0, 0x00)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("reassemble PAT: %w", err)
        }</span>

        <span class="cov4" title="21">pmtPID := uint16(0)
        if len(patSection) &gt;= 8 </span><span class="cov4" title="21">{
                sectionLen := int(patSection[1]&amp;0x0F)&lt;&lt;8 | int(patSection[2])
                progsEnd := 3 + sectionLen - 4 // section_length counts from byte 3; subtract 4 for CRC
                if progsEnd &gt; len(patSection) </span><span class="cov0" title="0">{
                        progsEnd = len(patSection)
                }</span>
                <span class="cov4" title="21">for j := 8; j+4 &lt;= progsEnd; j += 4 </span><span class="cov4" title="21">{
                        progNum := uint16(patSection[j])&lt;&lt;8 | uint16(patSection[j+1])
                        if progNum == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov4" title="21">pmtPID = uint16(patSection[j+2]&amp;0x1F)&lt;&lt;8 | uint16(patSection[j+3])
                        break</span>
                }
        }

        <span class="cov4" title="21">if pmtPID == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("PMT PID not found in PAT")
        }</span>

        // Find PMT and extract stream types.
        // PMT sections can span multiple TS packets, so we must reassemble.
        <span class="cov4" title="21">pmtSection, err := p.reassemblePSISection(data, startOffset, pmtPID, 0x02)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("reassemble PMT: %w", err)
        }</span>

        <span class="cov4" title="21">if len(pmtSection) &gt;= 12 </span><span class="cov4" title="21">{
                progInfoLen := int(pmtSection[10]&amp;0x0F)&lt;&lt;8 | int(pmtSection[11])
                streamsStart := 12 + progInfoLen
                sectionLen := int(pmtSection[1]&amp;0x0F)&lt;&lt;8 | int(pmtSection[2])
                streamsEnd := 3 + sectionLen - 4 // exclude CRC32

                if streamsEnd &gt; len(pmtSection) </span><span class="cov0" title="0">{
                        streamsEnd = len(pmtSection)
                }</span>

                <span class="cov4" title="21">var subStreamSeq byte
                for j := streamsStart; j+5 &lt;= streamsEnd; </span><span class="cov6" title="63">{
                        streamType := pmtSection[j]
                        esPID := uint16(pmtSection[j+1]&amp;0x1F)&lt;&lt;8 | uint16(pmtSection[j+2])
                        esInfoLen := int(pmtSection[j+3]&amp;0x0F)&lt;&lt;8 | int(pmtSection[j+4])

                        ct := tsStreamTypeToCodecType(streamType)
                        if ct != CodecUnknown </span><span class="cov6" title="63">{
                                if IsVideoCodec(ct) &amp;&amp; p.videoPID == 0 </span><span class="cov4" title="20">{
                                        p.videoPID = esPID
                                        p.videoCodec = ct
                                }</span> else<span class="cov5" title="43"> if IsAudioCodec(ct) || IsSubtitleCodec(ct) </span><span class="cov5" title="43">{
                                        p.audioPIDs = append(p.audioPIDs, esPID)
                                        p.pidToSubStream[esPID] = subStreamSeq
                                        p.subStreamToPID[subStreamSeq] = esPID
                                        p.subStreamCodec[subStreamSeq] = ct
                                        p.audioSubStreams = append(p.audioSubStreams, subStreamSeq)
                                        subStreamSeq++
                                }</span>
                        }

                        <span class="cov6" title="63">next := j + 5 + esInfoLen
                        if next &lt; j || next &gt; streamsEnd </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov6" title="63">j = next</span>
                }
        }

        <span class="cov4" title="21">return nil</span>
}

// buildFilteredVideoRanges creates filtered video ranges.
// For MPEG-2 video, this excludes user_data (00 00 01 B2) sections.
// For H.264/H.265, filtered ranges are the same as raw ranges (no filtering needed).
// reassemblePSISection collects a complete PSI section (PAT, PMT, etc.) from
// one or more TS packets. PSI sections can span multiple TS packets when the
// section is larger than a single TS payload (~170 bytes). This happens on
// Blu-ray discs with many audio and subtitle streams in the PMT.
func (p *MPEGTSParser) reassemblePSISection(data []byte, startOffset int, targetPID uint16, tableID byte) ([]byte, error) <span class="cov5" title="42">{
        var section []byte
        sectionLen := -1
        collecting := false

        for i := startOffset; i+p.packetSize &lt;= len(data); i += p.packetSize </span><span class="cov6" title="64">{
                tsStart := i + p.tsOffset
                if tsStart+188 &gt; len(data) || data[tsStart] != 0x47 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov6" title="64">pid := uint16(data[tsStart+1]&amp;0x1F)&lt;&lt;8 | uint16(data[tsStart+2])
                if pid != targetPID </span><span class="cov4" title="21">{
                        continue</span>
                }

                <span class="cov5" title="43">pusi := data[tsStart+1]&amp;0x40 != 0
                adaptFieldCtrl := (data[tsStart+3] &gt;&gt; 4) &amp; 0x03
                hdrLen := 4
                switch adaptFieldCtrl </span>{
                case 0x02, 0x03:<span class="cov0" title="0">
                        if tsStart+4 &gt;= len(data) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">hdrLen = 5 + int(data[tsStart+4])</span>
                case 0x01:<span class="cov5" title="43"></span>
                default:<span class="cov0" title="0">
                        continue</span>
                }
                <span class="cov5" title="43">if tsStart+hdrLen &gt;= tsStart+188 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov5" title="43">payload := data[tsStart+hdrLen : tsStart+188]

                if pusi </span><span class="cov5" title="42">{
                        // PUSI packet: skip pointer field, find section start
                        pointerField := int(payload[0])
                        sectionStart := 1 + pointerField
                        if sectionStart &gt;= len(payload) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov5" title="42">payload = payload[sectionStart:]
                        if len(payload) &lt; 3 || payload[0] != tableID </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov5" title="42">sectionLen = 3 + (int(payload[1]&amp;0x0F)&lt;&lt;8 | int(payload[2]))
                        section = make([]byte, 0, sectionLen)
                        collecting = true

                        // Append what we have from this packet
                        n := len(payload)
                        if n &gt; sectionLen </span><span class="cov5" title="41">{
                                n = sectionLen
                        }</span>
                        <span class="cov5" title="42">section = append(section, payload[:n]...)</span>
                } else<span class="cov1" title="1"> if collecting </span><span class="cov1" title="1">{
                        // Continuation packet
                        remaining := sectionLen - len(section)
                        n := len(payload)
                        if n &gt; remaining </span><span class="cov1" title="1">{
                                n = remaining
                        }</span>
                        <span class="cov1" title="1">section = append(section, payload[:n]...)</span>
                }

                <span class="cov5" title="43">if collecting &amp;&amp; len(section) &gt;= sectionLen </span><span class="cov5" title="42">{
                        return section, nil
                }</span>
        }

        <span class="cov0" title="0">if collecting </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("truncated PSI section for table ID 0x%02X on PID 0x%04X: got %d of %d bytes", tableID, targetPID, len(section), sectionLen)
        }</span>
        <span class="cov0" title="0">return nil, fmt.Errorf("PSI section with table ID 0x%02X not found on PID 0x%04X", tableID, targetPID)</span>
}

func (p *MPEGTSParser) buildFilteredVideoRanges() error <span class="cov4" title="20">{
        if len(p.videoRanges) == 0 </span><span class="cov1" title="2">{
                return nil
        }</span>

        // Only MPEG-2 needs user_data filtering
        <span class="cov4" title="18">if p.videoCodec != CodecMPEG2Video </span><span class="cov4" title="18">{
                // For H.264/H.265/etc, no filtering needed — use raw ranges directly
                p.filteredVideoRanges = p.videoRanges
                return nil
        }</span>

        // MPEG-2: scan for user_data sections and exclude them
        // Same algorithm as MPEGPSParser.buildFilteredVideoRanges
        <span class="cov0" title="0">filteredRanges := make([]PESPayloadRange, 0, len(p.videoRanges))
        var filteredESOffset int64

        for _, rawRange := range p.videoRanges </span><span class="cov0" title="0">{
                endOffset := rawRange.FileOffset + int64(rawRange.Size)
                if endOffset &gt; p.size </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">data := p.dataSlice(rawRange.FileOffset, endOffset)

                i := 2
                rangeStart := 0
                for i &lt; len(data)-1 </span><span class="cov0" title="0">{
                        idx := bytes.IndexByte(data[i:], 0x01)
                        if idx &lt; 0 </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">pos := i + idx

                        if pos &gt;= 2 &amp;&amp; pos &lt; len(data)-1 &amp;&amp;
                                data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 &amp;&amp; data[pos+1] == UserDataStartCode </span><span class="cov0" title="0">{
                                startCodePos := pos - 2
                                if startCodePos &gt; rangeStart </span><span class="cov0" title="0">{
                                        filteredRanges = append(filteredRanges, PESPayloadRange{
                                                FileOffset: rawRange.FileOffset + int64(rangeStart),
                                                Size:       startCodePos - rangeStart,
                                                ESOffset:   filteredESOffset,
                                        })
                                        filteredESOffset += int64(startCodePos - rangeStart)
                                }</span>

                                <span class="cov0" title="0">i = pos + 2
                                for i &lt; len(data)-1 </span><span class="cov0" title="0">{
                                        idx := bytes.IndexByte(data[i:], 0x01)
                                        if idx &lt; 0 </span><span class="cov0" title="0">{
                                                i = len(data)
                                                break</span>
                                        }
                                        <span class="cov0" title="0">nextPos := i + idx
                                        if nextPos &gt;= 2 &amp;&amp; data[nextPos-1] == 0x00 &amp;&amp; data[nextPos-2] == 0x00 </span><span class="cov0" title="0">{
                                                i = nextPos - 2
                                                break</span>
                                        }
                                        <span class="cov0" title="0">i = nextPos + 1</span>
                                }
                                <span class="cov0" title="0">rangeStart = i</span>
                        } else<span class="cov0" title="0"> {
                                i = pos + 1
                        }</span>
                }

                <span class="cov0" title="0">if rangeStart &lt; len(data) </span><span class="cov0" title="0">{
                        filteredRanges = append(filteredRanges, PESPayloadRange{
                                FileOffset: rawRange.FileOffset + int64(rangeStart),
                                Size:       len(data) - rangeStart,
                                ESOffset:   filteredESOffset,
                        })
                        filteredESOffset += int64(len(data) - rangeStart)
                }</span>
        }

        <span class="cov0" title="0">p.filteredVideoRanges = filteredRanges
        return nil</span>
}

// --- ESReader interface implementation ---

// ReadESData reads elementary stream data at the given ES offset.
func (p *MPEGTSParser) ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error) <span class="cov3" title="9">{
        if !isVideo </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("audio uses per-sub-stream methods, use ReadAudioSubStreamData")
        }</span>
        <span class="cov3" title="8">ranges := p.filteredVideoRanges
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                ranges = p.videoRanges
        }</span>
        <span class="cov3" title="8">return readFromRanges(p.data, p.multiRegion, p.size, ranges, esOffset, size)</span>
}

// ESOffsetToFileOffset converts an ES offset to a file offset and remaining bytes.
func (p *MPEGTSParser) ESOffsetToFileOffset(esOffset int64, isVideo bool) (fileOffset int64, remaining int) <span class="cov2" title="3">{
        var ranges []PESPayloadRange
        if isVideo </span><span class="cov1" title="2">{
                ranges = p.filteredVideoRanges
                if len(ranges) == 0 </span><span class="cov0" title="0">{
                        ranges = p.videoRanges
                }</span>
        } else<span class="cov1" title="1"> {
                return -1, 0
        }</span>

        <span class="cov1" title="2">idx := binarySearchRanges(ranges, esOffset)
        if idx &lt; 0 </span><span class="cov0" title="0">{
                return -1, 0
        }</span>
        <span class="cov1" title="2">r := ranges[idx]
        offsetInPayload := esOffset - r.ESOffset
        return r.FileOffset + offsetInPayload, r.Size - int(offsetInPayload)</span>
}

// TotalESSize returns the total size of the elementary stream.
func (p *MPEGTSParser) TotalESSize(isVideo bool) int64 <span class="cov3" title="7">{
        if !isVideo </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov3" title="7">if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov3" title="7">{
                return totalESSizeFromRanges(p.filteredVideoRanges)
        }</span>
        <span class="cov0" title="0">return totalESSizeFromRanges(p.videoRanges)</span>
}

// AudioSubStreams returns the list of audio sub-stream IDs.
func (p *MPEGTSParser) AudioSubStreams() []byte <span class="cov3" title="7">{
        return p.audioSubStreams
}</span>

// SubtitleSubStreams returns the sub-stream IDs that carry subtitle data (e.g., PGS).
func (p *MPEGTSParser) SubtitleSubStreams() []byte <span class="cov2" title="4">{
        var ids []byte
        for _, id := range p.audioSubStreams </span><span class="cov5" title="30">{
                if IsSubtitleCodec(p.subStreamCodec[id]) </span><span class="cov4" title="18">{
                        ids = append(ids, id)
                }</span>
        }
        <span class="cov2" title="4">return ids</span>
}

// AudioSubStreamESSize returns the ES size for a specific audio sub-stream.
func (p *MPEGTSParser) AudioSubStreamESSize(subStreamID byte) int64 <span class="cov3" title="7">{
        return totalESSizeFromRanges(p.audioBySubStream[subStreamID])
}</span>

// ReadAudioSubStreamData reads audio data from a specific sub-stream.
func (p *MPEGTSParser) ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error) <span class="cov2" title="5">{
        ranges, ok := p.audioBySubStream[subStreamID]
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("audio sub-stream %d not found", subStreamID)
        }</span>
        <span class="cov2" title="5">return readFromRanges(p.data, p.multiRegion, p.size, ranges, esOffset, size)</span>
}

// --- ESRangeConverter interface implementation ---

// RawRangesForESRegion returns the raw file ranges for a video ES region.
func (p *MPEGTSParser) RawRangesForESRegion(esOffset int64, size int, isVideo bool) ([]RawRange, error) <span class="cov2" title="3">{
        if !isVideo </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("audio uses per-sub-stream methods, use RawRangesForAudioSubStream")
        }</span>
        <span class="cov1" title="2">ranges := p.filteredVideoRanges
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                ranges = p.videoRanges
        }</span>
        <span class="cov1" title="2">return rawRangesFromPESRanges(ranges, esOffset, size)</span>
}

// RawRangesForAudioSubStream returns the raw file ranges for audio data from a specific sub-stream.
func (p *MPEGTSParser) RawRangesForAudioSubStream(subStreamID byte, esOffset int64, size int) ([]RawRange, error) <span class="cov1" title="2">{
        ranges, ok := p.audioBySubStream[subStreamID]
        if !ok </span><span class="cov1" title="1">{
                return nil, fmt.Errorf("audio sub-stream %d not found", subStreamID)
        }</span>
        <span class="cov1" title="1">return rawRangesFromPESRanges(ranges, esOffset, size)</span>
}

// --- Hint-based reading for matcher hot path ---

// ReadESByteWithHint reads a single byte from the ES stream with a range hint.
func (p *MPEGTSParser) ReadESByteWithHint(esOffset int64, isVideo bool, rangeHint int) (byte, int, bool) <span class="cov2" title="5">{
        if !isVideo </span><span class="cov1" title="1">{
                return 0, -1, false
        }</span>
        <span class="cov2" title="4">ranges := p.filteredVideoRanges
        if len(ranges) == 0 </span><span class="cov0" title="0">{
                ranges = p.videoRanges
        }</span>
        <span class="cov2" title="4">return readByteWithHint(p.data, p.multiRegion, p.size, ranges, esOffset, rangeHint)</span>
}

// ReadAudioByteWithHint reads a single byte from an audio sub-stream with a range hint.
func (p *MPEGTSParser) ReadAudioByteWithHint(subStreamID byte, esOffset int64, rangeHint int) (byte, int, bool) <span class="cov1" title="1">{
        return readByteWithHint(p.data, p.multiRegion, p.size, p.audioBySubStream[subStreamID], esOffset, rangeHint)
}</span>

// --- Accessors for indexer ---

// Data returns the raw mmap'd file data for zero-copy access.
// Returns nil when using multi-region data; use DataSlice instead.
func (p *MPEGTSParser) Data() []byte <span class="cov0" title="0">{
        return p.data
}</span>

// DataSlice returns a sub-slice of the backing data at the given offset and size.
// Works for both contiguous and multi-region data.
func (p *MPEGTSParser) DataSlice(off int64, size int) []byte <span class="cov0" title="0">{
        if p.multiRegion != nil </span><span class="cov0" title="0">{
                return p.multiRegion.Slice(off, off+int64(size))
        }</span>
        <span class="cov0" title="0">return p.data[off : off+int64(size)]</span>
}

// DataSize returns the total size of the backing data.
func (p *MPEGTSParser) DataSize() int64 <span class="cov3" title="6">{
        return p.size
}</span>

// FilteredVideoRanges returns the filtered video payload ranges.
func (p *MPEGTSParser) FilteredVideoRanges() []PESPayloadRange <span class="cov3" title="11">{
        if p.filterUserData &amp;&amp; len(p.filteredVideoRanges) &gt; 0 </span><span class="cov3" title="11">{
                return p.filteredVideoRanges
        }</span>
        <span class="cov0" title="0">return p.videoRanges</span>
}

// FilteredAudioRanges returns the audio payload ranges for a specific sub-stream.
func (p *MPEGTSParser) FilteredAudioRanges(subStreamID byte) []PESPayloadRange <span class="cov2" title="3">{
        return p.audioBySubStream[subStreamID]
}</span>

// RawVideoESSize returns the total size of raw (unfiltered) video ES.
func (p *MPEGTSParser) RawVideoESSize() int64 <span class="cov0" title="0">{
        return totalESSizeFromRanges(p.videoRanges)
}</span>

// FilteredVideoRangesCount returns the number of filtered video ranges.
func (p *MPEGTSParser) FilteredVideoRangesCount() int <span class="cov0" title="0">{
        return len(p.filteredVideoRanges)
}</span>

// AudioSubStreamCount returns the number of audio sub-streams.
func (p *MPEGTSParser) AudioSubStreamCount() int <span class="cov2" title="3">{
        return len(p.audioSubStreams)
}</span>

// VideoPID returns the video PID detected from the PMT.
func (p *MPEGTSParser) VideoPID() uint16 <span class="cov1" title="2">{
        return p.videoPID
}</span>

// AudioPIDs returns the audio PIDs detected from the PMT.
func (p *MPEGTSParser) AudioPIDs() []uint16 <span class="cov1" title="2">{
        return p.audioPIDs
}</span>

// VideoCodec returns the video codec type detected from the PMT.
func (p *MPEGTSParser) VideoCodec() CodecType <span class="cov1" title="1">{
        return p.videoCodec
}</span>

// splitTrueHDAC3Streams detects combined TrueHD+AC3 audio streams and splits
// them into separate sub-streams. On Blu-ray, TrueHD streams (PMT type 0x83)
// interleave an AC3 compatibility core in the same PID. MakeMKV splits these
// into separate MKV tracks, so we must split them here to match.
func (p *MPEGTSParser) splitTrueHDAC3Streams() <span class="cov4" title="20">{
        for _, subID := range p.audioSubStreams </span><span class="cov5" title="43">{
                if p.subStreamCodec[subID] != CodecTrueHDAudio </span><span class="cov5" title="41">{
                        continue</span>
                }
                <span class="cov1" title="2">ranges := p.audioBySubStream[subID]
                if len(ranges) == 0 </span><span class="cov1" title="1">{
                        continue</span>
                }

                // Check if this stream actually has interleaved AC3
                <span class="cov1" title="1">if !p.detectCombinedTrueHDAC3(ranges) </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Split the combined ranges
                <span class="cov1" title="1">ac3Ranges, truehdRanges := p.splitCombinedAudioRanges(ranges)
                if len(ac3Ranges) == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Merge adjacent ranges to reduce count
                <span class="cov1" title="1">ac3Ranges = mergeAdjacentRanges(ac3Ranges)
                truehdRanges = mergeAdjacentRanges(truehdRanges)

                // Replace original sub-stream with TrueHD-only ranges
                p.audioBySubStream[subID] = truehdRanges

                // Add AC3 as a new sub-stream
                newSubID := byte(len(p.audioSubStreams))
                p.audioBySubStream[newSubID] = ac3Ranges
                p.subStreamCodec[newSubID] = CodecAC3Audio
                p.audioSubStreams = append(p.audioSubStreams, newSubID)</span>

        }
}

// detectCombinedTrueHDAC3 checks if a TrueHD audio stream contains interleaved
// AC3 frames by scanning the first few KB of ES data for both sync patterns.
func (p *MPEGTSParser) detectCombinedTrueHDAC3(ranges []PESPayloadRange) bool <span class="cov2" title="4">{
        // Read up to 16KB of ES data to check for both patterns
        hasAC3 := false
        hasTrueHD := false
        bytesChecked := 0
        const maxCheck = 16 * 1024

        for _, r := range ranges </span><span class="cov2" title="5">{
                if bytesChecked &gt;= maxCheck </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov2" title="5">endOffset := r.FileOffset + int64(r.Size)
                if endOffset &gt; p.size </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov2" title="5">data := p.dataSlice(r.FileOffset, endOffset)
                // Clamp to remaining check budget
                remaining := maxCheck - bytesChecked
                if remaining &lt; len(data) </span><span class="cov0" title="0">{
                        data = data[:remaining]
                }</span>
                <span class="cov2" title="5">for i := 0; i &lt; len(data)-1; i++ </span><span class="cov10" title="1415">{
                        if data[i] == 0x0B &amp;&amp; data[i+1] == 0x77 </span><span class="cov2" title="3">{
                                hasAC3 = true
                        }</span>
                        <span class="cov10" title="1415">if i+3 &lt; len(data) &amp;&amp;
                                data[i] == 0xF8 &amp;&amp; data[i+1] == 0x72 &amp;&amp;
                                data[i+2] == 0x6F &amp;&amp; data[i+3] == 0xBA </span><span class="cov2" title="3">{
                                hasTrueHD = true
                        }</span>
                        <span class="cov10" title="1415">if hasAC3 &amp;&amp; hasTrueHD </span><span class="cov1" title="2">{
                                return true
                        }</span>
                }
                <span class="cov2" title="3">bytesChecked += len(data)</span>
        }
        <span class="cov1" title="2">return false</span>
}

// splitCombinedAudioRanges splits PES payload ranges of a combined TrueHD+AC3
// stream into separate AC3 and TrueHD ranges. It walks through the ranges,
// parsing AC3 frame headers to determine frame sizes, and assigns each byte
// to either the AC3 or TrueHD output.
func (p *MPEGTSParser) splitCombinedAudioRanges(ranges []PESPayloadRange) (ac3Ranges, truehdRanges []PESPayloadRange) <span class="cov2" title="3">{
        var ac3ES, truehdES int64 // cumulative ES offsets for output streams
        ac3Remaining := 0         // bytes remaining in current AC3 frame

        // Buffer for AC3 header detection across range boundaries.
        // We need bytes 0-1 (sync word 0B77) and byte 4 (fscod+frmsizecod).
        var headerBuf [5]byte
        headerBufLen := 0
        // Ranges from intermediate short ranges that contributed to headerBuf
        // but haven't been committed to either output yet.
        var headerPendingRanges []PESPayloadRange

        for _, r := range ranges </span><span class="cov3" title="8">{
                endOffset := r.FileOffset + int64(r.Size)
                if endOffset &gt; p.size </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov3" title="8">data := p.dataSlice(r.FileOffset, endOffset)
                pos := 0

                // Handle header bytes buffered from previous range.
                // The buffered bytes were trimmed from the previous range's TrueHD output,
                // so we must classify them here (as AC3 or TrueHD).
                if headerBufLen &gt; 0 &amp;&amp; ac3Remaining == 0 </span><span class="cov1" title="1">{
                        need := 5 - headerBufLen
                        if need &gt; len(data) </span><span class="cov0" title="0">{
                                // Still not enough data to complete header check.
                                // Buffer the bytes without committing to either output —
                                // we can't classify until we have the full 5-byte header.
                                copy(headerBuf[headerBufLen:], data)
                                headerBufLen += len(data)
                                headerPendingRanges = append(headerPendingRanges, r)
                                continue</span>
                        }
                        <span class="cov1" title="1">copy(headerBuf[headerBufLen:], data[:need])
                        if headerBuf[0] == 0x0B &amp;&amp; headerBuf[1] == 0x77 </span><span class="cov1" title="1">{
                                fscod := (headerBuf[4] &gt;&gt; 6) &amp; 0x03
                                frmsizecod := headerBuf[4] &amp; 0x3F
                                frameSize := AC3FrameSize(fscod, frmsizecod)
                                if frameSize &gt; 0 </span><span class="cov1" title="1">{
                                        // Valid AC3 frame header spanning range boundary.
                                        // The initial bytes from the first range were already
                                        // added to AC3 optimistically when buffered.
                                        // Add any intermediate pending ranges to AC3 too.
                                        for _, pr := range headerPendingRanges </span><span class="cov0" title="0">{
                                                ac3Ranges = append(ac3Ranges, PESPayloadRange{
                                                        FileOffset: pr.FileOffset,
                                                        Size:       pr.Size,
                                                        ESOffset:   ac3ES,
                                                })
                                                ac3ES += int64(pr.Size)
                                        }</span>
                                        <span class="cov1" title="1">headerPendingRanges = nil
                                        // Now add the header-completion bytes from this range to AC3.
                                        ac3Ranges = append(ac3Ranges, PESPayloadRange{
                                                FileOffset: r.FileOffset,
                                                Size:       need,
                                                ESOffset:   ac3ES,
                                        })
                                        ac3ES += int64(need)
                                        ac3Remaining = frameSize - 5 // remaining frame bytes after 5-byte header
                                        pos = need
                                        headerBufLen = 0
                                        // Fall through to normal scan which will consume ac3Remaining
                                        goto scanLoop</span>
                                }
                        }
                        // Not a valid AC3 header. The buffered bytes from the first range
                        // were added to AC3 ranges optimistically; re-attribute them
                        // to TrueHD by adjusting ES offsets.
                        <span class="cov0" title="0">if len(ac3Ranges) &gt; 0 </span><span class="cov0" title="0">{
                                last := ac3Ranges[len(ac3Ranges)-1]
                                ac3Ranges = ac3Ranges[:len(ac3Ranges)-1]
                                ac3ES -= int64(last.Size)
                                truehdRanges = append(truehdRanges, PESPayloadRange{
                                        FileOffset: last.FileOffset,
                                        Size:       last.Size,
                                        ESOffset:   truehdES,
                                })
                                truehdES += int64(last.Size)
                        }</span>
                        // Re-attribute any intermediate pending ranges to TrueHD.
                        <span class="cov0" title="0">for _, pr := range headerPendingRanges </span><span class="cov0" title="0">{
                                truehdRanges = append(truehdRanges, PESPayloadRange{
                                        FileOffset: pr.FileOffset,
                                        Size:       pr.Size,
                                        ESOffset:   truehdES,
                                })
                                truehdES += int64(pr.Size)
                        }</span>
                        <span class="cov0" title="0">headerPendingRanges = nil
                        headerBufLen = 0</span>
                        // Fall through to normal processing for the rest of this range
                }

        <span class="cov3" title="7">scanLoop:
                for pos &lt; len(data) </span><span class="cov4" title="21">{
                        if ac3Remaining &gt; 0 </span><span class="cov3" title="8">{
                                // Inside an AC3 frame - consume bytes
                                consume := ac3Remaining
                                if consume &gt; len(data)-pos </span><span class="cov1" title="2">{
                                        consume = len(data) - pos
                                }</span>
                                <span class="cov3" title="8">ac3Ranges = append(ac3Ranges, PESPayloadRange{
                                        FileOffset: r.FileOffset + int64(pos),
                                        Size:       consume,
                                        ESOffset:   ac3ES,
                                })
                                ac3ES += int64(consume)
                                ac3Remaining -= consume
                                pos += consume
                                continue</span>
                        }

                        // Look for AC3 sync word (need 5 bytes: 2-byte sync + byte 4 for frame size)
                        <span class="cov4" title="13">if pos+4 &lt; len(data) &amp;&amp; data[pos] == 0x0B &amp;&amp; data[pos+1] == 0x77 </span><span class="cov2" title="5">{
                                fscod := (data[pos+4] &gt;&gt; 6) &amp; 0x03
                                frmsizecod := data[pos+4] &amp; 0x3F
                                frameSize := AC3FrameSize(fscod, frmsizecod)
                                if frameSize &gt; 0 </span><span class="cov2" title="5">{
                                        ac3Remaining = frameSize
                                        continue</span> // will be consumed in ac3Remaining branch
                                }
                        }

                        // TrueHD data - scan forward to next AC3 sync word or end of range
                        <span class="cov3" title="8">start := pos
                        pos++
                        for pos &lt; len(data) </span><span class="cov9" title="822">{
                                if pos+4 &lt; len(data) &amp;&amp; data[pos] == 0x0B &amp;&amp; data[pos+1] == 0x77 </span><span class="cov1" title="2">{
                                        fscod := (data[pos+4] &gt;&gt; 6) &amp; 0x03
                                        frmsizecod := data[pos+4] &amp; 0x3F
                                        if AC3FrameSize(fscod, frmsizecod) &gt; 0 </span><span class="cov1" title="2">{
                                                break</span>
                                        }
                                }
                                <span class="cov9" title="820">pos++</span>
                        }
                        <span class="cov3" title="8">if pos &gt; start </span><span class="cov3" title="8">{
                                truehdRanges = append(truehdRanges, PESPayloadRange{
                                        FileOffset: r.FileOffset + int64(start),
                                        Size:       pos - start,
                                        ESOffset:   truehdES,
                                })
                                truehdES += int64(pos - start)
                        }</span>
                }

                // After processing all bytes in this range, check if trailing bytes
                // could be a partial AC3 header for cross-range detection.
                // Only relevant when not inside an AC3 frame.
                <span class="cov3" title="8">if ac3Remaining == 0 &amp;&amp; len(truehdRanges) &gt; 0 </span><span class="cov3" title="6">{
                        last := &amp;truehdRanges[len(truehdRanges)-1]
                        lastEnd := last.FileOffset + int64(last.Size)
                        rangeEnd := r.FileOffset + int64(r.Size)
                        if lastEnd == rangeEnd &amp;&amp; last.Size &gt; 0 </span><span class="cov3" title="6">{
                                // TrueHD range extends to end of PES range. Check if last
                                // 1-4 bytes could start an AC3 header (contain 0x0B).
                                checkStart := last.Size - 4
                                if checkStart &lt; 0 </span><span class="cov0" title="0">{
                                        checkStart = 0
                                }</span>
                                <span class="cov3" title="6">tailData := p.dataSlice(last.FileOffset, lastEnd)
                                bufStart := -1
                                for j := len(tailData) - 1; j &gt;= checkStart; j-- </span><span class="cov4" title="21">{
                                        if tailData[j] == 0x0B </span><span class="cov1" title="1">{
                                                bufStart = j
                                                break</span>
                                        }
                                }
                                <span class="cov3" title="6">if bufStart &gt;= 0 </span><span class="cov1" title="1">{
                                        tailLen := len(tailData) - bufStart
                                        copy(headerBuf[:], tailData[bufStart:])
                                        headerBufLen = tailLen
                                        // Trim TrueHD range and add trimmed bytes to AC3 optimistically
                                        last.Size -= tailLen
                                        truehdES -= int64(tailLen)
                                        if last.Size == 0 </span><span class="cov0" title="0">{
                                                truehdRanges = truehdRanges[:len(truehdRanges)-1]
                                        }</span>
                                        <span class="cov1" title="1">ac3Ranges = append(ac3Ranges, PESPayloadRange{
                                                FileOffset: rangeEnd - int64(tailLen),
                                                Size:       tailLen,
                                                ESOffset:   ac3ES,
                                        })
                                        ac3ES += int64(tailLen)</span>
                                }
                        }
                }
        }

        // If we ended with buffered bytes, they weren't AC3 — re-attribute to TrueHD
        <span class="cov2" title="3">if headerBufLen &gt; 0 </span><span class="cov0" title="0">{
                if len(ac3Ranges) &gt; 0 </span><span class="cov0" title="0">{
                        last := ac3Ranges[len(ac3Ranges)-1]
                        ac3Ranges = ac3Ranges[:len(ac3Ranges)-1]
                        ac3ES -= int64(last.Size)
                        truehdRanges = append(truehdRanges, PESPayloadRange{
                                FileOffset: last.FileOffset,
                                Size:       last.Size,
                                ESOffset:   truehdES,
                        })
                        truehdES += int64(last.Size)
                }</span>
                <span class="cov0" title="0">for _, pr := range headerPendingRanges </span><span class="cov0" title="0">{
                        truehdRanges = append(truehdRanges, PESPayloadRange{
                                FileOffset: pr.FileOffset,
                                Size:       pr.Size,
                                ESOffset:   truehdES,
                        })
                        truehdES += int64(pr.Size)
                }</span>
        }

        <span class="cov2" title="3">return ac3Ranges, truehdRanges</span>
}

// mergeAdjacentRanges merges consecutive PESPayloadRange entries that are
// contiguous in both file offset and ES offset.
func mergeAdjacentRanges(ranges []PESPayloadRange) []PESPayloadRange <span class="cov3" title="9">{
        if len(ranges) &lt;= 1 </span><span class="cov1" title="2">{
                return ranges
        }</span>
        <span class="cov3" title="7">merged := make([]PESPayloadRange, 0, len(ranges)/2)
        merged = append(merged, ranges[0])
        for i := 1; i &lt; len(ranges); i++ </span><span class="cov4" title="13">{
                last := &amp;merged[len(merged)-1]
                r := ranges[i]
                if r.FileOffset == last.FileOffset+int64(last.Size) &amp;&amp;
                        r.ESOffset == last.ESOffset+int64(last.Size) </span><span class="cov2" title="4">{
                        last.Size += r.Size
                }</span> else<span class="cov3" title="9"> {
                        merged = append(merged, r)
                }</span>
        }
        <span class="cov3" title="7">return merged</span>
}

// Ensure MPEGTSParser implements the required interfaces at compile time.
var (
        _ ESReader         = (*MPEGTSParser)(nil)
        _ ESRangeConverter = (*MPEGTSParser)(nil)
)
</pre>
		
		<pre class="file" id="file49" style="display: none">package source

import (
        "fmt"
        "os"
        "path/filepath"
        "strings"
)

// detectBlurayCodecs performs a lightweight scan of the first M2TS file
// to detect codecs via the MPEG-TS Program Map Table (PMT).
func detectBlurayCodecs(index *Index) (*SourceCodecs, error) <span class="cov0" title="0">{
        if len(index.Files) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no source files in index")
        }</span>

        // Find the largest M2TS file (most likely the main feature)
        <span class="cov0" title="0">var largestFile string
        var largestSize int64
        for _, f := range index.Files </span><span class="cov0" title="0">{
                if f.Size &gt; largestSize </span><span class="cov0" title="0">{
                        largestSize = f.Size
                        largestFile = f.RelativePath
                }</span>
        }

        <span class="cov0" title="0">if largestFile == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no valid M2TS files found")
        }</span>

        <span class="cov0" title="0">fullPath := filepath.Join(index.SourceDir, largestFile)
        return detectBlurayCodecsFromFile(fullPath)</span>
}

// detectBlurayCodecsFromFile parses the PMT from an M2TS file (or Blu-ray ISO)
// to detect codecs. For ISOs, it finds the largest M2TS file within the ISO
// and reads from that region.
func detectBlurayCodecsFromFile(path string) (*SourceCodecs, error) <span class="cov2" title="2">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("open file: %w", err)
        }</span>
        <span class="cov2" title="2">defer f.Close()

        // Determine read offset: for ISOs, find the largest M2TS within
        readOffset := int64(0)
        if strings.HasSuffix(strings.ToLower(path), ".iso") </span><span class="cov2" title="2">{
                m2tsFiles, err := findBlurayM2TSInISO(path)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("find M2TS in ISO: %w", err)
                }</span>
                // Find the largest M2TS (most likely the main feature)
                <span class="cov2" title="2">var largest isoFileExtent
                for _, m := range m2tsFiles </span><span class="cov2" title="2">{
                        if m.Size &gt; largest.Size </span><span class="cov2" title="2">{
                                largest = m
                        }</span>
                }
                <span class="cov2" title="2">if largest.Size == 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("no M2TS files found in Blu-ray ISO")
                }</span>
                <span class="cov2" title="2">readOffset = largest.Offset</span>
        }

        // Read 2MB from the M2TS data — enough to find PAT + PMT
        <span class="cov2" title="2">const scanSize = 2 * 1024 * 1024
        buf := make([]byte, scanSize)
        n, err := f.ReadAt(buf, readOffset)
        if err != nil &amp;&amp; n == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read M2TS data: %w", err)
        }</span>
        <span class="cov2" title="2">buf = buf[:n]

        // Need at least enough data for TS packet size detection (4 sync bytes at regular intervals)
        if len(buf) &lt; 192*4 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("M2TS data too small to detect TS structure (%d bytes)", len(buf))
        }</span>

        <span class="cov2" title="2">return parseTSCodecs(buf)</span>
}

// parseTSCodecs scans MPEG-TS data to find the PAT and PMT and extract stream types.
func parseTSCodecs(data []byte) (*SourceCodecs, error) <span class="cov3" title="4">{
        // Detect TS packet size: 188 (standard) or 192 (M2TS with 4-byte timestamp)
        packetSize, offset := detectTSPacketSize(data)
        if packetSize == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("cannot detect TS packet size")
        }</span>

        // Step 1: Find PAT (PID 0x0000) to get PMT PID
        <span class="cov3" title="4">pmtPID := uint16(0)
        for i := offset; i+packetSize &lt;= len(data); i += packetSize </span><span class="cov3" title="4">{
                tsOffset := i
                if packetSize == 192 </span><span class="cov3" title="4">{
                        tsOffset += 4 // Skip 4-byte M2TS timestamp
                }</span>
                <span class="cov3" title="4">if tsOffset+188 &gt; len(data) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov3" title="4">pkt := data[tsOffset : tsOffset+188]
                if pkt[0] != 0x47 </span><span class="cov0" title="0">{
                        continue</span> // Not a valid TS sync byte
                }

                <span class="cov3" title="4">pid := uint16(pkt[1]&amp;0x1F)&lt;&lt;8 | uint16(pkt[2])
                if pid != 0x0000 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // PAT found — parse it
                <span class="cov3" title="4">payloadStart := pkt[1]&amp;0x40 != 0
                if !payloadStart </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip adaptation field if present
                <span class="cov3" title="4">adaptationFieldControl := (pkt[3] &gt;&gt; 4) &amp; 0x03
                headerLen := 4
                switch adaptationFieldControl </span>{
                case 0x02, 0x03:<span class="cov0" title="0"> // Adaptation field present
                        adaptLen := int(pkt[4])
                        if adaptLen &gt; 183 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">headerLen = 5 + adaptLen</span>
                case 0x01:<span class="cov3" title="4"></span> // Payload only, no adaptation field
                default:<span class="cov0" title="0"> // 0x00 is reserved/invalid
                        continue</span>
                }
                <span class="cov3" title="4">if headerLen &gt;= 188 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip pointer field
                <span class="cov3" title="4">pointerField := int(pkt[headerLen])
                headerLen += 1 + pointerField
                if headerLen+8 &gt; 188 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov3" title="4">payload := pkt[headerLen:]
                // PAT: table_id(1) + flags+length(2) + tsid(2) + version(1) + section(1) + last_section(1)
                // then 4 bytes per program: program_number(2) + PMT_PID(2)
                if len(payload) &lt; 12 </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov3" title="4">if payload[0] != 0x00 </span><span class="cov0" title="0">{ // table_id for PAT
                        continue</span>
                }

                <span class="cov3" title="4">sectionLength := int(payload[1]&amp;0x0F)&lt;&lt;8 | int(payload[2])
                if sectionLength &lt; 9 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Programs start at offset 8, each is 4 bytes
                <span class="cov3" title="4">programsEnd := 8 + sectionLength - 4 // -4 for CRC
                if programsEnd &gt; len(payload) </span><span class="cov0" title="0">{
                        programsEnd = len(payload) - 4
                }</span>

                <span class="cov3" title="4">for j := 8; j+4 &lt;= programsEnd; j += 4 </span><span class="cov3" title="4">{
                        progNum := uint16(payload[j])&lt;&lt;8 | uint16(payload[j+1])
                        if progNum == 0 </span><span class="cov0" title="0">{
                                continue</span> // Network PID, skip
                        }
                        <span class="cov3" title="4">pmtPID = uint16(payload[j+2]&amp;0x1F)&lt;&lt;8 | uint16(payload[j+3])
                        break</span> // Use the first program
                }
                <span class="cov3" title="4">break</span>
        }

        <span class="cov3" title="4">if pmtPID == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("PMT PID not found in PAT")
        }</span>

        // Step 2: Find PMT and extract stream types
        <span class="cov3" title="4">codecs := &amp;SourceCodecs{}
        for i := offset; i+packetSize &lt;= len(data); i += packetSize </span><span class="cov4" title="8">{
                tsOffset := i
                if packetSize == 192 </span><span class="cov4" title="8">{
                        tsOffset += 4
                }</span>
                <span class="cov4" title="8">if tsOffset+188 &gt; len(data) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov4" title="8">pkt := data[tsOffset : tsOffset+188]
                if pkt[0] != 0x47 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov4" title="8">pid := uint16(pkt[1]&amp;0x1F)&lt;&lt;8 | uint16(pkt[2])
                if pid != pmtPID </span><span class="cov3" title="4">{
                        continue</span>
                }

                <span class="cov3" title="4">payloadStart := pkt[1]&amp;0x40 != 0
                if !payloadStart </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip adaptation field
                <span class="cov3" title="4">adaptationFieldControl := (pkt[3] &gt;&gt; 4) &amp; 0x03
                headerLen := 4
                switch adaptationFieldControl </span>{
                case 0x02, 0x03:<span class="cov0" title="0"> // Adaptation field present
                        adaptLen := int(pkt[4])
                        if adaptLen &gt; 183 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">headerLen = 5 + adaptLen</span>
                case 0x01:<span class="cov3" title="4"></span> // Payload only, no adaptation field
                default:<span class="cov0" title="0"> // 0x00 is reserved/invalid
                        continue</span>
                }
                <span class="cov3" title="4">if headerLen &gt;= 188 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip pointer field
                <span class="cov3" title="4">pointerField := int(pkt[headerLen])
                headerLen += 1 + pointerField
                if headerLen+12 &gt; 188 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov3" title="4">payload := pkt[headerLen:]
                if len(payload) &lt; 12 || payload[0] != 0x02 </span><span class="cov0" title="0">{ // table_id for PMT
                        continue</span>
                }

                <span class="cov3" title="4">sectionLength := int(payload[1]&amp;0x0F)&lt;&lt;8 | int(payload[2])
                if sectionLength &lt; 13 </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Program info length at offset 10
                <span class="cov3" title="4">progInfoLen := int(payload[10]&amp;0x0F)&lt;&lt;8 | int(payload[11])

                // Stream descriptors start after program info
                streamsStart := 12 + progInfoLen
                streamsEnd := 3 + sectionLength - 4 // section starts at byte 3, -4 for CRC
                if streamsEnd &gt; len(payload) </span><span class="cov0" title="0">{
                        streamsEnd = len(payload) - 4
                }</span>
                <span class="cov3" title="4">if streamsStart &gt; streamsEnd </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov3" title="4">for j := streamsStart; j+5 &lt;= streamsEnd; </span><span class="cov4" title="9">{
                        streamType := payload[j]
                        esInfoLen := int(payload[j+3]&amp;0x0F)&lt;&lt;8 | int(payload[j+4])

                        ct := tsStreamTypeToCodecType(streamType)
                        if ct != CodecUnknown </span><span class="cov4" title="9">{
                                if IsVideoCodec(ct) </span><span class="cov3" title="4">{
                                        if !containsCodec(codecs.VideoCodecs, ct) </span><span class="cov3" title="4">{
                                                codecs.VideoCodecs = append(codecs.VideoCodecs, ct)
                                        }</span>
                                } else<span class="cov3" title="5"> if IsAudioCodec(ct) </span><span class="cov3" title="5">{
                                        if !containsCodec(codecs.AudioCodecs, ct) </span><span class="cov3" title="5">{
                                                codecs.AudioCodecs = append(codecs.AudioCodecs, ct)
                                        }</span>
                                } else<span class="cov0" title="0"> if IsSubtitleCodec(ct) </span><span class="cov0" title="0">{
                                        if !containsCodec(codecs.SubtitleCodecs, ct) </span><span class="cov0" title="0">{
                                                codecs.SubtitleCodecs = append(codecs.SubtitleCodecs, ct)
                                        }</span>
                                }
                        }

                        <span class="cov4" title="9">next := j + 5 + esInfoLen
                        if next &lt; j || next &gt; streamsEnd </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov4" title="9">j = next</span>
                }

                <span class="cov3" title="4">break</span> // Found and parsed PMT
        }

        <span class="cov3" title="4">return codecs, nil</span>
}

// tsStreamTypeToCodecType maps MPEG-TS stream type values to CodecType.
func tsStreamTypeToCodecType(streamType byte) CodecType <span class="cov7" title="89">{
        switch streamType </span>{
        case 0x01:<span class="cov1" title="1">
                return CodecMPEG1Video</span>
        case 0x02:<span class="cov2" title="2">
                return CodecMPEG2Video</span>
        case 0x1B:<span class="cov5" title="24">
                return CodecH264Video</span>
        case 0x24:<span class="cov1" title="1">
                return CodecH265Video</span>
        case 0xEA:<span class="cov1" title="1">
                return CodecVC1Video</span>
        case 0x03, 0x04:<span class="cov2" title="2">
                return CodecMPEGAudio</span>
        case 0x0F:<span class="cov1" title="1">
                return CodecAACaudio</span>
        case 0x80:<span class="cov1" title="1">
                return CodecLPCMAudio</span>
        case 0x81:<span class="cov5" title="26">
                return CodecAC3Audio</span>
        case 0x82:<span class="cov2" title="2">
                return CodecDTSAudio</span>
        case 0x83:<span class="cov3" title="4">
                return CodecTrueHDAudio</span>
        case 0x84:<span class="cov1" title="1">
                return CodecEAC3Audio</span>
        case 0x85, 0x86:<span class="cov2" title="3">
                return CodecDTSHDAudio</span>
        case 0x90:<span class="cov5" title="19">
                return CodecPGSSubtitle</span>
        default:<span class="cov1" title="1">
                return CodecUnknown</span>
        }
}

// detectTSPacketSize determines TS packet size (188 or 192) and the offset to
// the first sync byte. Returns (0, 0) if no valid TS structure is found.
func detectTSPacketSize(data []byte) (int, int) <span class="cov5" title="27">{
        // Try both M2TS (192-byte packets) and standard TS (188-byte packets)
        for _, size := range []int{192, 188} </span><span class="cov6" title="29">{
                for startOffset := 0; startOffset &lt; size &amp;&amp; startOffset+size*3 &lt; len(data); startOffset++ </span><span class="cov10" title="395">{
                        syncOffset := startOffset
                        if size == 192 </span><span class="cov9" title="393">{
                                syncOffset += 4 // M2TS timestamp prefix
                        }</span>
                        <span class="cov10" title="395">if syncOffset &gt;= len(data) || data[syncOffset] != 0x47 </span><span class="cov9" title="367">{
                                continue</span>
                        }
                        // Verify 3 consecutive sync bytes
                        <span class="cov6" title="28">valid := true
                        for k := 1; k &lt;= 3; k++ </span><span class="cov7" title="82">{
                                nextSync := startOffset + k*size
                                if size == 192 </span><span class="cov7" title="76">{
                                        nextSync += 4
                                }</span>
                                <span class="cov7" title="82">if nextSync &gt;= len(data) || data[nextSync] != 0x47 </span><span class="cov1" title="1">{
                                        valid = false
                                        break</span>
                                }
                        }
                        <span class="cov6" title="28">if valid </span><span class="cov5" title="27">{
                                return size, startOffset
                        }</span>
                }
        }
        <span class="cov0" title="0">return 0, 0</span>
}
</pre>
		
		<pre class="file" id="file50" style="display: none">package source

import (
        "sort"
        "sync/atomic"
)

// multiRegionData provides a virtual contiguous view over multiple
// non-contiguous byte slices from a memory-mapped ISO. Used for
// multi-extent UDF files where M2TS data is split across
// non-contiguous ISO regions.
type multiRegionData struct {
        regions   []multiRegion
        totalSize int64
        lastIdx   atomic.Int32 // cached region index for fast sequential access
}

type multiRegion struct {
        data         []byte
        logicalStart int64 // cumulative offset in the virtual contiguous view
}

// newMultiRegionData creates a multiRegionData from ISO physical extents.
// Each extent becomes a region backed by a sub-slice of isoData (zero-copy).
func newMultiRegionData(extents []isoPhysicalRange, isoData []byte) *multiRegionData <span class="cov3" title="10">{
        mr := &amp;multiRegionData{
                regions: make([]multiRegion, len(extents)),
        }
        logicalOff := int64(0)
        isoLen := int64(len(isoData))
        for i, ext := range extents </span><span class="cov4" title="19">{
                end := ext.ISOOffset + ext.Length
                if ext.ISOOffset &lt; 0 || end &gt; isoLen </span><span class="cov0" title="0">{
                        // Clamp to ISO bounds (corrupted/malformed UDF metadata)
                        start := ext.ISOOffset
                        if start &lt; 0 </span><span class="cov0" title="0">{
                                start = 0
                        }</span>
                        <span class="cov0" title="0">if end &gt; isoLen </span><span class="cov0" title="0">{
                                end = isoLen
                        }</span>
                        <span class="cov0" title="0">if start &gt;= end </span><span class="cov0" title="0">{
                                mr.regions[i] = multiRegion{logicalStart: logicalOff}
                                continue</span>
                        }
                        <span class="cov0" title="0">mr.regions[i] = multiRegion{
                                data:         isoData[start:end],
                                logicalStart: logicalOff,
                        }
                        logicalOff += end - start
                        continue</span>
                }
                <span class="cov4" title="19">mr.regions[i] = multiRegion{
                        data:         isoData[ext.ISOOffset:end],
                        logicalStart: logicalOff,
                }
                logicalOff += ext.Length</span>
        }
        <span class="cov3" title="10">mr.totalSize = logicalOff
        return mr</span>
}

// Len returns the total logical size across all regions.
func (m *multiRegionData) Len() int64 <span class="cov3" title="9">{ return m.totalSize }</span>

// regionFor returns the index of the region containing the given logical offset.
// Returns len(m.regions) if the offset is beyond all regions.
func (m *multiRegionData) regionFor(off int64) int <span class="cov10" title="1946">{
        // Fast path: check cached index
        cached := int(m.lastIdx.Load())
        if cached &lt; len(m.regions) </span><span class="cov10" title="1946">{
                r := m.regions[cached]
                if off &gt;= r.logicalStart &amp;&amp; off &lt; r.logicalStart+int64(len(r.data)) </span><span class="cov9" title="1936">{
                        return cached
                }</span>
        }
        // Binary search
        <span class="cov3" title="10">idx := sort.Search(len(m.regions), func(i int) bool </span><span class="cov4" title="20">{
                return m.regions[i].logicalStart+int64(len(m.regions[i].data)) &gt; off
        }</span>)
        <span class="cov3" title="10">if idx &lt; len(m.regions) </span><span class="cov3" title="10">{
                m.lastIdx.Store(int32(idx))
        }</span>
        <span class="cov3" title="10">return idx</span>
}

// ByteAt returns the byte at the given logical offset.
// Returns 0 if the offset is out of bounds.
func (m *multiRegionData) ByteAt(off int64) byte <span class="cov9" title="1932">{
        if off &lt; 0 || off &gt;= m.totalSize </span><span class="cov2" title="3">{
                return 0
        }</span>
        <span class="cov9" title="1929">idx := m.regionFor(off)
        if idx &gt;= len(m.regions) </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov9" title="1929">r := m.regions[idx]
        return r.data[off-r.logicalStart]</span>
}

// Slice returns a byte slice for the given logical offset range [off, end).
// Returns a zero-copy sub-slice when the range falls within one region.
// Copies into a new buffer when the range straddles a region boundary.
func (m *multiRegionData) Slice(off, end int64) []byte <span class="cov4" title="20">{
        if off &lt; 0 || end &lt; 0 || off &gt;= end </span><span class="cov2" title="3">{
                return nil
        }</span>
        <span class="cov4" title="17">idx := m.regionFor(off)
        if idx &gt;= len(m.regions) </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov4" title="17">r := m.regions[idx]
        regionOff := off - r.logicalStart
        regionEnd := end - r.logicalStart
        if regionEnd &lt;= int64(len(r.data)) </span><span class="cov4" title="13">{
                // Fast path: entirely within one region (zero-copy)
                return r.data[regionOff:regionEnd]
        }</span>
        // Slow path: straddles region boundary — copy
        <span class="cov2" title="4">size := int(end - off)
        buf := make([]byte, size)
        copied := copy(buf, r.data[regionOff:])
        for i := idx + 1; i &lt; len(m.regions) &amp;&amp; copied &lt; size; i++ </span><span class="cov2" title="4">{
                r := m.regions[i]
                n := copy(buf[copied:], r.data)
                copied += n
        }</span>
        <span class="cov2" title="4">return buf</span>
}
</pre>
		
		<pre class="file" id="file51" style="display: none">// Package source provides functionality for indexing source media files (DVD ISOs, Blu-ray directories).
package source

import (
        "errors"
        "os"
        "path/filepath"
        "sort"
        "strings"
        "sync"

        "github.com/stuckj/mkvdup/internal/mmap"
)

// Type represents the type of source media.
type Type int

// Source type constants.
const (
        TypeDVD    Type = iota // Contains .iso file
        TypeBluray             // Contains BDMV/STREAM/*.m2ts
)

func (t Type) String() string <span class="cov2" title="7">{
        switch t </span>{
        case TypeDVD:<span class="cov1" title="2">
                return "DVD"</span>
        case TypeBluray:<span class="cov1" title="2">
                return "Blu-ray"</span>
        default:<span class="cov1" title="3">
                return "Unknown"</span>
        }
}

// ErrUnknownSourceType is returned when the source directory type cannot be determined.
var ErrUnknownSourceType = errors.New("unknown source type: directory contains neither ISO nor BDMV structure")

// DetectType determines whether a directory contains a DVD ISO or Blu-ray structure.
// ISOs are inspected to determine if they contain DVD (VIDEO_TS) or Blu-ray (BDMV) content.
func DetectType(dir string) (Type, error) <span class="cov3" title="33">{
        // Check for ISO files
        isos, err := filepath.Glob(filepath.Join(dir, "*.iso"))
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        // Also check for ISO in subdirectory (common structure)
        <span class="cov3" title="33">subIsos, err := filepath.Glob(filepath.Join(dir, "*", "*.iso"))
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov3" title="33">isos = append(isos, subIsos...)

        // If we found ISOs, inspect them to determine type
        if len(isos) &gt; 0 </span><span class="cov2" title="11">{
                // Check the first ISO to determine type
                isoType, err := detectISOType(isos[0])
                if err != nil </span><span class="cov2" title="6">{
                        // If we can't read the ISO, default to DVD (legacy behavior)
                        return TypeDVD, nil
                }</span>
                <span class="cov1" title="5">return isoType, nil</span>
        }

        // Check for Blu-ray directory structure
        <span class="cov2" title="22">m2ts, err := filepath.Glob(filepath.Join(dir, "BDMV", "STREAM", "*.m2ts"))
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov2" title="22">if len(m2ts) &gt; 0 </span><span class="cov1" title="1">{
                return TypeBluray, nil
        }</span>

        <span class="cov2" title="21">return 0, ErrUnknownSourceType</span>
}

// detectISOType examines an ISO file to determine if it's a DVD or Blu-ray.
// DVDs have VIDEO_TS directory, Blu-rays have BDMV directory.
// Uses minimal reads to avoid loading the entire ISO into memory.
func detectISOType(isoPath string) (Type, error) <span class="cov2" title="11">{
        f, err := os.Open(isoPath)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov2" title="11">defer f.Close()

        // ISO9660 primary volume descriptor is at sector 16 (2048 bytes per sector)
        // The root directory record is embedded in the volume descriptor at offset 156.
        const sectorSize = 2048
        const pvdOffset = 16 * sectorSize

        // Read the primary volume descriptor
        pvd := make([]byte, sectorSize)
        if _, err := f.ReadAt(pvd, pvdOffset); err != nil </span><span class="cov2" title="6">{
                return 0, err
        }</span>

        // Check volume descriptor type (byte 0) and signature "CD001" (bytes 1-5)
        <span class="cov1" title="5">if pvd[0] != 1 || string(pvd[1:6]) != "CD001" </span><span class="cov1" title="2">{
                // No ISO9660 PVD. Check for UDF (Blu-ray ISOs from CloneBD).
                if isUDFImage(f) </span><span class="cov1" title="2">{
                        return detectUDFISOType(f)
                }</span>
                <span class="cov0" title="0">return TypeDVD, nil</span>
        }

        // Root directory record is at offset 156, length at byte 0 of the record
        <span class="cov1" title="3">rootDirRecord := pvd[156:]
        if len(rootDirRecord) &lt; 34 </span><span class="cov0" title="0">{
                return TypeDVD, nil
        }</span>

        // Extract root directory extent location (bytes 2-5, little-endian)
        <span class="cov1" title="3">rootExtent := uint32(rootDirRecord[2]) | uint32(rootDirRecord[3])&lt;&lt;8 |
                uint32(rootDirRecord[4])&lt;&lt;16 | uint32(rootDirRecord[5])&lt;&lt;24
        // Extract root directory data length (bytes 10-13, little-endian)
        rootDataLen := uint32(rootDirRecord[10]) | uint32(rootDirRecord[11])&lt;&lt;8 |
                uint32(rootDirRecord[12])&lt;&lt;16 | uint32(rootDirRecord[13])&lt;&lt;24

        // Read the root directory
        // Limit to first 16KB to avoid reading huge directories
        if rootDataLen &gt; 16*1024 </span><span class="cov0" title="0">{
                rootDataLen = 16 * 1024
        }</span>
        <span class="cov1" title="3">rootDir := make([]byte, rootDataLen)
        if _, err := f.ReadAt(rootDir, int64(rootExtent)*sectorSize); err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        // Parse directory entries looking for VIDEO_TS or BDMV
        <span class="cov1" title="3">hasBDMV := false
        hasVideoTS := false

        offset := 0
        for offset &lt; len(rootDir) </span><span class="cov3" title="31">{
                recLen := int(rootDir[offset])
                if recLen == 0 </span><span class="cov1" title="3">{
                        // Move to next sector boundary
                        nextSector := ((offset / sectorSize) + 1) * sectorSize
                        if nextSector &gt;= len(rootDir) </span><span class="cov1" title="3">{
                                break</span>
                        }
                        <span class="cov0" title="0">offset = nextSector
                        continue</span>
                }
                <span class="cov2" title="28">if offset+recLen &gt; len(rootDir) </span><span class="cov0" title="0">{
                        break</span>
                }

                // Name length is at offset 32
                <span class="cov2" title="28">if offset+33 &gt; len(rootDir) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov2" title="28">nameLen := int(rootDir[offset+32])
                if offset+33+nameLen &gt; len(rootDir) </span><span class="cov0" title="0">{
                        break</span>
                }

                // Extract and check the filename
                <span class="cov2" title="28">name := strings.ToUpper(string(rootDir[offset+33 : offset+33+nameLen]))
                // Strip version number (;1) if present
                if idx := strings.Index(name, ";"); idx &gt;= 0 </span><span class="cov2" title="10">{
                        name = name[:idx]
                }</span>
                // Strip trailing dot if present
                <span class="cov2" title="28">name = strings.TrimSuffix(name, ".")

                if name == "BDMV" </span><span class="cov1" title="2">{
                        hasBDMV = true
                }</span>
                <span class="cov2" title="28">if name == "VIDEO_TS" </span><span class="cov1" title="1">{
                        hasVideoTS = true
                }</span>

                <span class="cov2" title="28">offset += recLen</span>
        }

        // Blu-ray takes precedence if both are present
        <span class="cov1" title="3">if hasBDMV </span><span class="cov1" title="2">{
                return TypeBluray, nil
        }</span>
        <span class="cov1" title="1">if hasVideoTS </span><span class="cov1" title="1">{
                return TypeDVD, nil
        }</span>

        // Default to DVD for unrecognized ISOs
        <span class="cov0" title="0">return TypeDVD, nil</span>
}

// File represents a source file within the source directory.
type File struct {
        RelativePath string // Path relative to source directory
        Size         int64
        Checksum     uint64 // xxhash of file for integrity
}

// Location represents a position within a source file where a hash was found.
type Location struct {
        FileIndex        uint16 // Index into Files array
        Offset           int64  // Offset within that file (or ES offset for MPEG-PS)
        IsVideo          bool   // For ES-based indexes: true for video ES, false for audio ES
        AudioSubStreamID byte   // For audio in MPEG-PS: sub-stream ID (0x80-0x87 = AC3, etc.)
}

// ESRangeConverter provides an interface for converting ES offsets to raw file offsets.
// This is used during dedup file creation to convert ES-based entries to raw-offset entries.
type ESRangeConverter interface {
        // RawRangesForESRegion returns the raw file ranges that contain the given ES region.
        // Each returned range represents a contiguous chunk of raw file data.
        // The sum of all returned range sizes equals the requested ES region size.
        // For video streams only - audio should use RawRangesForAudioSubStream.
        RawRangesForESRegion(esOffset int64, size int, isVideo bool) ([]RawRange, error)
        // RawRangesForAudioSubStream returns the raw file ranges for audio data from a specific sub-stream.
        RawRangesForAudioSubStream(subStreamID byte, esOffset int64, size int) ([]RawRange, error)
}

// ESReader provides an interface for reading elementary stream data from container files.
type ESReader interface {
        // ReadESData reads size bytes of ES data starting at esOffset.
        // The data is continuous ES data, with container headers stripped.
        // For video, this works as expected. For audio, use ReadAudioSubStreamData instead.
        ReadESData(esOffset int64, size int, isVideo bool) ([]byte, error)
        // ESOffsetToFileOffset converts an ES offset to a file offset and remaining bytes in that segment.
        ESOffsetToFileOffset(esOffset int64, isVideo bool) (fileOffset int64, remaining int)
        // TotalESSize returns the total size of the elementary stream.
        // For video, returns filtered video ES size. For audio, returns 0 - use AudioSubStreamESSize.
        TotalESSize(isVideo bool) int64
        // AudioSubStreams returns the list of audio sub-stream IDs in order of appearance.
        AudioSubStreams() []byte
        // AudioSubStreamESSize returns the ES size for a specific audio sub-stream.
        AudioSubStreamESSize(subStreamID byte) int64
        // ReadAudioSubStreamData reads audio data from a specific sub-stream.
        ReadAudioSubStreamData(subStreamID byte, esOffset int64, size int) ([]byte, error)
}

// PESRangeProvider provides access to PES payload ranges for building range maps.
// Both MPEGPSParser and MPEGTSParser implement this.
type PESRangeProvider interface {
        FilteredVideoRanges() []PESPayloadRange
        FilteredAudioRanges(subStreamID byte) []PESPayloadRange
        AudioSubStreams() []byte
}

// FileOffsetAdjuster provides a function to convert parser-relative FileOffset
// values to source-file-relative offsets for range map storage.
// Implemented by isoM2TSAdapter where the parser operates on a sub-region
// of the ISO and FileOffset values need to be adjusted to ISO-relative.
type FileOffsetAdjuster interface {
        FileOffsetConverter() func(int64) int64
}

// RawReader provides an interface for reading raw file data.
type RawReader interface {
        ReadAt(buf []byte, offset int64) (int, error)
        // Slice returns a zero-copy slice of the underlying data.
        // Returns nil if offset is out of range.
        Slice(offset int64, size int) []byte
        Len() int
        Close() error
}

// Index holds the hash-to-location mapping for fast lookup of byte sequences.
type Index struct {
        // HashToLocations maps from xxhash to list of locations where that hash was found
        HashToLocations map[uint64][]Location

        // SourceDir is the path to the source directory
        SourceDir string

        // SourceType indicates whether this is DVD or Blu-ray
        SourceType Type

        // Files lists all media files in the source
        Files []File

        // WindowSize is the number of bytes used for hashing
        WindowSize int

        // ESReaders provides ES-aware reading for each file (nil for raw files)
        // For MPEG-PS files, this allows reading continuous ES data.
        ESReaders []ESReader

        // RawReaders provides raw file reading for each file.
        // Used when raw file indexing is enabled.
        RawReaders []RawReader

        // MmapFiles holds the mmap file handles for proper cleanup.
        // These back the ESReaders for MPEG-PS files.
        MmapFiles []*mmap.File

        // UsesESOffsets indicates whether Location.Offset values are ES offsets
        // rather than raw file offsets. True for DVD (MPEG-PS) sources.
        UsesESOffsets bool

        // sortOnce ensures SortLocationsByOffset runs only once.
        sortOnce sync.Once
}

// NewIndex creates a new empty Index for the given source directory.
func NewIndex(sourceDir string, sourceType Type, windowSize int) *Index <span class="cov2" title="21">{
        return &amp;Index{
                HashToLocations: make(map[uint64][]Location),
                SourceDir:       sourceDir,
                SourceType:      sourceType,
                WindowSize:      windowSize,
        }
}</span>

// SortLocationsByOffset sorts all location slices by (FileIndex, Offset).
// This is a one-time cost at match setup time that enables binary search
// for nearby locations during matching. Must be called before concurrent access.
func (idx *Index) SortLocationsByOffset() <span class="cov1" title="1">{
        idx.sortOnce.Do(func() </span><span class="cov1" title="1">{
                for hash, locs := range idx.HashToLocations </span><span class="cov10" title="3727666">{
                        if len(locs) &gt; 1 </span><span class="cov7" title="122555">{
                                sort.Slice(locs, func(i, j int) bool </span><span class="cov8" title="417884">{
                                        if locs[i].FileIndex != locs[j].FileIndex </span><span class="cov0" title="0">{
                                                return locs[i].FileIndex &lt; locs[j].FileIndex
                                        }</span>
                                        <span class="cov8" title="417884">return locs[i].Offset &lt; locs[j].Offset</span>
                                })
                                <span class="cov7" title="122555">idx.HashToLocations[hash] = locs</span>
                        }
                }
        })
}

// EnumerateMediaFiles returns the list of media files to index based on source type.
func EnumerateMediaFiles(dir string, sourceType Type) ([]string, error) <span class="cov2" title="10">{
        var files []string

        switch sourceType </span>{
        case TypeDVD:<span class="cov1" title="3">
                // Look for ISO files
                isos, err := filepath.Glob(filepath.Join(dir, "*.iso"))
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov1" title="3">files = append(files, isos...)

                // Also check subdirectory
                isos, err = filepath.Glob(filepath.Join(dir, "*", "*.iso"))
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov1" title="3">files = append(files, isos...)</span>

        case TypeBluray:<span class="cov2" title="7">
                // Look for m2ts files in BDMV/STREAM (extracted Blu-ray)
                m2ts, err := filepath.Glob(filepath.Join(dir, "BDMV", "STREAM", "*.m2ts"))
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov2" title="7">files = append(files, m2ts...)

                // If no extracted M2TS files, look for Blu-ray ISOs
                if len(files) == 0 </span><span class="cov1" title="5">{
                        isos, err := filepath.Glob(filepath.Join(dir, "*.iso"))
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov1" title="5">files = append(files, isos...)

                        // Also check subdirectory (same pattern as DVD)
                        isos, err = filepath.Glob(filepath.Join(dir, "*", "*.iso"))
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov1" title="5">files = append(files, isos...)</span>
                }
        }

        // Convert to relative paths
        <span class="cov2" title="10">relFiles := make([]string, 0, len(files))
        for _, f := range files </span><span class="cov2" title="10">{
                rel, err := filepath.Rel(dir, f)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov2" title="10">relFiles = append(relFiles, rel)</span>
        }

        <span class="cov2" title="10">return relFiles, nil</span>
}

// GetFileInfo returns size information for a file.
func GetFileInfo(path string) (int64, error) <span class="cov2" title="8">{
        info, err := os.Stat(path)
        if err != nil </span><span class="cov1" title="1">{
                return 0, err
        }</span>
        <span class="cov2" title="7">return info.Size(), nil</span>
}

// ReadRawDataAt reads raw data from the source file at the given location.
// This is used for raw file indexing (non-ES mode).
// Note: This copies data. Prefer RawSlice for zero-copy access.
func (idx *Index) ReadRawDataAt(loc Location, size int) ([]byte, error) <span class="cov1" title="1">{
        if int(loc.FileIndex) &gt;= len(idx.RawReaders) || idx.RawReaders[loc.FileIndex] == nil </span><span class="cov1" title="1">{
                return nil, errors.New("no raw reader for file")
        }</span>
        <span class="cov0" title="0">buf := make([]byte, size)
        n, err := idx.RawReaders[loc.FileIndex].ReadAt(buf, loc.Offset)
        if err != nil &amp;&amp; n &lt; size </span><span class="cov0" title="0">{
                return buf[:n], err
        }</span>
        <span class="cov0" title="0">return buf[:n], nil</span>
}

// RawSlice returns a zero-copy slice of raw data at the given location.
// Returns nil if the location is out of range.
func (idx *Index) RawSlice(loc Location, size int) []byte <span class="cov1" title="1">{
        if int(loc.FileIndex) &gt;= len(idx.RawReaders) || idx.RawReaders[loc.FileIndex] == nil </span><span class="cov1" title="1">{
                return nil
        }</span>
        <span class="cov0" title="0">return idx.RawReaders[loc.FileIndex].Slice(loc.Offset, size)</span>
}
</pre>
		
		<pre class="file" id="file52" style="display: none">package source

// FindPGSSyncPoints returns byte offsets of PGS segment boundaries in data.
// PGS segments have a 3-byte header: [type (1 byte)] [size (2 bytes BE)].
// Each segment start is a sync point. Valid segment types are:
// 0x14 (PDS), 0x15 (ODS), 0x16 (PCS), 0x17 (WDS), 0x80 (END).
func FindPGSSyncPoints(data []byte) []int <span class="cov6" title="8">{
        var offsets []int
        off := 0
        for off+3 &lt;= len(data) </span><span class="cov8" title="13">{
                segType := data[off]
                if !isValidPGSSegmentType(segType) </span><span class="cov1" title="1">{
                        break</span>
                }
                <span class="cov7" title="12">offsets = append(offsets, off)
                segSize := int(data[off+1])&lt;&lt;8 | int(data[off+2])
                off += 3 + segSize</span>
        }
        <span class="cov6" title="8">return offsets</span>
}

func isValidPGSSegmentType(t byte) bool <span class="cov10" title="25">{
        switch t </span>{
        case 0x14, 0x15, 0x16, 0x17, 0x80:<span class="cov8" title="17">
                return true</span>
        }
        <span class="cov6" title="8">return false</span>
}
</pre>
		
		<pre class="file" id="file53" style="display: none">package source

import (
        "encoding/binary"
        "fmt"
        "os"
        "strings"
)

// UDF descriptor tag IDs.
const (
        udfTagAVDP          = 2
        udfTagPartitionDesc = 5
        udfTagLogicalVolume = 6
        udfTagFileSetDesc   = 256
        udfTagFileEntry     = 261
        udfTagFID           = 257
        udfTagExtFileEntry  = 266
)

// udfDescriptorTag is the 16-byte tag at the start of every UDF descriptor.
type udfDescriptorTag struct {
        TagID   uint16
        Version uint16
}

// udfExtent represents a physical extent (offset + length) on disk.
type udfExtent struct {
        Length   uint32
        Location uint32
}

// udfLongAD is a "long allocation descriptor" (16 bytes) used to reference
// data across partitions.
type udfLongAD struct {
        Length   uint32
        Location uint32 // logical block number within partition
        PartRef  uint16 // partition reference number
}

// udfShortAD is a "short allocation descriptor" (8 bytes).
type udfShortAD struct {
        Length   uint32
        Position uint32 // logical block number
}

// udfPartitionDesc holds fields from a UDF Partition Descriptor (tag 5).
type udfPartitionDesc struct {
        PartitionNumber  uint16
        StartingLocation uint32 // physical sector number
}

// udfLogicalVolumeDesc holds fields from a UDF Logical Volume Descriptor (tag 6).
type udfLogicalVolumeDesc struct {
        BlockSize     uint32
        FSDLocation   udfLongAD // File Set Descriptor location
        PartitionMaps []udfPartitionMap
}

// udfPartitionMap describes a partition map entry from the Logical Volume Descriptor.
type udfPartitionMap struct {
        Type         byte // 1 = physical, 2 = metadata/virtual/sparable
        PartitionNum uint16
        IsMetadata   bool
        MetaFileLoc  uint32 // for metadata partitions: file location
}

// udfFileEntry holds parsed fields from a File Entry (tag 261) or
// Extended File Entry (tag 266).
type udfFileEntry struct {
        ICBTag     byte // file type (4=directory, 5=file)
        InfoLength uint64
        AllocDescs []byte // raw allocation descriptors
        AllocType  byte   // 0=short_ad, 1=long_ad, 3=immediate/inline
        PartRef    uint16 // partition reference where this FE resides
}

// udfFID represents a File Identifier Descriptor (tag 257).
type udfFID struct {
        Name        string
        IsDir       bool
        IsParent    bool
        ICBLocation udfLongAD
}

// isUDFImage checks whether the file contains UDF Volume Recognition Sequence
// markers (BEA01/NSR02/NSR03) in sectors 16+.
func isUDFImage(f *os.File) bool <span class="cov3" title="4">{
        // VRS starts at sector 16. Scan up to sector 31 for BEA01 + NSR0x.
        buf := make([]byte, isoSectorSize)
        foundBEA := false
        foundNSR := false

        for sector := 16; sector &lt; 32; sector++ </span><span class="cov7" title="22">{
                n, err := f.ReadAt(buf, int64(sector)*isoSectorSize)
                if err != nil || n &lt; 6 </span><span class="cov5" title="8">{
                        continue</span>
                }
                <span class="cov6" title="14">ident := string(buf[1:6])
                switch ident </span>{
                case "BEA01":<span class="cov3" title="3">
                        foundBEA = true</span>
                case "NSR02", "NSR03":<span class="cov3" title="3">
                        foundNSR = true</span>
                }
                <span class="cov6" title="14">if foundBEA &amp;&amp; foundNSR </span><span class="cov3" title="3">{
                        return true
                }</span>
                <span class="cov6" title="11">if ident == "TEA01" </span><span class="cov0" title="0">{
                        break</span>
                }
        }
        <span class="cov1" title="1">return foundBEA &amp;&amp; foundNSR</span>
}

// detectUDFISOType navigates the UDF root directory to determine whether
// the ISO contains a Blu-ray (BDMV/) or DVD (VIDEO_TS/) structure.
func detectUDFISOType(f *os.File) (Type, error) <span class="cov2" title="2">{
        rootEntries, err := readUDFRootDir(f)
        if err != nil </span><span class="cov0" title="0">{
                return TypeDVD, nil // can't parse UDF, default to DVD
        }</span>

        <span class="cov2" title="2">hasBDMV := false
        hasVideoTS := false
        for _, fid := range rootEntries </span><span class="cov3" title="4">{
                name := strings.ToUpper(fid.Name)
                if name == "BDMV" </span><span class="cov2" title="2">{
                        hasBDMV = true
                }</span>
                <span class="cov3" title="4">if name == "VIDEO_TS" </span><span class="cov0" title="0">{
                        hasVideoTS = true
                }</span>
        }

        <span class="cov2" title="2">if hasBDMV </span><span class="cov2" title="2">{
                return TypeBluray, nil
        }</span>
        <span class="cov0" title="0">if hasVideoTS </span><span class="cov0" title="0">{
                return TypeDVD, nil
        }</span>
        <span class="cov0" title="0">return TypeDVD, nil</span>
}

// findBlurayM2TSInUDF navigates the UDF filesystem to find M2TS files
// under BDMV/STREAM/. Returns isoFileExtent entries compatible with
// the ISO9660 code path.
func findBlurayM2TSInUDF(f *os.File) ([]isoFileExtent, error) <span class="cov3" title="3">{
        ctx, err := newUDFContext(f)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Read root directory
        <span class="cov3" title="3">rootFIDs, err := ctx.readDirectoryFromFE(ctx.rootFE)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read UDF root directory: %w", err)
        }</span>

        // Navigate to BDMV
        <span class="cov3" title="3">bdmvFE, err := ctx.lookupDir(rootFIDs, "BDMV")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("find BDMV: %w", err)
        }</span>

        <span class="cov3" title="3">bdmvFIDs, err := ctx.readDirectoryFromFE(bdmvFE)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read BDMV directory: %w", err)
        }</span>

        // Navigate to STREAM
        <span class="cov3" title="3">streamFE, err := ctx.lookupDir(bdmvFIDs, "STREAM")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("find STREAM: %w", err)
        }</span>

        <span class="cov3" title="3">streamFIDs, err := ctx.readDirectoryFromFE(streamFE)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read STREAM directory: %w", err)
        }</span>

        // Collect M2TS files
        <span class="cov3" title="3">var m2tsFiles []isoFileExtent
        for _, fid := range streamFIDs </span><span class="cov4" title="6">{
                if fid.IsDir || fid.IsParent </span><span class="cov3" title="3">{
                        continue</span>
                }
                <span class="cov3" title="3">name := strings.ToUpper(fid.Name)
                if !strings.HasSuffix(name, ".M2TS") </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov3" title="3">fe, err := ctx.readFileEntryAt(fid.ICBLocation)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Collect all physical extents for this file.
                <span class="cov3" title="3">extents, err := ctx.resolveAllExtents(fe)
                if err != nil || len(extents) == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov3" title="3">m2ts := isoFileExtent{
                        Name:   name,
                        Offset: extents[0].ISOOffset,
                        Size:   int64(fe.InfoLength),
                        IsDir:  false,
                }

                // Only populate Extents if the data is non-contiguous.
                if !extentsContiguous(extents) </span><span class="cov0" title="0">{
                        m2ts.Extents = extents
                }</span>

                <span class="cov3" title="3">m2tsFiles = append(m2tsFiles, m2ts)</span>
        }

        <span class="cov3" title="3">if len(m2tsFiles) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no M2TS files found in UDF BDMV/STREAM/")
        }</span>

        <span class="cov3" title="3">return m2tsFiles, nil</span>
}

// udfContext holds the parsed UDF volume structures needed for navigation.
type udfContext struct {
        f          *os.File
        blockSize  uint32
        partStart  uint32 // physical sector of partition start
        partitions []udfPartitionDesc
        partMaps   []udfPartitionMap
        metaData   []byte // loaded metadata partition file (nil if Type 1 only)
        rootFE     *udfFileEntry
}

// newUDFContext reads and parses the UDF volume structures.
func newUDFContext(f *os.File) (*udfContext, error) <span class="cov4" title="5">{
        // Step 1: Read AVDP at sector 256 to find the VDS
        vdsExtent, err := readAVDP(f)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read AVDP: %w", err)
        }</span>

        // Step 2: Read VDS to get partition and logical volume descriptors
        <span class="cov4" title="5">partDescs, lvd, err := readVDS(f, vdsExtent)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read VDS: %w", err)
        }</span>
        <span class="cov4" title="5">if len(partDescs) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no partition descriptors found in VDS")
        }</span>

        // Match the first physical partition map's PartitionNum to the
        // corresponding partition descriptor. Fall back to partDescs[0].
        <span class="cov4" title="5">partStart := partDescs[0].StartingLocation
        if len(lvd.PartitionMaps) &gt; 0 </span><span class="cov4" title="5">{
                targetNum := lvd.PartitionMaps[0].PartitionNum
                for _, pd := range partDescs </span><span class="cov4" title="5">{
                        if pd.PartitionNumber == targetNum </span><span class="cov4" title="5">{
                                partStart = pd.StartingLocation
                                break</span>
                        }
                }
        }

        <span class="cov4" title="5">ctx := &amp;udfContext{
                f:          f,
                blockSize:  lvd.BlockSize,
                partStart:  partStart,
                partitions: partDescs,
                partMaps:   lvd.PartitionMaps,
        }

        // Step 3: Load metadata partition if present
        for _, pm := range lvd.PartitionMaps </span><span class="cov4" title="5">{
                if pm.IsMetadata </span><span class="cov0" title="0">{
                        metaData, err := ctx.readMetadataFile(pm.MetaFileLoc)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read metadata partition: %w", err)
                        }</span>
                        <span class="cov0" title="0">ctx.metaData = metaData
                        break</span>
                }
        }

        // Step 4: Read FSD to get root directory ICB
        <span class="cov4" title="5">rootFE, err := ctx.readFSDAndRoot(lvd.FSDLocation)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read FSD/root: %w", err)
        }</span>
        <span class="cov4" title="5">ctx.rootFE = rootFE

        return ctx, nil</span>
}

// readAVDP reads the Anchor Volume Descriptor Pointer at sector 256.
// Returns the extent of the Main Volume Descriptor Sequence.
func readAVDP(f *os.File) (udfExtent, error) <span class="cov4" title="5">{
        buf := make([]byte, isoSectorSize)
        if _, err := f.ReadAt(buf, 256*isoSectorSize); err != nil </span><span class="cov0" title="0">{
                return udfExtent{}, fmt.Errorf("read sector 256: %w", err)
        }</span>

        <span class="cov4" title="5">tag := parseDescriptorTag(buf)
        if tag.TagID != udfTagAVDP </span><span class="cov0" title="0">{
                return udfExtent{}, fmt.Errorf("sector 256: expected AVDP (tag 2), got tag %d", tag.TagID)
        }</span>

        // Main VDS extent at offset 16 (8 bytes: length + location)
        <span class="cov4" title="5">return udfExtent{
                Length:   binary.LittleEndian.Uint32(buf[16:20]),
                Location: binary.LittleEndian.Uint32(buf[20:24]),
        }, nil</span>
}

// readVDS reads the Volume Descriptor Sequence and extracts partition
// descriptors and the logical volume descriptor.
func readVDS(f *os.File, extent udfExtent) ([]udfPartitionDesc, *udfLogicalVolumeDesc, error) <span class="cov4" title="5">{
        var partDescs []udfPartitionDesc
        var lvd *udfLogicalVolumeDesc

        sectors := int(extent.Length) / isoSectorSize
        if sectors &gt; 64 </span><span class="cov0" title="0">{
                sectors = 64
        }</span>

        <span class="cov4" title="5">buf := make([]byte, isoSectorSize)
        for i := 0; i &lt; sectors; i++ </span><span class="cov6" title="15">{
                offset := int64(extent.Location+uint32(i)) * isoSectorSize
                if _, err := f.ReadAt(buf, offset); err != nil </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov6" title="15">tag := parseDescriptorTag(buf)
                switch tag.TagID </span>{
                case udfTagPartitionDesc:<span class="cov4" title="5">
                        pd := udfPartitionDesc{
                                PartitionNumber:  binary.LittleEndian.Uint16(buf[22:24]),
                                StartingLocation: binary.LittleEndian.Uint32(buf[188:192]),
                        }
                        partDescs = append(partDescs, pd)</span>

                case udfTagLogicalVolume:<span class="cov4" title="5">
                        blockSize := binary.LittleEndian.Uint32(buf[212:216])

                        // FSD location at offset 248 (16-byte long_ad)
                        fsdLoc := parseLongAD(buf[248:264])

                        // Partition maps at offset 440
                        mapTableLen := binary.LittleEndian.Uint32(buf[264:268])
                        numMaps := binary.LittleEndian.Uint32(buf[268:272])
                        mapData := buf[440:]
                        if int(mapTableLen) &lt; len(mapData) </span><span class="cov4" title="5">{
                                mapData = mapData[:mapTableLen]
                        }</span>
                        <span class="cov4" title="5">partMaps := parsePartitionMaps(mapData, int(numMaps))

                        lvd = &amp;udfLogicalVolumeDesc{
                                BlockSize:     blockSize,
                                FSDLocation:   fsdLoc,
                                PartitionMaps: partMaps,
                        }</span>

                case 8:<span class="cov4" title="5"></span> // Terminating Descriptor
                        // handled below
                }

                <span class="cov6" title="15">if tag.TagID == 8 </span><span class="cov4" title="5">{
                        break</span>
                }
        }

        <span class="cov4" title="5">if lvd == nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("no Logical Volume Descriptor found")
        }</span>

        <span class="cov4" title="5">return partDescs, lvd, nil</span>
}

// parsePartitionMaps parses the partition map table from the LVD.
func parsePartitionMaps(data []byte, count int) []udfPartitionMap <span class="cov4" title="5">{
        var maps []udfPartitionMap
        offset := 0
        for i := 0; i &lt; count &amp;&amp; offset &lt; len(data); i++ </span><span class="cov4" title="5">{
                if offset+2 &gt; len(data) </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov4" title="5">mapType := data[offset]
                mapLen := int(data[offset+1])
                if mapLen == 0 || offset+mapLen &gt; len(data) </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov4" title="5">pm := udfPartitionMap{Type: mapType}

                switch mapType </span>{
                case 1:<span class="cov4" title="5">
                        // Type 1: Physical partition (6 bytes)
                        if mapLen &gt;= 6 </span><span class="cov4" title="5">{
                                pm.PartitionNum = binary.LittleEndian.Uint16(data[offset+4 : offset+6])
                        }</span>
                case 2:<span class="cov0" title="0">
                        // Type 2: Could be metadata, virtual, or sparable (64 bytes)
                        if mapLen &gt;= 64 </span><span class="cov0" title="0">{
                                pm.PartitionNum = binary.LittleEndian.Uint16(data[offset+38 : offset+40])
                                // Check for metadata partition identifier at offset 4
                                ident := string(data[offset+4 : offset+36])
                                if strings.Contains(ident, "*UDF Metadata Partition") </span><span class="cov0" title="0">{
                                        pm.IsMetadata = true
                                        pm.MetaFileLoc = binary.LittleEndian.Uint32(data[offset+40 : offset+44])
                                }</span>
                        }
                }

                <span class="cov4" title="5">maps = append(maps, pm)
                offset += mapLen</span>
        }
        <span class="cov4" title="5">return maps</span>
}

// readMetadataFile loads the metadata virtual file from the partition.
// The metadata file is a File Entry at partStart + metaFileLoc, whose
// allocation descriptors point to the actual metadata data.
func (ctx *udfContext) readMetadataFile(metaFileLoc uint32) ([]byte, error) <span class="cov0" title="0">{
        // Read the File Entry for the metadata file
        physSector := ctx.partStart + metaFileLoc
        buf := make([]byte, ctx.blockSize)
        if _, err := ctx.f.ReadAt(buf, int64(physSector)*int64(ctx.blockSize)); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read metadata file entry at sector %d: %w", physSector, err)
        }</span>

        <span class="cov0" title="0">fe, err := parseFileEntry(buf)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("parse metadata file entry: %w", err)
        }</span>

        // The metadata file's FE is on the physical partition. Find the
        // physical (Type 1) partition map index so short_ad resolves correctly.
        <span class="cov0" title="0">for i, pm := range ctx.partMaps </span><span class="cov0" title="0">{
                if pm.Type == 1 </span><span class="cov0" title="0">{
                        fe.PartRef = uint16(i)
                        break</span>
                }
        }

        <span class="cov0" title="0">return ctx.readFileData(fe)</span>
}

// readFSDAndRoot reads the File Set Descriptor and follows it to the root
// directory File Entry.
func (ctx *udfContext) readFSDAndRoot(fsdLoc udfLongAD) (*udfFileEntry, error) <span class="cov4" title="5">{
        fsdData, err := ctx.readBlock(fsdLoc.Location, fsdLoc.PartRef)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read FSD block: %w", err)
        }</span>

        <span class="cov4" title="5">tag := parseDescriptorTag(fsdData)
        if tag.TagID != udfTagFileSetDesc </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("expected FSD (tag 256), got tag %d", tag.TagID)
        }</span>

        // Root directory ICB at offset 400 (16-byte long_ad)
        <span class="cov4" title="5">if len(fsdData) &lt; 416 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("FSD too short")
        }</span>
        <span class="cov4" title="5">rootICB := parseLongAD(fsdData[400:416])

        return ctx.readFileEntryAt(rootICB)</span>
}

// readFileEntryAt reads and parses a File Entry at the given location.
func (ctx *udfContext) readFileEntryAt(loc udfLongAD) (*udfFileEntry, error) <span class="cov6" title="14">{
        data, err := ctx.readBlock(loc.Location, loc.PartRef)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read file entry block %d (part %d): %w", loc.Location, loc.PartRef, err)
        }</span>
        <span class="cov6" title="14">fe, err := parseFileEntry(data)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov6" title="14">fe.PartRef = loc.PartRef
        return fe, nil</span>
}

// readDirectoryFromFE reads directory data from a File Entry and parses FIDs.
func (ctx *udfContext) readDirectoryFromFE(fe *udfFileEntry) ([]udfFID, error) <span class="cov6" title="11">{
        dirData, err := ctx.readFileData(fe)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov6" title="11">return parseUDFDirectory(dirData), nil</span>
}

// lookupDir finds a named subdirectory in a list of FIDs and reads its File Entry.
func (ctx *udfContext) lookupDir(fids []udfFID, name string) (*udfFileEntry, error) <span class="cov4" title="6">{
        upper := strings.ToUpper(name)
        for _, fid := range fids </span><span class="cov6" title="12">{
                if fid.IsParent </span><span class="cov4" title="6">{
                        continue</span>
                }
                <span class="cov4" title="6">if strings.ToUpper(fid.Name) == upper </span><span class="cov4" title="6">{
                        return ctx.readFileEntryAt(fid.ICBLocation)
                }</span>
        }
        <span class="cov0" title="0">return nil, fmt.Errorf("%q not found in directory", name)</span>
}

// resolveAllExtents collects all physical extents for a file entry.
// For long_ad, each AD has an explicit partition reference.
// For short_ad, the partition is inherited from the FE.
func (ctx *udfContext) resolveAllExtents(fe *udfFileEntry) ([]isoPhysicalRange, error) <span class="cov3" title="3">{
        switch fe.AllocType &amp; 0x07 </span>{
        case 0:<span class="cov3" title="3"> // short_ad
                if int(fe.PartRef) &lt; len(ctx.partMaps) &amp;&amp; ctx.partMaps[fe.PartRef].IsMetadata </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("short_ad on metadata partition not supported for file extents")
                }</span>
                <span class="cov3" title="3">var extents []isoPhysicalRange
                remaining := int64(fe.InfoLength)
                for off := 0; off+8 &lt;= len(fe.AllocDescs) &amp;&amp; remaining &gt; 0; off += 8 </span><span class="cov3" title="3">{
                        ad := parseShortAD(fe.AllocDescs[off : off+8])
                        extLen := int64(ad.Length &amp; 0x3FFFFFFF)
                        if extLen == 0 </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov3" title="3">if extLen &gt; remaining </span><span class="cov0" title="0">{
                                extLen = remaining
                        }</span>
                        <span class="cov3" title="3">extents = append(extents, isoPhysicalRange{
                                ISOOffset: ctx.resolveBlockPhysical(ad.Position),
                                Length:    extLen,
                        })
                        remaining -= extLen</span>
                }
                <span class="cov3" title="3">return extents, nil</span>

        case 1:<span class="cov0" title="0"> // long_ad
                var extents []isoPhysicalRange
                remaining := int64(fe.InfoLength)
                for off := 0; off+16 &lt;= len(fe.AllocDescs) &amp;&amp; remaining &gt; 0; off += 16 </span><span class="cov0" title="0">{
                        ad := parseLongAD(fe.AllocDescs[off : off+16])
                        extLen := int64(ad.Length &amp; 0x3FFFFFFF)
                        if extLen == 0 </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">if int(ad.PartRef) &lt; len(ctx.partMaps) &amp;&amp; ctx.partMaps[ad.PartRef].IsMetadata </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("long_ad extent on metadata partition")
                        }</span>
                        <span class="cov0" title="0">if extLen &gt; remaining </span><span class="cov0" title="0">{
                                extLen = remaining
                        }</span>
                        <span class="cov0" title="0">extents = append(extents, isoPhysicalRange{
                                ISOOffset: ctx.resolveBlockPhysical(ad.Location),
                                Length:    extLen,
                        })
                        remaining -= extLen</span>
                }
                <span class="cov0" title="0">return extents, nil</span>

        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported alloc type %d for extent resolution", fe.AllocType&amp;0x07)</span>
        }
}

// extentsContiguous returns true if all extents are physically adjacent.
func extentsContiguous(extents []isoPhysicalRange) bool <span class="cov3" title="3">{
        for i := 1; i &lt; len(extents); i++ </span><span class="cov0" title="0">{
                prevEnd := extents[i-1].ISOOffset + extents[i-1].Length
                if extents[i].ISOOffset != prevEnd </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov3" title="3">return true</span>
}

// readBlock reads one block from the given logical block number within
// the specified partition reference.
func (ctx *udfContext) readBlock(blockNum uint32, partRef uint16) ([]byte, error) <span class="cov7" title="19">{
        // Determine which partition map this references
        if int(partRef) &lt; len(ctx.partMaps) &amp;&amp; ctx.partMaps[partRef].IsMetadata </span><span class="cov0" title="0">{
                // Metadata partition: block is an offset into the loaded metadata data
                byteOffset := int64(blockNum) * int64(ctx.blockSize)
                if ctx.metaData == nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("metadata partition referenced but not loaded")
                }</span>
                <span class="cov0" title="0">if byteOffset+int64(ctx.blockSize) &gt; int64(len(ctx.metaData)) </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("metadata block %d out of range", blockNum)
                }</span>
                <span class="cov0" title="0">result := make([]byte, ctx.blockSize)
                copy(result, ctx.metaData[byteOffset:byteOffset+int64(ctx.blockSize)])
                return result, nil</span>
        }

        // Physical partition: blockNum is relative to partition start
        <span class="cov7" title="19">physOffset := int64(ctx.partStart+blockNum) * int64(ctx.blockSize)

        buf := make([]byte, ctx.blockSize)
        if _, err := ctx.f.ReadAt(buf, physOffset); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov7" title="19">return buf, nil</span>
}

// resolveBlockPhysical converts a logical block number to a physical byte offset
// using the default (first physical) partition.
func (ctx *udfContext) resolveBlockPhysical(blockNum uint32) int64 <span class="cov3" title="3">{
        return int64(ctx.partStart+blockNum) * int64(ctx.blockSize)
}</span>

// readFileData reads the complete data of a file described by a File Entry.
func (ctx *udfContext) readFileData(fe *udfFileEntry) ([]byte, error) <span class="cov6" title="11">{
        if fe.InfoLength == 0 </span><span class="cov0" title="0">{
                return nil, nil
        }</span>

        <span class="cov6" title="11">switch fe.AllocType &amp; 0x07 </span>{
        case 3:<span class="cov0" title="0"> // inline/immediate
                if uint64(len(fe.AllocDescs)) &lt; fe.InfoLength </span><span class="cov0" title="0">{
                        return fe.AllocDescs, nil
                }</span>
                <span class="cov0" title="0">return fe.AllocDescs[:fe.InfoLength], nil</span>

        case 0:<span class="cov6" title="11"> // short_ad
                return ctx.readFromShortADs(fe)</span>

        case 1:<span class="cov0" title="0"> // long_ad
                return ctx.readFromLongADs(fe)</span>

        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported allocation type %d", fe.AllocType&amp;0x07)</span>
        }
}

// readFromShortADs reads file data described by short allocation descriptors.
// Short ADs don't carry an explicit partition reference — they inherit the
// partition of the File Entry that contains them.
func (ctx *udfContext) readFromShortADs(fe *udfFileEntry) ([]byte, error) <span class="cov6" title="11">{
        // Determine if this FE's partition is the metadata partition.
        isMeta := int(fe.PartRef) &lt; len(ctx.partMaps) &amp;&amp; ctx.partMaps[fe.PartRef].IsMetadata &amp;&amp; ctx.metaData != nil

        result := make([]byte, 0, fe.InfoLength)
        remaining := int64(fe.InfoLength)

        for off := 0; off+8 &lt;= len(fe.AllocDescs) &amp;&amp; remaining &gt; 0; off += 8 </span><span class="cov6" title="11">{
                ad := parseShortAD(fe.AllocDescs[off : off+8])
                extLen := int64(ad.Length &amp; 0x3FFFFFFF) // mask off extent type bits
                if extLen == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov6" title="11">toRead := min(extLen, remaining)

                if isMeta </span><span class="cov0" title="0">{
                        // Resolve within the loaded metadata data.
                        byteOffset := int64(ad.Position) * int64(ctx.blockSize)
                        if byteOffset+toRead &gt; int64(len(ctx.metaData)) </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("metadata short_ad extent out of range (offset %d, len %d, metaLen %d)",
                                        byteOffset, toRead, len(ctx.metaData))
                        }</span>
                        <span class="cov0" title="0">result = append(result, ctx.metaData[byteOffset:byteOffset+toRead]...)</span>
                } else<span class="cov6" title="11"> {
                        physOffset := int64(ctx.partStart+ad.Position) * int64(ctx.blockSize)
                        buf := make([]byte, toRead)
                        if _, err := ctx.f.ReadAt(buf, physOffset); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read short_ad extent at offset %d: %w", physOffset, err)
                        }</span>
                        <span class="cov6" title="11">result = append(result, buf...)</span>
                }
                <span class="cov6" title="11">remaining -= toRead</span>
        }

        <span class="cov6" title="11">return result, nil</span>
}

// readFromLongADs reads file data described by long allocation descriptors.
func (ctx *udfContext) readFromLongADs(fe *udfFileEntry) ([]byte, error) <span class="cov0" title="0">{
        result := make([]byte, 0, fe.InfoLength)
        remaining := int64(fe.InfoLength)

        for off := 0; off+16 &lt;= len(fe.AllocDescs) &amp;&amp; remaining &gt; 0; off += 16 </span><span class="cov0" title="0">{
                ad := parseLongAD(fe.AllocDescs[off : off+16])
                extLen := int64(ad.Length &amp; 0x3FFFFFFF) // mask off extent type bits
                if extLen == 0 </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov0" title="0">toRead := min(extLen, remaining)

                // Check if this references the metadata partition
                if int(ad.PartRef) &lt; len(ctx.partMaps) &amp;&amp; ctx.partMaps[ad.PartRef].IsMetadata &amp;&amp; ctx.metaData != nil </span><span class="cov0" title="0">{
                        byteOffset := int64(ad.Location) * int64(ctx.blockSize)
                        if byteOffset+toRead &gt; int64(len(ctx.metaData)) </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("metadata extent out of range")
                        }</span>
                        <span class="cov0" title="0">result = append(result, ctx.metaData[byteOffset:byteOffset+toRead]...)</span>
                } else<span class="cov0" title="0"> {
                        physOffset := int64(ctx.partStart+ad.Location) * int64(ctx.blockSize)
                        buf := make([]byte, toRead)
                        if _, err := ctx.f.ReadAt(buf, physOffset); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("read long_ad extent at offset %d: %w", physOffset, err)
                        }</span>
                        <span class="cov0" title="0">result = append(result, buf...)</span>
                }

                <span class="cov0" title="0">remaining -= toRead</span>
        }

        <span class="cov0" title="0">return result, nil</span>
}

// readUDFRootDir is a convenience function that reads just the root directory
// entries from a UDF filesystem. Used by detectUDFISOType.
func readUDFRootDir(f *os.File) ([]udfFID, error) <span class="cov2" title="2">{
        ctx, err := newUDFContext(f)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov2" title="2">return ctx.readDirectoryFromFE(ctx.rootFE)</span>
}

// --- Low-level parsing helpers ---

// parseDescriptorTag parses the 16-byte UDF descriptor tag at the start of buf.
func parseDescriptorTag(buf []byte) udfDescriptorTag <span class="cov10" title="72">{
        if len(buf) &lt; 16 </span><span class="cov0" title="0">{
                return udfDescriptorTag{}
        }</span>
        <span class="cov10" title="72">return udfDescriptorTag{
                TagID:   binary.LittleEndian.Uint16(buf[0:2]),
                Version: binary.LittleEndian.Uint16(buf[2:4]),
        }</span>
}

// parseLongAD parses a 16-byte long allocation descriptor.
func parseLongAD(buf []byte) udfLongAD <span class="cov8" title="32">{
        return udfLongAD{
                Length:   binary.LittleEndian.Uint32(buf[0:4]),
                Location: binary.LittleEndian.Uint32(buf[4:8]),
                PartRef:  binary.LittleEndian.Uint16(buf[8:10]),
        }
}</span>

// parseShortAD parses an 8-byte short allocation descriptor.
func parseShortAD(buf []byte) udfShortAD <span class="cov6" title="14">{
        return udfShortAD{
                Length:   binary.LittleEndian.Uint32(buf[0:4]),
                Position: binary.LittleEndian.Uint32(buf[4:8]),
        }
}</span>

// parseFileEntry parses a UDF File Entry (tag 261) or Extended File Entry (tag 266).
func parseFileEntry(data []byte) (*udfFileEntry, error) <span class="cov6" title="14">{
        if len(data) &lt; 16 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("data too short for file entry")
        }</span>

        <span class="cov6" title="14">tag := parseDescriptorTag(data)
        if tag.TagID != udfTagFileEntry &amp;&amp; tag.TagID != udfTagExtFileEntry </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("expected File Entry (tag 261/266), got tag %d", tag.TagID)
        }</span>

        // ICB Tag at offset 16 (20 bytes), file type at ICB tag offset 11 (= data offset 27)
        <span class="cov6" title="14">if len(data) &lt; 28 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("data too short for ICB tag")
        }</span>
        <span class="cov6" title="14">fileType := data[27]

        var infoLength uint64
        var allocDescsOffset int
        var allocDescsLength uint32
        var icbFlags uint16

        if tag.TagID == udfTagFileEntry </span><span class="cov6" title="14">{
                // File Entry (tag 261)
                // ECMA-167 14.9: L_EA at 168, L_AD at 172, alloc descs at 176+L_EA
                if len(data) &lt; 176 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("file entry too short")
                }</span>
                <span class="cov6" title="14">infoLength = binary.LittleEndian.Uint64(data[56:64])
                icbFlags = binary.LittleEndian.Uint16(data[34:36])

                eaLen := binary.LittleEndian.Uint32(data[168:172])
                allocDescsLength = binary.LittleEndian.Uint32(data[172:176])
                allocDescsOffset = 176 + int(eaLen)</span>
        } else<span class="cov0" title="0"> {
                // Extended File Entry (tag 266)
                // ECMA-167 14.17: L_EA at 208, L_AD at 212, alloc descs at 216+L_EA
                if len(data) &lt; 216 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("extended file entry too short")
                }</span>
                <span class="cov0" title="0">infoLength = binary.LittleEndian.Uint64(data[56:64])
                icbFlags = binary.LittleEndian.Uint16(data[34:36])

                eaLen := binary.LittleEndian.Uint32(data[208:212])
                allocDescsLength = binary.LittleEndian.Uint32(data[212:216])
                allocDescsOffset = 216 + int(eaLen)</span>
        }

        // Guard against overflow or out-of-bounds from malformed eaLen
        <span class="cov6" title="14">if allocDescsOffset &lt; 0 || allocDescsOffset &gt; len(data) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("file entry alloc descs offset out of bounds: %d", allocDescsOffset)
        }</span>

        <span class="cov6" title="14">var allocDescs []byte
        if allocDescsOffset+int(allocDescsLength) &lt;= len(data) </span><span class="cov6" title="14">{
                allocDescs = make([]byte, allocDescsLength)
                copy(allocDescs, data[allocDescsOffset:allocDescsOffset+int(allocDescsLength)])
        }</span>

        <span class="cov6" title="14">return &amp;udfFileEntry{
                ICBTag:     fileType,
                InfoLength: infoLength,
                AllocDescs: allocDescs,
                AllocType:  byte(icbFlags &amp; 0x07),
        }, nil</span>
}

// parseUDFDirectory parses raw directory data into a list of FIDs.
func parseUDFDirectory(dirData []byte) []udfFID <span class="cov6" title="11">{
        var fids []udfFID
        offset := 0

        for offset+38 &lt;= len(dirData) </span><span class="cov8" title="33">{
                tag := parseDescriptorTag(dirData[offset:])
                if tag.TagID != udfTagFID </span><span class="cov6" title="11">{
                        break</span>
                }

                <span class="cov7" title="22">characteristics := dirData[offset+18]
                nameLen := int(dirData[offset+19])
                icbLoc := parseLongAD(dirData[offset+20 : offset+36])
                implUseLen := int(binary.LittleEndian.Uint16(dirData[offset+36 : offset+38]))

                nameStart := offset + 38 + implUseLen
                if nameStart+nameLen &gt; len(dirData) </span><span class="cov0" title="0">{
                        break</span>
                }

                <span class="cov7" title="22">isParent := characteristics&amp;0x08 != 0
                isDir := characteristics&amp;0x02 != 0

                name := ""
                if nameLen &gt; 0 &amp;&amp; !isParent </span><span class="cov6" title="11">{
                        nameBytes := dirData[nameStart : nameStart+nameLen]
                        name = decodeUDFString(nameBytes)
                }</span>

                <span class="cov7" title="22">fids = append(fids, udfFID{
                        Name:        name,
                        IsDir:       isDir,
                        IsParent:    isParent,
                        ICBLocation: icbLoc,
                })

                // FID total length: 38 + implUseLen + nameLen, padded to 4-byte boundary
                fidLen := 38 + implUseLen + nameLen
                fidLen = (fidLen + 3) &amp;^ 3
                offset += fidLen</span>
        }

        <span class="cov6" title="11">return fids</span>
}

// decodeUDFString decodes a UDF d-string/d-characters identifier.
// UDF uses either 8-bit (compression ID 8) or 16-bit (compression ID 16) encoding.
func decodeUDFString(data []byte) string <span class="cov6" title="11">{
        if len(data) == 0 </span><span class="cov0" title="0">{
                return ""
        }</span>

        <span class="cov6" title="11">compressionID := data[0]
        payload := data[1:]

        switch compressionID </span>{
        case 8:<span class="cov6" title="11">
                // 8-bit characters (Latin-1 / ASCII subset)
                return string(payload)</span>
        case 16:<span class="cov0" title="0">
                // 16-bit big-endian Unicode (UCS-2)
                var sb strings.Builder
                for i := 0; i+1 &lt; len(payload); i += 2 </span><span class="cov0" title="0">{
                        ch := rune(payload[i])&lt;&lt;8 | rune(payload[i+1])
                        sb.WriteRune(ch)
                }</span>
                <span class="cov0" title="0">return sb.String()</span>
        default:<span class="cov0" title="0">
                // Unknown compression ID — try as raw bytes
                return string(payload)</span>
        }
}
</pre>
		
		<pre class="file" id="file54" style="display: none">package source

import (
        "bytes"
        "encoding/binary"
)

// FindVideoStartCodes finds all video start code positions (00 00 01 XX pattern) in the data.
// Returns the position of the first 00 in each start code.
// These are potential sync points where video frames or other structures begin.
// Optimized to use bytes.IndexByte for fast scanning (uses SIMD on x86).
func FindVideoStartCodes(data []byte) []int <span class="cov2" title="8">{
        if len(data) &lt; 4 </span><span class="cov1" title="2">{
                return nil
        }</span>

        // Pre-allocate with estimated capacity (roughly 1 start code per 2KB of video data)
        <span class="cov1" title="6">offsets := make([]int, 0, len(data)/2048+1)

        // Use bytes.IndexByte to quickly find the 0x01 byte (third byte of start code)
        // This is faster than checking every byte since IndexByte uses SIMD
        i := 2 // Start at position 2 since we need at least 00 00 before 01
        for i &lt; len(data)-1 </span><span class="cov2" title="12">{
                // Find next 0x01 byte
                idx := bytes.IndexByte(data[i:], 0x01)
                if idx &lt; 0 </span><span class="cov1" title="2">{
                        break</span>
                }
                <span class="cov2" title="10">pos := i + idx

                // Check if preceded by 00 00
                if pos &gt;= 2 &amp;&amp; data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 </span><span class="cov2" title="9">{
                        offsets = append(offsets, pos-2)
                }</span>

                // Move past this position
                <span class="cov2" title="10">i = pos + 1</span>
        }

        <span class="cov1" title="6">return offsets</span>
}

// FindVideoStartCodesInRange finds video start codes within a specific range.
// Returns the position of the first 00 in each start code, offset by startOffset.
// Optimized version using bytes.IndexByte for fast scanning.
func FindVideoStartCodesInRange(data []byte, startOffset int) []int <span class="cov1" title="1">{
        if len(data) &lt; 4 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Pre-allocate with estimated capacity
        <span class="cov1" title="1">offsets := make([]int, 0, len(data)/2048+1)

        i := 2
        for i &lt; len(data)-1 </span><span class="cov1" title="3">{
                idx := bytes.IndexByte(data[i:], 0x01)
                if idx &lt; 0 </span><span class="cov1" title="1">{
                        break</span>
                }
                <span class="cov1" title="2">pos := i + idx

                if pos &gt;= 2 &amp;&amp; data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 </span><span class="cov1" title="2">{
                        offsets = append(offsets, startOffset+pos-2)
                }</span>

                <span class="cov1" title="2">i = pos + 1</span>
        }

        <span class="cov1" title="1">return offsets</span>
}

// FindVideoNALStarts finds NAL unit start positions in Annex B formatted data.
// Returns positions of NAL header bytes (the byte AFTER 00 00 01).
// This is used for hashing: NAL header + NAL data are identical in both
// Annex B (source) and AVCC (MKV) formats, enabling cross-format matching.
func FindVideoNALStarts(data []byte) []int <span class="cov8" title="1358941">{
        if len(data) &lt; 4 </span><span class="cov2" title="35">{
                return nil
        }</span>

        <span class="cov8" title="1358906">offsets := make([]int, 0, len(data)/2048+1)

        i := 2
        for i &lt; len(data)-1 </span><span class="cov10" title="57074412">{
                idx := bytes.IndexByte(data[i:], 0x01)
                if idx &lt; 0 </span><span class="cov8" title="1316156">{
                        break</span>
                }
                <span class="cov9" title="55758256">pos := i + idx

                // Check if preceded by 00 00 — start code is at pos-2
                // NAL header byte is at pos+1
                if pos &gt;= 2 &amp;&amp; data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 </span><span class="cov8" title="5517419">{
                        nalStart := pos + 1
                        if nalStart &lt; len(data) </span><span class="cov8" title="5515604">{
                                offsets = append(offsets, nalStart)
                        }</span>
                }

                <span class="cov9" title="55758256">i = pos + 1</span>
        }

        <span class="cov8" title="1358906">return offsets</span>
}

// FindVideoNALStartsInRange finds NAL unit start positions in a specific range.
// Returns positions offset by startOffset for use during chunked file processing.
func FindVideoNALStartsInRange(data []byte, startOffset int) []int <span class="cov1" title="1">{
        if len(data) &lt; 4 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov1" title="1">offsets := make([]int, 0, len(data)/2048+1)

        i := 2
        for i &lt; len(data)-1 </span><span class="cov1" title="3">{
                idx := bytes.IndexByte(data[i:], 0x01)
                if idx &lt; 0 </span><span class="cov1" title="1">{
                        break</span>
                }
                <span class="cov1" title="2">pos := i + idx

                if pos &gt;= 2 &amp;&amp; data[pos-1] == 0x00 &amp;&amp; data[pos-2] == 0x00 </span><span class="cov1" title="2">{
                        nalStart := pos + 1
                        if nalStart &lt; len(data) </span><span class="cov1" title="2">{
                                offsets = append(offsets, startOffset+nalStart)
                        }</span>
                }

                <span class="cov1" title="2">i = pos + 1</span>
        }

        <span class="cov1" title="1">return offsets</span>
}

// FindAVCCNALStarts finds NAL unit start positions in AVCC/HVCC formatted data.
// In AVCC format, each NAL unit is prefixed with a length field (nalLengthSize bytes,
// big-endian). Returns positions of NAL header bytes (the byte after each length prefix).
// nalLengthSize is typically 4 for H.264 AVCC and H.265 HVCC.
func FindAVCCNALStarts(data []byte, nalLengthSize int) []int <span class="cov2" title="8">{
        if nalLengthSize &lt; 1 || nalLengthSize &gt; 4 </span><span class="cov1" title="1">{
                return nil
        }</span>
        <span class="cov1" title="7">if len(data) &lt; nalLengthSize+1 </span><span class="cov1" title="1">{
                return nil
        }</span>

        <span class="cov1" title="6">offsets := make([]int, 0, len(data)/2048+1)

        pos := 0
        for pos+nalLengthSize &lt; len(data) </span><span class="cov2" title="9">{
                // Read NAL unit length
                var nalLen uint32
                switch nalLengthSize </span>{
                case 4:<span class="cov1" title="7">
                        nalLen = binary.BigEndian.Uint32(data[pos:])</span>
                case 3:<span class="cov0" title="0">
                        nalLen = uint32(data[pos])&lt;&lt;16 | uint32(data[pos+1])&lt;&lt;8 | uint32(data[pos+2])</span>
                case 2:<span class="cov1" title="1">
                        nalLen = uint32(binary.BigEndian.Uint16(data[pos:]))</span>
                case 1:<span class="cov1" title="1">
                        nalLen = uint32(data[pos])</span>
                }

                <span class="cov2" title="9">nalStart := pos + nalLengthSize
                if nalLen == 0 || nalStart &gt;= len(data) </span><span class="cov1" title="2">{
                        break</span>
                }

                <span class="cov1" title="7">offsets = append(offsets, nalStart)

                // Move to next NAL unit
                next := nalStart + int(nalLen)
                if next &lt;= pos </span><span class="cov0" title="0">{
                        break</span> // Overflow protection
                }
                <span class="cov1" title="7">pos = next</span>
        }

        <span class="cov1" title="6">return offsets</span>
}
</pre>
		
		<pre class="file" id="file55" style="display: none">// Package testdata provides helpers for locating integration test data.
//
// Test data (Big Buck Bunny DVD ISO and MKV) is not stored in the repository.
// See README.md in this directory for setup instructions.
package testdata

import (
        "os"
        "os/exec"
        "path/filepath"
        "runtime"
        "testing"
)

// Paths contains the resolved paths to test data files.
type Paths struct {
        Root      string // Base test data directory
        ISODir    string // Directory containing ISO file
        ISOFile   string // Path to the ISO file
        MKVDir    string // Directory containing MKV file(s)
        MKVFile   string // Path to the main MKV file
        Available bool   // True if all required files exist
}

// DefaultISOName is the expected ISO filename.
const DefaultISOName = "bbb-pal.iso"

// DefaultMKVPattern is the glob pattern for finding MKV files.
const DefaultMKVPattern = "*.mkv"

// Find locates the test data directory and checks for required files.
// It checks these locations in order:
//  1. $MKVDUP_TESTDATA environment variable
//  2. testdata/generated/ (relative to the testdata package, created by generate-test-data.sh)
//  3. ~/.cache/mkvdup/testdata/
//  4. /tmp/mkvdup-testdata/
//
// Returns Paths with Available=false if test data is not found.
func Find() Paths <span class="cov10" title="5">{
        var p Paths

        // Check environment variable first
        if envPath := os.Getenv("MKVDUP_TESTDATA"); envPath != "" </span><span class="cov10" title="5">{
                p.Root = envPath
                if checkPaths(&amp;p) </span><span class="cov10" title="5">{
                        return p
                }</span>
        }

        // Check testdata/generated/ (local to the repo, created by generate-test-data.sh)
        // This is the preferred location for reproducible test data
        <span class="cov0" title="0">if localPath := findLocalTestdataDir(); localPath != "" </span><span class="cov0" title="0">{
                p.Root = localPath
                if checkPaths(&amp;p) </span><span class="cov0" title="0">{
                        return p
                }</span>
        }

        // Check ~/.cache/mkvdup/testdata/
        <span class="cov0" title="0">if home, err := os.UserHomeDir(); err == nil </span><span class="cov0" title="0">{
                p.Root = filepath.Join(home, ".cache", "mkvdup", "testdata")
                if checkPaths(&amp;p) </span><span class="cov0" title="0">{
                        return p
                }</span>
        }

        // Check /tmp/mkvdup-testdata/
        <span class="cov0" title="0">p.Root = "/tmp/mkvdup-testdata"
        if checkPaths(&amp;p) </span><span class="cov0" title="0">{
                return p
        }</span>

        // Not found - clear all paths
        <span class="cov0" title="0">p.Root = ""
        p.ISODir = ""
        p.ISOFile = ""
        p.MKVDir = ""
        p.MKVFile = ""
        p.Available = false
        return p</span>
}

// checkPaths fills in the paths and returns true if all required files exist.
func checkPaths(p *Paths) bool <span class="cov10" title="5">{
        p.ISODir = filepath.Join(p.Root, "bigbuckbunny")
        p.MKVDir = filepath.Join(p.Root, "bigbuckbunny-mkv")

        // Check ISO file
        p.ISOFile = filepath.Join(p.ISODir, DefaultISOName)
        if _, err := os.Stat(p.ISOFile); err != nil </span><span class="cov0" title="0">{
                // Try NTSC variant
                p.ISOFile = filepath.Join(p.ISODir, "bbb-ntsc.iso")
                if _, err := os.Stat(p.ISOFile); err != nil </span><span class="cov0" title="0">{
                        p.Available = false
                        return false
                }</span>
        }

        // Find MKV file (first match)
        <span class="cov10" title="5">matches, err := filepath.Glob(filepath.Join(p.MKVDir, DefaultMKVPattern))
        if err != nil || len(matches) == 0 </span><span class="cov0" title="0">{
                p.Available = false
                return false
        }</span>
        <span class="cov10" title="5">p.MKVFile = matches[0]

        p.Available = true
        return true</span>
}

// SkipIfNotAvailable calls t.Skip if test data is not available.
// Use this at the start of integration tests.
func SkipIfNotAvailable(t interface{ Skip(...interface{}) }) Paths <span class="cov8" title="4">{
        p := Find()
        if !p.Available </span><span class="cov0" title="0">{
                t.Skip("Test data not available. See testdata/README.md for setup instructions.")
        }</span>
        <span class="cov8" title="4">return p</span>
}

// CreateBlurayData creates a Blu-ray directory structure by remuxing the MKV
// file to M2TS format using ffmpeg (copy codec, no re-encoding). The directory
// is created under tmpDir and has the layout BDMV/STREAM/00001.m2ts that
// DetectType recognises as TypeBluray.
//
// The test is skipped if ffmpeg is not available.
func (p Paths) CreateBlurayData(t testing.TB, tmpDir string) string <span class="cov1" title="1">{
        t.Helper()

        if _, err := exec.LookPath("ffmpeg"); err != nil </span><span class="cov0" title="0">{
                t.Skip("ffmpeg not available, skipping Blu-ray test")
        }</span>

        <span class="cov1" title="1">blurayRoot := filepath.Join(tmpDir, "bluray")
        streamDir := filepath.Join(blurayRoot, "BDMV", "STREAM")
        if err := os.MkdirAll(streamDir, 0755); err != nil </span><span class="cov0" title="0">{
                t.Fatalf("CreateBlurayData: mkdir: %v", err)
        }</span>

        <span class="cov1" title="1">m2tsPath := filepath.Join(streamDir, "00001.m2ts")
        cmd := exec.Command("ffmpeg",
                "-loglevel", "error",
                "-i", p.MKVFile,
                "-c", "copy",
                "-f", "mpegts",
                "-y", // overwrite if exists
                m2tsPath,
        )
        output, err := cmd.CombinedOutput()
        if err != nil </span><span class="cov0" title="0">{
                t.Fatalf("CreateBlurayData: ffmpeg remux failed: %v\n%s", err, output)
        }</span>

        <span class="cov1" title="1">return blurayRoot</span>
}

// findLocalTestdataDir returns the path to testdata/generated/ directory
// relative to this source file, or empty string if it cannot be determined.
func findLocalTestdataDir() string <span class="cov0" title="0">{
        _, filename, _, ok := runtime.Caller(0)
        if !ok </span><span class="cov0" title="0">{
                return ""
        }</span>
        // filename is the path to this file (testdata.go)
        // We want the "generated" subdirectory in the same directory
        <span class="cov0" title="0">dir := filepath.Dir(filename)
        return filepath.Join(dir, "generated")</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
